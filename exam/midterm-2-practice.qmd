---
title: Midterm 2 Practice Questions
execute:
  echo: false
---

```{r}
#| label: load-packages
#| message: false

library(tidyverse)
library(tidymodels)
library(openintro)
library(scales)
theme_set(theme_minimal(base_size = 12))
```

# Part 1 - Blizzard

```{r}
#| label: blizzard-data-prep

blizzard_salary <- blizzard_salary |>
  mutate(
    annual_salary = case_when(
      salary_type == "week" ~ current_salary * 52,
      salary_type == "hour" ~ current_salary * 40 * 52,
      TRUE ~ current_salary
    ),
    performance_rating = if_else(performance_rating == "Developing", "Poor", performance_rating)
  ) |>
  filter(salary_type != "week") |>
  mutate(
    salary_type = if_else(salary_type == "hour", "Hourly", "Salaried")
  ) |>
  filter(!is.na(annual_salary)) |>
  select(percent_incr, salary_type, annual_salary, performance_rating)
```

In 2020, employees of Blizzard Entertainment circulated a spreadsheet to anonymously share salaries and recent pay increases amidst rising tension in the video game industry over wage disparities and executive compensation. (Source: [Blizzard Workers Share Salaries in Revolt Over Pay](https://www.bloomberg.com/news/articles/2020-08-03/blizzard-workers-share-salaries-in-revolt-over-wage-disparities))

The name of the data frame used for this analysis is `blizzard_salary` and the variables are:

-   `percent_incr`: Raise given in July 2020, as percent increase with values ranging from 1 (1% increase to 21.5 (21.5% increase)

-   `salary_type`: Type of salary, with levels `Hourly` and `Salaried`

-   `annual_salary`: Annual salary, in USD, with values ranging from \$50,939 to \$216,856.

-   `performance_rating`: Most recent review performance rating, with levels `Poor`, `Successful`, `High`, and `Top`. The `Poor` level is the lowest rating and the `Top` level is the highest rating.

The top ten rows of `blizzard_salary` are shown below:

```{r}
blizzard_salary |>
  select(percent_incr, salary_type, annual_salary, performance_rating)
```

## Question 1

You fit a model for predicting raises (`percent_incr`) from salaries (`annual_salary`). We'll call this model `raise_1_fit`. A tidy output of the model is shown below.

```{r}
#| label: raise-salary-fit

raise_1_fit <- linear_reg() |>
  fit(percent_incr ~ annual_salary, data = blizzard_salary)

tidy(raise_1_fit)
```

Which of the following is the best interpretation of the slope coefficient?

a.  For every additional \$1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.55%.
b.  For every additional \$1,000 of annual salary, the raise goes up by 0.0155%.
c.  For every additional \$1,000 of annual salary, the model predicts the raise to be higher, on average, by 0.0155%.
d.  For every additional \$1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.87%.

## Question 2

You then fit a model for predicting raises (`percent_incr`) from salaries (`annual_salary`) and performance ratings (`performance_rating`). We'll call this model `raise_2_fit`. Which of the following is definitely true based on the information you have so far?

a.  Intercept of `raise_2_fit` is higher than intercept of `raise_1_fit`.
b.  Slope of `raise_2_fit` is higher than RMSE of `raise_1_fit`.
c.  Adjusted $R^2$ of `raise_2_fit` is higher than adjusted $R^2$ of `raise_1_fit`.
d.  $R^2$ of `raise_2_fit` is higher $R^2$ of `raise_1_fit`.

## Question 3

The tidy model output for the `raise_2_fit` model you fit is shown below.

```{r}
#| label: raise-salary-rating-fit

raise_2_fit <- linear_reg() |>
  fit(percent_incr ~ annual_salary + performance_rating, data = blizzard_salary)

tidy(raise_2_fit)
```

When your teammate sees this model output, they remark "The coefficient for `performance_ratingSuccessful` is negative, that's weird. I guess it means that people who get successful performance ratings get lower raises." How would you respond to your teammate?

::: {.content-visible when-format="pdf"}
$\vspace{2cm}$
:::

## Question 4

Ultimately, your teammate decides they don't like the negative slope coefficients in the model output you created (not that there's anything wrong with negative slope coefficients!), does something else, and comes up with the following model output.

```{r}
blizzard_salary <- blizzard_salary |>
  mutate(performance_rating = fct_relevel(performance_rating, "Poor", "Successful", "High", "Top"))

raise_2_fit <- linear_reg() |>
  fit(percent_incr ~ annual_salary + performance_rating, data = blizzard_salary)

tidy(raise_2_fit)
```

Unfortunately they didn't write their code in a Quarto document, instead just wrote some code in the Console and then lost track of their work. They remember using the `fct_relevel()` function and doing something like the following:

```{r}
#| eval: false
#| echo: true

blizzard_salary <- blizzard_salary |>
  mutate(performance_rating = fct_relevel(performance_rating, ___))
```

What should they put in the blanks to get the same model output as above?

a.  "Poor", "Successful", "High", "Top"
b.  "Successful", "High", "Top"
c.  "Top", "High", "Successful", "Poor"
d.  Poor, Successful, High, Top

## Question 5

Suppose we fit a model to predict `percent_incr` from `annual_salary` and `salary_type`. A tidy output of the model is shown below.

```{r}
#| label: raise-salary-type-fit

raise_3_fit <- linear_reg() |>
  fit(percent_incr ~ annual_salary + salary_type, data = blizzard_salary)

tidy(raise_3_fit)
```

Which of the following visualizations represent this model? Explain your reasoning.

```{r}
#| label: fig-raise-salary-type
#| warning: false
#| layout-ncol: 2
#| fig-cap: |
#|   Visualizations of the relationship between percent increase, annual 
#|   salary, and salary type
#| fig-subcap:
#|   - Option 1
#|   - Option 2
#|   - Option 3
#|   - Option 4

ggplot(blizzard_salary, aes(x = annual_salary, y = percent_incr, color = salary_type)) +
  geom_point(aes(shape = salary_type), alpha = 0.5, size = 2) +
  geom_smooth(aes(linetype = salary_type), method = "lm", se = FALSE, fullrange = TRUE, linewidth = 1.5) +
  labs(
    x = "Annual salary",
    y = "Percent increase",
    color = "Salary type",
    linetype = "Salary type",
    shape = "Salary type"
  ) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_percent(scale = 1)) +
  theme(legend.position = "top")

ggplot(blizzard_salary, aes(x = annual_salary, y = percent_incr, color = salary_type)) +
  geom_point(aes(shape = salary_type), alpha = 0.5, size = 2) +
  geom_smooth(aes(linetype = salary_type), se = FALSE, fullrange = TRUE, linewidth = 1.5) +
  labs(
    x = "Annual salary",
    y = "Percent increase"
  ) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_percent(scale = 1)) +
  theme(legend.position = "top")

ggplot(blizzard_salary, aes(x = annual_salary, y = percent_incr, color = salary_type)) +
  geom_point(aes(shape = salary_type), alpha = 0.5, size = 2, show.legend = FALSE) +
  geom_abline(intercept = 1.24, slope = 0.0000137, color = "#E87d72", linewidth = 1.5, linetype = "solid") +
  geom_abline(intercept = 1.24+0.913, slope = 0.0000137, color = "#56bcc2", linewidth = 1.5, linetype = "dashed") +
  labs(
    x = "Annual salary",
    y = "Percent increase",
  ) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_percent(scale = 1))

ggplot(blizzard_salary, aes(x = annual_salary, y = percent_incr, color = salary_type)) +
  geom_point(alpha = 0.5, size = 2, show.legend = FALSE) +
  geom_abline(intercept = 1.24, slope = 0.0000137, color = "#56bcc2", linewidth = 1.5, linetype = "dashed") +
  geom_abline(intercept = 1.24+0.913, slope = 0.0000137,  color = "#E87d72", linewidth = 1.5) +
  labs(
    x = "Annual salary",
    y = "Percent increase",
  ) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_percent(scale = 1))
```

::: {.content-visible when-format="pdf"}
{{< pagebreak >}}
:::

{{< pagebreak >}}

## Question 6

Suppose you now fit a model to predict the natural log of percent increase, `log(percent_incr)`, from performance rating. The model is called `raise_4_fit`.

```{r}
raise_4_fit <- linear_reg() |>
  fit(log(percent_incr+0.0001) ~ performance_rating, data = blizzard_salary)
```

You're provided the following:

```{r}
#| echo: true
tidy(raise_4_fit) |>
  select(term, estimate) |>
  mutate(exp_estimate = exp(estimate))
```

Based on this, which of the following is true?

a\. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by 10.25% compared to the employees with Poor performance rating.

b\. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by 6.93% compared to the employees with Poor performance rating.

c\. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by a factor of 1025 compared to the employees with Poor performance rating.

d\. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by a factor of 6.93 compared to the employees with Poor performance rating.

# Part 2 - Movies

The data for this part comes from the Internet Movie Database (IMDB). Specifically, the data are a random sample of movies released between 1980 and 2020.

```{r}
#| label: load-data
#| message: false
movies <- read_csv("data/movies.csv")
```

The name of the data frame used for this analysis is `movies`, and it contains the variables shown in @tbl-data-dictionary.

\setcounter{table}{0}

| Variable          | Description                                                             |
|----------------------|--------------------------------------------------|
| `name`            | name of the movie                                                       |
| `rating`          | rating of the movie (R, PG, etc.)                                       |
| `genre`           | main genre of the movie.                                                |
| `runtime`         | duration of the movie                                                   |
| `year`            | year of release                                                         |
| `release_date`    | release date (YYYY-MM-DD)                                               |
| `release_country` | release country                                                         |
| `score`           | IMDB user rating                                                        |
| `votes`           | number of user votes                                                    |
| `director`        | the director                                                            |
| `writer`          | writer of the movie                                                     |
| `star`            | main actor/actress                                                      |
| `country`         | country of origin                                                       |
| `budget`          | the budget of a movie (some movies don't have this, so it appears as 0) |
| `gross`           | revenue of the movie                                                    |
| `company`         | the production company                                                  |

: Data dictionary for `movies` {#tbl-data-dictionary tbl-colwidths="\[20,80\]"}

The first thirty rows of the `movies` data frame are shown in @tbl-data, with variable types suppressed (since we'll ask about them later).

{{< pagebreak >}}

```{r}
#| echo: false
movies_to_mark <- c("Blue City", "Rang De Basanti", "Winter Sleep")

movies <- movies |>
  mutate(
    mark = if_else(name %in% movies_to_mark, TRUE, FALSE),
    rating = case_when(
      rating == "TV-PG" ~ "PG",
      rating == "Unrated" ~ "Not Rated",
      is.na(rating) ~ "Not Rated",
      .default = rating
    ),
    rating = fct_relevel(rating, "G", "PG", "PG-13", "R", "NC-17", "Not Rated")
  ) |>
  arrange(desc(mark)) |>
  relocate(name, score, runtime, genre, rating, release_country, release_date, budget, gross, votes, year, director, writer, star, company, country)
```

````{=tex}
\begin{landscape}

::: {#tbl-data}
First 30 rows of `movies`, with variable types suppressed.

```{r}
#| echo: false
options(
  dplyr.print_min = 30,
  pillar.min_chars = 13,
  pillar.width = 110,
  pillar.sigfig = 6
)

format(movies |> select(!c(mark)))[-3L] |>
  str_remove_all(" <.*?>") |>
  cat(sep = "\n")

options(
  dplyr.print_min = 10,
  pillar.min_chars = 8,
  pillar.width = 80,
  pillar.sigfig = 3
)
```
:::

\end{landscape}
\clearpage
````

{{< pagebreak >}}

# Part 2a - Score vs. runtime

In this part, we fit a model predicting `score` from `runtime` and name it `score_runtime_fit`.

```{r}
#| echo: true
score_runtime_fit <- linear_reg() |>
  fit(score ~ runtime, data = movies)
```

@fig-score-runtime visualizes the relationship between `score` and `runtime` as well as the linear model for predicting `score` from `runtime`. The top three movies in @tbl-data are labeled in the visualization as well. Answer all questions in this part based on @fig-score-runtime.

```{r}
#| label: fig-score-runtime-prep
#| echo: false
movies <- movies |>
  mutate(
    runtime = parse_number(runtime),
    shape1 = case_when(
      name == movies_to_mark[1] ~ "circle",
      name == movies_to_mark[2] ~ "square",
      name == movies_to_mark[3] ~ "triangle",
      .default = "circle"
    ),
    shape2 = case_when(
      name == movies_to_mark[1] ~ "circle open",
      name == movies_to_mark[2] ~ "square open",
      name == movies_to_mark[3] ~ "triangle open",
      .default = NA
    ),
    color = if_else(mark, "black", "gray50"),
    alpha = if_else(mark, 1, 0.5)
  )
```

```{r}
#| label: fig-score-runtime
#| fig-cap: Scatterplot of `score` vs. `runtime` for `movies`.
#| echo: false
#| message: false
#| fig-asp: 0.5
#| fig-width: 6.5
ggplot(movies, aes(x = runtime, y = score)) +
  geom_point(aes(shape = shape1, color = color, alpha = alpha)) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  scale_shape_identity() +
  scale_alpha_identity() +
  scale_color_identity() +
  geom_point(
    data = movies |> filter(mark),
    aes(shape = shape2),
    size = 3
  ) +
  geom_label(
    data =  movies |> filter(mark), 
    aes(label = name),
    size = 3, 
    nudge_x = 1,
    nudge_y = c(-0.4, -0.4, 0.4)
  ) +
  scale_x_continuous(breaks = seq(80, 240, 20))
```

## Question 7

Partial code for producing @fig-score-runtime is given below. Which of the following goes in the blank on Line 2? **Select all that apply.**

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: true
movies |>
  mutate(runtime = ___) |>
  ggplot(aes(x = runtime, y = score)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE)
  # additional code for annotating Blue City on the plot
```

a.  `grepl(" mins", runtime)`

b.  `grep(" mins", runtime)`

c.  `str_remove(runtime, " mins")`

d.  `as.numeric(str_remove(runtime, " mins"))`

e.  `na.rm(runtime)`

{{< pagebreak >}}

## Question 8

Based on this model, order the three labeled movies in @fig-score-runtime in decreasing order of the magnitude (absolute value) of their residuals.

a.  Winter Sleep\> Rang De Basanti \> Blue City

b.  Winter Sleep\> Blue City \> Rang De Basanti

c.  Rang De Basanti \> Winter Sleep\> Blue City

d.  Blue City \> Winter Sleep \> Rang De Basanti

e.  Blue City \> Rang De Basanti \> Winter Sleep

\vspace{2cm}

## Question 9

```{r}
#| include: false
score_runtime_rsq <- round(glance(score_runtime_fit)$r.squared * 100, 0)
```

The R-squared for the model visualized in @fig-score-runtime is `{r} score_runtime_rsq`%. Which of the following is the [**best**]{.underline} interpretation of this value?

a.  `{r} score_runtime_rsq`% of the variability in movie runtimes is explained by their scores.

b.  `{r} score_runtime_rsq`% of the variability in movie scores is explained by their runtime.

c.  The model accurately predicts scores of `{r} score_runtime_rsq`% of the movies in this sample.

d.  The model accurately predicts scores of `{r} score_runtime_rsq`% of all movies.

e.  The correlation between scores and runtimes of movies is `{r} score_runtime_rsq / 100`.

{{< pagebreak >}}

# Part 2b - Score vs. runtime or year

The visualizations below show the relationship between `score` and `runtime` as well as `score` and `year`, respectively. Additionally, the lines of best fit are overlaid on the visualizations.

```{r}
#| layout-ncol: 2
#| echo: false
#| message: false
ggplot(movies, aes(x = runtime, y = score)) +
  geom_point(alpha = 0.5, color = "gray40") +
  geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 1.2)

ggplot(movies, aes(x = year, y = score)) +
  geom_point(alpha = 0.5, color = "gray40") +
  geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 1.2)
```

The correlation coefficients of these relationships are calculated below, though some of the code and the output are missing. Answer all questions in this part based on the code and output shown below.

```{r}
#| include: false
movies |>
  summarize(
    r_score_runtime = cor(runtime, score),
    r_score_year = cor(year, score)
  )
```

```{r}
#| eval: false
#| echo: true
movies |>
  __blank_1__(
    r_score_runtime = cor(runtime, score),
    r_score_year = cor(year, score)
  )
```

```         
# A tibble: 1 × 2
  r_score_runtime r_score_year
            <dbl>        <dbl>
1           0.434. __blank_2__       
```

::: {layout="[0.5, 0.5]"}
::: {#firstcol}
## Question 10

Which of the following goes in `__blank_1__`?

a.  `summarize`

b.  `mutate`

c.  `group_by`

d.  `arrange`

e.  `filter`
:::

::: {#secondcol}
## Question 11

What can we say about the value that goes in `__blank_2__`?

a.  `NA`

b.  A value between 0 and 0.434.

c.  A value between 0.434 and 1.

d.  A value between 0 and -0.434.

e.  A value between -1 and -0.434.
:::
:::

{{< pagebreak >}}

# Part 2c - Score vs. runtime and rating

In this part, we fit a model predicting `score` from `runtime` and `rating` (categorized as G, PG, PG-13, R, NC-17, and Not Rated), and name it `score_runtime_rating_fit`.

```{r}
score_runtime_rating_fit <- linear_reg() |>
  fit(score ~ runtime + rating, data = movies)
```

The model output for `score_runtime_rating_fit` is shown in @tbl-score-runtime-rating-tidy. Answer all questions in this part based on @tbl-score-runtime-rating-tidy.

```{r}
#| label: tbl-score-runtime-rating-tidy
#| tbl-cap: Regression output for `score_runtime_rating_fit`.
#| echo: false
tidy(score_runtime_rating_fit) |>
  knitr::kable(digits = 3)
```

\vspace{1cm}

## Question 12

Which of the following is [**TRUE**]{.underline} about the intercept of `score_runtime_rating_fit`? **Select all that are true.**

a.  Keeping runtime constant, G-rated movies are predicted to score, on average, 4.525 points.

b.  Keeping runtime constant, movies without a rating are predicted to score, on average, 4.525 points.

c.  Movies without a rating that are 0 minutes in length are predicted to score, on average, 4.525 points.

d.  All else held constant, movies that are 0 minutes in length are predicted to score, on average, 4.525 points.

e.  G-rated movies that are 0 minutes in length are predicted to score, on average, 4.525 points.

{{< pagebreak >}}

## Question 13

Which of the following is the [**best**]{.underline} interpretation of the slope of `runtime` in `score_runtime_rating_fit`?

a.  All else held constant, as runtime increases by 1 minute, the score of the movie increases by 0.021 points.

b.  For G-rated movies, all else held constant, as runtime increases by 1 minute, the score of the movie increases by 0.021 points.

c.  All else held constant, for each additional minute of runtime, movie scores will be higher by 0.021 points on average.

d.  G-rated movies that are 0 minutes in length are predicted to score 0.021 points on average.

e.  For each higher level of rating, the movie scores go up by 0.021 points on average.

\vspace{1.5cm}

## Question 14

Fill in the blank:

> R-squared for `score_runtime_rating_fit` (the model predicting `score` from `runtime` and `rating`) \_\_\_\_\_\_\_\_\_ the R-squared the model `score_runtime_fit` (for predicting `score` from `runtime` alone).

a.  is less than

b.  is equal to

c.  is greater than

d.  cannot be compared (based on the information provided) to

e.  is both greater than and less than

\vspace{1.5cm}

## Question 15

The model `score_runtime_rating_fit` (the model predicting `score` from `runtime` and `rating`) can be visualized as parallel lines for each level of `rating`. Which of the following is the equation of the line for R-rated movies?

a.  $\widehat{score} = (4.525 - 0.257) + 0.021 \times runtime$

b.  $score = (4.525 - 0.257) + 0.021 \times runtime$

c.  $\widehat{score} = 4.525 + (0.021 - 0.257) \times runtime$

d.  $score = 4.525 + (0.021 - 0.257) \times runtime$

e.  $\widehat{score} = (4.525 + 0.021) - 0.257 \times runtime$

{{< pagebreak >}}

# Part 3 - Miscellaneous

## Question 16

Which of the following is the definition of a regression model? Select all that apply.

a\. $\hat{y} = b_0 + b_1 X_1$

b\. $y = \beta_0 + \beta_1 X_1$

c\. $\hat{y} = \beta_0 + \beta_1 X_1 + \epsilon$

d\. $y = \beta_0 + \beta_1 X_1 + \epsilon$

## Question 17

**Choose the best answer.**

A survey based on a random sample of 2,045 American teenagers found that a 95% confidence interval for the mean number of texts sent per month was (1450, 1550). A valid interpretation of this interval is

a.  95% of all teens who text send between 1450 and 1550 text messages per month.
b.  If a new survey with the same sample size were to be taken, there is a 95% chance that the mean number of texts in the sample would be between 1450 and 1550.
c.  We are 95% confident that the mean number of texts per month of all American teens is between 1450 and 1550.
d.  We are 95% confident that, were we to repeat this survey, the mean number of texts per month of those taking part in the survey would be between 1450 and 1550.

{{< pagebreak >}}

## Question 18

Define the term "parsimonious model".

::: {.content-visible when-format="pdf"}
$\vspace{2cm}$
:::

# Part 4 - Building a spam filter

The data come from incoming emails in David Diez's (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed. The dataset is called `email` and it's in the **openintro** package.

The outcome variable is `spam`, which takes the value `1` if the email is spam, `0` otherwise.

## Question 19

a.  What type of variable is `spam`?
    What percent of the emails are spam?

b.  What type of variable is `dollar` - number of times a dollar sign or the word “dollar” appeared in the email?
    Visualize and describe its distribution, supporting your description with the appropriate summary statistics.

c.  Fit a logistic regression model predicting `spam` from `dollar`.
    Then, display the tidy output of the model.

d.  Using this model and the `predict()` function, predict the probability the email is spam if it contains 5 dollar signs.
    Based on this probability, how does the model classify this email?

    ::: callout-note
    To obtain the predicted probability, you can set the `type` argument in `predict()` to `"prob"`.
    :::

## Question 20

a.  Fit another logistic regression model predicting `spam` from `dollar`, `winner` (indicating whether “winner” appeared in the email), and `urgent_subj` (whether the word "urgent" is in the subject of the email).
    Then, display the tidy output of the model.

b.  Using this model and the `augment()` function, classify each email in the `email` dataset as spam or not spam.
    Store the resulting data frame with an appropriate name and display the data frame as well.

c.  Using your data frame from the previous part, determine, in a single pipeline, and using `count()`, the numbers of emails:

    -   that are labelled as spam that are actually spam
    -   that are not labelled as spam that are actually spam
    -   that are labelled as spam that are actually not spam
    -   that are not labelled as spam that are actually not spam

    Store the resulting data frame with an appropriate name and display the data frame as well.

d.  In a single pipeline, and using `mutate()`, calculate the false positive and false negative rates.
    In addition to these numbers showing in your R output, you must write a sentence that explicitly states and identified the two rates.

## Question 21

a.  Fit another logistic regression model predicting `spam` from `dollar` and another variable you think would be a good predictor.
    Provide a 1-sentence justification for why you chose this variable.
    Display the tidy output of the model.

b.  Using this model and the `augment()` function, classify each email in the `email` dataset as spam or not spam.
    Store the resulting data frame with an appropriate name and display the data frame as well.

c.  Using your data frame from the previous part, determine, in a single pipeline, and using `count()`, the numbers of emails:

    -   that are labelled as spam that are actually spam
    -   that are not labelled as spam that are actually spam
    -   that are labelled as spam that are actually not spam
    -   that are not labelled as spam that are actually not spam

    Store the resulting data frame with an appropriate name and display the data frame as well.

d.  In a single pipeline, and using `mutate()`, calculate the false positive and false negative rates.
    In addition to these numbers showing in your R output, you must write a sentence that explicitly states and identified the two rates.

e.  Based on the false positive and false negatives rates of this model, comment, in 1-2 sentences, on which model (one from Question 2 or Question 3) is preferable and why.
