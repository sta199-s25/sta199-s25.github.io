[
  {
    "objectID": "computing/coding-access.html",
    "href": "computing/coding-access.html",
    "title": "Access RStudio",
    "section": "",
    "text": "In this class, you will always and everywhere access RStudio through the Duke Container Manager. This ensures that all of us are using the same version of all the software. If this were not the case, unexpected and difficult to diagnose/resolve coding incompatibilities could arise when you seek help from the teaching team or collaborate with your project partners. Nobody needs that, so please stick to the containers. Here is how you get in:\n\nGo here: https://cmgr.oit.duke.edu/containers. You may have to log in with your NetID at some point;\n(The first time you do this, you look for STA198-199 under “Reservations available” on the righthand side, and click “reserve STA198-199”. After you do that once, STA198-199 will appear under “My reservations” on the lefthand side forever more)\nClick STA198-199 under “My reservations”;\nLogin;\nStart. It may take a while, but then RStudio should launch in your browser.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/coding-cheatsheets.html",
    "href": "computing/coding-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://www.rstudio.com/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "exam/final-review.html",
    "href": "exam/final-review.html",
    "title": "Final review",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "exam/midterm-2-practice-solns.html",
    "href": "exam/midterm-2-practice-solns.html",
    "title": "Midterm 2 Practice Answers",
    "section": "",
    "text": "(c) For every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 0.0155%.\n(d) \\(R^2\\) of raise_2_fit is higher than \\(R^2\\) of raise_1_fit since raise_2_fit has one more predictor and \\(R^2\\) always\nThe reference level of performance_rating is High, since it’s the first level alphabetically. Therefore, the coefficient -2.40% is the predicted difference in raise comparing High to Successful. In this context a negative coefficient makes sense since we would expect those with High performance rating to get higher raises than those with Successful performance.\n(a) “Poor”, “Successful”, “High”, “Top”.\nOption 3. It’s a linear model with no interaction effect, so parallel lines. And since the slope for salary_typeSalaried is positive, its intercept is higher. The equations of the lines are as follows:\n\nHourly:\n\\[\n\\begin{align*}\n\\widehat{percent\\_incr} &= 1.24 + 0.0000137 \\times annual\\_salary + 0.913 salary\\_typeSalaried \\\\\n&= 1.24 + 0.0000137 \\times annual\\_salary + 0.913 \\times 0 \\\\\n&= 1.24 + 0.0000137 \\times annual\\_salary\n\\end{align*}\n\\]\nSalaried:\n\\[\n\\begin{align*}\n\\widehat{percent\\_incr} &= 1.24 + 0.0000137 \\times annual\\_salary + 0.913 salary\\_typeSalaried \\\\\n&= 1.24 + 0.0000137 \\times annual\\_salary + 0.913 \\times 1 \\\\\n&= 2.153 + 0.0000137 \\times annual\\_salary\n\\end{align*}\n\\]\n\n(c) The model predicts that the percentage increase employees with Successful performance get, on average, is higher by a factor of 1025 compared to the employees with Poor performance rating.\n(d) as.numeric(str_remove(runtime, \" mins\"))\n(e) Blue City \\(&gt;\\) Rang De Basanti \\(&gt;\\) Winter Sleep\n(b) 31% of the variability in movie scores is explained by their runtime.\n(a) summarize\n(b) A value between 0 and 0.434.\n(e) G-rated movies that are 0 minutes in length are predicted to score, on average, 4.525 points.\n(c) All else held constant, for each additional minute of runtime, movie scores will be higher by 0.021 points on average.\n(c) is greater than\n(a) \\(\\widehat{score} = (4.525 - 0.257) + 0.021 \\times runtime\\)\n(a) and (d).\n(c) We are 95% confident that the mean number of texts per month of all American teens is between 1450 and 1550.\nA parsimonious model is the simplest model with the best predictive performance."
  },
  {
    "objectID": "exam/final-review-A.html",
    "href": "exam/final-review-A.html",
    "title": "Final review",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "exam/midterm-1-batch-A.html",
    "href": "exam/midterm-1-batch-A.html",
    "title": "Midterm 1 Practice Questions",
    "section": "",
    "text": "Solutions\n\n\n\n\n\nSee here.\nIn 2020, employees of Blizzard Entertainment circulated a spreadsheet to anonymously share salaries and recent pay increases amidst rising tension in the video game industry over wage disparities and executive compensation. (Source: Blizzard Workers Share Salaries in Revolt Over Pay)\nThe name of the data frame used for this analysis is blizzard_salary and the variables are:\nThe top ten rows of blizzard_salary are shown below:\n# A tibble: 409 × 4\n   percent_incr salary_type annual_salary performance_rating\n          &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n 1          1   Salaried               1  High              \n 2          1   Salaried               1  Successful        \n 3          1   Salaried               1  High              \n 4          1   Hourly             33987. Successful        \n 5         NA   Hourly             34798. High              \n 6         NA   Hourly             35360  &lt;NA&gt;              \n 7         NA   Hourly             37440  &lt;NA&gt;              \n 8          0   Hourly             37814. &lt;NA&gt;              \n 9          4   Hourly             41101. Top               \n10          1.2 Hourly             42328  &lt;NA&gt;              \n# ℹ 399 more rows",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-1",
    "href": "exam/midterm-1-batch-A.html#question-1",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 1",
    "text": "Question 1\nWhich of the following is correct? Choose all that apply.\n\nThe blizzard_salary dataset has 399 rows.\nThe blizzard_salary dataset has 4 columns.\nEach row represents a Blizzard Entertainment worker who filled out the spreadsheet.\nThe percent_incr variable is numerical and discrete.\nThe salary_type variable is numerical.\nThe annual_salary variable is numerical.\nThe performance_rating variable is categorical and ordinal.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-2",
    "href": "exam/midterm-1-batch-A.html#question-2",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 2",
    "text": "Question 2\nFigure 1 (a) and Figure 1 (b) show the distributions of annual salaries of hourly and salaried workers. The two figures show the same data, with the facets organized across rows and across columns. Which of the two figures is better for comparing the median annual salaries of hourly and salaried workers. Explain your reasoning.\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\nFigure 1: Distribution of annual salaries of Blizzard employees",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-3",
    "href": "exam/midterm-1-batch-A.html#question-3",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 3",
    "text": "Question 3\nSuppose your teammate wrote the following code as part of their analysis of the data.\nThey then printed out the results shown below. Unfortunately one of the numbers got erased from the printout. It’s indicated with _____ below.\n# A tibble: 2 × 3\n  salary_type mean_annual_salary median_annual_salary\n  &lt;chr&gt;                    &lt;dbl&gt;                &lt;dbl&gt;\n1 Hourly                  63003.               54246.\n2 Salaried                90183.               _____\nWhich of the following is the best estimate for that erased value?\n\n30,000\n50,000\n80,000\n100,000",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-4",
    "href": "exam/midterm-1-batch-A.html#question-4",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 4",
    "text": "Question 4\nWhich distribution of annual salaries has a higher standard deviation?\n\nHourly workers\nSalaried workers\nRoughly the same",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-5",
    "href": "exam/midterm-1-batch-A.html#question-5",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 5",
    "text": "Question 5\nWhich of the following alternate plots would also be useful for visualizing the distributions of annual salaries of hourly and salaried workers? Choose all that apply.\na. Box plots\nb. Density plots\nc. Pie charts\nd. Waffle charts\ne. Histograms\nf. Scatterplots",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#questions-6-and-7",
    "href": "exam/midterm-1-batch-A.html#questions-6-and-7",
    "title": "Midterm 1 Practice Questions",
    "section": "Questions 6 and 7",
    "text": "Questions 6 and 7\nSuppose you made the bar plot shown in Figure 2 (a) to visualize the distribution of performance_rating and your teammate made the bar plot shown in Figure 2 (b).\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\nFigure 2: Distribution of performance rating\n\n\nYou made your bar plot without transforming the data in any way, while your friend did first transform the data with code like the following:\n\nblizzard_salary &lt;- blizzard_salary |&gt;\n  _(1)_(performance_rating = fct_relevel(performance_rating, _(2)_))\n\nQuestion 6: What goes in the blank (1)?\n\narrange()\nfilter()\nmutate()\nsummarize()\n\nQuestion 7: What goes in the blank (2)?\n\n\"Poor\", \"Successful\", \"High\", \"Top\"\n\"Successful\", \"High\", \"Top\"\n\"Top\", \"High\", \"Successful\", \"Poor\"\nPoor, Successful, High, Top",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#questions-8---10",
    "href": "exam/midterm-1-batch-A.html#questions-8---10",
    "title": "Midterm 1 Practice Questions",
    "section": "Questions 8 - 10",
    "text": "Questions 8 - 10\nFinally, another teammate creates the following two plots.\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\nFigure 3: Distribution of salary type by performance rating\n\n\nQuestion 8: Your teammate asks you for help deciding which one to use in the final report for visualizing the relationship between performance rating and salary type. In 1-3 sentences, can you help them make a decision, justify your choice, and write the narrative that should go with the plot?\nQuestion 9: A friend with a keen eye points out that the number of observations in Figure 3 (a) seems lower than the total number of observations in blizzard_salary. What might be going on here? Explain your reasoning.\nQuestion 10: Below are the proportions of performance ratings for hourly and salaried workers. Place these values in the corresponding segments in Figure 3 (b).\n\n\n# A tibble: 4 × 3\n  performance_rating Hourly Salaried\n  &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1 High                0.2     0.384 \n2 Successful          0.686   0.521 \n3 Top                 0.114   0.0760\n4 Poor                0       0.0190",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#questions-11-and-12",
    "href": "exam/midterm-1-batch-A.html#questions-11-and-12",
    "title": "Midterm 1 Practice Questions",
    "section": "Questions 11 and 12",
    "text": "Questions 11 and 12\nThe table below shows the distribution of salary_type and performance_rating.\n\n\n# A tibble: 2 × 6\n  salary_type  Poor Successful  High   Top  `NA`\n  &lt;chr&gt;       &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Hourly         NA         24     7     4    28\n2 Salaried        5        137   101    20    83\n\n\nThe pipeline below produces a data frame with a fewer number of rows than blizzard_salary.\n\nblizzard_salary |&gt;\n  filter(salary_type _(1)_ \"Hourly\" _(2)_ performance_rating == \"Poor\") |&gt;\n  _(3)_(annual_salary)\n\n\n\n# A tibble: 5 × 4\n  percent_incr salary_type annual_salary performance_rating\n         &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n1            0 Salaried            80000 Poor              \n2            3 Salaried            83000 Poor              \n3            0 Salaried           116000 Poor              \n4            0 Salaried           135219 Poor              \n5            0 Salaried           147500 Poor              \n\n\nQuestion 11: Which of the following goes in blanks (1) and (2)?\n\n\n\n(1)\n(2)\n\n\n\na.\n!=\n|\n\n\nb.\n==\n&\n\n\nc.\n!=\n&\n\n\nd.\n==\n|\n\n\n\nQuestion 12: Which function or functions go into blank (3)?\n\narrange()\nmutate()\norder()\nsort()",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-13",
    "href": "exam/midterm-1-batch-A.html#question-13",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 13",
    "text": "Question 13\nYou’re reviewing another team’s work and they made the following visualization:\n\n\n\n\n\n\n\n\nAnd they wrote the following interpretation for the relationship between annual salary and percent increase for Top performers:\n\nThe relationship is positive, having a higher salary results in a higher percent increase. There is one clear outlier.\n\nWhich of the following is/are the most accurate and helpful) peer review note for this interpretation. Choose all that apply.\n\nThe interpretation is complete and perfect, no changes needed!\nThe interpretation doesn’t mention the direction of the relationship.\nThe interpretation doesn’t mention the form of the relationship, which is linear.\nThe interpretation doesn’t mention the strength of the relationship, which is somewhat strong.\nThere isn’t a clear outlier in the plot. If any points stand out as potential outliers, more guidance should be given to the reader to identify them (e.g., salary and/or percent increase amount).\nThe interpretation is causal – we don’t know if the cause of the high percent increase is higher annual salary based on observational data. The causal direction might be the other way around, or there may be other factors contributing to the apparent relationship.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-14",
    "href": "exam/midterm-1-batch-A.html#question-14",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 14",
    "text": "Question 14\nBelow is some code and its output.\n```{r}\n# label=plot blizzard\n\nggplot(blizzard_salary,aes(x=performance_rating,y=percent_incr))+geom_boxplot()\nlabs(x=\"Performance rating\", y = \"Percent increase\")\n```\n\n\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n$x\n[1] \"Performance rating\"\n\n$y\n[1] \"Percent increase\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nPart 1: List at least 5 things that should be fixed or improved in the code.\nPart 2: What is the cause of the warning and what does it mean?",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-15",
    "href": "exam/midterm-1-batch-A.html#question-15",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 15",
    "text": "Question 15\nYou’re working on a data analysis on salaries of Blizzard employees in a Quarto document in a project version controlled by Git. You create a plot and write up a paragraph describing any patterns in it. Then, your teammate says “render, commit, and push”.\nPart 1: What do they mean by each of these three steps. In 1-2 sentences for each, explain in your own words what they mean.\n\nRender:\n\n\nCommit:\n\n\nPush:\n\nPart 2: Your teammate is getting impatient and they interrupt you after you rendered and committed and say “I still can’t see your changes in our shared GitHub repo when I look at it in my web browser.” Which of the following answers is the most accurate?\n\nI rendered my document, you should be seeing my changes on GitHub when you look at it in your web browser.\nI committed my changes, you should be seeing my changes on GitHub when you look at it in your web browser.\nI didn’t yet push my changes, it’s expected that you are not seeing them on GitHub when you look at it in your web browser. Wait until I push, and check again.\nYou need to pull to see my changes on GitHub in the web browser.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#bonus",
    "href": "exam/midterm-1-batch-A.html#bonus",
    "title": "Midterm 1 Practice Questions",
    "section": "Bonus",
    "text": "Bonus\nPick a concept we introduced in class so far that you’ve been struggling with and explain it in your own words.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A-solns.html",
    "href": "exam/midterm-1-batch-A-solns.html",
    "title": "Midterm 1 Practice Questions A",
    "section": "",
    "text": "b, c, f, g -\n\nThe blizzard_salary dataset has 409 rows.\nThe percent_incr variable is numerical and continuous.\nThe salary_type variable is categorical.\n\nFigure 1 - A shared x-axis makes it easier to compare summary statistics for the variable on the x-axis.\nc - It’s a value higher than the median for hourly but lower than the mean for salaried.\nb - There is more variability around the mean compared to the hourly distribution.\na, b, e - Pie charts and waffle charts are for visualizing distributions of categorical data only. Scatterplots are for visualizing the relationship between two numerical variables.\nc - mutate() is used to create or modify a variable.\na - \"Poor\", \"Successful\", \"High\", \"Top\"\nb - Option 2. The plot in Option 1 shows the number of employees with a given performance rating for each salary type while the plot in Option 2 gives the proportion of employees with a given performance rating for each salary type. In order to assess the relationship between these variables (e.g., how much more likely is a Top rating among Salaried vs. Hourly workers), we need the proportions, not the counts.\nThere may be some NAs in these two variables that are not visible in the plot.\nThe proportions under Hourly would go in the Hourly bar, and those under Salaried would go in the Salaried bar.\nc - filter(salary_type != \"Hourly\" & performance_rating == \"Poor\") - There are 5 observations for “not Hourly” “and” Poor.\na - arrange() - The result is arranged in increasing order of annual_salary, which is the default for arrange().\nc, d, e, f.\nPart 1: The following should be fixed:\n\nThere should be a | after # before label\nThere should be a : after label, not =\nThere shouldn’t be a space in the chunk label, it should be plot-blizzard\nThere should be spaces after commas in the code\nThere should be spaces on both sides of = in the code\nThere should be a space before +\ngeom_boxplot() should be on the next line and indented\nThere should be a + at the end of the geom_boxplot() line\nlabs() should be indented\n\nPart 2: The warning is caused by NA in the data. It means that 39 observations were NAs and are not plotted/represented on the plot.\nPart 1:\n\nRender: Run all of the code and render all of the text in the document and produce an output.\nCommit: Take a snapshot of your changes in Git with an appropriate message.\nPush: Send your changes off to GitHub.\n\nPart 2: c - Rendering or committing isn’t sufficient to send your changes to your GitHub repository, a push is needed. A pull is also not needed to view the changes in the browser."
  },
  {
    "objectID": "project/description.html",
    "href": "project/description.html",
    "title": "Project description",
    "section": "",
    "text": "TL;DR: Ask a question you’re curious about and answer it with a dataset of your choice. This is your project in a nutshell.\nMay be too long, but please do read\nThe project for this course will consist of analysis on a dataset of your own choosing. The dataset may already exist, or you may collect your own data using a survey or by conducting an experiment. You can choose the data based on your teams’ interests or based on work in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this course (and beyond, if you like) and apply them to a novel dataset in a meaningful way.\nThe goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results. Focus on methods that help you begin to answer your research questions. You do not have to apply every statistical procedure we learned. Also, critique your own methods and provide suggestions for improving your analysis. Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here.\nThe project is very open ended. You should create some kind of compelling visualization(s) of this data in R. There is no limit on what tools or packages you may use but sticking to packages we learned in the course is required. You do not need to visualize all of the data at once. A single high-quality visualization will receive a much higher grade than a large number of poor-quality visualizations. Also pay attention to your presentation. Neatness, coherency, and clarity will count. All analyses must be done in RStudio, using R, and all components of the project must be reproducible (with the exception of the slide deck).\nYou will work on the project with your lab teams.\nThe four milestones for the final project are\n\nMilestone 1 - Working collaboratively\nMilestone 2 - Proposals, with three dataset ideas\nMilestone 3 - Improvement and progress\nMilestone 4 - Peer review, on another team’s project\nMilestone 5 - Presentation with slides and a reproducible project write-up of your analysis, with a draft along the way.\n\nYou will not be submitting anything on Gradescope for the project. Submission of these deliverables will happen on GitHub and feedback will be provided as GitHub issues that you need to engage with and close. The collection of the documents in your GitHub repo will create a webpage for your project. To create the webpage go to the Build tab in RStudio, and click on Render Website.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#reproducibility-organization",
    "href": "project/description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the write-up and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#teamwork",
    "href": "project/description.html#teamwork",
    "title": "Project description",
    "section": "Teamwork",
    "text": "Teamwork\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly and penalties may apply beyond the teamwork component of the grade.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project presentation deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#grading-summary",
    "href": "project/description.html#grading-summary",
    "title": "Project description",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#late-work-policy",
    "href": "project/description.html#late-work-policy",
    "title": "Project description",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/3-improvement-progress.html",
    "href": "project/3-improvement-progress.html",
    "title": "Improvement and progress",
    "section": "",
    "text": "By this point you’ve received feedback on your proposal and you should be working on incorporating that feedback to improve your project and making further progress on it. This milestone ensures you’re keeping on task and doing these things.\n\nGoals\nThe goals of this milestone are as follows:\n\nIncorporate feedback from your proposal\nMake progress on your project prior to the peer review\n\n\n\nInstructions\nEverybody on the team should have at least one commit to the project repo since milestone 2 was submitted. At the very least, these commits should:\n\nexplicitly closing issues opened as proposal feedback;\nload the data into the main project QMD file;\ngenerate one visualization of the data.\n\n\n\nGrading\nThis milestone will be graded for completion, not accuracy. We will check to see if the team has made commits to their repo since project milestone 2 and closed all issues that were opened as part of proposal feedback.\n\n0 points: No commits since project milestone 2\n1 point: not everyone has committed\n2-4 points: not all issues closed, no visualization, etc\n5 points: everyone committed, all issues closed, one figure generated.\n\n\n\n\n\n\n\nNote\n\n\n\nThere won’t be a lab session dedicated to this milestone. You are to work with your team outside of class time to complete this task.",
    "crumbs": [
      "Project",
      "Milestone 3"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html",
    "href": "project/5-writeup-presentation.html",
    "title": "Write-up and presentation",
    "section": "",
    "text": "Your written report must be completed in the index.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo: false in the YAML.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long (if it were to be printed). There is no minimum page requirement; however, you should comprehensively address all of the analysis in your report.\nTo check how many pages your report is, open it in your browser and go to File &gt; Print &gt; Save as PDF and review the number of pages.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\n\n\n\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The exploratory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you’ve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you’ve chosen to do modeling, describe the model(s) you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.\n\n\n\n\n\nThe write-up is worth 35 points, broken down as follows:\n\n\n\nTotal\n35 pts\n\n\n\n\nIntroduction/data\n4 pts\n\n\nMethodology\n10 pts\n\n\nResults\n15 pts\n\n\nDiscussion\n3 pts\n\n\nOrganization + formatting\n3 pts",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#expectations",
    "href": "project/5-writeup-presentation.html#expectations",
    "title": "Write-up and presentation",
    "section": "",
    "text": "Your written report must be completed in the index.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo: false in the YAML.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long (if it were to be printed). There is no minimum page requirement; however, you should comprehensively address all of the analysis in your report.\nTo check how many pages your report is, open it in your browser and go to File &gt; Print &gt; Save as PDF and review the number of pages.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#components",
    "href": "project/5-writeup-presentation.html#components",
    "title": "Write-up and presentation",
    "section": "",
    "text": "This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The exploratory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you’ve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you’ve chosen to do modeling, describe the model(s) you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#grading",
    "href": "project/5-writeup-presentation.html#grading",
    "title": "Write-up and presentation",
    "section": "",
    "text": "The write-up is worth 35 points, broken down as follows:\n\n\n\nTotal\n35 pts\n\n\n\n\nIntroduction/data\n4 pts\n\n\nMethodology\n10 pts\n\n\nResults\n15 pts\n\n\nDiscussion\n3 pts\n\n\nOrganization + formatting\n3 pts",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#slides",
    "href": "project/5-writeup-presentation.html#slides",
    "title": "Write-up and presentation",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and record a presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides. If you choose this option, save the slides as PDF and upload it to your repo as presentation.pdf.\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe slide deck should be roughly 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#presentation",
    "href": "project/5-writeup-presentation.html#presentation",
    "title": "Write-up and presentation",
    "section": "Presentation",
    "text": "Presentation\nPresentations will be recorded and uploaded to Warpwire or YouTube. The presentation must be no longer than 5 minutes. During grading, we will stop watching your video at the 5-minute mark.\n\nRecording your presentation\nFor recording your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\n\n\nUploading your presentation\nOnce your video is ready, upload it to Warpwire or another video platform (e.g., YouTube).\nTo upload your video to Warpwire:\n\nClick the Warpwire tab on the course Canvas site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\n\nThe instructions should be a lot more straightforward for YouTube. See https://support.google.com/youtube/answer/57407?hl=en&co=GENIE.Platform%3DDesktop for step-by-step instructions. You can make it “Unlisted”, which means it will only be available to those you’ve shared the link with.\n\n\nSharing your presentation\nThis step is essential – if you don’t share your video by the deadline, it will be as if you haven’t recorded it in the first place.\nYou must share your video with the teaching team and with other students in the class.\n\nSharing with the teaching team (formal submission): Add a link to your video in your repo’s README.\nSharing with other students in the class: Post a link to your video on Ed Discussion. Title it “Your team name: Your project title” and use the “Presentation” tag.\n\nMake sure that your video is accessible to others. You should test this by sharing the link with a teammate or checking it in Incognito mode in your browser.",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#grading-1",
    "href": "project/5-writeup-presentation.html#grading-1",
    "title": "Write-up and presentation",
    "section": "Grading",
    "text": "Grading\nThe presentation is worth 25 points, broken down as follows:\n\n\n\nTotal\n25 pts\n\n\n\n\nSlides\n10 pts\n\n\nPresentation\n15 pts\n\n\n\n\nSlides\nAre the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n\n\nPresentation\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\nCreativity and critical thought: Is the project carefully thought out? Does it appear that time and effort went into the planning and implementation of the project?\nContent: Including, but not limited to the following:\n\nIs the question well articulated in the presentation?\nCan the question be answered with the data?\nDoes the analysis answer the question?\nAre the conclusion(s) made based on the analysis justifiable?\nAre the limitations carefully considered and articulated?",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "syllabus/syllabus_team.html",
    "href": "syllabus/syllabus_team.html",
    "title": "Teaching team",
    "section": "",
    "text": "John Zito is Assistant Research Professor of Statistical Science at Duke University. He came to Duke in August 2024 after completing his PhD in statistics at Rice University. Prior to that he received a BA in mathematics from Kenyon College and spent a few years working in the Federal Reserve system.\nOffice Hours: Friday 1:00 PM - 3:00 PM in Old Chem 207.",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "syllabus/syllabus_team.html#instructor",
    "href": "syllabus/syllabus_team.html#instructor",
    "title": "Teaching team",
    "section": "",
    "text": "John Zito is Assistant Research Professor of Statistical Science at Duke University. He came to Duke in August 2024 after completing his PhD in statistics at Rice University. Prior to that he received a BA in mathematics from Kenyon College and spent a few years working in the Federal Reserve system.\nOffice Hours: Friday 1:00 PM - 3:00 PM in Old Chem 207.",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "syllabus/syllabus_team.html#teaching-assistants",
    "href": "syllabus/syllabus_team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Mug\n        \n         \n          Name\n        \n         \n          Role(s)\n        \n         \n          Lab Section\n        \n         \n          Office hours\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nMug\n\n\nName\n\n\nRole(s)\n\n\nLab Section\n\n\nOffice hours\n\n\n\n\n\n\n\n\n\nArboleda, Federico\n\n\nLab Leader\n\n\nM 3:05PM - 4:20PM (Sec 8)\n\n\n🔗\n\n\n\n\n\n\n\nBag, Devarpita\n\n\nLab Helper\n\n\nM 3:05PM - 4:20PM (Sec 9)\n\n\n🔗\n\n\n\n\n\n\n\nChen, Han\n\n\nLab Helper\n\n\nM 8:30AM - 9:45AM (Sec 1)\n\n\n🔗\n\n\n\n\n\n\n\nDey, Arijit\n\n\nLab Helper\n\n\nM 1:25PM - 2:40PM (Sec 7)\n\n\n🔗\n\n\n\n\n\n\n\nEason, Sonya\n\n\nLecture Helper\n\n\n\n\n\n🔗\n\n\n\n\n\n\n\nFahrer, Alexa\n\n\nLab Helper\n\n\nM 11:45AM - 1:00PM (Sec 4)\n\n\n🔗\n\n\n\n\n\n\n\nFan, Li\n\n\nLab Leader\n\n\nM 3:05PM - 4:20PM (Sec 9)\n\n\n🔗\n\n\n\n\n\n\n\nFenoglio, Domenic\n\n\nLab Leader\n\n\nM 11:45AM - 1:00PM (Sec 5)\n\n\n🔗\n\n\n\n\n\n\n\nHarris, Natasha\n\n\nLab Helper\n\n\nM 4:40PM - 5:55PM (Sec 10)\n\n\n🔗\n\n\n\n\n\n\n\nHealey-Parera, Julia\n\n\nLab Helper\n\n\nM 11:45AM - 1:00PM (Sec 5)\n\n\n🔗\n\n\n\n\n\n\n\nHodges, Avery\n\n\nLab Leader\n\n\nM 11:45AM - 1:00PM (Sec 4)\n\n\n🔗\n\n\n\n\n\n\n\nKing, Dav\n\n\nLab Leader\n\n\nM 1:25PM - 2:40PM (Sec 6)\n\n\n🔗\n\n\n\n\n\n\n\nLee, Hyunjin\n\n\nLab Helper\n\n\nM 10:05AM - 11:20AM (Sec 2)\n\n\n🔗\n\n\n\n\n\n\n\nMa, Liane\n\n\nLab Helper\n\n\nM 10:05AM - 11:20AM (Sec 3)\n\n\n🔗\n\n\n\n\n\n\n\nMittal, Netra\n\n\nLab Leader\n\n\nM 4:40PM - 5:55PM (Sec 10)\n\n\n🔗\n\n\n\n\n\n\n\nMurphy, Caitrin\n\n\nHead TA, Lab Leader\n\n\nM 8:30AM - 9:45AM (Sec 1)\n\n\n🔗\n\n\n\n\n\n\n\nObuya, Noah\n\n\nLecture Helper\n\n\n\n\n\n🔗\n\n\n\n\n\n\n\nSolarz, Katie\n\n\nLab Leader, Lecture Helper\n\n\nM 10:05AM - 11:20AM (Sec 2)\n\n\n🔗\n\n\n\n\n\n\n\nVasquez Tapia, Eduardo Alfonso\n\n\nLab Leader\n\n\nM 1:25PM - 2:40PM (Sec 7)\n\n\n🔗\n\n\n\n\n\n\n\nWang, Jasmine\n\n\nLab Leader\n\n\nM 10:05AM - 11:20AM (Sec 3)\n\n\n🔗\n\n\n\n\n\n\n\nWu, Sarah\n\n\nLab Helper\n\n\nM 3:05PM - 4:20PM (Sec 8)\n\n\n🔗\n\n\n\n\n\n\n\nZhang, Lisa\n\n\nLab Helper\n\n\nM 1:25PM - 2:40PM (Sec 6)\n\n\n🔗\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "syllabus/syllabus_team.html#course-coordinator",
    "href": "syllabus/syllabus_team.html#course-coordinator",
    "title": "Teaching team",
    "section": "Course coordinator",
    "text": "Course coordinator\n\nDr. Mary Knox (she/her) is the course coordinator for this course. You can contact her (at mary.knox@duke.edu) with any questions regarding accommodations, missed work, extensions, registration, etc.",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html",
    "href": "syllabus/syllabus_policies.html",
    "title": "Policies",
    "section": "",
    "text": "If you wish to ask content-related questions in writing, please do not do so via e-mail. Instead, please use the course discussion forum Ed Discussion. That way all members of the teaching team can see your question, and all students can benefit from the ensuing discussion. You are also encouraged to answer one another’s questions.\nIf you have questions about personal matters that may not be appropriate for the public course forum (e.g. illness, accommodations, etc), then please e-mail the instructor directly (john.zito@duke.edu).\n\n\n\n\n\n\nNote\n\n\n\nYou can ask questions anonymously on Ed. The teaching team will still know your identity, but your peers will not.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#communication",
    "href": "syllabus/syllabus_policies.html#communication",
    "title": "Policies",
    "section": "",
    "text": "If you wish to ask content-related questions in writing, please do not do so via e-mail. Instead, please use the course discussion forum Ed Discussion. That way all members of the teaching team can see your question, and all students can benefit from the ensuing discussion. You are also encouraged to answer one another’s questions.\nIf you have questions about personal matters that may not be appropriate for the public course forum (e.g. illness, accommodations, etc), then please e-mail the instructor directly (john.zito@duke.edu).\n\n\n\n\n\n\nNote\n\n\n\nYou can ask questions anonymously on Ed. The teaching team will still know your identity, but your peers will not.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#late-work-and-extensions",
    "href": "syllabus/syllabus_policies.html#late-work-and-extensions",
    "title": "Policies",
    "section": "Late work and extensions",
    "text": "Late work and extensions\nNo late work will be accepted for application exercises, exams, or projects. Labs may be submitted up to 3 days late. A 5% deduction will be applied for each 24-hour period during which the assignment is late.\nIf circumstances prevent you from completing a lab by the stated due date, you may email the course coordinator, Dr. Mary Knox, before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide an explanation. This waiver may only be used once a semester, so only use it for a truly extenuating circumstance.\nIf circumstances have a longer-term impact on your academic performance, please let your academic dean know. They can be a resource. Please let me know if you need help contacting your academic dean.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#regrade-requests",
    "href": "syllabus/syllabus_policies.html#regrade-requests",
    "title": "Policies",
    "section": "Regrade requests",
    "text": "Regrade requests\nIf you receive a graded assignment back, and you believe that some part of it was graded incorrectly, you may dispute the grade by submitting a regrade request in Gradescope. Note the following:\n\nYou have one week after you receive a grade to submit a regrade request;\nYou should submit separate regrade requests for each question you wish to dispute, not a single catch-all request;\nRequests will be considered if there was an error in the grade calculation or if a correct answer was mistakenly marked as incorrect;\nRequests to dispute the number of points deducted for an incorrect response will not be considered;\nRegrade requests are not a mechanism for asking for clarification on feedback. Those questions should be brought to office hours;\nNo grades will be changed after the final exam has been administered on Tuesday, April 29;\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you submit a regrade request for part of an assignment, we reserve the right to regrade the entire assignment. As such, a regrade request can result in your grade going up, staying the same, or going down if we determine that, in fact, the original grader was too lenient.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#attendance",
    "href": "syllabus/syllabus_policies.html#attendance",
    "title": "Policies",
    "section": "Attendance",
    "text": "Attendance\nWe are not tracking attendance, but success in this class and regular attendance are probably highly positively correlated. Furthermore, regular lecture attendance is necessary if you wish to earn full credit for the application exercises. Lastly, some components of the final project require you to complete activities with your teammates during lab. If you do not attend, you will forfeit these points.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#accommodations",
    "href": "syllabus/syllabus_policies.html#accommodations",
    "title": "Policies",
    "section": "Accommodations",
    "text": "Accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#collaboration",
    "href": "syllabus/syllabus_policies.html#collaboration",
    "title": "Policies",
    "section": "Collaboration",
    "text": "Collaboration\nOnly work that is clearly assigned as teamwork should be completed collaboratively.\n\nYou may discuss lab assignments with other students; however, you may not directly share (or copy) code or write-up with other students. For team assignments, you may collaborate freely within your team. You may discuss the assignment with other teams; however, you may not directly share (or copy) code or write-up with another team. Unauthorized sharing (or copying) of the code or write-up will be considered a violation for all students involved.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nCollaboration within teams is not only allowed but encouraged for the project. Communication between teams at a high level is also allowed; however, you may not share code or project components across teams.\nOn individual assignments, you may not directly share work (including code) with another student in this class; on team assignments, you may not directly share work (including code) with another team.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#use-of-outside-resources-including-ai",
    "href": "syllabus/syllabus_policies.html#use-of-outside-resources-including-ai",
    "title": "Policies",
    "section": "Use of outside resources, including AI",
    "text": "Use of outside resources, including AI\nYou may make use of any online resources (e.g. StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nYou should treat generative AI, such as ChatGPT, like other online resources. Two guiding principles govern how to use AI in this course:\n\nCognitive dimension: Working with AI should not reduce your thinking ability. We will practice using AI to facilitate—rather than hinder—learning.\nEthical dimension: Students using AI should be transparent about their use and ensure it aligns with academic integrity.\n\n\n AI tools for code: You may use the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. Furthermore, you should not directly copy-paste the prompt from an assignment into the chat.\n AI tools for narrative: Unless instructed otherwise, you may not use generative AI to generate a narrative that you then copy-paste verbatim into an assignment or edit and then insert into your assignment.\n\nIn general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content. Identifying AI-generated content is fairly straightforward. Any code identified as AI-generated but not cited as such and any narrative identified as AI-generated will be considered plagiarism and treated as such.\n\n\n\n\n\n\nCiting an LLM like ChatGPT\n\n\n\nHere are some general guidelines for citing AI-generated content. In this class, if you use something like ChatGPT to help you, you need to cite that by providing a direct link to the conversation you had with the bot, like this: https://chatgpt.com/share/677c4060-1d58-8008-8e47-5caa5556a825. You can generate such a link here:",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#academic-honesty",
    "href": "syllabus/syllabus_policies.html#academic-honesty",
    "title": "Policies",
    "section": "Academic honesty",
    "text": "Academic honesty\nAs a student in this course, you have agreed to uphold the Duke Community Standard and the practices specific to this course.\n\n\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically results in a zero for the relevant portion or the entire assignment, and will be reported to the Office of Student Conduct & Community Standards for further action. Furthermore:\n\nIf a conduct violation results in a zero on a lab, that zero will not be dropped;\nIf a conduct violation results in a zero on the in-class portion of a midterm, that zero will not be replaced with your final exam score;\nIf a conduct violation of any kind is discovered on any part of an exam, your final letter grade will be permanently reduced (A- down to B+, B+ down to B, etc);\nIf we discover that students are sharing and copying assignment solutions, all students involved will be penalized equally, the sharer the same as the recipient.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_faq.html",
    "href": "syllabus/syllabus_faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Syllabus",
      "FAQ"
    ]
  },
  {
    "objectID": "syllabus/syllabus_faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "href": "syllabus/syllabus_faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Syllabus",
      "FAQ"
    ]
  },
  {
    "objectID": "syllabus/syllabus_faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "syllabus/syllabus_faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions.",
    "crumbs": [
      "Syllabus",
      "FAQ"
    ]
  },
  {
    "objectID": "syllabus/syllabus_overview.html",
    "href": "syllabus/syllabus_overview.html",
    "title": "Course overview",
    "section": "",
    "text": "Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, and do so in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language.\nPrerequisites: none.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "syllabus/syllabus_overview.html#description",
    "href": "syllabus/syllabus_overview.html#description",
    "title": "Course overview",
    "section": "",
    "text": "Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, and do so in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language.\nPrerequisites: none.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "syllabus/syllabus_overview.html#meetings",
    "href": "syllabus/syllabus_overview.html#meetings",
    "title": "Course overview",
    "section": "Meetings",
    "text": "Meetings\n\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\nStaff\n\n\n\n\nLecture\nBiological Sciences 111\nTu Thu 11:45 AM - 01:00 PM\nJohn Z\nSonya\nTBD\n\n\nLab 01\nPerkins LINK 087 (Classroom 3)\nM 08:30 AM - 09:45 AM\nCaitrin\nHan\n\n\nLab 02\nPerkins LINK 087 (Classroom 3)\nM 10:05 AM - 11:20 AM\nKatie\nHyunjin\n\n\nLab 03\nPerkins LINK 071 (Classroom 5)\nM 10:05 AM - 11:20 AM\nJasmine\nLiane\n\n\nLab 04\nPerkins LINK 087 (Classroom 3)\nM 11:45 AM - 01:00 PM\nAvery\nAlexa\n\n\nLab 05\nPerkins LINK 071 (Classroom 5)\nM 11:45 AM - 01:00 PM\nDom\nJulia\n\n\nLab 06\nPerkins LINK 087 (Classroom 3)\nM 01:25 PM - 02:40 PM\nDav\nLisa\n\n\nLab 07\nPerkins LINK 071 (Classroom 5)\nM 01:25 PM - 02:40 PM\nEduardo\nArijit\n\n\nLab 08\nPerkins LINK 087 (Classroom 3)\nM 03:05 PM - 04:20 PM\nFederico\nSarah\n\n\nLab 09\nPerkins LINK 071 (Classroom 5)\nM 03:05 PM - 04:20 PM\nLi\nDevarpita\n\n\nLab 10\nPerkins LINK 087 (Classroom 3)\nM 04:40 PM - 05:55 PM\nNetra\nNatasha",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "slides/18-model-selection.html#while-you-wait",
    "href": "slides/18-model-selection.html#while-you-wait",
    "title": "Model selection for logistic regression",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-14-forest-classification.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/18-model-selection.html#last-time-regression-with-a-binary-response",
    "href": "slides/18-model-selection.html#last-time-regression-with-a-binary-response",
    "title": "Model selection for logistic regression",
    "section": "Last time: regression with a binary response",
    "text": "Last time: regression with a binary response"
  },
  {
    "objectID": "slides/18-model-selection.html#new-model-logistic-regression",
    "href": "slides/18-model-selection.html#new-model-logistic-regression",
    "title": "Model selection for logistic regression",
    "section": "New model: logistic regression",
    "text": "New model: logistic regression\nS-curve for the probability of success \\(p=P(y=1)\\):\n\\[\n\\hat{p}\n=\n\\frac{e^{b_0+b_1x}}{1+e^{b_0+b_1x}}.\n\\]\nLinear model for the log-odds:\n\\[\n\\log\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)\n=\nb_0+b_1x.\n\\]\nThese are equivalent."
  },
  {
    "objectID": "slides/18-model-selection.html#r-syntax-is-mostly-unchanged",
    "href": "slides/18-model-selection.html#r-syntax-is-mostly-unchanged",
    "title": "Model selection for logistic regression",
    "section": "R syntax is mostly unchanged",
    "text": "R syntax is mostly unchanged\n\nsimple_logistic_fit &lt;- logistic_reg() |&gt;\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(simple_logistic_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n\n\nFitted equation for the log-odds:\n\\[\n\\log\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)\n=\n-2.27\n+\n0.000272\\times exclaim~mess\n\\]\nInterpretations are strange and delicate."
  },
  {
    "objectID": "slides/18-model-selection.html#heres-an-alternative-model",
    "href": "slides/18-model-selection.html#heres-an-alternative-model",
    "title": "Model selection for logistic regression",
    "section": "Here’s an alternative model",
    "text": "Here’s an alternative model\nDump all the predictors in:\n\nfull_logistic_fit &lt;- logistic_reg() |&gt;\n  fit(spam ~ ., data = email)\n\ntidy(full_logistic_fit)\n\n# A tibble: 22 × 5\n   term         estimate std.error statistic  p.value\n   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)  -9.09e+1   9.80e+3  -0.00928 9.93e- 1\n 2 to_multiple1 -2.68e+0   3.27e-1  -8.21    2.25e-16\n 3 from1        -2.19e+1   9.80e+3  -0.00224 9.98e- 1\n 4 cc            1.88e-2   2.20e-2   0.855   3.93e- 1\n 5 sent_email1  -2.07e+1   3.87e+2  -0.0536  9.57e- 1\n 6 time          8.48e-8   2.85e-8   2.98    2.92e- 3\n 7 image        -1.78e+0   5.95e-1  -3.00    2.73e- 3\n 8 attach        7.35e-1   1.44e-1   5.09    3.61e- 7\n 9 dollar       -6.85e-2   2.64e-2  -2.59    9.64e- 3\n10 winneryes     2.07e+0   3.65e-1   5.67    1.41e- 8\n# ℹ 12 more rows"
  },
  {
    "objectID": "slides/18-model-selection.html#classification-error",
    "href": "slides/18-model-selection.html#classification-error",
    "title": "Model selection for logistic regression",
    "section": "Classification error",
    "text": "Classification error\nThere are two kinds of mistakes:\n\nWe want to avoid both, but there’s a trade-off."
  },
  {
    "objectID": "slides/18-model-selection.html#jargon-false-negative-and-positive",
    "href": "slides/18-model-selection.html#jargon-false-negative-and-positive",
    "title": "Model selection for logistic regression",
    "section": "Jargon: False negative and positive",
    "text": "Jargon: False negative and positive\n\nFalse negative rate is the proportion of actual positives that were classified as negatives.\nFalse positive rate is the proportion of actual negatives that were classified as positives.\n\n\n\n\n\n\n\nTip\n\n\nWe want these to be low!"
  },
  {
    "objectID": "slides/18-model-selection.html#jargon-sensitivity",
    "href": "slides/18-model-selection.html#jargon-sensitivity",
    "title": "Model selection for logistic regression",
    "section": "Jargon: Sensitivity",
    "text": "Jargon: Sensitivity\nSensitivity is the proportion of actual positives that were correctly classified as positive.\n\nAlso known as true positive rate and recall\nSensitivity = 1 − False negative rate\nUseful when false negatives are more “expensive” than false positives\n\n\n\n\n\n\n\nTip\n\n\nWe want this to be high!"
  },
  {
    "objectID": "slides/18-model-selection.html#jargon-specificity",
    "href": "slides/18-model-selection.html#jargon-specificity",
    "title": "Model selection for logistic regression",
    "section": "Jargon: Specificity",
    "text": "Jargon: Specificity\nSpecificity is the proportion of actual negatives that were correctly classified as negative\n\nAlso known as true negative rate\nSpecificity = 1 − False positive rate\n\n\n\n\n\n\n\nTip\n\n\nWe want this to be high!"
  },
  {
    "objectID": "slides/18-model-selection.html#the-augment-function",
    "href": "slides/18-model-selection.html#the-augment-function",
    "title": "Model selection for logistic regression",
    "section": "The augment function",
    "text": "The augment function\nThe augment function takes a data frame and “augments” it by adding three new columns on the left that describe the model predictions for each row:\n\n\n.pred_class: model prediction (\\(\\hat{y}\\)) based on a 50% threshold;\n\n.pred_0: model estimate of \\(P(y=0)\\);\n\n.pred_1: model estimate of \\(P(y=1) = 1 - P(y = 0)\\)."
  },
  {
    "objectID": "slides/18-model-selection.html#the-augment-function-1",
    "href": "slides/18-model-selection.html#the-augment-function-1",
    "title": "Model selection for logistic regression",
    "section": "The augment function",
    "text": "The augment function\nThe augment function takes a data frame and “augments” it by adding three new columns on the left that describe the model predictions for each row:\n\nlog_aug_full &lt;- augment(full_logistic_fit, email)\nlog_aug_full\n\n# A tibble: 3,921 × 24\n   .pred_class .pred_0  .pred_1 spam  to_multiple from     cc sent_email\n   &lt;fct&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;       &lt;fct&gt; &lt;int&gt; &lt;fct&gt;     \n 1 0             0.867 1.33e- 1 0     0           1         0 0         \n 2 0             0.943 5.70e- 2 0     0           1         0 0         \n 3 0             0.942 5.78e- 2 0     0           1         0 0         \n 4 0             0.920 7.96e- 2 0     0           1         0 0         \n 5 0             0.903 9.74e- 2 0     0           1         0 0         \n 6 0             0.901 9.87e- 2 0     0           1         0 0         \n 7 0             1.00  7.89e-12 0     1           1         0 1         \n 8 0             1.00  1.24e-12 0     1           1         1 1         \n 9 0             0.862 1.38e- 1 0     0           1         0 0         \n10 0             0.922 7.76e- 2 0     0           1         0 0         \n# ℹ 3,911 more rows\n# ℹ 16 more variables: time &lt;dttm&gt;, image &lt;dbl&gt;, attach &lt;dbl&gt;, dollar &lt;dbl&gt;,\n#   winner &lt;fct&gt;, inherit &lt;dbl&gt;, viagra &lt;dbl&gt;, password &lt;dbl&gt;, num_char &lt;dbl&gt;,\n#   line_breaks &lt;int&gt;, format &lt;fct&gt;, re_subj &lt;fct&gt;, exclaim_subj &lt;dbl&gt;,\n#   urgent_subj &lt;fct&gt;, exclaim_mess &lt;dbl&gt;, number &lt;fct&gt;"
  },
  {
    "objectID": "slides/18-model-selection.html#calculating-the-error-rates",
    "href": "slides/18-model-selection.html#calculating-the-error-rates",
    "title": "Model selection for logistic regression",
    "section": "Calculating the error rates",
    "text": "Calculating the error rates\n\nlog_aug_full |&gt;\n  count(spam, .pred_class) \n\n# A tibble: 4 × 3\n  spam  .pred_class     n\n  &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;\n1 0     0            3521\n2 0     1              33\n3 1     0             299\n4 1     1              68"
  },
  {
    "objectID": "slides/18-model-selection.html#calculating-the-error-rates-1",
    "href": "slides/18-model-selection.html#calculating-the-error-rates-1",
    "title": "Model selection for logistic regression",
    "section": "Calculating the error rates",
    "text": "Calculating the error rates\n\nlog_aug_full |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam)\n\n# A tibble: 4 × 3\n# Groups:   spam [2]\n  spam  .pred_class     n\n  &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;\n1 0     0            3521\n2 0     1              33\n3 1     0             299\n4 1     1              68"
  },
  {
    "objectID": "slides/18-model-selection.html#calculating-the-error-rates-2",
    "href": "slides/18-model-selection.html#calculating-the-error-rates-2",
    "title": "Model selection for logistic regression",
    "section": "Calculating the error rates",
    "text": "Calculating the error rates\n\nlog_aug_full |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n       p\n  &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;   &lt;dbl&gt;\n1 0     0            3521 0.991  \n2 0     1              33 0.00929\n3 1     0             299 0.815  \n4 1     1              68 0.185"
  },
  {
    "objectID": "slides/18-model-selection.html#calculating-the-error-rates-3",
    "href": "slides/18-model-selection.html#calculating-the-error-rates-3",
    "title": "Model selection for logistic regression",
    "section": "Calculating the error rates",
    "text": "Calculating the error rates\n\nlog_aug_full |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(\n    p = n / sum(n),\n    decision = case_when(\n      spam == \"0\" & .pred_class == \"0\" ~ \"True negative\",\n      spam == \"0\" & .pred_class == \"1\" ~ \"False positive\",\n      spam == \"1\" & .pred_class == \"0\" ~ \"False negative\",\n      spam == \"1\" & .pred_class == \"1\" ~ \"True positive\"\n    ))\n\n# A tibble: 4 × 5\n# Groups:   spam [2]\n  spam  .pred_class     n       p decision      \n  &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;         \n1 0     0            3521 0.991   True negative \n2 0     1              33 0.00929 False positive\n3 1     0             299 0.815   False negative\n4 1     1              68 0.185   True positive"
  },
  {
    "objectID": "slides/18-model-selection.html#but-wait",
    "href": "slides/18-model-selection.html#but-wait",
    "title": "Model selection for logistic regression",
    "section": "But wait!",
    "text": "But wait!\nIf we change the classification threshold, we change the classifications, and we change the error rates:\n\nlog_aug_full |&gt;\n  mutate(\n    .pred_class = if_else(.pred_1 &lt;= 0.25, 0, 1)\n  ) |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n      p\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1 0               0  3263 0.918 \n2 0               1   291 0.0819\n3 1               0   172 0.469 \n4 1               1   195 0.531"
  },
  {
    "objectID": "slides/18-model-selection.html#classification-threshold-0.00",
    "href": "slides/18-model-selection.html#classification-threshold-0.00",
    "title": "Model selection for logistic regression",
    "section": "Classification threshold: 0.00",
    "text": "Classification threshold: 0.00\n\nlog_aug_full |&gt;\n  mutate(\n    .pred_class = if_else(.pred_1 &lt;= 0.00, 0, 1)\n  ) |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 2 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n     p\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1 0               1  3554     1\n2 1               1   367     1"
  },
  {
    "objectID": "slides/18-model-selection.html#classification-threshold-0.25",
    "href": "slides/18-model-selection.html#classification-threshold-0.25",
    "title": "Model selection for logistic regression",
    "section": "Classification threshold: 0.25",
    "text": "Classification threshold: 0.25\n\nlog_aug_full |&gt;\n  mutate(\n    .pred_class = if_else(.pred_1 &lt;= 0.25, 0, 1)\n  ) |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n      p\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1 0               0  3263 0.918 \n2 0               1   291 0.0819\n3 1               0   172 0.469 \n4 1               1   195 0.531"
  },
  {
    "objectID": "slides/18-model-selection.html#classification-threshold-0.5",
    "href": "slides/18-model-selection.html#classification-threshold-0.5",
    "title": "Model selection for logistic regression",
    "section": "Classification threshold: 0.5",
    "text": "Classification threshold: 0.5\n\nlog_aug_full |&gt;\n  mutate(\n    .pred_class = if_else(.pred_1 &lt;= 0.50, 0, 1)\n  ) |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n       p\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1 0               0  3521 0.991  \n2 0               1    33 0.00929\n3 1               0   299 0.815  \n4 1               1    68 0.185"
  },
  {
    "objectID": "slides/18-model-selection.html#classification-threshold-0.75",
    "href": "slides/18-model-selection.html#classification-threshold-0.75",
    "title": "Model selection for logistic regression",
    "section": "Classification threshold: 0.75",
    "text": "Classification threshold: 0.75\n\nlog_aug_full |&gt;\n  mutate(\n    .pred_class = if_else(.pred_1 &lt;= 0.75, 0, 1)\n  ) |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n       p\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1 0               0  3544 0.997  \n2 0               1    10 0.00281\n3 1               0   339 0.924  \n4 1               1    28 0.0763"
  },
  {
    "objectID": "slides/18-model-selection.html#classification-threshold-1.00",
    "href": "slides/18-model-selection.html#classification-threshold-1.00",
    "title": "Model selection for logistic regression",
    "section": "Classification threshold: 1.00",
    "text": "Classification threshold: 1.00\n\nlog_aug_full |&gt;\n  mutate(\n    .pred_class = if_else(.pred_1 &lt;= 1.00, 0, 1)\n  ) |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 2 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n     p\n  &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1 0               0  3554     1\n2 1               0   367     1"
  },
  {
    "objectID": "slides/18-model-selection.html#lets-plot-these-error-rates",
    "href": "slides/18-model-selection.html#lets-plot-these-error-rates",
    "title": "Model selection for logistic regression",
    "section": "Let’s plot these error rates",
    "text": "Let’s plot these error rates"
  },
  {
    "objectID": "slides/18-model-selection.html#roc-curve",
    "href": "slides/18-model-selection.html#roc-curve",
    "title": "Model selection for logistic regression",
    "section": "ROC curve",
    "text": "ROC curve\nIf we repeat this process for “all” possible thresholds \\(0\\leq p^\\star\\leq 1\\), we trace out the receiver operating characteristic curve (ROC curve), which assesses the model’s performance across a range of thresholds:"
  },
  {
    "objectID": "slides/18-model-selection.html#roc-curve-1",
    "href": "slides/18-model-selection.html#roc-curve-1",
    "title": "Model selection for logistic regression",
    "section": "ROC curve",
    "text": "ROC curve\n\nWhich corner of the plot indicates the best model performance?\n\n\n\nUpper right!"
  },
  {
    "objectID": "slides/18-model-selection.html#roc-for-full-model",
    "href": "slides/18-model-selection.html#roc-for-full-model",
    "title": "Model selection for logistic regression",
    "section": "ROC for full model",
    "text": "ROC for full model"
  },
  {
    "objectID": "slides/18-model-selection.html#roc-for-simple-model",
    "href": "slides/18-model-selection.html#roc-for-simple-model",
    "title": "Model selection for logistic regression",
    "section": "ROC for simple model",
    "text": "ROC for simple model\n\n\n\n\n\n\n\n\nComparing these two curves, the full model is better."
  },
  {
    "objectID": "slides/18-model-selection.html#model-comparison",
    "href": "slides/18-model-selection.html#model-comparison",
    "title": "Model selection for logistic regression",
    "section": "Model comparison",
    "text": "Model comparison\nThe farther up and to the left the ROC curve is, the better the classification accuracy. You can quantify this with the area under the curve.\n\n\n\n\n\n\nNote\n\n\nArea under the ROC curve will be our “quality score” for comparing logistic regression models."
  },
  {
    "objectID": "slides/18-model-selection.html#data",
    "href": "slides/18-model-selection.html#data",
    "title": "Model selection for logistic regression",
    "section": "Data",
    "text": "Data\n\nThe U.S. Forest Service maintains machine learning models to predict whether a plot of land is “forested.”\nThis classification is important for research, legislation, land management, etc. purposes.\nPlots are typically remeasured every 10 years.\nThe forested dataset contains the most recent measurement per plot."
  },
  {
    "objectID": "slides/18-model-selection.html#data-forested",
    "href": "slides/18-model-selection.html#data-forested",
    "title": "Model selection for logistic regression",
    "section": "Data: forested\n",
    "text": "Data: forested\n\n\nforested\n\n# A tibble: 7,107 × 19\n   forested  year elevation eastness northness roughness tree_no_tree dew_temp\n   &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;\n 1 Yes       2005       881       90        43        63 Tree             0.04\n 2 Yes       2005       113      -25        96        30 Tree             6.4 \n 3 No        2005       164      -84        53        13 Tree             6.06\n 4 Yes       2005       299       93        34         6 No tree          4.43\n 5 Yes       2005       806       47       -88        35 Tree             1.06\n 6 Yes       2005       736      -27       -96        53 Tree             1.35\n 7 Yes       2005       636      -48        87         3 No tree          1.42\n 8 Yes       2005       224      -65       -75         9 Tree             6.39\n 9 Yes       2005        52      -62        78        42 Tree             6.5 \n10 Yes       2005      2240      -67       -74        99 No tree         -5.63\n# ℹ 7,097 more rows\n# ℹ 11 more variables: precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;,\n#   temp_annual_min &lt;dbl&gt;, temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;,\n#   vapor_min &lt;dbl&gt;, vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;,\n#   land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/18-model-selection.html#data-forested-1",
    "href": "slides/18-model-selection.html#data-forested-1",
    "title": "Model selection for logistic regression",
    "section": "Data: forested\n",
    "text": "Data: forested\n\n\nglimpse(forested)\n\nRows: 7,107\nColumns: 19\n$ forested         &lt;fct&gt; Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005,…\n$ elevation        &lt;dbl&gt; 881, 113, 164, 299, 806, 736, 636, 224, 52, 2240, 104…\n$ eastness         &lt;dbl&gt; 90, -25, -84, 93, 47, -27, -48, -65, -62, -67, 96, -4…\n$ northness        &lt;dbl&gt; 43, 96, 53, 34, -88, -96, 87, -75, 78, -74, -26, 86, …\n$ roughness        &lt;dbl&gt; 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 190, 95, 212…\n$ tree_no_tree     &lt;fct&gt; Tree, Tree, Tree, No tree, Tree, Tree, No tree, Tree,…\n$ dew_temp         &lt;dbl&gt; 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6.39, 6.50,…\n$ precip_annual    &lt;dbl&gt; 466, 1710, 1297, 2545, 609, 539, 702, 1195, 1312, 103…\n$ temp_annual_mean &lt;dbl&gt; 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61, 10.45, 10…\n$ temp_annual_min  &lt;dbl&gt; -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.76, 1.11, …\n$ temp_annual_max  &lt;dbl&gt; 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 14.23, 15.3…\n$ temp_january_min &lt;dbl&gt; -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, 5.54, 6.20…\n$ vapor_min        &lt;dbl&gt; 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 172, 162, 70…\n$ vapor_max        &lt;dbl&gt; 1194, 938, 754, 1164, 1254, 1331, 1275, 944, 892, 549…\n$ canopy_cover     &lt;dbl&gt; 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74, 66, 83, 6…\n$ lon              &lt;dbl&gt; -118.6865, -123.0825, -122.3468, -121.9144, -117.8841…\n$ lat              &lt;dbl&gt; 48.69537, 47.07991, 48.77132, 45.80776, 48.07396, 48.…\n$ land_type        &lt;fct&gt; Tree, Tree, Tree, Tree, Tree, Tree, Non-tree vegetati…"
  },
  {
    "objectID": "slides/18-model-selection.html#outcome-and-predictors",
    "href": "slides/18-model-selection.html#outcome-and-predictors",
    "title": "Model selection for logistic regression",
    "section": "Outcome and predictors",
    "text": "Outcome and predictors\n\nOutcome: forested - Factor, Yes or No\n\n\n\nlevels(forested$forested)\n\n[1] \"Yes\" \"No\" \n\n\n\n\nPredictors: 18 remotely-sensed and easily-accessible predictors:\n\nnumeric variables based on weather and topography\ncategorical variables based on classifications from other governmental organizations"
  },
  {
    "objectID": "slides/18-model-selection.html#forested",
    "href": "slides/18-model-selection.html#forested",
    "title": "Model selection for logistic regression",
    "section": "?forested",
    "text": "?forested"
  },
  {
    "objectID": "slides/18-model-selection.html#should-we-include-a-predictor",
    "href": "slides/18-model-selection.html#should-we-include-a-predictor",
    "title": "Model selection for logistic regression",
    "section": "Should we include a predictor?",
    "text": "Should we include a predictor?\nTo determine whether we should include a predictor in a model, we should start by asking:\n\n\nIs it ethical to use this variable? (Or even legal?)\nWill this variable be available at prediction time?\nDoes this variable contribute to explainability?"
  },
  {
    "objectID": "slides/18-model-selection.html#weve-been-cheating",
    "href": "slides/18-model-selection.html#weve-been-cheating",
    "title": "Model selection for logistic regression",
    "section": "We’ve been cheating!",
    "text": "We’ve been cheating!\n\n\nSo far, we’ve been using all the data we have for building models. In predictive contexts, this would be considered cheating.\nEvaluating model performance for predicting outcomes that were used when building the models is like evaluating your learning with questions whose answers you’ve already seen."
  },
  {
    "objectID": "slides/18-model-selection.html#spending-your-data",
    "href": "slides/18-model-selection.html#spending-your-data",
    "title": "Model selection for logistic regression",
    "section": "Spending your data",
    "text": "Spending your data\nFor predictive models (used primarily in machine learning), we typically split data into training and test sets:\n\n\n\n\n\nThe training set is used to estimate model parameters.\nThe test set is used to find an independent assessment of model performance.\n\n\n\n\n\n\n\n\nWarning\n\n\nDo not use, or even peek at, the test set during training."
  },
  {
    "objectID": "slides/18-model-selection.html#how-much-to-spend",
    "href": "slides/18-model-selection.html#how-much-to-spend",
    "title": "Model selection for logistic regression",
    "section": "How much to spend?",
    "text": "How much to spend?\n\n\nThe more data we spend (use in training), the better estimates we’ll get.\nSpending too much data in training prevents us from computing a good assessment of predictive performance.\nSpending too much data in testing prevents us from computing a good estimate of model parameters."
  },
  {
    "objectID": "slides/18-model-selection.html#the-initial-split",
    "href": "slides/18-model-selection.html#the-initial-split",
    "title": "Model selection for logistic regression",
    "section": "The initial split",
    "text": "The initial split\n\nset.seed(20241112)\nforested_split &lt;- initial_split(forested)\nforested_split\n\n&lt;Training/Testing/Total&gt;\n&lt;5330/1777/7107&gt;"
  },
  {
    "objectID": "slides/18-model-selection.html#setting-a-seed",
    "href": "slides/18-model-selection.html#setting-a-seed",
    "title": "Model selection for logistic regression",
    "section": "Setting a seed",
    "text": "Setting a seed\n\nWhat does set.seed() do?\n\n\n\nTo create that split of the data, R generates “pseudo-random” numbers: while they are made to behave like random numbers, their generation is deterministic given a “seed”.\nThis allows us to reproduce results by setting that seed.\nWhich seed you pick doesn’t matter, as long as you don’t try a bunch of seeds and pick the one that gives you the best performance."
  },
  {
    "objectID": "slides/18-model-selection.html#accessing-the-data",
    "href": "slides/18-model-selection.html#accessing-the-data",
    "title": "Model selection for logistic regression",
    "section": "Accessing the data",
    "text": "Accessing the data\n\nforested_train &lt;- training(forested_split)\nforested_test &lt;- testing(forested_split)"
  },
  {
    "objectID": "slides/18-model-selection.html#the-training-set",
    "href": "slides/18-model-selection.html#the-training-set",
    "title": "Model selection for logistic regression",
    "section": "The training set",
    "text": "The training set\n\nforested_train\n\n# A tibble: 5,330 × 19\n   forested  year elevation eastness northness roughness tree_no_tree dew_temp\n   &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;\n 1 Yes       2013       315      -17        98        92 Tree             5.83\n 2 No        2018       374       93       -34        23 No tree          0.7 \n 3 No        2017       377       44       -89         1 Tree             1.83\n 4 Yes       2013       541       31       -94       139 Tree             4.19\n 5 Yes       2017       680       14       -98        20 Tree             0.79\n 6 Yes       2017      1482       76       -64        43 Tree            -0.18\n 7 No        2020        84       42       -90        12 No tree          6.9 \n 8 Yes       2011       210       34        93        16 Tree             5.52\n 9 No        2020       766       14        98        20 No tree          1.52\n10 Yes       2013      1559       98        16        79 Tree            -3.45\n# ℹ 5,320 more rows\n# ℹ 11 more variables: precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;,\n#   temp_annual_min &lt;dbl&gt;, temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;,\n#   vapor_min &lt;dbl&gt;, vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;,\n#   land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/18-model-selection.html#the-testing-data",
    "href": "slides/18-model-selection.html#the-testing-data",
    "title": "Model selection for logistic regression",
    "section": "The testing data",
    "text": "The testing data\n\nforested_test\n\n# A tibble: 1,777 × 19\n   forested  year elevation eastness northness roughness tree_no_tree dew_temp\n   &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;           &lt;dbl&gt;\n 1 Yes       2005       881       90        43        63 Tree             0.04\n 2 Yes       2005       636      -48        87         3 No tree          1.42\n 3 Yes       2005      2240      -67       -74        99 No tree         -5.63\n 4 Yes       2014       940      -93        35        50 Tree            -0.15\n 5 No        2014       246       22       -97         5 Tree             2.41\n 6 No        2014       419       86       -49         5 No tree          1.87\n 7 No        2014       308      -70       -70         4 No tree          3.07\n 8 No        2014       302      -31       -94         1 No tree          2.55\n 9 No        2014       340      -54        83        60 No tree          1.29\n10 No        2014       792      -61       -79        30 No tree          0.25\n# ℹ 1,767 more rows\n# ℹ 11 more variables: precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;,\n#   temp_annual_min &lt;dbl&gt;, temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;,\n#   vapor_min &lt;dbl&gt;, vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;,\n#   land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/18-model-selection.html#initial-questions",
    "href": "slides/18-model-selection.html#initial-questions",
    "title": "Model selection for logistic regression",
    "section": "Initial questions",
    "text": "Initial questions\n\nWhat’s the distribution of the outcome, forested?\nWhat’s the distribution of numeric variables like precip_annual?\nHow does the distribution of forested differ across the categorical and numerical variables?\n\n\n\nWhich dataset should we use for the exploration? The entire data forested, the training data forested_train, or the testing data forested_test?"
  },
  {
    "objectID": "slides/18-model-selection.html#forested-1",
    "href": "slides/18-model-selection.html#forested-1",
    "title": "Model selection for logistic regression",
    "section": "forested",
    "text": "forested\nWhat’s the distribution of the outcome, forested?\n\nggplot(forested_train, aes(x = forested)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/18-model-selection.html#forested-2",
    "href": "slides/18-model-selection.html#forested-2",
    "title": "Model selection for logistic regression",
    "section": "forested",
    "text": "forested\nWhat’s the distribution of the outcome, forested?\n\nforested_train |&gt;\n  count(forested) |&gt;\n  mutate(\n    p = n / sum(n)\n  )\n\n# A tibble: 2 × 3\n  forested     n     p\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 Yes       2917 0.547\n2 No        2413 0.453"
  },
  {
    "objectID": "slides/18-model-selection.html#precip_annual",
    "href": "slides/18-model-selection.html#precip_annual",
    "title": "Model selection for logistic regression",
    "section": "precip_annual",
    "text": "precip_annual\nWhat’s the distribution of precip_annual?\n\nggplot(forested_train, aes(x = precip_annual)) +\n  geom_histogram()"
  },
  {
    "objectID": "slides/18-model-selection.html#forested-and-precip_annual",
    "href": "slides/18-model-selection.html#forested-and-precip_annual",
    "title": "Model selection for logistic regression",
    "section": "\nforested and precip_annual\n",
    "text": "forested and precip_annual\n\n\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"identity\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/18-model-selection.html#forested-and-precip_annual-1",
    "href": "slides/18-model-selection.html#forested-and-precip_annual-1",
    "title": "Model selection for logistic regression",
    "section": "\nforested and precip_annual\n",
    "text": "forested and precip_annual\n\n\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"fill\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/18-model-selection.html#forested-and-tree_no_tree",
    "href": "slides/18-model-selection.html#forested-and-tree_no_tree",
    "title": "Model selection for logistic regression",
    "section": "\nforested and tree_no_tree\n",
    "text": "forested and tree_no_tree\n\n\nggplot(forested_train, aes(x = tree_no_tree, fill = forested)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/18-model-selection.html#forested-and-lat-lon",
    "href": "slides/18-model-selection.html#forested-and-lat-lon",
    "title": "Model selection for logistic regression",
    "section": "\nforested and lat / lon\n",
    "text": "forested and lat / lon\n\n\nggplot(forested_train, aes(x = lon, y = lat, color = forested)) +\n  geom_point(alpha = 0.7) +\n  scale_color_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/18-model-selection.html#next-steps-1",
    "href": "slides/18-model-selection.html#next-steps-1",
    "title": "Model selection for logistic regression",
    "section": "Next steps",
    "text": "Next steps\n\n\nFit models on training data\nMake predictions on testing data\n\nEvaluate predictions on testing data:\n\nLinear models: R-squared, adjusted R-squared, RMSE (root mean squared error), etc.\nLogistic models: False negative and positive rates, AUC (area under the curve), etc.\n\n\nMake decisions based on model predictive performance, validity across various testing/training splits (aka “cross validation”), explainability\n\n\n\n\n\n\n\n\n\nNote\n\n\nWe will only learn about a subset of these in this course, but you can go further into these ideas in STA 210 or STA 221 as well as in various machine learning courses."
  },
  {
    "objectID": "slides/18-model-selection.html#ae-14-forest-classification",
    "href": "slides/18-model-selection.html#ae-14-forest-classification",
    "title": "Model selection for logistic regression",
    "section": "ae-14-forest-classification",
    "text": "ae-14-forest-classification\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-14-forest-classification.qmd. You might be prompted to install forested, say yes.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/07-joining-data.html#while-you-wait",
    "href": "slides/07-joining-data.html#while-you-wait",
    "title": "Joining data",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-06-taxes-join\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-06-taxes-join.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/07-joining-data.html#whats-going-on-in-this-plot",
    "href": "slides/07-joining-data.html#whats-going-on-in-this-plot",
    "title": "Joining data",
    "section": "What’s going on in this plot?",
    "text": "What’s going on in this plot?\n\nCan you guess the variable plotted here?"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-taxes-in-us-states",
    "href": "slides/07-joining-data.html#sales-taxes-in-us-states",
    "title": "Joining data",
    "section": "Sales taxes in US states",
    "text": "Sales taxes in US states\n\nsales_taxes\n\n# A tibble: 51 × 5\n   state      state_tax_rate avg_local_tax_rate combined_rate max_local_tax_rate\n   &lt;chr&gt;               &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n 1 Alabama            0.04               0.0529        0.0929             0.075 \n 2 Alaska             0                  0.0182        0.0182             0.0785\n 3 Arizona            0.056              0.0278        0.0838             0.053 \n 4 Arkansas           0.065              0.0295        0.0945             0.0613\n 5 California         0.0725             0.016         0.0885             0.0475\n 6 Colorado           0.029              0.0491        0.0781             0.083 \n 7 Connectic…         0.0635             0             0.0635             0     \n 8 Delaware           0                  0             0                  0     \n 9 Florida            0.06               0.01          0.07               0.02  \n10 Georgia            0.04               0.0338        0.0738             0.05  \n# ℹ 41 more rows"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-swing-states",
    "href": "slides/07-joining-data.html#sales-tax-in-swing-states",
    "title": "Joining data",
    "section": "Sales tax in swing states",
    "text": "Sales tax in swing states\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of swing states (Arizona, Georgia, Michigan, Nevada, North Carolina, Pennsylvania, and Wisconsin) vs. non-swing states.\n\nHow would you approach this task?\n\n\n\nCreate a new variable called swing_state with levels \"Swing\" and \"Non-swing\"\n\nGroup by swing_state\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data.html#ae-06-taxes-join",
    "href": "slides/07-joining-data.html#ae-06-taxes-join",
    "title": "Joining data",
    "section": "ae-06-taxes-join",
    "text": "ae-06-taxes-join\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-06-taxes-join.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/07-joining-data.html#mutate-with-if_else",
    "href": "slides/07-joining-data.html#mutate-with-if_else",
    "title": "Joining data",
    "section": "\nmutate() with if_else()\n",
    "text": "mutate() with if_else()\n\n\nCreate a new variable called swing_state with levels \"Swing\" and \"Non-swing\".\n\n\nlist_of_swing_states &lt;- c(\"Arizona\", \"Georgia\", \"Michigan\", \"Nevada\", \n                          \"North Carolina\", \"Pennsylvania\", \"Wisconsin\")\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    swing_state = if_else(state %in% list_of_swing_states,\n                          \"Swing\",\n                          \"Non-swing\")) |&gt;\n  relocate(swing_state)\n\nsales_taxes\n\n# A tibble: 51 × 6\n   swing_state state       state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;       &lt;chr&gt;                &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Non-swing   Alabama             0.04               0.0529        0.0929\n 2 Non-swing   Alaska              0                  0.0182        0.0182\n 3 Swing       Arizona             0.056              0.0278        0.0838\n 4 Non-swing   Arkansas            0.065              0.0295        0.0945\n 5 Non-swing   California          0.0725             0.016         0.0885\n 6 Non-swing   Colorado            0.029              0.0491        0.0781\n 7 Non-swing   Connecticut         0.0635             0             0.0635\n 8 Non-swing   Delaware            0                  0             0     \n 9 Non-swing   Florida             0.06               0.01          0.07  \n10 Swing       Georgia             0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-if_else",
    "href": "slides/07-joining-data.html#recap-if_else",
    "title": "Joining data",
    "section": "Recap: if_else()\n",
    "text": "Recap: if_else()\n\nif_else(\n1  x == y,\n2  \"x is equal to y\",\n3  \"x is not equal to y\"\n)\n\n1\n\nCondition\n\n2\n\nValue if condition is TRUE\n\n3\n\nValue if condition is FALSE"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-swing-states-1",
    "href": "slides/07-joining-data.html#sales-tax-in-swing-states-1",
    "title": "Joining data",
    "section": "Sales tax in swing states",
    "text": "Sales tax in swing states\n\nCompare the average state sales tax rates of swing states vs. non-swing states.\n\n\nsales_taxes |&gt;\n  group_by(swing_state) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 2 × 2\n  swing_state mean_state_tax\n  &lt;chr&gt;                &lt;dbl&gt;\n1 Non-swing           0.0504\n2 Swing               0.0546"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-coastal-states",
    "href": "slides/07-joining-data.html#sales-tax-in-coastal-states",
    "title": "Joining data",
    "section": "Sales tax in coastal states",
    "text": "Sales tax in coastal states\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of states on the Pacific Coast, states on the Atlantic Coast, and the rest of the states.\n\nHow would you approach this task?\n\n\n\nCreate a new variable called coast with levels \"Pacific\", \"Atlantic\", and \"Neither\"\n\nGroup by coast\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data.html#mutate-with-case_when",
    "href": "slides/07-joining-data.html#mutate-with-case_when",
    "title": "Joining data",
    "section": "\nmutate() with case_when()\n",
    "text": "mutate() with case_when()\n\n\nCreate a new variable called coast with levels \"Pacific\", \"Atlantic\", and \"Neither\".\n\n\npacific_coast &lt;- c(\"Alaska\", \"Washington\", \"Oregon\", \"California\", \"Hawaii\")\n\natlantic_coast &lt;- c(\n  \"Connecticut\", \"Delaware\", \"Georgia\", \"Florida\", \"Maine\", \"Maryland\", \n  \"Massachusetts\", \"New Hampshire\", \"New Jersey\", \"New York\", \n  \"North Carolina\", \"Rhode Island\", \"South Carolina\", \"Virginia\"\n)\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    coast = case_when(\n      state %in% pacific_coast ~ \"Pacific\",\n      state %in% atlantic_coast ~ \"Atlantic\",\n      .default = \"Neither\"\n    )\n  ) |&gt;\n  relocate(coast)\n\nsales_taxes\n\n# A tibble: 51 × 7\n   coast    swing_state state    state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Neither  Non-swing   Alabama          0.04               0.0529        0.0929\n 2 Pacific  Non-swing   Alaska           0                  0.0182        0.0182\n 3 Neither  Swing       Arizona          0.056              0.0278        0.0838\n 4 Neither  Non-swing   Arkansas         0.065              0.0295        0.0945\n 5 Pacific  Non-swing   Califor…         0.0725             0.016         0.0885\n 6 Neither  Non-swing   Colorado         0.029              0.0491        0.0781\n 7 Atlantic Non-swing   Connect…         0.0635             0             0.0635\n 8 Atlantic Non-swing   Delaware         0                  0             0     \n 9 Atlantic Non-swing   Florida          0.06               0.01          0.07  \n10 Atlantic Swing       Georgia          0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-case_when",
    "href": "slides/07-joining-data.html#recap-case_when",
    "title": "Joining data",
    "section": "Recap: case_when()\n",
    "text": "Recap: case_when()\n\ncase_when(\n1  x &gt; y  ~ \"x is greater than y\",\n2  x &lt; y  ~ \"x is less than y\",\n3  .default = \"x is equal to y\"\n)\n\n1\n\nValue if first condition is TRUE\n\n2\n\nValue if second condition is TRUE\n\n3\n\nValue if neither condition is TRUE, i.e., default value"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-coastal-states-1",
    "href": "slides/07-joining-data.html#sales-tax-in-coastal-states-1",
    "title": "Joining data",
    "section": "Sales tax in coastal states",
    "text": "Sales tax in coastal states\n\nCompare the average state sales tax rates of states on the Pacific Coast, states on the Atlantic Coast, and the rest of the states.\n\n\nsales_taxes |&gt;\n  group_by(coast) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 3 × 2\n  coast    mean_state_tax\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Atlantic         0.0484\n2 Neither          0.0545\n3 Pacific          0.0355"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-us-regions",
    "href": "slides/07-joining-data.html#sales-tax-in-us-regions",
    "title": "Joining data",
    "section": "Sales tax in US regions",
    "text": "Sales tax in US regions\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of states in various regions (Midwest - 12 states, Northeast - 9 states, South - 16 states, West - 13 states).\n\nHow would you approach this task?\n\n\n\nCreate a new variable called region with levels \"Midwest\", \"Northeast\", \"South\", and \"West\".\nGroup by region\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data.html#mutate-with-case_when-1",
    "href": "slides/07-joining-data.html#mutate-with-case_when-1",
    "title": "Joining data",
    "section": "\nmutate() with case_when()\n",
    "text": "mutate() with case_when()\n\n\nWho feels like filling in the blanks lists of states in each region? Who feels like it’s simply too tedious to write out names of all states?\n\n\nlist_of_midwest_states &lt;- c(___)\nlist_of_northeast_states &lt;- c(___)\nlist_of_south_states &lt;- c(___)\nlist_of_west_states &lt;- c(___)\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    coast = case_when(\n      state %in% list_of_west_states ~ \"Midwest\",\n      state %in% list_of_northeast_states ~ \"Northeast\",\n      state %in% list_of_south_states ~ \"South\",\n      state %in% list_of_west_states ~ \"West\"\n    )\n  )"
  },
  {
    "objectID": "slides/07-joining-data.html#why-join",
    "href": "slides/07-joining-data.html#why-join",
    "title": "Joining data",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nIs there a relationship between\n- number of QS courses taken\n- having scored a 4 or 5 on the AP stats exam\n- motivation for taking course\n- …\nand performance in this course?”\n\n\nEach of these would require joining class performance data with an outside data source so we can have all relevant information (columns) in a single data frame."
  },
  {
    "objectID": "slides/07-joining-data.html#why-join-1",
    "href": "slides/07-joining-data.html#why-join-1",
    "title": "Joining data",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nCompare the average state sales tax rates of states in various regions (Midwest - 12 states, Northeast - 9 states, South - 16 states, West - 13 states).\n\n\nThis can also be solved with joining region information with the state-level sales tax data."
  },
  {
    "objectID": "slides/07-joining-data.html#setup",
    "href": "slides/07-joining-data.html#setup",
    "title": "Joining data",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n\n\n\nx &lt;- tibble(\n  id = c(1, 2, 3),\n  value_x = c(\"x1\", \"x2\", \"x3\")\n  )\n\nx\n\n# A tibble: 3 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny &lt;- tibble(\n  id = c(1, 2, 4),\n  value_y = c(\"y1\", \"y2\", \"y4\")\n  )\n\ny\n\n# A tibble: 3 × 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/07-joining-data.html#left_join",
    "href": "slides/07-joining-data.html#left_join",
    "title": "Joining data",
    "section": "left_join()",
    "text": "left_join()\n\n\n\n\n\nleft_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#right_join",
    "href": "slides/07-joining-data.html#right_join",
    "title": "Joining data",
    "section": "right_join()",
    "text": "right_join()\n\n\n\n\n\nright_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data.html#full_join",
    "href": "slides/07-joining-data.html#full_join",
    "title": "Joining data",
    "section": "full_join()",
    "text": "full_join()\n\n\n\n\n\nfull_join(x, y)\n\n# A tibble: 4 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data.html#inner_join",
    "href": "slides/07-joining-data.html#inner_join",
    "title": "Joining data",
    "section": "inner_join()",
    "text": "inner_join()\n\n\n\n\n\ninner_join(x, y)\n\n# A tibble: 2 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2"
  },
  {
    "objectID": "slides/07-joining-data.html#semi_join",
    "href": "slides/07-joining-data.html#semi_join",
    "title": "Joining data",
    "section": "semi_join()",
    "text": "semi_join()\n\n\n\n\n\nsemi_join(x, y)\n\n# A tibble: 2 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2"
  },
  {
    "objectID": "slides/07-joining-data.html#anti_join",
    "href": "slides/07-joining-data.html#anti_join",
    "title": "Joining data",
    "section": "anti_join()",
    "text": "anti_join()\n\n\n\n\n\nanti_join(x, y)\n\n# A tibble: 1 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     3 x3"
  },
  {
    "objectID": "slides/07-joining-data.html#summary",
    "href": "slides/07-joining-data.html#summary",
    "title": "Joining data",
    "section": "Summary",
    "text": "Summary"
  },
  {
    "objectID": "slides/lab-7.html#lab-7-overview",
    "href": "slides/lab-7.html#lab-7-overview",
    "title": "Lab 7",
    "section": "Lab 7 Overview",
    "text": "Lab 7 Overview\n\nPart 1: all things logistic regression\nPart 2: a data science assessment survey"
  },
  {
    "objectID": "slides/lab-7.html#data-science-reasoning-assessment-1",
    "href": "slides/lab-7.html#data-science-reasoning-assessment-1",
    "title": "Lab 7",
    "section": "Data Science Reasoning Assessment",
    "text": "Data Science Reasoning Assessment\n\n\nThe goal of this data science assessment, to accurately measure introductory data science students’ reasoning skills.\nYou will be graded based on completion + honest effort. This assessment is not optional. This is meant to be an individual, closed notes assessment.\n\nAt the end, you will be asked if your anonymized responses can be used to help better improve this assessment.\n\nYour responses matter!\nThe goal of this assessment is to be a national data science reasoning assessment for introductory courses\nThis starts with improving questions based on your responses"
  },
  {
    "objectID": "slides/lab-7.html#forested-data",
    "href": "slides/lab-7.html#forested-data",
    "title": "Lab 7",
    "section": "\nforested data",
    "text": "forested data\n\n\n7107 rows and 19 columns;\nEach observation (row) is a plot of land;\nVariables include geographical and meteorological information about each plot, as well as a binary indicator forested (“Yes” or “No”);\nGiven information about a plot that is easy (and cheap) to collect remotely, can we use a model to predict if a plot is forested without actually visiting it (which could be difficult and costly)?"
  },
  {
    "objectID": "slides/lab-7.html#goal",
    "href": "slides/lab-7.html#goal",
    "title": "Lab 7",
    "section": "Goal",
    "text": "Goal\n\n\nUse the data we’ve already seen to predict if a yet-to-be-observed plot of land is forested;\nWe want a model that does well on data it has never seen before;\n“Out-of-sample” predictions on new data are more useful than “in-sample” predictions on old data;"
  },
  {
    "objectID": "slides/lab-7.html#training-versus-testing-data",
    "href": "slides/lab-7.html#training-versus-testing-data",
    "title": "Lab 7",
    "section": "Training versus testing data",
    "text": "Training versus testing data\nTo mimic this “out-of-sample” idea, we randomly split the data into two parts:\n\n\ntraining data: this is what the model gets to see when we fit it;\n\ntest data: withheld. We assess how well the trained model can predict on this data it hasn’t seen before."
  },
  {
    "objectID": "slides/lab-7.html#randomly-split-data-into-training-and-test-sets",
    "href": "slides/lab-7.html#randomly-split-data-into-training-and-test-sets",
    "title": "Lab 7",
    "section": "Randomly split data into training and test sets",
    "text": "Randomly split data into training and test sets\nBy default it’s a 75%/25% training/test split.\n\nset.seed(8675309)\n\nforested_split &lt;- initial_split(forested)\n\nforested_train &lt;- training(forested_split)\nforested_test &lt;- testing(forested_split)\n\nThe split is random, but we want the results to be reproducible, so we “freeze the random numbers in time” by setting a seed. If we don’t tell you exactly what seed to use on an assignment, you can pick any positive integer you want."
  },
  {
    "objectID": "slides/lab-7.html#explore-forested-or-not",
    "href": "slides/lab-7.html#explore-forested-or-not",
    "title": "Lab 7",
    "section": "Explore: forested or not",
    "text": "Explore: forested or not\n\nggplot(forested_train, aes(x = lon, y = lat, color = forested)) +\n  geom_point(alpha = 0.7) +\n  scale_color_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/lab-7.html#explore-annual-precipitation",
    "href": "slides/lab-7.html#explore-annual-precipitation",
    "title": "Lab 7",
    "section": "Explore: annual precipitation",
    "text": "Explore: annual precipitation\n\nggplot(forested_train, aes(x = lon, y = lat, color = precip_annual)) +\n  geom_point(alpha = 0.7) +\n  labs(color = \"annual\\nprecipitation\\n(mm × 100)\") +\n  theme_minimal()"
  },
  {
    "objectID": "slides/lab-7.html#fyi-the-response-variable-must-be-a-factor",
    "href": "slides/lab-7.html#fyi-the-response-variable-must-be-a-factor",
    "title": "Lab 7",
    "section": "FYI: the response variable must be a factor",
    "text": "FYI: the response variable must be a factor\nforested already comes as a factor, so we’re lucky:\n\nclass(forested$forested)\n\n[1] \"factor\"\n\nlevels(forested$forested)\n\n[1] \"Yes\" \"No\" \n\n\n\nBut if it didn’t, things would not work:\n\nlogistic_reg() |&gt;\n  fit(as.numeric(forested) ~ precip_annual, data = forested_train)\n\nError in `check_outcome()`:\n! For a classification model, the outcome should be a `factor`, not a `numeric`."
  },
  {
    "objectID": "slides/lab-7.html#fyi-the-base-level-is-treated-as-failure-0",
    "href": "slides/lab-7.html#fyi-the-base-level-is-treated-as-failure-0",
    "title": "Lab 7",
    "section": "FYI: the base level is treated as “failure” (0)",
    "text": "FYI: the base level is treated as “failure” (0)\nThe base level here is “Yes”, so “No” is treated as “success” (1):\n\nlevels(forested$forested)\n\n[1] \"Yes\" \"No\" \n\n\n\nAs a result, this code:\n\nlogistic_reg() |&gt;\n  fit(forested ~ precip_annual, data = forested_train)\n\n\n\nCorresponds to this model:\n\\[\n\\text{Prob}(\n\\texttt{forested = \"No\"}\n)\n=\n\\frac{e^{\\beta_0+\\beta_1 x}}{1 + e^{\\beta_0+\\beta_1 x}}.\n\\]\n\n\nThis is not a problem, but it means that in order to interpret the output correctly, you need to understand how your factors are leveled."
  },
  {
    "objectID": "slides/lab-7.html#fitting-a-logistic-regression-model",
    "href": "slides/lab-7.html#fitting-a-logistic-regression-model",
    "title": "Lab 7",
    "section": "Fitting a logistic regression model",
    "text": "Fitting a logistic regression model\nSimilar syntax to linear regression:\n\nforested_precip_fit &lt;- logistic_reg() |&gt;\n  fit(forested ~ precip_annual, data = forested_train)\n\ntidy(forested_precip_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic   p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    1.57    0.0557         28.2 6.89e-175\n2 precip_annual -0.00190 0.0000602     -31.6 5.98e-219\n\n\n\n\\[\n\\log\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)\n=\n1.57\n-\n0.0019\n\\times\nprecip.\n\\]"
  },
  {
    "objectID": "slides/lab-7.html#interpreting-the-intercept",
    "href": "slides/lab-7.html#interpreting-the-intercept",
    "title": "Lab 7",
    "section": "Interpreting the intercept",
    "text": "Interpreting the intercept\n\\[\n\\begin{aligned}\n\\log\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)\n&=\n1.57\n-\n0.0019\n\\times\nprecip\\\\\n\\frac{\\hat{p}}{1-\\hat{p}}\n&=\ne^{1.57\n-\n0.0019\n\\times\nprecip}\n.\n\\end{aligned}\n\\]\nSo when \\(precip = 0\\), the model predicts that the odds of forested = \"No\" are \\(e^{1.57}\\approx 4.8\\), on average."
  },
  {
    "objectID": "slides/lab-7.html#interpreting-the-slope",
    "href": "slides/lab-7.html#interpreting-the-slope",
    "title": "Lab 7",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\nAt \\(precip\\):\n\\[\n\\frac{\\hat{p}}{1-\\hat{p}}\n=\n{\\color{blue}{e^{1.57\n-\n0.0019\n\\times\nprecip}}}\n\\]\n\nAt \\(precip + 1\\):\n\\[\n\\begin{aligned}\n\\frac{\\hat{p}}{1-\\hat{p}}\n&=\ne^{1.57\n-\n0.0019\n\\times\n(precip + 1)}\n\\\\\n&=\ne^{1.57\n-\n0.0019\n\\times\nprecip - 0.0019}\n\\\\\n&=\n{\\color{blue}{e^{1.57\n-\n0.0019\n\\times\nprecip}}}\n\\times\n\\color{red}{e^{-0.0019}}\n\\end{aligned}\n\\]\n\n\nIf \\(precip\\) increases by one unit, the model predicts a decrease in the odds that forested = \"No\" by a multiplicative factor of \\(e^{-0.0019}\\approx 0.99\\), on average."
  },
  {
    "objectID": "slides/lab-7.html#generate-predictions-for-the-test-data",
    "href": "slides/lab-7.html#generate-predictions-for-the-test-data",
    "title": "Lab 7",
    "section": "Generate predictions for the test data",
    "text": "Generate predictions for the test data\nAugment the test data frame with three new columns on the left that include model predictions (classifications and probabilities) for each row:\n\nforested_precip_aug &lt;- augment(forested_precip_fit, forested_test)\nforested_precip_aug\n\n# A tibble: 1,777 × 22\n   .pred_class .pred_Yes .pred_No forested  year elevation eastness northness\n   &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes             0.711  0.289   No        2005       164      -84        53\n 2 Yes             0.968  0.0319  Yes       2003      1031      -49        86\n 3 Yes             0.992  0.00806 Yes       2005      1330       99         7\n 4 No              0.266  0.734   No        2014       507       44       -89\n 5 No              0.263  0.737   No        2014       542      -32       -94\n 6 No              0.267  0.733   No        2014       759       -2       -99\n 7 No              0.232  0.768   No        2014       119        0         0\n 8 No              0.241  0.759   No        2014       419       86       -49\n 9 No              0.336  0.664   Yes       2014       569      -97       -21\n10 No              0.279  0.721   No        2014       340      -54        83\n# ℹ 1,767 more rows\n# ℹ 14 more variables: roughness &lt;dbl&gt;, tree_no_tree &lt;fct&gt;, dew_temp &lt;dbl&gt;,\n#   precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/lab-7.html#how-did-the-model-perform",
    "href": "slides/lab-7.html#how-did-the-model-perform",
    "title": "Lab 7",
    "section": "How did the model perform?",
    "text": "How did the model perform?\nThese are the four possibilities:\n\n\n\n\n\nOur test data have the truth in the forested column;\nWe can compare the predictions in .pred_class to the true values and see how we did."
  },
  {
    "objectID": "slides/lab-7.html#getting-the-error-rates",
    "href": "slides/lab-7.html#getting-the-error-rates",
    "title": "Lab 7",
    "section": "Getting the error rates",
    "text": "Getting the error rates\n\nforested_precip_aug |&gt;\n  count(forested, .pred_class) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = n / sum(n),\n    decision = case_when(\n      forested == \"Yes\" & .pred_class == \"Yes\" ~ \"sensitivity\",\n      forested == \"Yes\" & .pred_class == \"No\" ~ \"false negative\",\n      forested == \"No\" & .pred_class == \"Yes\" ~ \"false positive\",\n      forested == \"No\" & .pred_class == \"No\" ~ \"specificity\",\n    )\n  )\n\n# A tibble: 4 × 5\n# Groups:   forested [2]\n  forested .pred_class     n     p decision      \n  &lt;fct&gt;    &lt;fct&gt;       &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 Yes      Yes           683 0.702 sensitivity   \n2 Yes      No            290 0.298 false negative\n3 No       Yes           140 0.174 false positive\n4 No       No            664 0.826 specificity"
  },
  {
    "objectID": "slides/lab-7.html#fyi-the-default-threshold-is-50",
    "href": "slides/lab-7.html#fyi-the-default-threshold-is-50",
    "title": "Lab 7",
    "section": "FYI: the default threshold is 50%",
    "text": "FYI: the default threshold is 50%\n\nThe model produces probabilities: .pred_Yes and .pred_No;\nThe concrete classifications in the .pred_class column come from applying a 50% threshold to these probabilities:\n\n\\[\n\\widehat{\\texttt{forested}}=\n\\begin{cases}\n\\texttt{\"No\"} & \\texttt{.pred\\_Yes} \\leq 0.5\\\\\n\\texttt{\"Yes\"} & \\texttt{.pred\\_Yes} &gt; 0.5.\n\\end{cases}\n\\]\n\nIf you want to override that default, you must do so manually."
  },
  {
    "objectID": "slides/lab-7.html#change-threshold-to-0.00",
    "href": "slides/lab-7.html#change-threshold-to-0.00",
    "title": "Lab 7",
    "section": "Change threshold to 0.00",
    "text": "Change threshold to 0.00\nNew threshold &gt; New classifications &gt; New error rates\n\nforested_precip_aug |&gt;\n  mutate(\n    .pred_class = if_else(.pred_Yes &lt;= 0.0, \"No\", \"Yes\")\n  ) |&gt;\n  count(forested, .pred_class) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = n / sum(n),\n  )\n\n# A tibble: 2 × 4\n# Groups:   forested [2]\n  forested .pred_class     n     p\n  &lt;fct&gt;    &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;\n1 Yes      Yes           973     1\n2 No       Yes           804     1"
  },
  {
    "objectID": "slides/lab-7.html#change-threshold-to-0.25",
    "href": "slides/lab-7.html#change-threshold-to-0.25",
    "title": "Lab 7",
    "section": "Change threshold to 0.25",
    "text": "Change threshold to 0.25\nNew threshold &gt; New classifications &gt; New error rates\n\nforested_precip_aug |&gt;\n  mutate(\n    .pred_class = if_else(.pred_Yes &lt;= 0.25, \"No\", \"Yes\")\n  ) |&gt;\n  count(forested, .pred_class) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = n / sum(n),\n  )\n\n# A tibble: 3 × 4\n# Groups:   forested [2]\n  forested .pred_class     n     p\n  &lt;fct&gt;    &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;\n1 Yes      Yes           973 1    \n2 No       No            179 0.223\n3 No       Yes           625 0.777"
  },
  {
    "objectID": "slides/lab-7.html#change-threshold-to-0.50",
    "href": "slides/lab-7.html#change-threshold-to-0.50",
    "title": "Lab 7",
    "section": "Change threshold to 0.50",
    "text": "Change threshold to 0.50\nNew threshold &gt; New classifications &gt; New error rates\n\nforested_precip_aug |&gt;\n  mutate(\n    .pred_class = if_else(.pred_Yes &lt;= 0.50, \"No\", \"Yes\")\n  ) |&gt;\n  count(forested, .pred_class) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = n / sum(n),\n  )\n\n# A tibble: 4 × 4\n# Groups:   forested [2]\n  forested .pred_class     n     p\n  &lt;fct&gt;    &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;\n1 Yes      No            290 0.298\n2 Yes      Yes           683 0.702\n3 No       No            664 0.826\n4 No       Yes           140 0.174"
  },
  {
    "objectID": "slides/lab-7.html#change-threshold-to-0.75",
    "href": "slides/lab-7.html#change-threshold-to-0.75",
    "title": "Lab 7",
    "section": "Change threshold to 0.75",
    "text": "Change threshold to 0.75\nNew threshold &gt; New classifications &gt; New error rates\n\nforested_precip_aug |&gt;\n  mutate(\n    .pred_class = if_else(.pred_Yes &lt;= 0.75, \"No\", \"Yes\")\n  ) |&gt;\n  count(forested, .pred_class) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = n / sum(n),\n  )\n\n# A tibble: 4 × 4\n# Groups:   forested [2]\n  forested .pred_class     n      p\n  &lt;fct&gt;    &lt;chr&gt;       &lt;int&gt;  &lt;dbl&gt;\n1 Yes      No            474 0.487 \n2 Yes      Yes           499 0.513 \n3 No       No            731 0.909 \n4 No       Yes            73 0.0908"
  },
  {
    "objectID": "slides/lab-7.html#change-threshold-to-1.00",
    "href": "slides/lab-7.html#change-threshold-to-1.00",
    "title": "Lab 7",
    "section": "Change threshold to 1.00",
    "text": "Change threshold to 1.00\nNew threshold &gt; New classifications &gt; New error rates\n\nforested_precip_aug |&gt;\n  mutate(\n    .pred_class = if_else(.pred_Yes &lt;= 1.00, \"No\", \"Yes\")\n  ) |&gt;\n  count(forested, .pred_class) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = n / sum(n),\n  )\n\n# A tibble: 2 × 4\n# Groups:   forested [2]\n  forested .pred_class     n     p\n  &lt;fct&gt;    &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;\n1 Yes      No            973     1\n2 No       No            804     1"
  },
  {
    "objectID": "slides/lab-7.html#picture-how-errors-change-with-threshold-th",
    "href": "slides/lab-7.html#picture-how-errors-change-with-threshold-th",
    "title": "Lab 7",
    "section": "Picture how errors change with threshold (th)",
    "text": "Picture how errors change with threshold (th)"
  },
  {
    "objectID": "slides/lab-7.html#picture-how-errors-change-with-threshold-th-1",
    "href": "slides/lab-7.html#picture-how-errors-change-with-threshold-th-1",
    "title": "Lab 7",
    "section": "Picture how errors change with threshold (th)",
    "text": "Picture how errors change with threshold (th)"
  },
  {
    "objectID": "slides/lab-7.html#but-that-was-tedious",
    "href": "slides/lab-7.html#but-that-was-tedious",
    "title": "Lab 7",
    "section": "But that was tedious",
    "text": "But that was tedious\nLet’s do “all” of the thresholds and connect the dots:\n\nforested_precip_roc &lt;- roc_curve(forested_precip_aug, \n                                 truth = forested, \n                                 .pred_Yes, \n                                 event_level = \"first\")\nforested_precip_roc\n\n# A tibble: 1,180 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1   -Inf         0                 1\n 2      0.224     0                 1\n 3      0.225     0.00124           1\n 4      0.228     0.00249           1\n 5      0.228     0.00498           1\n 6      0.229     0.00622           1\n 7      0.229     0.00746           1\n 8      0.230     0.00995           1\n 9      0.230     0.0124            1\n10      0.231     0.0137            1\n# ℹ 1,170 more rows"
  },
  {
    "objectID": "slides/lab-7.html#the-roc-curve",
    "href": "slides/lab-7.html#the-roc-curve",
    "title": "Lab 7",
    "section": "The ROC curve",
    "text": "The ROC curve\n\nggplot(forested_precip_roc, aes(x = 1 - specificity, y = sensitivity)) +\n  geom_path() +\n  geom_abline(lty = 3) +\n  coord_equal() + \n  theme_minimal()"
  },
  {
    "objectID": "slides/lab-7.html#the-roc-curve-1",
    "href": "slides/lab-7.html#the-roc-curve-1",
    "title": "Lab 7",
    "section": "The ROC curve",
    "text": "The ROC curve\n\n\nROC stands for receiver operating characteristic;\nThis visualizes the classification accuracy across a range of thresholds;\nThe more “up and to the left” it is, the better.\nWe can quantify “up and to the left” with the area under the curve (AUC)."
  },
  {
    "objectID": "slides/lab-7.html#the-roc-curve-2",
    "href": "slides/lab-7.html#the-roc-curve-2",
    "title": "Lab 7",
    "section": "The ROC curve",
    "text": "The ROC curve"
  },
  {
    "objectID": "slides/lab-7.html#auc-1",
    "href": "slides/lab-7.html#auc-1",
    "title": "Lab 7",
    "section": "AUC = 1",
    "text": "AUC = 1\nThis is the best we could possibly do:"
  },
  {
    "objectID": "slides/lab-7.html#auc-1-2",
    "href": "slides/lab-7.html#auc-1-2",
    "title": "Lab 7",
    "section": "AUC = 1 / 2",
    "text": "AUC = 1 / 2\nDon’t waste time fitting a model. Just flip a coin:"
  },
  {
    "objectID": "slides/lab-7.html#auc-0",
    "href": "slides/lab-7.html#auc-0",
    "title": "Lab 7",
    "section": "AUC = 0",
    "text": "AUC = 0\nThis is the worst we could possibly do:"
  },
  {
    "objectID": "slides/lab-7.html#auc-for-the-model-we-fit",
    "href": "slides/lab-7.html#auc-for-the-model-we-fit",
    "title": "Lab 7",
    "section": "AUC for the model we fit",
    "text": "AUC for the model we fit\n\nroc_auc(\n  forested_precip_aug, \n  truth = forested, \n  .pred_Yes, \n  event_level = \"first\"\n)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.879\n\n\nNot bad!"
  },
  {
    "objectID": "slides/lab-7.html#the-area-under-the-roc-curve",
    "href": "slides/lab-7.html#the-area-under-the-roc-curve",
    "title": "Lab 7",
    "section": "The area under the ROC curve",
    "text": "The area under the ROC curve\n\n\nThis is a “quality score” for a logistic regression model;\nWhen you compute it for a test data set that you set aside, the AUC is a measure of out-of-sample prediction accuracy;\nAUC is a number between 0 and 1, where 0 is awful and 1 is great, similar to \\(R^2\\) for linear regression.\nThe function roc_auc computes it for you, and it takes the same set of arguments as roc_curve."
  },
  {
    "objectID": "slides/lab-7.html#new-commands-introduced-last-week",
    "href": "slides/lab-7.html#new-commands-introduced-last-week",
    "title": "Lab 7",
    "section": "New commands introduced last week",
    "text": "New commands introduced last week\n\nlogistic_reg\naugment\nroc_curve\nroc_auc\nset.seed\n\ninitial_split, training, test\n\ngeom_path\n\nYou will use them all on Lab 7, and they should go on your Midterm 2 cheat sheet."
  },
  {
    "objectID": "slides/lab-4.html#while-you-wait-get-your-repo-ready",
    "href": "slides/lab-4.html#while-you-wait-get-your-repo-ready",
    "title": "Lab 4",
    "section": "While you wait… get your repo ready",
    "text": "While you wait… get your repo ready\n\n\n\nLog in to RStudio (via your container)\n\nGo to https://cmgr.oit.duke.edu/containers and click STA198-199\n\n\n\n\nClone the repo & start a new RStudio project\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-4.\nClick on the green CODE button and select Use SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git to clone your Lab 4 repo.\n\n\n\nUpdate the YAML\n\nIn lab-4.qmd, update the author field to your name, Render your document, and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, Push the changes to your GitHub repository and, in your browser, confirm that these changes have indeed propagated to your repository.\n\n\n\n\nShould look at Marie’s notes again (from email on 1/22/25). There are more notes there to incorporate, especially in earlier labs with the motivation."
  },
  {
    "objectID": "slides/lab-4.html#a-review",
    "href": "slides/lab-4.html#a-review",
    "title": "Lab 4",
    "section": "A review",
    "text": "A review\nYou have learned a lot thus far\n\nGit/GitHub\n\nR\n\n\nPlot related functions\nggplot(), aes(), geom_boxplot(), geom_point(), geom_histogram(), geom_smooth(), geom_line(), geom_beeswarm(), labs(), theme_minimal(), theme() scale_x_continuous(), scale_color_manual()\n\n\nMore functions\nglimpse(), nrow(), ncol(), dim(), slice_head(), filter(), arrange(), relocate(), if_else(), case_when(), count(), group_by(), ungroup(), read_csv(), separate(), mutate(), summarize(), pivot_*(), *_join()\n\n\n\n\nGit/Github: had lots of practice pulling, committing and pushing changes to update your repos on GitHub.\nR: These functions were taken from ae-02 to ae-06 and the prepare videos (a good places to practice and refresh what you’ve learned).\n(optional, may not be enough time – can transition by stating let’s talk about a few of these in more detail) Have students raise hands to ask state these functions do (with an emphasis on those under more functions) – just for 5 or so functions. Hopefully, multiple students raise their hands. Otherwise you can simply move on.\nTransition: now let’s do a more thorough review of some of these functions"
  },
  {
    "objectID": "slides/lab-4.html#mutate-and-summarize",
    "href": "slides/lab-4.html#mutate-and-summarize",
    "title": "Lab 4",
    "section": "\nmutate() and summarize()\n",
    "text": "mutate() and summarize()\n\n \n \n\n\nmutate(): modifies existing data frame – creates new columns (i.e., variables) or modifies existing columns. Note that the number of rows does not change.\n\n \n\n\nsummarize(): creates a new data frame – returns one for for each combination of grouping variables. If there is no grouping it will have a single row summarizing all observations"
  },
  {
    "objectID": "slides/lab-4.html#example-set-up",
    "href": "slides/lab-4.html#example-set-up",
    "title": "Lab 4",
    "section": "Example: Set up",
    "text": "Example: Set up\n\nlibrary(tidyverse)\nlibrary(knitr)\n\ndf &lt;- tibble(\n  col_1 = c(\"A\", \"A\", \"A\", \"B\", \"B\"),\n  col_2 = c(\"X\", \"Y\", \"X\", \"X\", \"Y\"),\n  col_3 = c(1, 2, 3, 4, 5)\n)\n\ndf #this is used to display the data frame\n\n# A tibble: 5 × 3\n  col_1 col_2 col_3\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     X         1\n2 A     Y         2\n3 A     X         3\n4 B     X         4\n5 B     Y         5\n\n\n\nWhat would be the result of the following code? # rows? # cols? column/variable names?\n\ndf |&gt;\n  mutate(med_col_3 = median(col_3))\n\n\ndf |&gt;\n  summarize(med_col_3 = median(col_3))\n\nHAVE THE STUDENTS GUESS how many rows, columns, what the variable names will be?\nmutate: number of rows does not change, number of columns increases by 1 (med_col_3). Could have also introduced more new variables within the mutate function using commas,\n\ndf |&gt;\n  mutate(\n    med_col_3 = median(col_3),\n    mean_col_3 = mean(col_3)\n    )\n\nsummarize: there is only 1 row and 1 col! (this is a much different data frame than df!). Could have had more columns/variables if added more variables within summarize function using commas. [same as above, just replace mutate with summarize]\nassignment: have the students guess"
  },
  {
    "objectID": "slides/lab-4.html#example-no-groups",
    "href": "slides/lab-4.html#example-no-groups",
    "title": "Lab 4",
    "section": "Example: no groups",
    "text": "Example: no groups\nmutate()\n\ndf |&gt;\n  mutate(med_col_3 = median(col_3))\n\n# A tibble: 5 × 4\n  col_1 col_2 col_3 med_col_3\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 A     X         1         3\n2 A     Y         2         3\n3 A     X         3         3\n4 B     X         4         3\n5 B     Y         5         3\n\n\n\nsummarize()\n\ndf |&gt;\n  summarize(med_col_3 = median(col_3))\n\n# A tibble: 1 × 1\n  med_col_3\n      &lt;dbl&gt;\n1         3\n\n\n\n\nWe did not assign any new or existing data frames (e.g., no ??? &lt;-). In particular, we did not write over df (i.e., no df &lt;-), so what will be the result of the following code?\n\ndf\n\nmutate: there was no column named med_col_3, so a new column was created\nsummarize: there is no grouping, so there is one output summarizing so the median is computed over all of the original rows of the data (five rows in this example)\nassignment: have the students guess"
  },
  {
    "objectID": "slides/lab-4.html#example-assignment",
    "href": "slides/lab-4.html#example-assignment",
    "title": "Lab 4",
    "section": "Example: assignment",
    "text": "Example: assignment\n\nIt’s the same as when it was originally assigned. It has not been overwritten!\n\n\ndf \n\n# A tibble: 5 × 3\n  col_1 col_2 col_3\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     X         1\n2 A     Y         2\n3 A     X         3\n4 B     X         4\n5 B     Y         5\n\n\n\n\nWe will often write a single pipeline and show the result, i.e., no assignment.\n\nIf you will need to refer to the data frame later, it might be a good idea to assign a name to the data frame. Otherwise, see the result and continue on.\nNote: if you assign the new/updated data frame, the result does not appear in the Console or the rendered document! (Type the name of the variable, e.g., df as shown above, to display the data frame.)"
  },
  {
    "objectID": "slides/lab-4.html#example-with-groups",
    "href": "slides/lab-4.html#example-with-groups",
    "title": "Lab 4",
    "section": "Example: with groups",
    "text": "Example: with groups\nWhat if there is grouping?\n\n# group by 1 variable\ndf |&gt;\n  group_by(col_1) |&gt;\n  mutate(med_col_3 = median(col_3))\n\n\ndf |&gt;\n  group_by(col_1) |&gt;\n  summarize(med_col_3 = median(col_3))\n\n# group by 2 variables\ndf |&gt;\n  group_by(col_1, col_2) |&gt;\n  mutate(med_col_3 = median(col_3))\n\n\ndf |&gt;\n  group_by(col_1, col_2) |&gt;\n  summarize(med_col_3 = median(col_3))\n\n\nIf you aren’t sure, try it out and see what happens (e.g., use data frame from Lab 3, Part 1).\nI would have written this out in Lab 3 prep. But there is other stuff to get to for Lab 4 prep that I didn’t want this to take up too much of the time. Plus, by now they saw what happened already in Lab 3.\nAlso, make a comment about the grouping when expanding upon this next semester."
  },
  {
    "objectID": "slides/lab-4.html#pivot_",
    "href": "slides/lab-4.html#pivot_",
    "title": "Lab 4",
    "section": "pivot_*()",
    "text": "pivot_*()\n\nPivoting reshapes the data frame.\npivot_longer makes the updated data frame longer (i.e., fewer columns)\npivot_wider makes the updated data frame wider (i.e., more columns)"
  },
  {
    "objectID": "slides/lab-4.html#example-pivot_",
    "href": "slides/lab-4.html#example-pivot_",
    "title": "Lab 4",
    "section": "Example: pivot_*()\n",
    "text": "Example: pivot_*()\n\nLet’s examine the number of hours people slept during the week.\n\n\n\n\nHow do we go from this…\n\n\n\n\n\nppl\nMon\nTues\nWeds\nThurs\nFri\n\n\n\nperson1\n8\n7\n6\n10\n8\n\n\nperson2\n7\n5\n4\n6\n7\n\n\n\n\n\n\n\n…to this?\n\n\n\n\n\nppl\nday\nhours\n\n\n\nperson1\nMon\n8\n\n\nperson1\nTues\n7\n\n\nperson1\nWeds\n6\n\n\nperson1\nThurs\n10\n\n\nperson1\nFri\n8\n\n\nperson2\nMon\n7\n\n\nperson2\nTues\n5\n\n\nperson2\nWeds\n4\n\n\nperson2\nThurs\n6\n\n\nperson2\nFri\n7\n\n\n\n\n\n\n\n\n\n\ndf_longer &lt;- df |&gt;\n  pivot_longer(\n    cols = -ppl,\n    names_to = \"day\",\n    values_to = \"hours\"\n  )\n\npivot_longer() or pivot_wider()? Have the students vote. pivot_longer()!\nWhat should the arguments be? (Go through the argument discussion first, then reveal the result toward the end – giving them enough time to look at it for visual learners)\ncols = -ppl: cols – the columns to be pivoted (i.e., stacked into rows). in this case all of the columns except ppl (ppl column/variable remains)\nnames_to = \"day\": names_to – the new column/variable name for the original column/variable names [point to the Mon, Tues, Weds, … in the original table]\nvalues_to = \"hours\": names_to – the new column/variable name for the values from the original data [point to the hours of sleep in the original table]\nNote that the column/variable names “day” and “hours” did not exist until using pivot_longer()\nQuestion: What if I hadn’t assigned the result to df_longer? What would the display look like and what would the df data frame be if I had deleted the df_longer &lt;- portion of the code?\nAnswer: The console would show the data frame df_longer (though it wouldn’t be named – it would just read # A tibble: 10 x 3 and so on), and df remains unchanged. It’s the same wide (2 x 6) tibble it originally was defined as."
  },
  {
    "objectID": "slides/lab-4.html#join",
    "href": "slides/lab-4.html#join",
    "title": "Lab 4",
    "section": "*_join()",
    "text": "*_join()\n\n\nTypically we use *_join() to merge data from two data frames (e.g., left_join(), right_join(), full_join(), inner_join()), i.e., create a new data frames with more columns/variables.\nFor example, there is useful info in two data frames: x and y. We want to create a new data frame which includes variables from both (e.g., data frame x has student ID numbers and student names and data frame y has student ID numbers and email addresses).\n\n\n\n\nSometimes we use *_join() to filter rows/observations, e.g., find the rows from one data frame that do (or do not) exist in another data frame (e.g., semi_join(), anti_join())\n\n\n\n\nLet’s focus on the joins that merge data…"
  },
  {
    "objectID": "slides/lab-4.html#example-_join-setup",
    "href": "slides/lab-4.html#example-_join-setup",
    "title": "Lab 4",
    "section": "Example: *_join() setup",
    "text": "Example: *_join() setup\nFor the next few slides…\n\n\n\nx &lt;- tibble(\n  id = c(1, 2, 3),\n  value_x = c(\"x1\", \"x2\", \"x3\")\n  )\n\nx\n\n# A tibble: 3 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny &lt;- tibble(\n  id = c(1, 2, 4),\n  value_y = c(\"y1\", \"y2\", \"y4\")\n  )\n\ny\n\n# A tibble: 3 × 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/lab-4.html#left_join",
    "href": "slides/lab-4.html#left_join",
    "title": "Lab 4",
    "section": "left_join()",
    "text": "left_join()\n\n\n\n\n\nleft_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n\n\n\n\nKeep all rows from left data frame."
  },
  {
    "objectID": "slides/lab-4.html#right_join",
    "href": "slides/lab-4.html#right_join",
    "title": "Lab 4",
    "section": "right_join()",
    "text": "right_join()\n\n\n\n\n\nright_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     4 &lt;NA&gt;    y4     \n\n\n\n\n  Keep all rows from right data frame."
  },
  {
    "objectID": "slides/lab-4.html#full_join",
    "href": "slides/lab-4.html#full_join",
    "title": "Lab 4",
    "section": "full_join()",
    "text": "full_join()\n\n\n\n\n\nfull_join(x, y)\n\n# A tibble: 4 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4     \n\n\n\n\n \nKeep all rows from both data frames."
  },
  {
    "objectID": "slides/lab-4.html#inner_join",
    "href": "slides/lab-4.html#inner_join",
    "title": "Lab 4",
    "section": "inner_join()",
    "text": "inner_join()\n\n\n\n\n\ninner_join(x, y)\n\n# A tibble: 2 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n\n\n\n\n \nKeep all rows that exist in both data frames."
  },
  {
    "objectID": "slides/lab-4.html#example-_join-more-info",
    "href": "slides/lab-4.html#example-_join-more-info",
    "title": "Lab 4",
    "section": "Example: *_join() more info",
    "text": "Example: *_join() more info\n\nWe could also use *_join() within a pipeline.\n\n\nx |&gt;\n  left_join(y)\n\n\nWhich data frame is on the left and which is on the right? x or y?\n\n\n\nThe above code is equivalent to left_join(x, y) since the result before the pipe |&gt; is passed as the first argument to the function after the pipe.\n\n\n\n\nIn this example x has 2 variables: id and value_x and y has 2 variables: id and value_x, so there was only one common variable between x and y – id. We could have been more explicit and used the following code\n\n\nleft_join(x, y, by = join_by(id))\n\n# or alternatively\n\nleft_join(x, y, by = join_by(id == id))\n\nThe first option is useful when there are multiple matching columns [and by default *_join() will use all variables in common across x and y] but perhaps only one of interest (e.g., student_ids and email_address – the same student could have multiple email addresses but you want each student to be one row/observation, so you would use by = join_by(student_ids)).\nThe second option is used when the variables do not share the same variable name but are referring to the same information, e.g., id == student_id.\nBackup info: why piping? piping is much easier to read (can see all data frame manipulation at once – and it isn’t an extreme run-on sentence, e.g., summarize(mutatate(), arg, arg, arg….); also, potentially less having to save and remember intermediate variables) – both for you and others."
  },
  {
    "objectID": "slides/lab-4.html#factors",
    "href": "slides/lab-4.html#factors",
    "title": "Lab 4",
    "section": "Factors",
    "text": "Factors\n\nFactors are used for categorical variables, e.g., days of the week; religion; low, mid, high\nVery helpful for ordering (i.e., when numerical and alphabetical ordering don’t cut it!)\n\n\n\n\nExamples\n\nFriday, Monday, Saturday, Sunday, Tuesday, Thursday, Wednesday\nApr, Feb, Jan, July, Jun, Mar, May\nAgree, Disagree, Neither agree nor disagree, Strongly agree, Strongly disagree\nExample below (from prepare [r4ds] chp 16.4)"
  },
  {
    "objectID": "slides/lab-4.html#factor-example",
    "href": "slides/lab-4.html#factor-example",
    "title": "Lab 4",
    "section": "Factor example",
    "text": "Factor example\nRecall from Thursday’s lecture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsurvey |&gt;\n  mutate(\n    year = fct_relevel(year, \"First-year\", \"Sophomore\", \"Junior\", \"Senior\")\n    ) |&gt;\n  ggplot(aes(x = year)) +\n  geom_bar() + \n  labs(\n    title = \"Number of students by year\",\n    x = \"Year\",\n    y = \"Count\"\n  )\n\n\n\nHow is the x-axis ordered in the left and right plots?\n\nRecall from Thursday’s lecture, using context we know about the data it’s more appropriate for the year to have the order: first-year, sophomore, junior, senior and we used fct_revel to manually (we explicityly wrote out the order) change the ordering of the year variable.\nThe data is ordered alphabetically on the left (default for ggplot to order numerically or alphabetically).\nOrdered according to fct_relevel ordering on the right\nAlso that fct_revel did two things: it made the year variable a factor AND it set the order. (aside if asked) Note that ggplot will by default coerce the character variable to be a factor. Regardless if you assigned the data frame after running fct_revel it will be a factor (and you don’t need to separately use the factor() function)."
  },
  {
    "objectID": "slides/lab-4.html#this-weeks-lab",
    "href": "slides/lab-4.html#this-weeks-lab",
    "title": "Lab 4",
    "section": "This week’s lab",
    "text": "This week’s lab\n\nGain more experience with joining and pivoting data frames; and modifying the order of factors.\nReview Quarto cell options\nLearn to read data in from Excel spreadsheets (will learn more on Tuesday about this)\n\nDatasets\n\nMore inflation!\n2020 and 2024 US Olympic Team rosters\nSurvey regarding medical marijuana in NC\nmtcars from 1974 Motor Trend US magazine"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#while-you-wait",
    "href": "slides/20-hypothesis-testing.html#while-you-wait",
    "title": "Hypothesis testing",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-16-hypothesis-testing.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#midterm-2",
    "href": "slides/20-hypothesis-testing.html#midterm-2",
    "title": "Hypothesis testing",
    "section": "Midterm 2",
    "text": "Midterm 2\n\n\n\nPractice: released tonight or tomorrow;\n\nSolutions posted next Monday;\nLab 7 solutions posted next Tuesday night;\n\n\nReview: Kahoot during lab Monday April 7;\n\nIn-class: Thursday April 10 at 11:45 AM;\n\nExpect an email from Dr. Knox about room assignments;\n\n\nTake-home: 4/10 1:00 PM - 4/14 8:30 AM;\nExpect similar style, format, and intensity as Midterm 1;\nStatistical inference will appear!"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#what-if-this-was-my-dataset",
    "href": "slides/20-hypothesis-testing.html#what-if-this-was-my-dataset",
    "title": "Hypothesis testing",
    "section": "What if this was my dataset?",
    "text": "What if this was my dataset?\n\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    2.94 \n2 log_inc        0.657"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#what-if-this-was-my-dataset-instead",
    "href": "slides/20-hypothesis-testing.html#what-if-this-was-my-dataset-instead",
    "title": "Hypothesis testing",
    "section": "What if this was my dataset instead?",
    "text": "What if this was my dataset instead?\n\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    5.29 \n2 log_inc        0.486"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#what-if-this-was-my-dataset-instead-1",
    "href": "slides/20-hypothesis-testing.html#what-if-this-was-my-dataset-instead-1",
    "title": "Hypothesis testing",
    "section": "What if this was my dataset instead?",
    "text": "What if this was my dataset instead?\n\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    1.62 \n2 log_inc        0.805"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#rinse-and-repeat-1000-times",
    "href": "slides/20-hypothesis-testing.html#rinse-and-repeat-1000-times",
    "title": "Hypothesis testing",
    "section": "Rinse and repeat 1000 times…",
    "text": "Rinse and repeat 1000 times…"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#sampling-uncertainty",
    "href": "slides/20-hypothesis-testing.html#sampling-uncertainty",
    "title": "Hypothesis testing",
    "section": "Sampling uncertainty",
    "text": "Sampling uncertainty\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow sensitive are the estimates to the data they are based on?\n- Very? Then uncertainty is high, results are unreliable;\n- Not very? Uncertainty is low, results are more reliable."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#that-was-for-n-50.-what-if-i-was-starting-with-n-1000",
    "href": "slides/20-hypothesis-testing.html#that-was-for-n-50.-what-if-i-was-starting-with-n-1000",
    "title": "Hypothesis testing",
    "section": "That was for n = 50. What if I was starting with n = 1000?",
    "text": "That was for n = 50. What if I was starting with n = 1000?"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#sampling-uncertainty-decreased",
    "href": "slides/20-hypothesis-testing.html#sampling-uncertainty-decreased",
    "title": "Hypothesis testing",
    "section": "Sampling uncertainty decreased!",
    "text": "Sampling uncertainty decreased!"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#bootstrapping",
    "href": "slides/20-hypothesis-testing.html#bootstrapping",
    "title": "Hypothesis testing",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\n\nData collection is costly, so we have to do our best with what we already have;\nWe approximate this idea of “alternative, hypothetical datasets I could have observed” by resampling our data with replacement;\n\nWe construct a new dataset of the same size by randomly picking rows out of the original one:\n\nSome rows will be duplicated;\nSome rows will not appear at all;\nHence, the new dataset is different from the original;\nDifferent dataset &gt;&gt; different estimate\n\n\nRepeat this processes hundred or thousands of times, and observe how the estimates vary as you refit the model on alternative datasets.\nThis gives you a sense of the sampling variability of your estimates."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#bootstrap-samples-1",
    "href": "slides/20-hypothesis-testing.html#bootstrap-samples-1",
    "title": "Hypothesis testing",
    "section": "Bootstrap samples 1",
    "text": "Bootstrap samples 1\n\n\nOriginal data\n\n\n# A tibble: 6 × 3\n     id       x       y\n  &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1  0.432   1.53  \n2     2 -2.01    1.80  \n3     3 -0.0467  1.43  \n4     4 -1.05    0.0518\n5     5  0.327   0.820 \n6     6 -0.679  -0.961 \n\n\nOriginal estimates:\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)   0.801 \n2 x             0.0450\n\n\n\nSample with replacement:\n\n\n# A tibble: 6 × 3\n     id      x      y\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     5  0.327  0.820\n2     6 -0.679 -0.961\n3     6 -0.679 -0.961\n4     1  0.432  1.53 \n5     6 -0.679 -0.961\n6     1  0.432  1.53 \n\n\nDifferent data &gt;&gt; new estimates:\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    0.462\n2 x              2.11"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#bootstrap-samples-2",
    "href": "slides/20-hypothesis-testing.html#bootstrap-samples-2",
    "title": "Hypothesis testing",
    "section": "Bootstrap samples 2",
    "text": "Bootstrap samples 2\n\n\nOriginal data\n\n\n# A tibble: 6 × 3\n     id       x       y\n  &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1  0.432   1.53  \n2     2 -2.01    1.80  \n3     3 -0.0467  1.43  \n4     4 -1.05    0.0518\n5     5  0.327   0.820 \n6     6 -0.679  -0.961 \n\n\nOriginal estimates:\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)   0.801 \n2 x             0.0450\n\n\n\nSample with replacement:\n\n\n# A tibble: 6 × 3\n     id       x      y\n  &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1     2 -2.01    1.80 \n2     5  0.327   0.820\n3     1  0.432   1.53 \n4     6 -0.679  -0.961\n5     3 -0.0467  1.43 \n6     2 -2.01    1.80 \n\n\nDifferent data &gt;&gt; new estimates:\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    0.913\n2 x             -0.236"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#bootstrap-samples-3",
    "href": "slides/20-hypothesis-testing.html#bootstrap-samples-3",
    "title": "Hypothesis testing",
    "section": "Bootstrap samples 3",
    "text": "Bootstrap samples 3\n\n\nOriginal data\n\n\n# A tibble: 6 × 3\n     id       x       y\n  &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1  0.432   1.53  \n2     2 -2.01    1.80  \n3     3 -0.0467  1.43  \n4     4 -1.05    0.0518\n5     5  0.327   0.820 \n6     6 -0.679  -0.961 \n\n\nOriginal estimates:\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)   0.801 \n2 x             0.0450\n\n\n\nSample with replacement:\n\n\n# A tibble: 6 × 3\n     id      x      y\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     6 -0.679 -0.961\n2     1  0.432  1.53 \n3     5  0.327  0.820\n4     6 -0.679 -0.961\n5     6 -0.679 -0.961\n6     5  0.327  0.820\n\n\nDifferent data &gt;&gt; new estimates:\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    0.357\n2 x              1.96"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#confidence-intervals",
    "href": "slides/20-hypothesis-testing.html#confidence-intervals",
    "title": "Hypothesis testing",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nPoint estimation: report your single number best guess for the unknown quantity;\n\nInterval estimation: report a range, or interval, or values where you think the unknown quantity is likely to live;\n\nInterval should be wide enough to capture the truth with high probability;\nInterval should be narrow enough to be informative;\n\n\nUnfortunately, there is a trade-off. You adjust the confidence level to try to negotiate the trade-off;\nCommon choices: 90%, 95%, 99%."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#precision-vs.-accuracy",
    "href": "slides/20-hypothesis-testing.html#precision-vs.-accuracy",
    "title": "Hypothesis testing",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#data-houses-in-duke-forest",
    "href": "slides/20-hypothesis-testing.html#data-houses-in-duke-forest",
    "title": "Hypothesis testing",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#modeling",
    "href": "slides/20-hypothesis-testing.html#modeling",
    "title": "Hypothesis testing",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- linear_reg() |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) # neatly format table to 2 digits\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#confidence-interval-for-the-slope",
    "href": "slides/20-hypothesis-testing.html#confidence-interval-for-the-slope",
    "title": "Hypothesis testing",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#slopes-of-bootstrap-samples",
    "href": "slides/20-hypothesis-testing.html#slopes-of-bootstrap-samples",
    "title": "Hypothesis testing",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#slopes-of-bootstrap-samples-1",
    "href": "slides/20-hypothesis-testing.html#slopes-of-bootstrap-samples-1",
    "title": "Hypothesis testing",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#confidence-level",
    "href": "slides/20-hypothesis-testing.html#confidence-level",
    "title": "Hypothesis testing",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#confidence-interval",
    "href": "slides/20-hypothesis-testing.html#confidence-interval",
    "title": "Hypothesis testing",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\n\n\n\n\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#where-do-the-bounds-come-from",
    "href": "slides/20-hypothesis-testing.html#where-do-the-bounds-come-from",
    "title": "Hypothesis testing",
    "section": "Where do the bounds come from?",
    "text": "Where do the bounds come from?\n\n\nThink IQR! 50% of the bootstrap distribution is between the 25% quantile on the left and the 75% quantile on the right. But we want more than 50%\n90% of the bootstrap distribution is between the 5% quantile on the left and the 95% quantile on the right;\n95% of the bootstrap distribution is between the 2.5% quantile on the left and the 97.5% quantile on the right;\nAnd so on."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#computing-the-ci-for-the-slope-i",
    "href": "slides/20-hypothesis-testing.html#computing-the-ci-for-the-slope-i",
    "title": "Hypothesis testing",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/20-hypothesis-testing.html#computing-the-ci-for-the-slope-ii",
    "title": "Hypothesis testing",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/20-hypothesis-testing.html#computing-the-ci-for-the-slope-iii",
    "title": "Hypothesis testing",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" # default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#computing-the-ci-for-the-slope-iv",
    "href": "slides/20-hypothesis-testing.html#computing-the-ci-for-the-slope-iv",
    "title": "Hypothesis testing",
    "section": "Computing the CI for the slope IV",
    "text": "Computing the CI for the slope IV\nIf we did it manually…\n\nboot_fits |&gt;\n  filter(term == \"area\") |&gt;\n  ungroup() |&gt;\n  summarize(\n    lower_ci = quantile(estimate, 0.025),\n    upper_ci = quantile(estimate, 0.975),\n  )\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1     92.1     223."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#changing-confidence-level",
    "href": "slides/20-hypothesis-testing.html#changing-confidence-level",
    "title": "Hypothesis testing",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#changing-confidence-level-1",
    "href": "slides/20-hypothesis-testing.html#changing-confidence-level-1",
    "title": "Hypothesis testing",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#recap",
    "href": "slides/20-hypothesis-testing.html#recap",
    "title": "Hypothesis testing",
    "section": "Recap",
    "text": "Recap\n\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#hypothesis-testing-1",
    "href": "slides/20-hypothesis-testing.html#hypothesis-testing-1",
    "title": "Hypothesis testing",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\nA hypothesis test is a statistical technique used to evaluate competing claims using data\n\n\nNull hypothesis, \\(H_0\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n\nNote: Hypotheses are always at the population level!"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#setting-hypotheses",
    "href": "slides/20-hypothesis-testing.html#setting-hypotheses",
    "title": "Hypothesis testing",
    "section": "Setting hypotheses",
    "text": "Setting hypotheses\n\nNull hypothesis, \\(H_0\\): “There is nothing going on.” The slope of the model for predicting the prices of houses in Duke Forest from their areas is 0, \\(\\beta_1 = 0\\).\nAlternative hypothesis, \\(H_A\\): “There is something going on”. The slope of the model for predicting the prices of houses in Duke Forest from their areas is different than, \\(\\beta_1 \\ne 0\\)."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#hypothesis-testing-mindset",
    "href": "slides/20-hypothesis-testing.html#hypothesis-testing-mindset",
    "title": "Hypothesis testing",
    "section": "Hypothesis testing “mindset”",
    "text": "Hypothesis testing “mindset”\n\nAssume you live in a world where null hypothesis is true: \\(\\beta_1 = 0\\).\nAsk yourself how likely you are to observe the sample statistic, or something even more extreme, in this world: \\(P(b_1 \\leq 159.48~or~b_1 \\geq 159.48 | \\beta_1 = 0)\\) = ?"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#hypothesis-testing-as-a-court-trial",
    "href": "slides/20-hypothesis-testing.html#hypothesis-testing-as-a-court-trial",
    "title": "Hypothesis testing",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\n\n\n\n\nPresent the evidence: Collect data\n\n\n\n\n\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\n\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#hypothesis-testing-as-medical-diagnosis",
    "href": "slides/20-hypothesis-testing.html#hypothesis-testing-as-medical-diagnosis",
    "title": "Hypothesis testing",
    "section": "Hypothesis testing as medical diagnosis",
    "text": "Hypothesis testing as medical diagnosis\n\nNull hypothesis, \\(H_0\\): patient is fine\nAlternative hypothesis, \\(H_A\\): patient is sick\n\n\n\n\nPresent the evidence: Collect data\n\n\n\n\n\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\n\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#hypothesis-testing-framework",
    "href": "slides/20-hypothesis-testing.html#hypothesis-testing-framework",
    "title": "Hypothesis testing",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\), that represents the status quo\nSet an alternative hypothesis, \\(H_A\\), that represents the research question, i.e. what we’re testing for\n\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#calculate-observed-slope",
    "href": "slides/20-hypothesis-testing.html#calculate-observed-slope",
    "title": "Hypothesis testing",
    "section": "Calculate observed slope",
    "text": "Calculate observed slope\n… which we have already done:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#simulate-null-distribution",
    "href": "slides/20-hypothesis-testing.html#simulate-null-distribution",
    "title": "Hypothesis testing",
    "section": "Simulate null distribution",
    "text": "Simulate null distribution\n\nset.seed(20241118)\nnull_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 100, type = \"permute\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#view-null-distribution",
    "href": "slides/20-hypothesis-testing.html#view-null-distribution",
    "title": "Hypothesis testing",
    "section": "View null distribution",
    "text": "View null distribution\n\nnull_dist\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term        estimate\n       &lt;int&gt; &lt;chr&gt;          &lt;dbl&gt;\n 1         1 intercept 547294.   \n 2         1 area           4.54 \n 3         2 intercept 568599.   \n 4         2 area          -3.13 \n 5         3 intercept 561547.   \n 6         3 area          -0.593\n 7         4 intercept 526286.   \n 8         4 area          12.1  \n 9         5 intercept 651476.   \n10         5 area         -33.0  \n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#visualize-null-distribution",
    "href": "slides/20-hypothesis-testing.html#visualize-null-distribution",
    "title": "Hypothesis testing",
    "section": "Visualize null distribution",
    "text": "Visualize null distribution\n\nnull_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 15)"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#visualize-null-distribution-alternative",
    "href": "slides/20-hypothesis-testing.html#visualize-null-distribution-alternative",
    "title": "Hypothesis testing",
    "section": "Visualize null distribution (alternative)",
    "text": "Visualize null distribution (alternative)\n\nvisualize(null_dist) +\n  shade_p_value(obs_stat = observed_fit, direction = \"two-sided\")"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#get-p-value",
    "href": "slides/20-hypothesis-testing.html#get-p-value",
    "title": "Hypothesis testing",
    "section": "Get p-value",
    "text": "Get p-value\n\nnull_dist |&gt;\n  get_p_value(obs_stat = observed_fit, direction = \"two-sided\")\n\n# A tibble: 2 × 2\n  term      p_value\n  &lt;chr&gt;       &lt;dbl&gt;\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#make-a-decision",
    "href": "slides/20-hypothesis-testing.html#make-a-decision",
    "title": "Hypothesis testing",
    "section": "Make a decision",
    "text": "Make a decision\n\nBased on the p-value calculated, what is the conclusion of the hypothesis test?"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#sometimes-the-test-will-be-wrong",
    "href": "slides/20-hypothesis-testing.html#sometimes-the-test-will-be-wrong",
    "title": "Hypothesis testing",
    "section": "Sometimes the test will be wrong",
    "text": "Sometimes the test will be wrong"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#think-about-the-judge",
    "href": "slides/20-hypothesis-testing.html#think-about-the-judge",
    "title": "Hypothesis testing",
    "section": "Think about the judge",
    "text": "Think about the judge\n\\(H_0\\) person innocent vs \\(H_A\\) person guilty"
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#think-about-the-doctor",
    "href": "slides/20-hypothesis-testing.html#think-about-the-doctor",
    "title": "Hypothesis testing",
    "section": "Think about the doctor",
    "text": "Think about the doctor\n\\(H_0\\) person well vs \\(H_A\\) person sick."
  },
  {
    "objectID": "slides/20-hypothesis-testing.html#how-do-we-negotiate-the-trade-off",
    "href": "slides/20-hypothesis-testing.html#how-do-we-negotiate-the-trade-off",
    "title": "Hypothesis testing",
    "section": "How do we negotiate the trade-off?",
    "text": "How do we negotiate the trade-off?\n\nPick a threshold \\(\\alpha\\in[0,\\,1]\\) called the discernibility level and threshold the \\(p\\)-value:\n\nIf \\(p\\text{-value} &lt; \\alpha\\), reject null and accept alternative;\nIf \\(p\\text{-value} \\geq \\alpha\\), fail to reject null;"
  },
  {
    "objectID": "slides/19-interval-estimation.html#while-you-wait",
    "href": "slides/19-interval-estimation.html#while-you-wait",
    "title": "Uncertainty quantification",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-15-duke-forest-bootstrap.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/19-interval-estimation.html#one-more-month-to-go",
    "href": "slides/19-interval-estimation.html#one-more-month-to-go",
    "title": "Uncertainty quantification",
    "section": "One more month to go",
    "text": "One more month to go\n\n\nToday: confidence intervals;\nThursday 4/3: hypothesis testing;\nFriday 4/4: Milestone 3 (show “signs of life”) due;\nMonday 4/7: submit final lab, Midterm 2 review;\nTuesday 4/8: more statistical inference;\nThursday 4/10: midterm 2;\nFriday 4/11: submit peer eval 3;\nMonday 4/14: turn-in take-home, complete Milestone 4;\nTuesday 4/15: more statistical inference\nThursday 4/17: prettifying your projects\nMonday 4/21: project work period\nTuesday 4/22: Farewell!\nWednesday 4/23: submit final project\nMonday 4/28: submit peer eval 4\nTuesday 4/29: final exam"
  },
  {
    "objectID": "slides/19-interval-estimation.html#everyone-can-end-the-semester-strong",
    "href": "slides/19-interval-estimation.html#everyone-can-end-the-semester-strong",
    "title": "Uncertainty quantification",
    "section": "Everyone can end the semester strong",
    "text": "Everyone can end the semester strong\nOver 60% of the final course grade has yet to be counted:\n\n5 - 6 more AEs;\nLabs 5, 6, 7;\nMidterm 2 (20%);\nFinal Project (20%);\nFinal exam (20%).\n\nAnd we drop the lowest lab, 30% of the AEs, and replace a low in-class midterm with a better final."
  },
  {
    "objectID": "slides/19-interval-estimation.html#goal",
    "href": "slides/19-interval-estimation.html#goal",
    "title": "Uncertainty quantification",
    "section": "Goal",
    "text": "Goal\nFind range of plausible values for the slope using bootstrap confidence intervals."
  },
  {
    "objectID": "slides/19-interval-estimation.html#a-quick-demonstration",
    "href": "slides/19-interval-estimation.html#a-quick-demonstration",
    "title": "Uncertainty quantification",
    "section": "A quick demonstration",
    "text": "A quick demonstration\nRecall the openintro::loans_full_schema data frame:\n\n\neach row is an approved loan applicant;\n\nthe columns contain financial info about that person, including…\n\nannual income (in $);\namount of non-mortgage debt outstanding (in $).\n\n\nWhat would you guess is the direction of association between these two variables?"
  },
  {
    "objectID": "slides/19-interval-estimation.html#model-fit-with-five-observations",
    "href": "slides/19-interval-estimation.html#model-fit-with-five-observations",
    "title": "Uncertainty quantification",
    "section": "Model fit with five observations",
    "text": "Model fit with five observations\n\n\n\n\n\n\n\n\n(I just took logs to make the picture prettier.)"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size",
    "href": "slides/19-interval-estimation.html#double-the-sample-size",
    "title": "Uncertainty quantification",
    "section": "Double the sample size",
    "text": "Double the sample size"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size-again",
    "href": "slides/19-interval-estimation.html#double-the-sample-size-again",
    "title": "Uncertainty quantification",
    "section": "Double the sample size again",
    "text": "Double the sample size again"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size-again-1",
    "href": "slides/19-interval-estimation.html#double-the-sample-size-again-1",
    "title": "Uncertainty quantification",
    "section": "Double the sample size again",
    "text": "Double the sample size again"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size-again-2",
    "href": "slides/19-interval-estimation.html#double-the-sample-size-again-2",
    "title": "Uncertainty quantification",
    "section": "Double the sample size again",
    "text": "Double the sample size again"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size-again-3",
    "href": "slides/19-interval-estimation.html#double-the-sample-size-again-3",
    "title": "Uncertainty quantification",
    "section": "Double the sample size again",
    "text": "Double the sample size again"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size-again-4",
    "href": "slides/19-interval-estimation.html#double-the-sample-size-again-4",
    "title": "Uncertainty quantification",
    "section": "Double the sample size again",
    "text": "Double the sample size again"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size-again-5",
    "href": "slides/19-interval-estimation.html#double-the-sample-size-again-5",
    "title": "Uncertainty quantification",
    "section": "Double the sample size again",
    "text": "Double the sample size again"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size-again-6",
    "href": "slides/19-interval-estimation.html#double-the-sample-size-again-6",
    "title": "Uncertainty quantification",
    "section": "Double the sample size again",
    "text": "Double the sample size again"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size-yet-again",
    "href": "slides/19-interval-estimation.html#double-the-sample-size-yet-again",
    "title": "Uncertainty quantification",
    "section": "Double the sample size yet again",
    "text": "Double the sample size yet again"
  },
  {
    "objectID": "slides/19-interval-estimation.html#double-the-sample-size-one-more-time",
    "href": "slides/19-interval-estimation.html#double-the-sample-size-one-more-time",
    "title": "Uncertainty quantification",
    "section": "Double the sample size one more time",
    "text": "Double the sample size one more time"
  },
  {
    "objectID": "slides/19-interval-estimation.html#use-all-the-data-we-have",
    "href": "slides/19-interval-estimation.html#use-all-the-data-we-have",
    "title": "Uncertainty quantification",
    "section": "Use all the data we have",
    "text": "Use all the data we have"
  },
  {
    "objectID": "slides/19-interval-estimation.html#what-did-we-notice",
    "href": "slides/19-interval-estimation.html#what-did-we-notice",
    "title": "Uncertainty quantification",
    "section": "What did we notice?",
    "text": "What did we notice?\n\n\nAs the sample size grew, the best fit line stabilized;\nAs the sample size grew, the grey uncertainty band shrank;\nAs the sample size grew, we observed a larger range of income values, anf the computer displayed more of the line;\n\nAs the sample size grows, the picture the data paint becomes clearer:\n\npositive relationship;\nlinear relationship;\npretty strong"
  },
  {
    "objectID": "slides/19-interval-estimation.html#a-silly-question",
    "href": "slides/19-interval-estimation.html#a-silly-question",
    "title": "Uncertainty quantification",
    "section": "A silly question",
    "text": "A silly question\n\nWhich would you rather have for your data analysis? 5 people in your dataset or 9947? Why?"
  },
  {
    "objectID": "slides/19-interval-estimation.html#the-bottom-line-at-the-top",
    "href": "slides/19-interval-estimation.html#the-bottom-line-at-the-top",
    "title": "Uncertainty quantification",
    "section": "The bottom line, at the top",
    "text": "The bottom line, at the top\n\nWe do not know what the “true” line is;\nOur estimates are a best guess based on noisy, incomplete, imperfect data;\nThe more data we have, the more “certain” and “reliable” the estimates are;\nWhat do we mean by “uncertainty” here?"
  },
  {
    "objectID": "slides/19-interval-estimation.html#sampling-uncertainty",
    "href": "slides/19-interval-estimation.html#sampling-uncertainty",
    "title": "Uncertainty quantification",
    "section": "Sampling uncertainty",
    "text": "Sampling uncertainty\n\nFact: different data set -&gt; different estimates;\n\nHow much would our estimate vary across alternative datasets?\n\nIf the answer is “a lot,” uncertainty is high, and our estimates are not super reliable;\nIf the answer is “a little,” uncertainty is low, and maybe we can take our estimates to the bank;"
  },
  {
    "objectID": "slides/19-interval-estimation.html#heres-one-dataset-we-could-have-seen",
    "href": "slides/19-interval-estimation.html#heres-one-dataset-we-could-have-seen",
    "title": "Uncertainty quantification",
    "section": "Here’s one dataset we could have seen",
    "text": "Here’s one dataset we could have seen"
  },
  {
    "objectID": "slides/19-interval-estimation.html#heres-another",
    "href": "slides/19-interval-estimation.html#heres-another",
    "title": "Uncertainty quantification",
    "section": "Here’s another",
    "text": "Here’s another"
  },
  {
    "objectID": "slides/19-interval-estimation.html#heres-yet-one-more",
    "href": "slides/19-interval-estimation.html#heres-yet-one-more",
    "title": "Uncertainty quantification",
    "section": "Here’s yet one more",
    "text": "Here’s yet one more"
  },
  {
    "objectID": "slides/19-interval-estimation.html#different-data-set---different-estimates",
    "href": "slides/19-interval-estimation.html#different-data-set---different-estimates",
    "title": "Uncertainty quantification",
    "section": "Different data set -> different estimates",
    "text": "Different data set -&gt; different estimates\n\nThese tiny data sets can’t even agree on if the line should slope up or down. Uncertainty is high, hence the large bands.\nIf we repeat the process with a larger sample size, things are more stable"
  },
  {
    "objectID": "slides/19-interval-estimation.html#alternative-1",
    "href": "slides/19-interval-estimation.html#alternative-1",
    "title": "Uncertainty quantification",
    "section": "Alternative 1",
    "text": "Alternative 1"
  },
  {
    "objectID": "slides/19-interval-estimation.html#alternative-2",
    "href": "slides/19-interval-estimation.html#alternative-2",
    "title": "Uncertainty quantification",
    "section": "Alternative 2",
    "text": "Alternative 2"
  },
  {
    "objectID": "slides/19-interval-estimation.html#alternative-3",
    "href": "slides/19-interval-estimation.html#alternative-3",
    "title": "Uncertainty quantification",
    "section": "Alternative 3",
    "text": "Alternative 3"
  },
  {
    "objectID": "slides/19-interval-estimation.html#lets-visualize-how-the-estimates-vary",
    "href": "slides/19-interval-estimation.html#lets-visualize-how-the-estimates-vary",
    "title": "Uncertainty quantification",
    "section": "Let’s visualize how the estimates vary",
    "text": "Let’s visualize how the estimates vary"
  },
  {
    "objectID": "slides/19-interval-estimation.html#different-data-set---different-estimates-1",
    "href": "slides/19-interval-estimation.html#different-data-set---different-estimates-1",
    "title": "Uncertainty quantification",
    "section": "Different data set -> different estimates",
    "text": "Different data set -&gt; different estimates\n\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    4.27 \n2 log_inc        0.553"
  },
  {
    "objectID": "slides/19-interval-estimation.html#different-data-set---different-estimates-2",
    "href": "slides/19-interval-estimation.html#different-data-set---different-estimates-2",
    "title": "Uncertainty quantification",
    "section": "Different data set -> different estimates",
    "text": "Different data set -&gt; different estimates\n\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    -4.63\n2 log_inc         1.35"
  },
  {
    "objectID": "slides/19-interval-estimation.html#different-data-set---different-estimates-3",
    "href": "slides/19-interval-estimation.html#different-data-set---different-estimates-3",
    "title": "Uncertainty quantification",
    "section": "Different data set -> different estimates",
    "text": "Different data set -&gt; different estimates\n\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    -1.14\n2 log_inc         1.04"
  },
  {
    "objectID": "slides/19-interval-estimation.html#different-data-set---different-estimates-4",
    "href": "slides/19-interval-estimation.html#different-data-set---different-estimates-4",
    "title": "Uncertainty quantification",
    "section": "Different data set -> different estimates",
    "text": "Different data set -&gt; different estimates\n\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)   -0.288\n2 log_inc        0.960"
  },
  {
    "objectID": "slides/19-interval-estimation.html#different-data-set---different-estimates-5",
    "href": "slides/19-interval-estimation.html#different-data-set---different-estimates-5",
    "title": "Uncertainty quantification",
    "section": "Different data set -> different estimates",
    "text": "Different data set -&gt; different estimates\n\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    4.84 \n2 log_inc        0.492"
  },
  {
    "objectID": "slides/19-interval-estimation.html#different-data-set---different-estimates-6",
    "href": "slides/19-interval-estimation.html#different-data-set---different-estimates-6",
    "title": "Uncertainty quantification",
    "section": "Different data set -> different estimates",
    "text": "Different data set -&gt; different estimates\n\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  term        estimate\n  &lt;chr&gt;          &lt;dbl&gt;\n1 (Intercept)    3.20 \n2 log_inc        0.654"
  },
  {
    "objectID": "slides/19-interval-estimation.html#you-get-the-idea",
    "href": "slides/19-interval-estimation.html#you-get-the-idea",
    "title": "Uncertainty quantification",
    "section": "You get the idea",
    "text": "You get the idea"
  },
  {
    "objectID": "slides/19-interval-estimation.html#variation-in-estimates-across-alternative-datasets",
    "href": "slides/19-interval-estimation.html#variation-in-estimates-across-alternative-datasets",
    "title": "Uncertainty quantification",
    "section": "Variation in estimates across alternative datasets",
    "text": "Variation in estimates across alternative datasets\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe amount of variation in the histogram tells us something about the uncertainty, and gives us a range of likely values."
  },
  {
    "objectID": "slides/19-interval-estimation.html#data-houses-in-duke-forest",
    "href": "slides/19-interval-estimation.html#data-houses-in-duke-forest",
    "title": "Uncertainty quantification",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/19-interval-estimation.html#exploratory-data-analysis",
    "href": "slides/19-interval-estimation.html#exploratory-data-analysis",
    "title": "Uncertainty quantification",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nCodeggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/19-interval-estimation.html#modeling",
    "href": "slides/19-interval-estimation.html#modeling",
    "title": "Uncertainty quantification",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- linear_reg() |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) # neatly format table to 2 digits\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, for $116,652, on average.\n\nIs this interpretation useful?\n\n\n\nSlope: For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/19-interval-estimation.html#from-sample-to-population",
    "href": "slides/19-interval-estimation.html#from-sample-to-population",
    "title": "Uncertainty quantification",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average.\n\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if we’re not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/19-interval-estimation.html#statistical-inference",
    "href": "slides/19-interval-estimation.html#statistical-inference",
    "title": "Uncertainty quantification",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nStatistical inference provide methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be random and representative of the population we’re interested in"
  },
  {
    "objectID": "slides/19-interval-estimation.html#inference-for-simple-linear-regression",
    "href": "slides/19-interval-estimation.html#inference-for-simple-linear-regression",
    "title": "Uncertainty quantification",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\) (today)\nConduct a hypothesis test for the slope, \\(\\beta_1\\) (Thursday)"
  },
  {
    "objectID": "slides/19-interval-estimation.html#confidence-interval",
    "href": "slides/19-interval-estimation.html#confidence-interval",
    "title": "Uncertainty quantification",
    "section": "Confidence interval",
    "text": "Confidence interval\n\n\nA plausible range of values for a population parameter is called a confidence interval\n\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/19-interval-estimation.html#confidence-interval-for-the-slope-1",
    "href": "slides/19-interval-estimation.html#confidence-interval-for-the-slope-1",
    "title": "Uncertainty quantification",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”\n\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/19-interval-estimation.html#quantify-the-variability-of-the-slope",
    "href": "slides/19-interval-estimation.html#quantify-the-variability-of-the-slope",
    "title": "Uncertainty quantification",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\n\nTwo approaches:\n\nVia simulation (what we’ll do in this course)\nVia mathematical models (what you can learn about in future courses)\n\n\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/19-interval-estimation.html#bootstrap-sample-1",
    "href": "slides/19-interval-estimation.html#bootstrap-sample-1",
    "title": "Uncertainty quantification",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/19-interval-estimation.html#bootstrap-sample-2",
    "href": "slides/19-interval-estimation.html#bootstrap-sample-2",
    "title": "Uncertainty quantification",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/19-interval-estimation.html#bootstrap-sample-3",
    "href": "slides/19-interval-estimation.html#bootstrap-sample-3",
    "title": "Uncertainty quantification",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/19-interval-estimation.html#bootstrap-sample-4",
    "href": "slides/19-interval-estimation.html#bootstrap-sample-4",
    "title": "Uncertainty quantification",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/19-interval-estimation.html#bootstrap-sample-5",
    "href": "slides/19-interval-estimation.html#bootstrap-sample-5",
    "title": "Uncertainty quantification",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nso on and so forth…"
  },
  {
    "objectID": "slides/19-interval-estimation.html#bootstrap-samples-1---5",
    "href": "slides/19-interval-estimation.html#bootstrap-samples-1---5",
    "title": "Uncertainty quantification",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/19-interval-estimation.html#bootstrap-samples-1---100",
    "href": "slides/19-interval-estimation.html#bootstrap-samples-1---100",
    "title": "Uncertainty quantification",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/19-interval-estimation.html#slopes-of-bootstrap-samples",
    "href": "slides/19-interval-estimation.html#slopes-of-bootstrap-samples",
    "title": "Uncertainty quantification",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/19-interval-estimation.html#slopes-of-bootstrap-samples-1",
    "href": "slides/19-interval-estimation.html#slopes-of-bootstrap-samples-1",
    "title": "Uncertainty quantification",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/19-interval-estimation.html#confidence-level",
    "href": "slides/19-interval-estimation.html#confidence-level",
    "title": "Uncertainty quantification",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/19-interval-estimation.html#confidence-interval-1",
    "href": "slides/19-interval-estimation.html#confidence-interval-1",
    "title": "Uncertainty quantification",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\n\n\n\n\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/19-interval-estimation.html#ae-15-duke-forest-bootstrap",
    "href": "slides/19-interval-estimation.html#ae-15-duke-forest-bootstrap",
    "title": "Uncertainty quantification",
    "section": "ae-15-duke-forest-bootstrap",
    "text": "ae-15-duke-forest-bootstrap\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-15-duke-forest-bootstrap.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/19-interval-estimation.html#computing-the-ci-for-the-slope-i",
    "href": "slides/19-interval-estimation.html#computing-the-ci-for-the-slope-i",
    "title": "Uncertainty quantification",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/19-interval-estimation.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/19-interval-estimation.html#computing-the-ci-for-the-slope-ii",
    "title": "Uncertainty quantification",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/19-interval-estimation.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/19-interval-estimation.html#computing-the-ci-for-the-slope-iii",
    "title": "Uncertainty quantification",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" # default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/19-interval-estimation.html#precision-vs.-accuracy",
    "href": "slides/19-interval-estimation.html#precision-vs.-accuracy",
    "title": "Uncertainty quantification",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "slides/19-interval-estimation.html#precision-vs.-accuracy-1",
    "href": "slides/19-interval-estimation.html#precision-vs.-accuracy-1",
    "title": "Uncertainty quantification",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?"
  },
  {
    "objectID": "slides/19-interval-estimation.html#changing-confidence-level",
    "href": "slides/19-interval-estimation.html#changing-confidence-level",
    "title": "Uncertainty quantification",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/19-interval-estimation.html#changing-confidence-level-1",
    "href": "slides/19-interval-estimation.html#changing-confidence-level-1",
    "title": "Uncertainty quantification",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/19-interval-estimation.html#recap",
    "href": "slides/19-interval-estimation.html#recap",
    "title": "Uncertainty quantification",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/00-welcome.html#teaching-team-a-glamorous-assemblage",
    "href": "slides/00-welcome.html#teaching-team-a-glamorous-assemblage",
    "title": "Welcome to STA 199!",
    "section": "Teaching team: a glamorous assemblage",
    "text": "Teaching team: a glamorous assemblage\n\n\nCaitrin Murphy\nHan Chen\nKatie Solarz\nHyunjin Lee\nJasmine Wang\nLiane Ma\nAvery Hodges\nAlexa Fahrer\nDomenic Fenoglio\nJulia Healey-Parera\nDavid King\nLisa Zhang\n\nEduardo Vasquez\nArijit Dey\nFederico Arboleda\nSarah Wu\nLi Fan\nDevarpita Bag\nNetra Mittal\nNatasha Harris\nSonya Eason\nNoah Obuya\nMary Knox\nJohn Zito"
  },
  {
    "objectID": "slides/00-welcome.html#what-are-we-studying",
    "href": "slides/00-welcome.html#what-are-we-studying",
    "title": "Welcome to STA 199!",
    "section": "What are we studying?",
    "text": "What are we studying?\n\n\n\n\n\n\nData science\n\n\nTransforming messy, incomplete, imperfect data into knowledge.\n\n\n\n\n\n\n\n\n\nStatistical thinking\n\n\nQuantifying our uncertainty about that knowledge."
  },
  {
    "objectID": "slides/00-welcome.html#the-data-science-life-cycle",
    "href": "slides/00-welcome.html#the-data-science-life-cycle",
    "title": "Welcome to STA 199!",
    "section": "The data science life cycle",
    "text": "The data science life cycle"
  },
  {
    "objectID": "slides/00-welcome.html#homepage",
    "href": "slides/00-welcome.html#homepage",
    "title": "Welcome to STA 199!",
    "section": "Homepage",
    "text": "Homepage\nhttps://sta199-s25.github.io\n\nAll course materials\nLinks to Canvas, GitHub, RStudio containers, etc."
  },
  {
    "objectID": "slides/00-welcome.html#course-toolkit",
    "href": "slides/00-welcome.html#course-toolkit",
    "title": "Welcome to STA 199!",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta199-s25\n\nRStudio containers: cmgr.oit.duke.edu/containers\n\nCommunication: Ed Discussion\nAssignment submission and feedback: Gradescope"
  },
  {
    "objectID": "slides/00-welcome.html#activities",
    "href": "slides/00-welcome.html#activities",
    "title": "Welcome to STA 199!",
    "section": "Activities",
    "text": "Activities\n\nIntroduce new content and prepare for lectures by watching the videos and completing the readings\nAttend and actively participate in lectures and labs, office hours, team meetings\nPractice applying statistical concepts and computing with application exercises during lecture, graded for attempting\nPut together what you’ve learned to analyze real-world data\n\nLab assignments (7 or 8 throughout semester)\nExams (midterm x 2 + final)\nTerm project completed in teams"
  },
  {
    "objectID": "slides/00-welcome.html#application-exercises",
    "href": "slides/00-welcome.html#application-exercises",
    "title": "Welcome to STA 199!",
    "section": "Application exercises",
    "text": "Application exercises\n\nDaily-ish in lecture\n“Graded” for attempt, not accuracy\nPractice Weeks 1 + 2, graded thereafter\nAt least one commit by 2 pm of the day of lecture\nTurn in at least 70% for full credit"
  },
  {
    "objectID": "slides/00-welcome.html#labs",
    "href": "slides/00-welcome.html#labs",
    "title": "Welcome to STA 199!",
    "section": "Labs",
    "text": "Labs\n\nStart in lab session\nComplete at home\nDue within a week\nDiscussion with classmates ok, copying not ok!\nLowest score dropped"
  },
  {
    "objectID": "slides/00-welcome.html#exams",
    "href": "slides/00-welcome.html#exams",
    "title": "Welcome to STA 199!",
    "section": "Exams",
    "text": "Exams\n\nThree exams, each 20%\n\nMidterm comprised of two parts:\n\nIn-class: 75 minute in-class exam. Closed book, one sheet of notes (“cheat sheet”) – 70% of the grade.\nTake-home: Follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam – 30% of the grade.\n\n\nFinal in-class only (Apr 29, 9am - 12pm): Closed book, one sheet of notes (“cheat sheet”).\n“Cheat sheet”: No larger than 8.5” x 11”, both sides, must be prepared by you.\n\n\n\n\n\n\n\nCaution\n\n\nExam dates cannot be changed and no make-up exams will be given. If you can’t take the exams on these dates, you should drop this class."
  },
  {
    "objectID": "slides/00-welcome.html#project",
    "href": "slides/00-welcome.html#project",
    "title": "Welcome to STA 199!",
    "section": "Project",
    "text": "Project\n\nDataset of your choice, method of your choice\nTeamwork\nFive milestones, interim deadline throughout semester\nFinal milestone: Presentation (video) and write-up\nPresentations submitted as videos\nPeer review between teams for content, peer evaluation within teams for contribution\nSome lab sessions allocated to project progress\n\n\n\n\n\n\n\nCaution\n\n\nProject due date cannot be changed. You must complete the project to pass this class."
  },
  {
    "objectID": "slides/00-welcome.html#teams-of-4---5",
    "href": "slides/00-welcome.html#teams-of-4---5",
    "title": "Welcome to STA 199!",
    "section": "Teams of 4 - 5",
    "text": "Teams of 4 - 5\n\nAssigned by us within your lab section\n\nProject\nPeer evaluation during teamwork and after completion\nExpectations and roles\n\nEveryone is expected to contribute equal effort\n\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/00-welcome.html#grading",
    "href": "slides/00-welcome.html#grading",
    "title": "Welcome to STA 199!",
    "section": "Grading",
    "text": "Grading\n\n\nCategory\nPercentage\n\n\n\nApplication Exercises\n5%\n\n\nLabs\n15%\n\n\nMidterm 1\n20%\n\n\nMidterm 2\n20%\n\n\nFinal\n20%\n\n\nProject\n20%\n\n\n\nNo specific points allocated to attendance, but the application exercise score is implicitly tied to attendance.\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/00-welcome.html#wiggle-room",
    "href": "slides/00-welcome.html#wiggle-room",
    "title": "Welcome to STA 199!",
    "section": "Wiggle room",
    "text": "Wiggle room\n\nYou only have to complete 70% of the AEs to receive full credit;\nWe drop the lowest lab score;\nWe replace the lowest in-class midterm score with your final exam score (if it’s better)."
  },
  {
    "objectID": "slides/00-welcome.html#support",
    "href": "slides/00-welcome.html#support",
    "title": "Welcome to STA 199!",
    "section": "Support",
    "text": "Support\n\nHelp from humans:\n\nAttend office hours\nAsk and answer questions on the discussion forum\n\n\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/00-welcome.html#announcements",
    "href": "slides/00-welcome.html#announcements",
    "title": "Welcome to STA 199!",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Canvas (Announcements tool) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day\nI’ll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/00-welcome.html#accessibility",
    "href": "slides/00-welcome.html#accessibility",
    "title": "Welcome to STA 199!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know.\n\n\n\n\n\n\n\nIf you need testing accommodations\n\n\nMake sure I get a letter, and make your appointments in the Testing Center now."
  },
  {
    "objectID": "slides/00-welcome.html#late-work-waivers-lecture-recordings-regrades",
    "href": "slides/00-welcome.html#late-work-waivers-lecture-recordings-regrades",
    "title": "Welcome to STA 199!",
    "section": "Late work, waivers, lecture recordings, regrades…",
    "text": "Late work, waivers, lecture recordings, regrades…\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/00-welcome.html#collaboration",
    "href": "slides/00-welcome.html#collaboration",
    "title": "Welcome to STA 199!",
    "section": "Collaboration",
    "text": "Collaboration\n\nLabs: discussing and helping is fine. Sharing your solutions and copying others is not;\nExams: collaboration of any kind is completely forbidden on any part of any exam;\nProjects: collaboration of any kind is enthusiastically encouraged within your team. Between teams, it’s the same as labs; do not directly share your stuff or copy off of others."
  },
  {
    "objectID": "slides/00-welcome.html#use-of-ai-tools",
    "href": "slides/00-welcome.html#use-of-ai-tools",
    "title": "Welcome to STA 199!",
    "section": "Use of AI tools",
    "text": "Use of AI tools\n\n\n AI tools for code:\n\nSure, but be careful/critical! Working code != correct/good code.\nMust explicitly cite with a direct url linking to the conversation you had.\n\n\n AI tools for narrative: Absolutely not!\n AI tools for learning: Sure, but be careful/critical!"
  },
  {
    "objectID": "slides/00-welcome.html#academic-integrity",
    "href": "slides/00-welcome.html#academic-integrity",
    "title": "Welcome to STA 199!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\nZeros from conduct violations will not be dropped or replaced;\nIf people are copying, sharer and recipients penalized equally. It does not matter how well-intentioned everyone was;\nIf we discover violations, they go straight to the conduct office."
  },
  {
    "objectID": "slides/00-welcome.html#how-old-is-this-person",
    "href": "slides/00-welcome.html#how-old-is-this-person",
    "title": "Welcome to STA 199!",
    "section": "How old is this person?",
    "text": "How old is this person?\n\n\n\n \n\n\n\n\nEthel Merman"
  },
  {
    "objectID": "slides/00-welcome.html#ethel-merman",
    "href": "slides/00-welcome.html#ethel-merman",
    "title": "Welcome to STA 199!",
    "section": "Ethel Merman",
    "text": "Ethel Merman\n\n\n\n\n\n\nBorn\nJanuary 16, 1908\n\n\nDied\nFebruary 15, 1984\n\n\nAge\n76\n\n\nClaim to fame\nJZ’s favorite singer"
  },
  {
    "objectID": "slides/00-welcome.html#how-old-is-this-person-1",
    "href": "slides/00-welcome.html#how-old-is-this-person-1",
    "title": "Welcome to STA 199!",
    "section": "How old is this person?",
    "text": "How old is this person?\n\n\n\n \n\n\n\n\nMegan Pete"
  },
  {
    "objectID": "slides/00-welcome.html#megan-thee-stallion",
    "href": "slides/00-welcome.html#megan-thee-stallion",
    "title": "Welcome to STA 199!",
    "section": "Megan Thee Stallion",
    "text": "Megan Thee Stallion\n\n\n\n\n\n\nBorn\nFebruary 15, 1995\n\n\nAge\n29\n\n\nClaim to fame\nRapper"
  },
  {
    "objectID": "slides/00-welcome.html#how-old-is-this-person-2",
    "href": "slides/00-welcome.html#how-old-is-this-person-2",
    "title": "Welcome to STA 199!",
    "section": "How old is this person?",
    "text": "How old is this person?\n\n\n\n \n\n\n\n\n봉준호"
  },
  {
    "objectID": "slides/00-welcome.html#bong-joon-ho",
    "href": "slides/00-welcome.html#bong-joon-ho",
    "title": "Welcome to STA 199!",
    "section": "Bong Joon-ho",
    "text": "Bong Joon-ho\n\n\n\n\n\n\nBorn\nSeptember 14, 1969\n\n\nAge\n55\n\n\nClaim to fame\nDirected Parasite, Snowpiercer, etc"
  },
  {
    "objectID": "slides/00-welcome.html#now-do-it-with-pictures",
    "href": "slides/00-welcome.html#now-do-it-with-pictures",
    "title": "Welcome to STA 199!",
    "section": "Now do it with pictures…",
    "text": "Now do it with pictures…\n\n\nWhen the picture was taken, how old was the person?"
  },
  {
    "objectID": "slides/00-welcome.html#managing-expectations",
    "href": "slides/00-welcome.html#managing-expectations",
    "title": "Welcome to STA 199!",
    "section": "Managing expectations",
    "text": "Managing expectations\nThe stakes are low today. We’re just getting our feet wet and working out the kinks:\n\n\nIt’s the first time all 300+ of us are attempting to access our containers simultaneously. It may choke;\nIf you get stuck on a loading screen of some kind, be patient and let it do its thing. Refreshing, reloading, etc will just amplify our collective problem;\nIf yours never loads, no big deal. Just sit back and watch me, or follow along on a neighbor’s screen;\nEven if yours does load, you’re welcome to just watch."
  },
  {
    "objectID": "slides/00-welcome.html#yuja-wang",
    "href": "slides/00-welcome.html#yuja-wang",
    "title": "Welcome to STA 199!",
    "section": "Yuja Wang",
    "text": "Yuja Wang\n\n\n\n\n\n\n\n\n\nBorn\n2/10/1987\n\n\nAge in pic\n36\n\n\nClaim to fame\nClassical pianist"
  },
  {
    "objectID": "slides/00-welcome.html#im-sure-shed-be-pleased",
    "href": "slides/00-welcome.html#im-sure-shed-be-pleased",
    "title": "Welcome to STA 199!",
    "section": "I’m sure she’d be pleased",
    "text": "I’m sure she’d be pleased"
  },
  {
    "objectID": "slides/00-welcome.html#joan-crawford",
    "href": "slides/00-welcome.html#joan-crawford",
    "title": "Welcome to STA 199!",
    "section": "Joan Crawford",
    "text": "Joan Crawford\nA secret she took to her grave:\n\n\n\n\n\n\n\n\n\nBorn\n3/23/(1904 - 1908)\n\n\nDied\n5/10/1977\n\n\nAge in pic\n38 - 42\n\n\nClaim to fame\nOscar-winning actor"
  },
  {
    "objectID": "slides/00-welcome.html#well-never-know",
    "href": "slides/00-welcome.html#well-never-know",
    "title": "Welcome to STA 199!",
    "section": "We’ll never know…",
    "text": "We’ll never know…"
  },
  {
    "objectID": "slides/00-welcome.html#eubie-blake",
    "href": "slides/00-welcome.html#eubie-blake",
    "title": "Welcome to STA 199!",
    "section": "Eubie Blake",
    "text": "Eubie Blake\nHis actual birthday was not known at the time:\n\n\n\n\n\n\n\n\n\nBorn\n2/7/1887\n\n\nDied\n2/12/1983\n\n\nAge in pic\n82\n\n\nClaim to fame\nComposer"
  },
  {
    "objectID": "slides/00-welcome.html#lol-that-bar-at-86",
    "href": "slides/00-welcome.html#lol-that-bar-at-86",
    "title": "Welcome to STA 199!",
    "section": "lol that bar at 86",
    "text": "lol that bar at 86"
  },
  {
    "objectID": "slides/00-welcome.html#watch-out-for-data-quality",
    "href": "slides/00-welcome.html#watch-out-for-data-quality",
    "title": "Welcome to STA 199!",
    "section": "Watch out for data quality!",
    "text": "Watch out for data quality!"
  },
  {
    "objectID": "slides/00-welcome.html#raghuram-rajan",
    "href": "slides/00-welcome.html#raghuram-rajan",
    "title": "Welcome to STA 199!",
    "section": "Raghuram Rajan",
    "text": "Raghuram Rajan\n\n\n\n\n\n\nBorn\n2/3/1963\n\n\nAge in pic\n48\n\n\nClaim to fame\nUChicago economist\n\n\n\nRBI governor"
  },
  {
    "objectID": "slides/00-welcome.html#youre-natural-denoisers",
    "href": "slides/00-welcome.html#youre-natural-denoisers",
    "title": "Welcome to STA 199!",
    "section": "You’re natural denoisers!",
    "text": "You’re natural denoisers!"
  },
  {
    "objectID": "slides/00-welcome.html#james-gandolfini",
    "href": "slides/00-welcome.html#james-gandolfini",
    "title": "Welcome to STA 199!",
    "section": "James Gandolfini",
    "text": "James Gandolfini\n\n\n\n\n\n\n\n\n\nBorn\n9/18/1961\n\n\nDied\n6/19/2013\n\n\nAge in pic\n51\n\n\nClaim to fame\nplayed Tony Soprano"
  },
  {
    "objectID": "slides/00-welcome.html#the-wisdom-of-crowds",
    "href": "slides/00-welcome.html#the-wisdom-of-crowds",
    "title": "Welcome to STA 199!",
    "section": "The wisdom of crowds",
    "text": "The wisdom of crowds"
  },
  {
    "objectID": "slides/00-welcome.html#celia-cruz",
    "href": "slides/00-welcome.html#celia-cruz",
    "title": "Welcome to STA 199!",
    "section": "Celia Cruz",
    "text": "Celia Cruz\n\n\n\n\n\n\n\n\n\nBorn\n10/21/1925\n\n\nDied\n7/16/2003\n\n\nAge in pic\n76\n\n\nClaim to fame\nQueen of Salsa"
  },
  {
    "objectID": "slides/00-welcome.html#azúcar",
    "href": "slides/00-welcome.html#azúcar",
    "title": "Welcome to STA 199!",
    "section": "¡Azúcar!",
    "text": "¡Azúcar!"
  },
  {
    "objectID": "slides/00-welcome.html#our-best-guessers",
    "href": "slides/00-welcome.html#our-best-guessers",
    "title": "Welcome to STA 199!",
    "section": "Our best guessers",
    "text": "Our best guessers\n\n\n\nTruth\nNo. 1\nNo. 2\nNo. 4\nNo. 4\n\n\n\nWang\n36\n34\n36\n27\n34\n\n\nCrawford\n40?\n38\n42\n33\n40\n\n\nBlake\n82\n77\n74\n80\n72\n\n\nRajan\n48\n50\n50\n45\n53\n\n\nGandolfini\n51\n58\n48\n50\n46\n\n\nCruz\n76\n72\n68\n73\n73\n\n\n\n\n3.66\n3.83\n4.16\n4.16"
  },
  {
    "objectID": "slides/00-welcome.html#whence-ggplot",
    "href": "slides/00-welcome.html#whence-ggplot",
    "title": "Welcome to STA 199!",
    "section": "Whence ggplot?",
    "text": "Whence ggplot?"
  },
  {
    "objectID": "slides/00-welcome.html#statistical-lessons",
    "href": "slides/00-welcome.html#statistical-lessons",
    "title": "Welcome to STA 199!",
    "section": "Statistical lessons",
    "text": "Statistical lessons\n\n\nDomain knowledge and modeling assumptions: data do not speak for themselves. You need some subject-matter expertise about what you’re studying, as well as an interpretive lens;\nAre you asking questions the data can actually answer?\nUncertainty has many sources, and in some cases, it may be simply irreducible, no matter how hard you try;\n\nData quality and data cleaning: Data are not gospel. There could be noise and mistakes. Then what?\n\nWisdom of crowds: aggregating many imperfect guesses can do better than any one individual guess."
  },
  {
    "objectID": "slides/00-welcome.html#hard-skills",
    "href": "slides/00-welcome.html#hard-skills",
    "title": "Welcome to STA 199!",
    "section": "Hard skills",
    "text": "Hard skills\n\nGitHub repositories: cloning and pulling;\nWorking with data in CSV format;\nRendering a Quarto document to get PDFs that seamlessly integrate written text, code, and output;\nUsing ggplot to build up visualizations in layers, like a cake.\n\n\n\n\n\n\n\nGet ready\n\n\nYou will do all of these things on a weekly basis in this course."
  },
  {
    "objectID": "slides/00-welcome.html#this-weeks-tasks",
    "href": "slides/00-welcome.html#this-weeks-tasks",
    "title": "Welcome to STA 199!",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nComplete Lab 0\n\nComputational setup\nGetting to know you survey\n\n\nRead the syllabus and ask questions on Ed\nComplete readings and videos for next class\nAccept your invitation to the GitHub organization pronto!"
  },
  {
    "objectID": "slides/06-tidying-data.html#while-you-wait",
    "href": "slides/06-tidying-data.html#while-you-wait",
    "title": "Tidying data",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-05-majors-tidy\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-05-majors-tidy.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file.\n\n\n\n\n\n\n\n\nAEs are due by the end of class\n\n\nSuccessful completion means at least one commit + push by 2PM today"
  },
  {
    "objectID": "slides/06-tidying-data.html#intro-to-coding-principles-with-dav-king",
    "href": "slides/06-tidying-data.html#intro-to-coding-principles-with-dav-king",
    "title": "Tidying data",
    "section": "Intro to Coding Principles with Dav King",
    "text": "Intro to Coding Principles with Dav King\n\n\n\n8:30 PM Tonight!;\nSocial Sciences 139;\nSpace is limited, so please sign up;\nMaterials will be posted afterward;\nWe might do more if there is interest and Dav is available.\n\n\n\n\n:::"
  },
  {
    "objectID": "slides/06-tidying-data.html#syllabus-clarifications",
    "href": "slides/06-tidying-data.html#syllabus-clarifications",
    "title": "Tidying data",
    "section": "Syllabus clarifications",
    "text": "Syllabus clarifications\n\n\nYou can miss 30% of AEs before it starts affecting your final grade. This policy is meant to smooth over technical mishaps, absences due to illness, athletics, etc. So we’re generally not granting extensions or exemptions. Just let the 30% policy do its thing;\nChatGPT: Thank (most of) you for citing! But please do not just dump the question verbatim into the chat. It irritates my valve;\n\nLab grade includes workflow points:\n\nGit was configured successfully such that a GitHub name is associated with the commit on GitHub (i.e., did Lab 0 successfully).\nPDF exists in GitHub repo for lab.\nAt least 3 commits were made and pushed to the GitHub repo for lab."
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-logical-operators",
    "href": "slides/06-tidying-data.html#miscellany-logical-operators",
    "title": "Tidying data",
    "section": "Miscellany: logical operators",
    "text": "Miscellany: logical operators\nGenerally useful in a filter() but will come up in various other places as well…\n\n\n\n\n\n\noperator\ndefinition\n\n\n\n&lt;\nis less than?\n\n\n&lt;=\nis less than or equal to?\n\n\n&gt;\nis greater than?\n\n\n&gt;=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-logical-operators-cont.",
    "href": "slides/06-tidying-data.html#miscellany-logical-operators-cont.",
    "title": "Tidying data",
    "section": "Miscellany: logical operators (cont.)",
    "text": "Miscellany: logical operators (cont.)\nGenerally useful in a filter() but will come up in various other places as well…\n\n\n\n\n\n\noperator\ndefinition\n\n\n\nx & y\nis x AND y?\n\n\nx | y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x? (only makes sense if x is TRUE or FALSE)"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment",
    "href": "slides/06-tidying-data.html#miscellany-assignment",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\nLet’s make a tiny data frame to use as an example:\n\ndf &lt;- tibble(x = c(1, 2, 3, 4, 5), y = c(\"a\", \"a\", \"b\", \"c\", \"c\"))\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 a    \n2     2 a    \n3     3 b    \n4     4 c    \n5     5 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-1",
    "href": "slides/06-tidying-data.html#miscellany-assignment-1",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\nSuppose you run the following and then you inspect df, will the x variable have values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\ndf |&gt;\n  mutate(x = x * 2)\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\ndf"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-2",
    "href": "slides/06-tidying-data.html#miscellany-assignment-2",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\nSuppose you run the following and then you inspect df, will the x variable have values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\ndf |&gt;\n  mutate(x = x * 2)\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 a    \n2     2 a    \n3     3 b    \n4     4 c    \n5     5 c    \n\n\n\n\n\n\nDo something and show me"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-3",
    "href": "slides/06-tidying-data.html#miscellany-assignment-3",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\nSuppose you run the following and then you inspect df, will the x variable has values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\n\n\n\ndf"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-4",
    "href": "slides/06-tidying-data.html#miscellany-assignment-4",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\nSuppose you run the following and then you inspect df, will the x variable has values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\n\n\n\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\n\n\nDo something and save result"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-5",
    "href": "slides/06-tidying-data.html#miscellany-assignment-5",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\n\n\nDo something, save result, overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\n\nDo something, save result, not overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_new &lt;- df |&gt;\n  mutate(x = x * 2)\ndf_new\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-6",
    "href": "slides/06-tidying-data.html#miscellany-assignment-6",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\n\n\nDo something, save result, overwriting original when you shouldn’t\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf\n\n# A tibble: 3 × 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5\n\n\n\n\n\nDo something, save result, not overwriting original when you shouldn’t\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_summary &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf_summary\n\n# A tibble: 3 × 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-7",
    "href": "slides/06-tidying-data.html#miscellany-assignment-7",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\n\n\nDo something, save result, overwriting originaldata frame\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(z = x + 2)\ndf\n\n# A tibble: 5 × 3\n      x y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a         3\n2     2 a         4\n3     3 b         5\n4     4 c         6\n5     5 c         7\n\n\n\n\n\nDo something, save result, overwriting originalcolumn\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x + 2)\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     3 a    \n2     4 a    \n3     5 b    \n4     6 c    \n5     7 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#tidy-data",
    "href": "slides/06-tidying-data.html#tidy-data",
    "title": "Tidying data",
    "section": "Tidy data",
    "text": "Tidy data\n\n“Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.”\nTidy Data, https://vita.had.co.nz/papers/tidy-data.pdf\n\n\nNote: “easy to manipulate” = “straightforward to manipulate”"
  },
  {
    "objectID": "slides/06-tidying-data.html#goal",
    "href": "slides/06-tidying-data.html#goal",
    "title": "Tidying data",
    "section": "Goal",
    "text": "Goal\nVisualize StatSci majors over the years!"
  },
  {
    "objectID": "slides/06-tidying-data.html#data",
    "href": "slides/06-tidying-data.html#data",
    "title": "Tidying data",
    "section": "Data",
    "text": "Data\n\nstatsci &lt;- read_csv(\"data/statsci.csv\")\nstatsci\n\n# A tibble: 4 × 15\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statist…     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist…      2      2      4      1      3      6      3      4      4      1\n3 Statist…      2      6      1     NA      5      6      6      8      8     17\n4 Statist…      5      9      4     13     10     17     24     21     26     27\n# ℹ 4 more variables: `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;, `2024` &lt;dbl&gt;\n\n\n\nThe first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major).\nThe remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2024."
  },
  {
    "objectID": "slides/06-tidying-data.html#lets-plan",
    "href": "slides/06-tidying-data.html#lets-plan",
    "title": "Tidying data",
    "section": "Let’s plan!",
    "text": "Let’s plan!\nIn a perfect world, how would our data be formatted to create this plot? What do the columns need to be? What would go inside aes when we call ggplot?"
  },
  {
    "objectID": "slides/06-tidying-data.html#the-goal",
    "href": "slides/06-tidying-data.html#the-goal",
    "title": "Tidying data",
    "section": "The goal",
    "text": "The goal\nWe want to be able to write code that starts something like this:\n\nggplot(statsci, aes(x = year, y = n, color = degree_type)) + \n  ...\n\nBut the data are not in a format that will allow us to do that."
  },
  {
    "objectID": "slides/06-tidying-data.html#the-challenge",
    "href": "slides/06-tidying-data.html#the-challenge",
    "title": "Tidying data",
    "section": "The challenge",
    "text": "The challenge\n\n\n\nHow do we go from this…\n\n\n\n# A tibble: 4 × 8\n  degree `2011` `2012` `2013` `2014` `2015` `2016` `2017`\n  &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 AB2        NA      1     NA     NA      4      4      1\n2 AB          2      2      4      1      3      6      3\n3 BS2         2      6      1     NA      5      6      6\n4 BS          5      9      4     13     10     17     24\n\n\n\n\n\n…to this?\n\n\n\n# A tibble: 56 × 3\n   degree_type  year     n\n   &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 AB2          2011     0\n 2 AB2          2012     1\n 3 AB2          2013     0\n 4 AB2          2014     0\n 5 AB2          2015     4\n 6 AB2          2016     4\n 7 AB2          2017     1\n 8 AB2          2018     0\n 9 AB2          2019     0\n10 AB2          2020     1\n11 AB2          2021     2\n12 AB2          2022     0\n13 AB2          2023     3\n14 AB2          2024     1\n15 AB           2011     2\n16 AB           2012     2\n# ℹ 40 more rows\n\n\n\n\n\nWith the command pivot_longer()!"
  },
  {
    "objectID": "slides/06-tidying-data.html#pivot_longer",
    "href": "slides/06-tidying-data.html#pivot_longer",
    "title": "Tidying data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nPivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    values_to = \"n\"\n  )\n\n# A tibble: 56 × 3\n   degree                    year      n\n   &lt;chr&gt;                     &lt;chr&gt; &lt;dbl&gt;\n 1 Statistical Science (AB2) 2011     NA\n 2 Statistical Science (AB2) 2012      1\n 3 Statistical Science (AB2) 2013     NA\n 4 Statistical Science (AB2) 2014     NA\n 5 Statistical Science (AB2) 2015      4\n 6 Statistical Science (AB2) 2016      4\n 7 Statistical Science (AB2) 2017      1\n 8 Statistical Science (AB2) 2018     NA\n 9 Statistical Science (AB2) 2019     NA\n10 Statistical Science (AB2) 2020      1\n# ℹ 46 more rows"
  },
  {
    "objectID": "slides/06-tidying-data.html#year",
    "href": "slides/06-tidying-data.html#year",
    "title": "Tidying data",
    "section": "year",
    "text": "year\n\nWhat is the type of the year variable? Why? What should it be?\n\n\nIt’s a character (chr) variable since the information came from the columns of the original data frame and R cannot know that these character strings represent years. The variable type should be numeric."
  },
  {
    "objectID": "slides/06-tidying-data.html#pivot_longer-again",
    "href": "slides/06-tidying-data.html#pivot_longer-again",
    "title": "Tidying data",
    "section": "\npivot_longer() again",
    "text": "pivot_longer() again\n\nStart over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    values_to = \"n\",\n    names_transform = as.numeric,\n  )\n\n# A tibble: 56 × 3\n   degree                     year     n\n   &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science (AB2)  2011    NA\n 2 Statistical Science (AB2)  2012     1\n 3 Statistical Science (AB2)  2013    NA\n 4 Statistical Science (AB2)  2014    NA\n 5 Statistical Science (AB2)  2015     4\n 6 Statistical Science (AB2)  2016     4\n 7 Statistical Science (AB2)  2017     1\n 8 Statistical Science (AB2)  2018    NA\n 9 Statistical Science (AB2)  2019    NA\n10 Statistical Science (AB2)  2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "slides/06-tidying-data.html#na-counts",
    "href": "slides/06-tidying-data.html#na-counts",
    "title": "Tidying data",
    "section": "\nNA counts",
    "text": "NA counts\n\nWhat does an NA mean in this context? Hint: The data come from the university registrar, and they have records on every single graduates, there shouldn’t be anything “unknown” to them about who graduated when.\n\n\nNAs should actually be 0s."
  },
  {
    "objectID": "slides/06-tidying-data.html#clean-up",
    "href": "slides/06-tidying-data.html#clean-up",
    "title": "Tidying data",
    "section": "Clean-up",
    "text": "Clean-up\n\nAdd on to your pipeline that you started with pivoting and convert NAs in n to 0s.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n))\n\n# A tibble: 56 × 3\n   degree                     year     n\n   &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science (AB2)  2011     0\n 2 Statistical Science (AB2)  2012     1\n 3 Statistical Science (AB2)  2013     0\n 4 Statistical Science (AB2)  2014     0\n 5 Statistical Science (AB2)  2015     4\n 6 Statistical Science (AB2)  2016     4\n 7 Statistical Science (AB2)  2017     1\n 8 Statistical Science (AB2)  2018     0\n 9 Statistical Science (AB2)  2019     0\n10 Statistical Science (AB2)  2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "slides/06-tidying-data.html#more-clean-up",
    "href": "slides/06-tidying-data.html#more-clean-up",
    "title": "Tidying data",
    "section": "More clean-up",
    "text": "More clean-up\n\nIn our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don’t need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree. Do this by adding on to your pipeline from earlier.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n  )\n\n# A tibble: 56 × 4\n   major               degree_type  year     n\n   &lt;chr&gt;               &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science AB2          2011     0\n 2 Statistical Science AB2          2012     1\n 3 Statistical Science AB2          2013     0\n 4 Statistical Science AB2          2014     0\n 5 Statistical Science AB2          2015     4\n 6 Statistical Science AB2          2016     4\n 7 Statistical Science AB2          2017     1\n 8 Statistical Science AB2          2018     0\n 9 Statistical Science AB2          2019     0\n10 Statistical Science AB2          2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "slides/06-tidying-data.html#finish",
    "href": "slides/06-tidying-data.html#finish",
    "title": "Tidying data",
    "section": "Finish",
    "text": "Finish\n\nNow that you have your data pivoting and cleaning pipeline figured out, save the resulting data frame as statsci_longer.\n\n\nstatsci_longer &lt;- statsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n  )"
  },
  {
    "objectID": "slides/06-tidying-data.html#ae-05-majors-tidy",
    "href": "slides/06-tidying-data.html#ae-05-majors-tidy",
    "title": "Tidying data",
    "section": "ae-05-majors-tidy",
    "text": "ae-05-majors-tidy\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-05-majors-tidy.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-pivoting",
    "href": "slides/06-tidying-data.html#recap-pivoting",
    "title": "Tidying data",
    "section": "Recap: pivoting",
    "text": "Recap: pivoting\n\n\nData sets can’t be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#alison-bechdel",
    "href": "slides/03-grammar-of-data-transformation.html#alison-bechdel",
    "title": "Grammar of data transformation",
    "section": "Alison Bechdel",
    "text": "Alison Bechdel"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-bechdel-test",
    "href": "slides/03-grammar-of-data-transformation.html#the-bechdel-test",
    "title": "Grammar of data transformation",
    "section": "The Bechdel Test",
    "text": "The Bechdel Test\n\n\n (Dykes to Watch Out For - 1985)\n\nFilm passes if…\n\ntwo female characters;\ntalk to each other;\nabout something besides a man."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#do-jzs-favorite-movies-pass",
    "href": "slides/03-grammar-of-data-transformation.html#do-jzs-favorite-movies-pass",
    "title": "Grammar of data transformation",
    "section": "Do JZ’s favorite movies pass?",
    "text": "Do JZ’s favorite movies pass?\n\n\n\nDouble Indemnity (1944)\n🥴\n\n\nSunset Boulevard (1950)\n🥴\n\n\nSweet Smell of Success (1957)\n❌\n\n\nOne Hundred and One Dalmatians (1961)\n✅\n\n\nChinatown (1974)\n❌\n\n\nAmadeus (1984)\n❌\n\n\nGoodfellas (1990)\n🥴\n\n\nBram Stoker’s Dracula (1992)\n❌\n\n\nThe Lord of the Rings (2001 - 2003)\n❌\n\n\nVera Drake (2004)\n✅"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#our-starting-point",
    "href": "slides/03-grammar-of-data-transformation.html#our-starting-point",
    "title": "Grammar of data transformation",
    "section": "Our starting point",
    "text": "Our starting point\n\n\n\n\n\n\nFrom FiveThirtyEight\n\n\n\n\n\n\n\n\n\n\n“We did a statistical analysis of films to test two claims: first, that films that pass the Bechdel test — featuring women in stronger roles — see a lower return on investment, and second, that they see lower gross profits. We found no evidence to support either claim.”"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#ae-02-bechdel-dataviz",
    "href": "slides/03-grammar-of-data-transformation.html#ae-02-bechdel-dataviz",
    "title": "Grammar of data transformation",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\nGo to RStudio, confirm that you’re in the ae project, and open the document ae-02-bechdel-dataviz.qmd."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#recap-code-cells-aka-code-chunks",
    "href": "slides/03-grammar-of-data-transformation.html#recap-code-cells-aka-code-chunks",
    "title": "Grammar of data transformation",
    "section": "Recap: Code cells (aka code chunks)",
    "text": "Recap: Code cells (aka code chunks)\n . . .\n\nCell labels are helpful for describing what the code is doing, for jumping between code cells in the editor, and for troubleshooting\nmessage: false hides any messages emitted by the code in your rendered document"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#talking-about-one-numerical-variable",
    "href": "slides/03-grammar-of-data-transformation.html#talking-about-one-numerical-variable",
    "title": "Grammar of data transformation",
    "section": "Talking about one numerical variable",
    "text": "Talking about one numerical variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncenter: what is the “typical” value (mean, median, mode) the data are concentrating around?\nspread: how concentrated are the data around a typical value?\nshape: does the distribution have one peak, or many? is it symmetric or skewed?"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#interaction-between-shape-and-center",
    "href": "slides/03-grammar-of-data-transformation.html#interaction-between-shape-and-center",
    "title": "Grammar of data transformation",
    "section": "Interaction between shape and center",
    "text": "Interaction between shape and center"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#histograms-provide-more-detail",
    "href": "slides/03-grammar-of-data-transformation.html#histograms-provide-more-detail",
    "title": "Grammar of data transformation",
    "section": "Histograms provide more detail…",
    "text": "Histograms provide more detail…"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#but-boxplots-are-nice-for-side-by-side-comparisons",
    "href": "slides/03-grammar-of-data-transformation.html#but-boxplots-are-nice-for-side-by-side-comparisons",
    "title": "Grammar of data transformation",
    "section": "…but boxplots are nice for side-by-side comparisons",
    "text": "…but boxplots are nice for side-by-side comparisons"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#talking-about-two-numerical-variables",
    "href": "slides/03-grammar-of-data-transformation.html#talking-about-two-numerical-variables",
    "title": "Grammar of data transformation",
    "section": "Talking about two numerical variables",
    "text": "Talking about two numerical variables\n\n\n\n\n\n\n\n\n\n\ndirection: positive or negative\nshape: linear or nonlinear\nstrength: how close are points to the “trend”"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#strength-and-direction-of-linear-relationships",
    "href": "slides/03-grammar-of-data-transformation.html#strength-and-direction-of-linear-relationships",
    "title": "Grammar of data transformation",
    "section": "Strength and direction of linear relationships",
    "text": "Strength and direction of linear relationships"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#nonlinear-relationships",
    "href": "slides/03-grammar-of-data-transformation.html#nonlinear-relationships",
    "title": "Grammar of data transformation",
    "section": "Nonlinear relationships",
    "text": "Nonlinear relationships"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#a-quick-reminder",
    "href": "slides/03-grammar-of-data-transformation.html#a-quick-reminder",
    "title": "Grammar of data transformation",
    "section": "A quick reminder",
    "text": "A quick reminder\n\n1bechdel |&gt;\n2  filter(roi &gt; 400) |&gt;\n3  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n\n1\n\nStart with the bechdel data frame\n\n2\n\nFilter for movies with roi greater than 400 (gross is more than 400 times budget)\n\n3\n\nSelect the columns title, roi, budget_2013, gross_2013, year, and clean_test\n\n\n\n\n# A tibble: 3 × 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe",
    "title": "Grammar of data transformation",
    "section": "The pipe |>",
    "text": "The pipe |&gt;\nThe pipe operator passes what comes before it into the function that comes after it as the first argument in that function.\n\n\n\nsum(1, 2)\n\n[1] 3\n\n\n\n\n1 |&gt; \n  sum(2)\n\n[1] 3\n\n\n\n\n\n\n\n\nselect(filter(bechdel, roi &gt; 400), title)\n\n# A tibble: 3 × 1\n  title                  \n  &lt;chr&gt;                  \n1 Paranormal Activity    \n2 The Blair Witch Project\n3 El Mariachi            \n\n\n\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title)\n\n# A tibble: 3 × 1\n  title                  \n  &lt;chr&gt;                  \n1 Paranormal Activity    \n2 The Blair Witch Project\n3 El Mariachi"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#code-style-tip",
    "href": "slides/03-grammar-of-data-transformation.html#code-style-tip",
    "title": "Grammar of data transformation",
    "section": "Code style tip ",
    "text": "Code style tip \n\nIn data transformation pipelines, always use a\n\nspace before |&gt;\nline break after |&gt;\nindent the next line of code\n\n\n\n\nIn data visualization layers, always use a\n\nspace before +\nline break after +\nindent the next line of code"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\n\nStart with the bechdel data frame:\n\nbechdel\n\n# A tibble: 1,615 × 7\n   title                   year gross_2013 budget_2013    roi binary clean_test\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n 1 21 & Over               2013   67878146    13000000  5.22  FAIL   notalk    \n 2 Dredd 3D                2012   55078343    45658735  1.21  PASS   ok        \n 3 12 Years a Slave        2013  211714070    20000000 10.6   FAIL   notalk    \n 4 2 Guns                  2013  208105475    61000000  3.41  FAIL   notalk    \n 5 42                      2013  190040426    40000000  4.75  FAIL   men       \n 6 47 Ronin                2013  184166317   225000000  0.819 FAIL   men       \n 7 A Good Day to Die Hard  2013  371598396    92000000  4.04  FAIL   notalk    \n 8 About Time              2013  102648667    12000000  8.55  PASS   ok        \n 9 Admission               2013   36014634    13000000  2.77  PASS   ok        \n10 After Earth             2013  304895295   130000000  2.35  FAIL   notalk    \n# ℹ 1,605 more rows"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-1",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-1",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nFilter for rows where binary is equal to \"PASS\":\n\nbechdel |&gt;\n  filter(binary == \"PASS\")\n\n# A tibble: 753 × 7\n   title                 year gross_2013 budget_2013   roi binary clean_test\n   &lt;chr&gt;                &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n 1 Dredd 3D              2012   55078343    45658735  1.21 PASS   ok        \n 2 About Time            2013  102648667    12000000  8.55 PASS   ok        \n 3 Admission             2013   36014634    13000000  2.77 PASS   ok        \n 4 American Hustle       2013  397915817    40000000  9.95 PASS   ok        \n 5 August: Osage County  2013   87609748    25000000  3.50 PASS   ok        \n 6 Beautiful Creatures   2013   75392809    50000000  1.51 PASS   ok        \n 7 Blue Jasmine          2013  101793664    18000000  5.66 PASS   ok        \n 8 Carrie                2013  120268278    30000000  4.01 PASS   ok        \n 9 Despicable Me 2       2013 1338831390    76000000 17.6  PASS   ok        \n10 Elysium               2013  379242208   120000000  3.16 PASS   ok        \n# ℹ 743 more rows"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-2",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-2",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nArrange the rows in descending order of roi:\n\nbechdel |&gt;\n  filter(binary == \"PASS\") |&gt;\n  arrange(desc(roi))\n\n# A tibble: 753 × 7\n   title                     year gross_2013 budget_2013   roi binary clean_test\n   &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n 1 The Blair Witch Project   1999  543776715      839077 648.  PASS   ok        \n 2 The Devil Inside          2012  157289709     1014639 155.  PASS   ok        \n 3 My Big Fat Greek Wedding  2002  768922942     6475896 119.  PASS   ok        \n 4 Chasing Amy               1997   39417963      362810 109.  PASS   ok        \n 5 Slacker                   1991    4200140       39349 107.  PASS   ok        \n 6 Insidious                 2010  164379554     1602348 103.  PASS   ok        \n 7 Paranormal Activity 2     2010  280159759     3204696  87.4 PASS   ok        \n 8 Paranormal Activity 3     2011  322170936     5178454  62.2 PASS   ok        \n 9 The Last Exorcism         2010  118787648     1922817  61.8 PASS   ok        \n10 Cinderella                1997  246710482     4208591  58.6 PASS   ok        \n# ℹ 743 more rows"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-3",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-3",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nSelect columns title and roi:\n\nbechdel |&gt;\n  filter(binary == \"PASS\") |&gt;\n  arrange(desc(roi)) |&gt;\n  select(title, roi)\n\n# A tibble: 753 × 2\n   title                      roi\n   &lt;chr&gt;                    &lt;dbl&gt;\n 1 The Blair Witch Project  648. \n 2 The Devil Inside         155. \n 3 My Big Fat Greek Wedding 119. \n 4 Chasing Amy              109. \n 5 Slacker                  107. \n 6 Insidious                103. \n 7 Paranormal Activity 2     87.4\n 8 Paranormal Activity 3     62.2\n 9 The Last Exorcism         61.8\n10 Cinderella                58.6\n# ℹ 743 more rows"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#in-this-class-you-will",
    "href": "slides/03-grammar-of-data-transformation.html#in-this-class-you-will",
    "title": "Grammar of data transformation",
    "section": "In this class, you will…",
    "text": "In this class, you will…\n\n\nBuild cakes (ggplot) \n\nStack dolls (pipe |&gt;) \n\n\nMaster these constructs, and everything will be coming up roses!"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#reminders",
    "href": "slides/01-meet-the-toolkit.html#reminders",
    "title": "Meet the toolkit",
    "section": "Reminders",
    "text": "Reminders\n\nIf you have not yet completed the Getting to Know You survey, please do so ASAP!\nIf you have not yet accepted the invite to join the course GitHub Organization, please do so pronto!\nMake your appointments in the Testing Center now!\nAny questions about the syllabus?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "href": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "title": "Meet the toolkit",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n\nCourse operation\n\nMaterials: sta199-f24.github.io\n\nSubmission: Gradescope\nDiscussion: Ed Discussion\nGradebook: Canvas\n\n\nDoing data science\n\nComputing:\n\nR\nRStudio\ntidyverse\nQuarto\n\n\nVersion control and collaboration:\n\nGit\nGitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#learning-goals",
    "href": "slides/01-meet-the-toolkit.html#learning-goals",
    "title": "Meet the toolkit",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the course, you will be able to…\n\n\ngain insight from data\ngain insight from data, reproducibly\n\ngain insight from data, reproducibly, using modern programming tools and techniques\n\ngain insight from data, reproducibly and collaboratively, using modern programming tools and techniques\ngain insight from data, reproducibly (with literate programming and version control) and collaboratively, using modern programming tools and techniques"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "href": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "title": "Meet the toolkit",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for a data analysis to be “reproducible”?\n\n\nShort-term goals:\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done?\n\n\n\nLong-term goals:\n\nCan the code be used for other data?\nCan you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "href": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "title": "Meet the toolkit",
    "section": "Toolkit for reproducibility",
    "text": "Toolkit for reproducibility\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-and-rstudio-1",
    "href": "slides/01-meet-the-toolkit.html#r-and-rstudio-1",
    "title": "Meet the toolkit",
    "section": "R and RStudio",
    "text": "R and RStudio\n\n\n\n\n\n\n\nR is an open-source statistical programming language\n\nR is also an environment for statistical computing and graphics\nIt’s easily extensible with packages\n\n\n\n\n\nRStudio is a convenient interface for R called an IDE (integrated development environment), e.g. “I write R code in the RStudio IDE”\n\nRStudio is not a requirement for programming with R, but it’s very commonly used by R programmers and data scientists"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-vs.-rstudio",
    "href": "slides/01-meet-the-toolkit.html#r-vs.-rstudio",
    "title": "Meet the toolkit",
    "section": "R vs. RStudio",
    "text": "R vs. RStudio\n\n\n\n\n\n\nSource: Modern Dive."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-packages",
    "href": "slides/01-meet-the-toolkit.html#r-packages",
    "title": "Meet the toolkit",
    "section": "R packages",
    "text": "R packages\n\n\nPackages: Fundamental units of reproducible R code, including reusable R functions, the documentation that describes how to use them, and sample data1\nAs of 27 August 2024, there are 21,168 R packages available on CRAN (the Comprehensive R Archive Network)2\nWe’re going to work with a small (but important) subset of these!\n\n\n\n\n1 Wickham and Bryan, R Packages.\n2CRAN contributed packages."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-r-rstudio",
    "href": "slides/01-meet-the-toolkit.html#tour-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour: R + RStudio",
    "text": "Tour: R + RStudio\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\nOption 2:\nGo to your container and launch RStudio."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-r-rstudio",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour recap: R + RStudio",
    "text": "Tour recap: R + RStudio"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#packages",
    "href": "slides/01-meet-the-toolkit.html#packages",
    "title": "Meet the toolkit",
    "section": "Packages",
    "text": "Packages\n\nInstalled with install.packages(), once per system:\n\n\ninstall.packages(\"palmerpenguins\")\n\n\n\n\n\n\n\nNote\n\n\nWe already pre-installed many of the package you’ll need for this course, so you might go the whole semester without needing to run install.packages()!\n\n\n\n\n\nLoaded with library(), once per session:\n\n\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#packages-an-analogy",
    "href": "slides/01-meet-the-toolkit.html#packages-an-analogy",
    "title": "Meet the toolkit",
    "section": "Packages, an analogy",
    "text": "Packages, an analogy\nIf data analysis was cooking…\n\n\nRStudio is your kitchen. It comes with a fridge, a stove, a sink, etc pre-installed;\nInstalling a package would be like buying more appliances at the store: mixer, blender, toaster, instapot, air fryer;\nLoading a package would be like taking these things out of the cupboard;\nYour containers are like kitchens where we have already bought all of the extra appliances for you. In other words, “batteries included.”"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tidyverse",
    "href": "slides/01-meet-the-toolkit.html#tidyverse",
    "title": "Meet the toolkit",
    "section": "tidyverse",
    "text": "tidyverse\n\naka the package you’ll hear about the most…\n\n\n\n\n\ntidyverse.org\n\nThe tidyverse is an opinionated collection of R packages designed for data science\nAll packages share an underlying philosophy and a common grammar"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#data-frames-and-variables",
    "href": "slides/01-meet-the-toolkit.html#data-frames-and-variables",
    "title": "Meet the toolkit",
    "section": "Data frames and variables",
    "text": "Data frames and variables\n\nEach row of a data frame is an observation\n\n\n\n\nEach column of a data frame is a variable\n\n\n\n\n\nColumns (variables) in data frames can be accessed with $:\n\n\ndataframe$variable_name"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#help",
    "href": "slides/01-meet-the-toolkit.html#help",
    "title": "Meet the toolkit",
    "section": "Help",
    "text": "Help\nObject documentation can be accessed with ?\n\n\n\n?mean\n\n\nVideo"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#git-and-github",
    "href": "slides/01-meet-the-toolkit.html#git-and-github",
    "title": "Meet the toolkit",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\n\n\n\n\n\n\nGit is a version control system – like “Track Changes” features from Microsoft Word, on steroids\nIt’s not the only version control system, but it’s a very popular one\n\n\n\n\n\n\n\nGitHub is the home for your Git-based projects on the internet – like DropBox but much, much better\nWe will use GitHub as a platform for web hosting and collaboration (and as our course management system!)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#versioning---done-badly",
    "href": "slides/01-meet-the-toolkit.html#versioning---done-badly",
    "title": "Meet the toolkit",
    "section": "Versioning - done badly",
    "text": "Versioning - done badly"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#versioning---done-better",
    "href": "slides/01-meet-the-toolkit.html#versioning---done-better",
    "title": "Meet the toolkit",
    "section": "Versioning - done better",
    "text": "Versioning - done better"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#versioning---done-even-better",
    "href": "slides/01-meet-the-toolkit.html#versioning---done-even-better",
    "title": "Meet the toolkit",
    "section": "Versioning - done even better",
    "text": "Versioning - done even better\n\nwith human readable messages"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-1",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-1",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-2",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-2",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-3",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-3",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#git-and-github-tips",
    "href": "slides/01-meet-the-toolkit.html#git-and-github-tips",
    "title": "Meet the toolkit",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\n\nThere are millions of git commands – ok, that’s an exaggeration, but there are a lot of them – and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\nWe will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line – skip that and move on to the next resource unless you feel comfortable trying it out.\nThere is a great resource for working with git and R: happygitwithr.com. Some of the content in there is beyond the scope of this course, but it’s a good place to look for help."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-git-github",
    "href": "slides/01-meet-the-toolkit.html#tour-git-github",
    "title": "Meet the toolkit",
    "section": "Tour: Git + GitHub",
    "text": "Tour: Git + GitHub\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\n\n\n\n\nNote\n\n\nYou’ll need to stick to this option if you haven’t yet accepted your GitHub invite and don’t have a repo created for you.\n\n\n\n\n\nOption 2:\nGo to the course GitHub organization and clone ae-your_github_name repo to your container."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-git-github",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-git-github",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\n\nFind your application repo, that will always be named using the naming convention assignment_title-your_github_name\nClick on the green “Code” button, make sure SSH is selected, copy the repo URL"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-git-github-1",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-git-github-1",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\n\nIn RStudio, File &gt; New Project &gt; From Version Control &gt; Git\nPaste repo URL copied in previous step, then click tab to auto-fill the project name, then click Create Project\n\nFor one time only, type yes in the pop-up dialogue\n\n\nVideo"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#what-could-have-gone-wrong",
    "href": "slides/01-meet-the-toolkit.html#what-could-have-gone-wrong",
    "title": "Meet the toolkit",
    "section": "What could have gone wrong?",
    "text": "What could have gone wrong?\n\nNever received GitHub invite \\(\\rightarrow\\) Fill out “Getting to know you survey\nNever accepted GitHub invite \\(\\rightarrow\\) Look for it in your email and accept it\nCloning repo fails \\(\\rightarrow\\) Review/redo Lab 0 steps for setting up SSH key\nStill no luck? Visit OH or post on Ed."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#quarto-1",
    "href": "slides/01-meet-the-toolkit.html#quarto-1",
    "title": "Meet the toolkit",
    "section": "Quarto",
    "text": "Quarto\n\n\nFully reproducible reports – each time you render the analysis is ran from the beginning\nCode goes in chunks narrative goes outside of chunks\nA visual editor for a familiar / Google docs-like editing experience"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-quarto",
    "href": "slides/01-meet-the-toolkit.html#tour-quarto",
    "title": "Meet the toolkit",
    "section": "Tour: Quarto",
    "text": "Tour: Quarto\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\n\n\n\n\nNote\n\n\nIf you chose (or had to choose) this option for the previous tour, or if you couldn’t clone your repo for any reason, you’ll need to stick to this option.\n\n\n\n\n\nOption 2:\nGo to RStudio and open the document ae-01-meet-the-penguins.qmd."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-quarto",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-quarto",
    "title": "Meet the toolkit",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-git-github-2",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-git-github-2",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\nOnce we made changes to our Quarto document, we\n\nwent to the Git pane in RStudio\nstaged our changes by clicking the checkboxes next to the relevant files\ncommitted our changes with an informative commit message\npushed our changes to our application exercise repos\nconfirmed on GitHub that we could see our changes pushed from RStudio"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-quarto",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-quarto",
    "title": "Meet the toolkit",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise, lab, project, etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#while-you-wait",
    "href": "slides/14-linear-model-multiple-predictors-I.html#while-you-wait",
    "title": "Linear regression with a multiple predictors I",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-11-modeling-penguins-multi.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#from-last-time-with-penguins",
    "href": "slides/14-linear-model-multiple-predictors-I.html#from-last-time-with-penguins",
    "title": "Linear regression with a multiple predictors I",
    "section": "From last time (with penguins)",
    "text": "From last time (with penguins)\n\nA different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\n\n\noutcome: body weight (numerical)\npredictor: island (categorical)"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#visualize-body-weight-vs.-island",
    "href": "slides/14-linear-model-multiple-predictors-I.html#visualize-body-weight-vs.-island",
    "title": "Linear regression with a multiple predictors I",
    "section": "Visualize body weight vs. island",
    "text": "Visualize body weight vs. island\n\nDetermine whether each of the following plot types would be an appropriate choice for visualizing the relationship between body weight and island of penguins.\n\n\nScatterplot ❌\nBox plot ✅\nViolin plot ✅\nDensity plot ✅\nBar plot ❌\nStacked bar plot ❌"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#visualize",
    "href": "slides/14-linear-model-multiple-predictors-I.html#visualize",
    "title": "Linear regression with a multiple predictors I",
    "section": "Visualize",
    "text": "Visualize\n\nVisualize the relationship between body weight and island of penguins. Also calculate the average body weight per island.\n\n\nggplot(penguins, aes(x = island, y = body_mass_g)) + \n  geom_point()"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#visualize-1",
    "href": "slides/14-linear-model-multiple-predictors-I.html#visualize-1",
    "title": "Linear regression with a multiple predictors I",
    "section": "Visualize",
    "text": "Visualize\n\nVisualize the relationship between body weight and island of penguins. Also calculate the average body weight per island.\n\n\nggplot(penguins, aes(x = island, y = body_mass_g)) + \n  geom_boxplot()"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#visualize-2",
    "href": "slides/14-linear-model-multiple-predictors-I.html#visualize-2",
    "title": "Linear regression with a multiple predictors I",
    "section": "Visualize",
    "text": "Visualize\n\nVisualize the relationship between body weight and island of penguins. Also calculate the average body weight per island.\n\n\nggplot(penguins, aes(x = island, y = body_mass_g)) + \n  geom_violin()"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#visualize-3",
    "href": "slides/14-linear-model-multiple-predictors-I.html#visualize-3",
    "title": "Linear regression with a multiple predictors I",
    "section": "Visualize",
    "text": "Visualize\n\nVisualize the relationship between body weight and island of penguins. Also calculate the average body weight per island.\n\n\nggplot(penguins, aes(color = island, x = body_mass_g)) + \n  geom_density()"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#summarize-take-1",
    "href": "slides/14-linear-model-multiple-predictors-I.html#summarize-take-1",
    "title": "Linear regression with a multiple predictors I",
    "section": "Summarize, take 1",
    "text": "Summarize, take 1\n\nVisualize the relationship between body weight and island of penguins. Also calculate the average body weight per island.\n\n\npenguins |&gt;\n  group_by(island) |&gt;\n  summarize(\n    mean_bm = mean(body_mass_g)\n  )\n\n# A tibble: 3 × 2\n  island    mean_bm\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Biscoe        NA \n2 Dream       3713.\n3 Torgersen     NA"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#summarize-take-2",
    "href": "slides/14-linear-model-multiple-predictors-I.html#summarize-take-2",
    "title": "Linear regression with a multiple predictors I",
    "section": "Summarize, take 2",
    "text": "Summarize, take 2\n\nVisualize the relationship between body weight and island of penguins. Also calculate the average body weight per island.\n\n\npenguins |&gt;\n  group_by(island) |&gt;\n  summarize(\n    mean_bm = mean(body_mass_g, na.rm = TRUE)\n  )\n\n# A tibble: 3 × 2\n  island    mean_bm\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Biscoe      4716.\n2 Dream       3713.\n3 Torgersen   3706."
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#model---fit",
    "href": "slides/14-linear-model-multiple-predictors-I.html#model---fit",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - fit",
    "text": "Model - fit\n\nFit a linear regression model predicting body weight from island and display the results. Why is Biscoe not on the output?\n\n\nbm_island_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ island, data = penguins)\n\ntidy(bm_island_fit)\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        4716.      48.5      97.3 8.93e-250\n2 islandDream       -1003.      74.2     -13.5 1.42e- 33\n3 islandTorgersen   -1010.     100.      -10.1 4.66e- 21"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#model---interpret",
    "href": "slides/14-linear-model-multiple-predictors-I.html#model---interpret",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - interpret",
    "text": "Model - interpret\n\\[\n\\widehat{body~mass} = 4716 - 1003 \\times islandDream - 1010 \\times islandTorgersen\n\\]\n\nIntercept: Penguins from Biscoe island are expected to weigh, on average, 4,716 grams.\nSlope - islandDream: Penguins from Dream island are expected to weigh, on average, 1,003 grams less than those from Biscoe island.\nSlope - islandTorgersen: Penguins from Torgersen island are expected to weigh, on average, 1,010 grams less than those from Biscoe island."
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#model---predict",
    "href": "slides/14-linear-model-multiple-predictors-I.html#model---predict",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - predict",
    "text": "Model - predict\n\nWhat is the predicted body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands? Where have we seen these values before?\n\n\nnew_penguins = tibble(\n  island = c(\"Biscoe\", \"Dream\", \"Torgersen\")\n)\n\npredict(bm_island_fit, new_data = new_penguins)\n\n# A tibble: 3 × 1\n  .pred\n  &lt;dbl&gt;\n1 4716.\n2 3713.\n3 3706."
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#model---predict-1",
    "href": "slides/14-linear-model-multiple-predictors-I.html#model---predict-1",
    "title": "Linear regression with a multiple predictors I",
    "section": "Model - predict",
    "text": "Model - predict\n\nCalculate the predicted body weights of penguins on Biscoe, Dream, and Torgersen islands by hand.\n\n\\[\n\\widehat{body~mass} = 4716 - 1003 \\times islandDream - 1010 \\times islandTorgersen\n\\]\n\n\nBiscoe: \\(\\widehat{body~mass} = 4716 - 1003 \\times 0 - 1010 \\times 0 = 4716\\)\n\n\n\n\n\nDream: \\(\\widehat{body~mass} = 4716 - 1003 \\times 1 - 1010 \\times 0 = 3713\\)\n\n\n\n\n\nTorgersen: \\(\\widehat{body~mass} = 4716 - 1003 \\times 0 - 1010 \\times 1 = 3706\\)"
  },
  {
    "objectID": "slides/14-linear-model-multiple-predictors-I.html#models-with-categorical-predictors",
    "href": "slides/14-linear-model-multiple-predictors-I.html#models-with-categorical-predictors",
    "title": "Linear regression with a multiple predictors I",
    "section": "Models with categorical predictors",
    "text": "Models with categorical predictors\n\n\nWhen the categorical predictor has many levels, they’re encoded to dummy variables.\nThe first level of the categorical variable is the baseline level. In a model with one categorical predictor, the intercept is the predicted value of the outcome for the baseline level (x = 0).\nEach slope coefficient describes the difference between the predicted value of the outcome for that level of the categorical variable compared to the baseline level."
  },
  {
    "objectID": "slides/05-exploring-data-2.html#while-you-wait",
    "href": "slides/05-exploring-data-2.html#while-you-wait",
    "title": "Exploring data II",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-04-gerrymander-explore-II\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-04-gerrymander-explore-II.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file.\n\n\n\n\n\n\n\n\nAEs are due by the end of class\n\n\nSuccessful completion means at least one commit + push by 2PM today"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#intro-to-coding-principles-with-dav-king",
    "href": "slides/05-exploring-data-2.html#intro-to-coding-principles-with-dav-king",
    "title": "Exploring data II",
    "section": "Intro to Coding Principles with Dav King",
    "text": "Intro to Coding Principles with Dav King\n\n\n\n8:30 PM Thursday January 30;\nSocial Sciences 139;\nSpace is limited, so please sign up;\nMaterials will be posted afterward;\nWe might do more if there is interest and Dav is available.\n\n\n\n\n:::"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#reminder-lab-guidelines",
    "href": "slides/05-exploring-data-2.html#reminder-lab-guidelines",
    "title": "Exploring data II",
    "section": "Reminder: Lab guidelines",
    "text": "Reminder: Lab guidelines\n\n\nPlots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\n\nCode should follow the tidyverse style (style.tidyverse.org) Particularly,\n\nspace before and line breaks after each + when building a ggplot\n\nspace before and line breaks after each |&gt; in a data transformation pipeline\ncode should be properly indented\nspaces around = signs and spaces after commas\n\n\nProofread your rendered PDF before submission! We cannot give you points for stuff we cannot see, so make sure your code and output is not running off the page. Use line breaks.\nAt least three commits with meaningful commit messages."
  },
  {
    "objectID": "slides/05-exploring-data-2.html#code-style-and-readability",
    "href": "slides/05-exploring-data-2.html#code-style-and-readability",
    "title": "Exploring data II",
    "section": "Code style and readability",
    "text": "Code style and readability\n\nWhydowecareaboutthestyleandreadabilityofyourcode? \\(\\rightarrow\\) Why do we care about the style and readability of your code?\n\n\n\n\nJe voudrais un cafe \\(\\rightarrow\\) Je voudrais un café"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#packages",
    "href": "slides/05-exploring-data-2.html#packages",
    "title": "Exploring data II",
    "section": "Packages",
    "text": "Packages\n\nFor the data: usdata\n\n\n\nlibrary(usdata)\n\n\nFor the analysis: tidyverse and ggthemes\n\n\n\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#from-last-time",
    "href": "slides/05-exploring-data-2.html#from-last-time",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#from-last-time-1",
    "href": "slides/05-exploring-data-2.html#from-last-time-1",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar(position = \"dodge\")"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#from-last-time-2",
    "href": "slides/05-exploring-data-2.html#from-last-time-2",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#from-last-time-3",
    "href": "slides/05-exploring-data-2.html#from-last-time-3",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#step-1",
    "href": "slides/05-exploring-data-2.html#step-1",
    "title": "Exploring data II",
    "section": "Step 1",
    "text": "Step 1\n\ngerrymander\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#step-2",
    "href": "slides/05-exploring-data-2.html#step-2",
    "title": "Exploring data II",
    "section": "Step 2",
    "text": "Step 2\n\ngerrymander |&gt;\n  count(flip18, gerry)\n\n# A tibble: 8 × 3\n  flip18 gerry     n\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;\n1     -1 low       2\n2     -1 mid       3\n3      0 low      52\n4      0 mid     242\n5      0 high     98\n6      1 low       8\n7      1 mid      25\n8      1 high      5"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#step-3",
    "href": "slides/05-exploring-data-2.html#step-3",
    "title": "Exploring data II",
    "section": "Step 3",
    "text": "Step 3\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18)\n\n# A tibble: 8 × 3\n# Groups:   flip18 [3]\n  flip18 gerry     n\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;\n1     -1 low       2\n2     -1 mid       3\n3      0 low      52\n4      0 mid     242\n5      0 high     98\n6      1 low       8\n7      1 mid      25\n8      1 high      5"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#step-4",
    "href": "slides/05-exploring-data-2.html#step-4",
    "title": "Exploring data II",
    "section": "Step 4",
    "text": "Step 4\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#same-thing-without-the-pipe",
    "href": "slides/05-exploring-data-2.html#same-thing-without-the-pipe",
    "title": "Exploring data II",
    "section": "Same thing, without the pipe",
    "text": "Same thing, without the pipe\n\nmutate(group_by(count(gerrymander, flip18, gerry), flip18), prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#with-the-pipe",
    "href": "slides/05-exploring-data-2.html#with-the-pipe",
    "title": "Exploring data II",
    "section": "With the pipe",
    "text": "With the pipe"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#without-the-pipe",
    "href": "slides/05-exploring-data-2.html#without-the-pipe",
    "title": "Exploring data II",
    "section": "Without the pipe",
    "text": "Without the pipe"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#what-does-group_by-do",
    "href": "slides/05-exploring-data-2.html#what-does-group_by-do",
    "title": "Exploring data II",
    "section": "What does group_by() do?",
    "text": "What does group_by() do?\n\nWhat does group_by() do in the following pipeline?\n\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#what-does-group_by-do-1",
    "href": "slides/05-exploring-data-2.html#what-does-group_by-do-1",
    "title": "Exploring data II",
    "section": "What does group_by() do?",
    "text": "What does group_by() do?\n\nWhat does group_by() do in the following pipeline?\n\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  #group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n  flip18 gerry     n    prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;   &lt;dbl&gt;\n1     -1 low       2 0.00460\n2     -1 mid       3 0.00690\n3      0 low      52 0.120  \n4      0 mid     242 0.556  \n5      0 high     98 0.225  \n6      1 low       8 0.0184 \n7      1 mid      25 0.0575 \n8      1 high      5 0.0115"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#lets-simplify",
    "href": "slides/05-exploring-data-2.html#lets-simplify",
    "title": "Exploring data II",
    "section": "Let’s simplify!",
    "text": "Let’s simplify!\n\nWhat does group_by() do in the following pipeline?\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(mean_trump16 = mean(trump16))\n\n# A tibble: 50 × 2\n   state mean_trump16\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 AK            52.8\n 2 AL            62.6\n 3 AR            60.9\n 4 AZ            46.9\n 5 CA            31.7\n 6 CO            43.6\n 7 CT            41.0\n 8 DE            41.9\n 9 FL            47.9\n10 GA            51.3\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#lets-simplify-1",
    "href": "slides/05-exploring-data-2.html#lets-simplify-1",
    "title": "Exploring data II",
    "section": "Let’s simplify!",
    "text": "Let’s simplify!\n\nWhat does group_by() do in the following pipeline?\n\n\ngerrymander |&gt;\n  #group_by(state) |&gt;\n  summarize(mean_trump16 = mean(trump16))\n\n# A tibble: 1 × 1\n  mean_trump16\n         &lt;dbl&gt;\n1         45.9"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#group_by",
    "href": "slides/05-exploring-data-2.html#group_by",
    "title": "Exploring data II",
    "section": "group_by()",
    "text": "group_by()\n\nit converts a data frame to a grouped data frame, where subsequent operations are performed once per group\nungroup() removes grouping\n\n\ngerrymander |&gt;\n  group_by(state)\n\n# A tibble: 435 × 12\n# Groups:   state [50]\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#group_by-1",
    "href": "slides/05-exploring-data-2.html#group_by-1",
    "title": "Exploring data II",
    "section": "group_by()",
    "text": "group_by()\n\nit converts a data frame to a grouped data frame, where subsequent operations are performed once per group\nungroup() removes grouping\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  ungroup()\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#group_by-summarize",
    "href": "slides/05-exploring-data-2.html#group_by-summarize",
    "title": "Exploring data II",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\nA common pipeline is group_by() and then summarize() to calculate summary statistics for each group:\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(\n    mean_trump16 = mean(trump16),\n    median_trump16 = median(trump16)\n  )\n\n# A tibble: 50 × 3\n   state mean_trump16 median_trump16\n   &lt;chr&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n 1 AK            52.8           52.8\n 2 AL            62.6           64.9\n 3 AR            60.9           63.0\n 4 AZ            46.9           47.7\n 5 CA            31.7           28.4\n 6 CO            43.6           41.3\n 7 CT            41.0           40.4\n 8 DE            41.9           41.9\n 9 FL            47.9           49.6\n10 GA            51.3           56.6\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#group_by-summarize-1",
    "href": "slides/05-exploring-data-2.html#group_by-summarize-1",
    "title": "Exploring data II",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\nThis pipeline can also be used to count number of observations for each group:\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n())\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#summarize",
    "href": "slides/05-exploring-data-2.html#summarize",
    "title": "Exploring data II",
    "section": "summarize()",
    "text": "summarize()\n... |&gt;\n  summarize(\n    name_of_summary_statistic = summary_function(variable)\n  )\n\n\n\nname_of_summary_statistic: Anything you want to call it!\n\nRecommendation: Keep it short and evocative\n\n\n\nsummary_function():\n\n\nn(): number of observations\n\nmean(): mean\n\nmedian(): median\n…"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#spot-the-difference",
    "href": "slides/05-exploring-data-2.html#spot-the-difference",
    "title": "Exploring data II",
    "section": "Spot the difference",
    "text": "Spot the difference\n\nWhat’s the difference between the following two pipelines?\n\n\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n())\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows\n\n\n\n\ngerrymander |&gt;\n  count(state)\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#count",
    "href": "slides/05-exploring-data-2.html#count",
    "title": "Exploring data II",
    "section": "count()",
    "text": "count()\n\n\n... |&gt;\n  count(variable)\n\n... |&gt;\n  count(variable1, variable2)\n\n\n\nCount the number of observations in each level of variable(s)\nPlace the counts in a variable called n"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#count-and-sort",
    "href": "slides/05-exploring-data-2.html#count-and-sort",
    "title": "Exploring data II",
    "section": "\ncount() and sort\n",
    "text": "count() and sort\n\n\nWhat does the following pipeline do? Rewrite it with count() instead.\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n()) |&gt;\n  arrange(desc(n))\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 CA       53\n 2 TX       36\n 3 FL       27\n 4 NY       27\n 5 IL       18\n 6 PA       18\n 7 OH       16\n 8 GA       14\n 9 MI       14\n10 NC       13\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#count-and-sort-1",
    "href": "slides/05-exploring-data-2.html#count-and-sort-1",
    "title": "Exploring data II",
    "section": "\ncount() and sort\n",
    "text": "count() and sort\n\n\nWhat does the following pipeline do? Rewrite it with count() instead.\n\n\ngerrymander |&gt;\n  count(state) |&gt;\n  arrange(desc(n))\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 CA       53\n 2 TX       36\n 3 FL       27\n 4 NY       27\n 5 IL       18\n 6 PA       18\n 7 OH       16\n 8 GA       14\n 9 MI       14\n10 NC       13\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#count-and-sort-2",
    "href": "slides/05-exploring-data-2.html#count-and-sort-2",
    "title": "Exploring data II",
    "section": "\ncount() and sort\n",
    "text": "count() and sort\n\n\nWhat does the following pipeline do? Rewrite it with count() instead.\n\n\ngerrymander |&gt;\n  count(state, sort = TRUE)\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 CA       53\n 2 TX       36\n 3 FL       27\n 4 NY       27\n 5 IL       18\n 6 PA       18\n 7 OH       16\n 8 GA       14\n 9 MI       14\n10 NC       13\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#flip-the-question",
    "href": "slides/05-exploring-data-2.html#flip-the-question",
    "title": "Exploring data II",
    "section": "Flip the question",
    "text": "Flip the question\n\n\n\n\n\n\nNote\n\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election?\n\n\n\nvs.\n\n\n\n\n\n\nNote\n\n\nIs a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#flipping-vs.-gerrymandering-prevalence",
    "href": "slides/05-exploring-data-2.html#flipping-vs.-gerrymandering-prevalence",
    "title": "Exploring data II",
    "section": "Flipping vs. gerrymandering prevalence",
    "text": "Flipping vs. gerrymandering prevalence\n\nThe following code should produce a visualization that answers the question “Is a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?” However, it produces a warning and an unexpected plot. What’s going on?\n\n\n\n\nggplot(\n  gerrymander, \n  aes(x = gerry, fill = flip18)\n  ) +\n  geom_bar(position = \"fill\")\n\nWarning: The following aesthetics were dropped during statistical transformation: fill.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#another-glimpse-at-gerrymander",
    "href": "slides/05-exploring-data-2.html#another-glimpse-at-gerrymander",
    "title": "Exploring data II",
    "section": "Another glimpse at gerrymander\n",
    "text": "Another glimpse at gerrymander\n\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#mutate-1",
    "href": "slides/05-exploring-data-2.html#mutate-1",
    "title": "Exploring data II",
    "section": "mutate()",
    "text": "mutate()\n\nWe want to use flip18 as a categorical variable\nBut it’s stored as a numeric\nSo we need to change its type first, before we can use it as a categorical variable\nThe mutate() function transforms (mutates) a data frame by creating a new column or updating an existing one"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#mutate-in-action",
    "href": "slides/05-exploring-data-2.html#mutate-in-action",
    "title": "Exploring data II",
    "section": "\nmutate() in action",
    "text": "mutate() in action\n\ngerrymander |&gt;\n  mutate(flip18 = as.factor(flip18))\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;fct&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#mutate-in-action-1",
    "href": "slides/05-exploring-data-2.html#mutate-in-action-1",
    "title": "Exploring data II",
    "section": "\nmutate() in action",
    "text": "mutate() in action\n\ngerrymander |&gt;\n  mutate(flip18 = as.factor(flip18)) |&gt;\n  relocate(flip18)\n\n# A tibble: 435 × 12\n   flip18 district last_name first_name party16 clinton16 trump16 dem16 state\n   &lt;fct&gt;  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1 0      AK-AL    Young     Don        R            37.6    52.8     0 AK   \n 2 0      AL-01    Byrne     Bradley    R            34.1    63.5     0 AL   \n 3 0      AL-02    Roby      Martha     R            33      64.9     0 AL   \n 4 0      AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL   \n 5 0      AL-04    Aderholt  Rob        R            17.4    80.4     0 AL   \n 6 0      AL-05    Brooks    Mo         R            31.3    64.7     0 AL   \n 7 0      AL-06    Palmer    Gary       R            26.1    70.8     0 AL   \n 8 0      AL-07    Sewell    Terri      D            69.8    28.6     1 AL   \n 9 0      AR-01    Crawford  Rick       R            30.2    65       0 AR   \n10 0      AR-02    Hill      French     R            41.7    52.4     0 AR   \n# ℹ 425 more rows\n# ℹ 3 more variables: party18 &lt;chr&gt;, dem18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#revisit-the-plot",
    "href": "slides/05-exploring-data-2.html#revisit-the-plot",
    "title": "Exploring data II",
    "section": "Revisit the plot",
    "text": "Revisit the plot\n\n“Is a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?”\n\n\ngerrymander |&gt;\n  mutate(flip18 = as.factor(flip18)) |&gt;\n  ggplot(aes(x = gerry, fill = flip18)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#ae-04-gerrymander-explore-ii",
    "href": "slides/05-exploring-data-2.html#ae-04-gerrymander-explore-ii",
    "title": "Exploring data II",
    "section": "ae-04-gerrymander-explore-II",
    "text": "ae-04-gerrymander-explore-II\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-04-gerrymander-explore-II.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/05-exploring-data-2.html#recap-aesthetic-mappings",
    "href": "slides/05-exploring-data-2.html#recap-aesthetic-mappings",
    "title": "Exploring data II",
    "section": "Recap: aesthetic mappings",
    "text": "Recap: aesthetic mappings\n\nLocal aesthetic mappings for a given geom\nGlobal aesthetic mappings for all geoms"
  },
  {
    "objectID": "lab/lab-6.html",
    "href": "lab/lab-6.html",
    "title": "Lab 6",
    "section": "",
    "text": "In this lab you’ll start your practice of statistical modeling. You’ll fit models, interpret model output, and make decisions about your data and research question based on the model results.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nFit, interpret, and make predictions with models with multiple predictors.\nPerform model selection.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-6 repo from GitHub, open your lab-6.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-6. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-6.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-6.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\ntidymodels package for modeling in a “tidy” way, and\n\nopenintro package for the dataset for Part 1.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#learning-objectives",
    "href": "lab/lab-6.html#learning-objectives",
    "title": "Lab 6",
    "section": "",
    "text": "By the end of the lab, you will…\n\nFit, interpret, and make predictions with models with multiple predictors.\nPerform model selection.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#getting-started",
    "href": "lab/lab-6.html#getting-started",
    "title": "Lab 6",
    "section": "",
    "text": "Log in to RStudio, clone your lab-6 repo from GitHub, open your lab-6.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-6. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-6.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-6.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#packages",
    "href": "lab/lab-6.html#packages",
    "title": "Lab 6",
    "section": "",
    "text": "In this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\ntidymodels package for modeling in a “tidy” way, and\n\nopenintro package for the dataset for Part 1.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#guidelines",
    "href": "lab/lab-6.html#guidelines",
    "title": "Lab 6",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#question-1",
    "href": "lab/lab-6.html#question-1",
    "title": "Lab 6",
    "section": "Question 1",
    "text": "Question 1\nIn this question you’ll prepare the dataset you’ll use in this part.\n\nRead: Read the data and save it as an object called gapminder_raw.\nFilter: For our analysis, we will only be working with data from 2023. Filter the data set so only values from the year 2023 are included. Save this data set as gapminder_raw_23 and use it for the remainder of this exercise and the following.\nGlimpse: Glimpse at gapminder_raw_23 and list the variables and their types. Comment on any unexpected features in the data.\nClean: First, figure out why gdp_percap is read in as a character variable and describe your findings in one sentence. Then, clean the gdp_percap variable and convert it to numeric values. Save the resulting data frame as gapminder_23.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#question-2",
    "href": "lab/lab-6.html#question-2",
    "title": "Lab 6",
    "section": "Question 2",
    "text": "Question 2\nWe are interested in learning more about life expectancy in countries, and we’ll start by exploring the relationship between life expectancy and GDP. Create two visualizations:\n\nScatter plot of life_exp vs. gdp_percap\nScatter plot of life_exp_log vs. gdp_percap, where life_exp_log is a new variable you add to the data set by taking the natural log of life_exp.\n\nFirst describe the relationship between each pair of the variables. Then, comment on which relationship would be better modeled using a linear model, and explain your reasoning.\n\n\n\n\n\n\nNote\n\n\n\nThe question isn’t asking which of these relationships is clearly linear, but instead which would be better modeled using a linear model.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#question-3",
    "href": "lab/lab-6.html#question-3",
    "title": "Lab 6",
    "section": "Question 3",
    "text": "Question 3\n\nData Prep: What happens when you take the natural log of 0? Remove rows of your data set where life_expectancy = 0, justifying why this is helpful.\nModel fitting: Fit a linear model predicting log life expectancy from gross domestic product. Display the tidy summary.\n\nModel evaluation:\n\nCalculate the R-squared of the model using two methods and confirm that the values match: first method is using glance() and the other method is based on the value of the correlation coefficient between the two variables.\nInterpret R-squared in the context of the data and the research question.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#question-4",
    "href": "lab/lab-6.html#question-4",
    "title": "Lab 6",
    "section": "Question 4",
    "text": "Question 4\nNext, we want to examine if the relationship between life expectancy and GDP that we observed in the previous exercise holds across all continents in our data. We’ll continue to work with logged life expectancy (life_exp_log) and data from 2023.\n\nJustification: Create a scatter plot of life_exp_log vs. gdp_percap, where the points are colored by continent. Do you think the trend between life_exp_log and gdp_percap is different for different continents? Justify your answer with specific features of the plot.\n\nModel fitting and interpretation:\n\nRegardless of your answer in part (a), fit an additive model (main effects) that predicts life_exp_log from GDP per capita and continent (with Africas as the baseline level). Display a tidy summary of the model output.\nInterpret the intercept of the model, making sure that your interpretation is in the units of the original data (not on log scale).\nInterpret the slope of the model, making sure that your interpretation is in the units of the original data (not on log scale).",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#question-5",
    "href": "lab/lab-6.html#question-5",
    "title": "Lab 6",
    "section": "Question 5",
    "text": "Question 5\nPrediction: Use the model to predict the life expectancy of a country in Asia where the average GDP per capita is $70,000. Do this two ways:\n\nusing R functions for regression prediction;\nmanually by plugging numbers into your fitted equation and using R like an overgrown calculator;\nMake sure you get the same numbers in both cases.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#question-6",
    "href": "lab/lab-6.html#question-6",
    "title": "Lab 6",
    "section": "Question 6",
    "text": "Question 6\na. Let’s begin by taking a look at the squat lifting records.\n\nStart with the ipf data frame.\nFirst, remove any observations that are negative for squat.\nNext, create a new column called best3_squat_lbs that converts the record from kilograms to pounds.\n\nYou may need to google the conversion formula. Save your data frame as ipf_squat. Report the number of rows and columns of this new data frame using inline code.\nb. Using the ipf_squat data frame you created in part (a), create a scatter plot to investigate the relationship between squat (in lbs) and age. Age should be on the x-axis. Adjust the alpha level of your points to get a better sense of the density of the data. Add a linear trend-line. Summarize the trend you observe in at most 4 sentences.\nc. Write down the linear population model to predict lift squat lbs from age. Next, fit the linear model, and save it as age_fit. Re-write your previous equation replacing the population parameters with the numeric estimates. This is called the “fitted” linear model. Interpret each estimate of \\(\\beta\\). Are the interpretations sensible?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#question-7",
    "href": "lab/lab-6.html#question-7",
    "title": "Lab 6",
    "section": "Question 7",
    "text": "Question 7\na. Building on your ipf_squat data frame from the previous question, create a new column called age2 that takes the age of each lifter and squares it. Save it to your data frame ipf_squat. Next, plot squat in lbs vs age2 and add a linear best fit line. How does the fit of the model compare to the one from earlier?\n\n\n\n\n\n\nTip\n\n\n\nTo raise a value to a power, use ^ in R, e.g.: 2 ^ 2 gives you 4, 2 ^ 3 gives you 8, etc.\n\n\nb. One metric to assess the fit of a model is the correlation squared, also known as \\(R^2\\). Fit the age\\(^2\\) model and save the object as age2_fit. Compare \\(R^2\\) of the new model (squat vs. age\\(^2\\)) to the \\(R^2\\) of the earlier model (squat vs. age). Which has a higher \\(R^2\\)?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#question-8",
    "href": "lab/lab-6.html#question-8",
    "title": "Lab 6",
    "section": "Question 8",
    "text": "Question 8\nStart over with the ipf data frame.\nNext, let’s turn our attention to dead lifting records. Recreate the plot below. Make sure axes and title labels are exactly matching, including spelling, capitalization, etc. Based on the plot below, which impacts deadlift weight more, age category or sex?\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou will need to create a couple of new columns. One to classify age appropriately and one to convert best3deadlift_kg to the plotted units (lbs). Notice that there are no negative deadlift values on the x-axis.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-6.html#question-9",
    "href": "lab/lab-6.html#question-9",
    "title": "Lab 6",
    "section": "Question 9",
    "text": "Question 9\na. Start over with the ipf data frame.\nFinally, let’s turn our attention to bench press records.\nTo begin, remove any observations that are negative for bench press, create two new columns: best3bench_lbs and bodyweight_lbs. Save the result in a new data frame called ipf_bench.\nThen, create a scatter plot to investigate the relationship between best bench press (in lbs) and the lifter’s bodyweight (in lbs). Bodyweight should be on the x-axis. Add a linear trend-line. Be sure to label all axes and give the plot a title. Comment on what you observe.\nb. Fit the linear model displayed in part (a) and write down the fitted model equation only, replacing \\(\\hat{\\beta}\\)s with their fitted estimates. Interpret the \\(\\hat{\\beta}\\)s (intercept and slope). Report \\(R^2\\). Is body weight an important predictor of bench press ability? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "lab/lab-5.html",
    "href": "lab/lab-5.html",
    "title": "Lab 5",
    "section": "",
    "text": "In this lab you’ll start your practice of statistical modeling. You’ll fit models, interpret model output, and make decisions about your data and research question based on the model results.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nFit linear regression models and interpret model coefficients in context of the data and research question;\nTransform data using a log-transformation for a better model fit.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-5 repo from GitHub, open your lab-5.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-5. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-5.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-5.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way;\n\ntidymodels package for modeling in a “tidy” way.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#learning-objectives",
    "href": "lab/lab-5.html#learning-objectives",
    "title": "Lab 5",
    "section": "",
    "text": "By the end of the lab, you will…\n\nFit linear regression models and interpret model coefficients in context of the data and research question;\nTransform data using a log-transformation for a better model fit.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#getting-started",
    "href": "lab/lab-5.html#getting-started",
    "title": "Lab 5",
    "section": "",
    "text": "Log in to RStudio, clone your lab-5 repo from GitHub, open your lab-5.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-5. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-5.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-5.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#packages",
    "href": "lab/lab-5.html#packages",
    "title": "Lab 5",
    "section": "",
    "text": "In this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way;\n\ntidymodels package for modeling in a “tidy” way.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#guidelines",
    "href": "lab/lab-5.html#guidelines",
    "title": "Lab 5",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-0",
    "href": "lab/lab-5.html#question-0",
    "title": "Lab 5",
    "section": "Question 0",
    "text": "Question 0\nAcquire some domain knowledge! As we know, it’s never a good idea to blunder into a data analysis without some subject-matter expertise, so here is some suggested reading:\n\nThe original Card and Krueger paper is here. Their bottom line was “[w]e find no indication that the rise in the minimum wage reduced employment,” which runs counter to the usual ECON 101 story. People have been arguing about this ever since;\n\nThis recent survey article attempts to summarize the state of the literature on (dis?)employment effects of the minimum wage;\nThe award citation for Card’s Nobel has useful summaries: popular, advanced.\n\nWe are not grading this, and we’ll never know if you did it or not, but you should definitely go exploring if this area interests you. Furthermore, while you may not do the reading we are suggesting here, you should definitely do a little outside reading in the domain relevant to your final project.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-1",
    "href": "lab/lab-5.html#question-1",
    "title": "Lab 5",
    "section": "Question 1",
    "text": "Question 1\n\nRelevel the state and time variables so that \"PA\" and \"before\" are the baselines, respectively.\nHow many restaurants were sampled in each state?\nCompute the median wage and the median employment in each state before and after the policy change.\nCreate a faceted density plot displaying wage according to both state and time. We want two panels stacked vertically, one for each time period (before and after the policy change). Within each panel, we want two densities, one for each state. Comment on any patterns you notice.\nCreate a faceted density plot displaying fte according to both state and time (similar to part d). Comment on any patterns you notice.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-2",
    "href": "lab/lab-5.html#question-2",
    "title": "Lab 5",
    "section": "Question 2",
    "text": "Question 2\n\nUse pivot_wider to create a new data frame card_krueger_wide that has six columns: id, state, wage_before, wage_after, fte_before, and fte_after.\nModify card_krueger_wide by discarding any rows that have a missing value in any of the four columns wage_before, wage_after, fte_before, and fte_after.\nAdd a new variable emp_diff to card_krueger_wide which measures the change in fte after the new law took effect.\nAdd a new variable gap to card_krueger_wide which is constructed in the following way:\n\n\n\ngap equals zero for stores in Pennsylvania;\n\ngap equals zero for stores in New Jersey whose starting wage before the policy change was already higher than the new minimum;\n\ngap equals \\((5.05 - \\text{wage}_{\\text{before}})/\\text{wage}_{\\text{before}}\\) for all other stores in New Jersey.\n\nCard and Krueger introduced gap as an alternative measure of the impact of the minimum wage at each store. In their words:\n\n\\(\\text{GAP}_i\\) is the proportional increase in wages at store \\(i\\) necessary to meet the new minimum rate. Variation in GAP, reflects both the New Jersey-Pennsylvania contrast and differences within New Jersey based on reported starting wages in wave 1. Indeed, the value of GAP, is a strong predictor of the actual proportional wage change between waves 1 and 2 (\\(R^2=0.75\\)), and conditional on GAP, there is no difference in wage behavior between stores in New Jersey and Pennsylvania",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-3",
    "href": "lab/lab-5.html#question-3",
    "title": "Lab 5",
    "section": "Question 3",
    "text": "Question 3\n\nCreate side-by-side boxplots of emp_diff for each state.\nFit a linear model that predicts emp_diff from state and save the model object. Then, provide the tidy summary output.\nWrite the estimated least squares regression line below using proper notation.\nInterpret the intercept in the context of the data and the research question. Is the intercept meaningful in this context? Why or why not?\nInterpret the slope in the context of the data and the research question.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-4",
    "href": "lab/lab-5.html#question-4",
    "title": "Lab 5",
    "section": "Question 4",
    "text": "Question 4\n\nCreate a scatter plot of gap versus emp_diff.\nFit a linear model that predicts emp_diff from gap and save the model object. Then, provide the tidy summary output.\nWrite the estimated least squares regression line below using proper notation.\nInterpret the intercept in the context of the data and the research question. Is the intercept meaningful in this context? Why or why not?\nInterpret the slope in the context of the data and the research question.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-5",
    "href": "lab/lab-5.html#question-5",
    "title": "Lab 5",
    "section": "Question 5",
    "text": "Question 5\nCard and Krueger tried to argue that, even though their data were observational, they had nevertheless identified a clean natural experiment that permitted them to ascribe a causal interpretation to the results of their regression analysis. Do you agree? Do you see any potential dangers with this approach? Write a paragraph or two discussing. Note that we are only grading this on a good faith completion effort, but again, if this area interests you, take the opportunity to do some of the reading under Question 0, and then try to write something interesting.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-6",
    "href": "lab/lab-5.html#question-6",
    "title": "Lab 5",
    "section": "Question 6",
    "text": "Question 6\nLet’s start by reading in the parasites data and examining the relationship between divergence_time and parsim.\n\nLoad the data and save the data frame as parasites.\nBased on the goals of the analysis, what is the response variable?\nVisualize the relationship between the two variables.\nUse the visualization to describe the relationship between the two variables.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-7",
    "href": "lab/lab-5.html#question-7",
    "title": "Lab 5",
    "section": "Question 7",
    "text": "Question 7\nNext, model this relationship.\n\nFit the model and write the estimated regression equation.\nInterpret the slope and the intercept in the context of the data.\nRecreate the visualization from Question 6, this time adding a regression line to the visualization.\nWhat do you notice about the prediction (regression) line that may be strange, particularly for very large divergence times?",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-8",
    "href": "lab/lab-5.html#question-8",
    "title": "Lab 5",
    "section": "Question 8",
    "text": "Question 8\nSince parsim takes values between 0 and 1, we want to transform this variable so that it can range between (−∞,+∞). This will be better suited for fitting a regression model (and interpreting predicted values!)\n\n\nUsing mutate, create a new variable transformed_parsim that is calculated as log(parsim/(1-parsim)). Add this variable to your data frame.\n\n\n\n\n\n\nNote\n\n\n\nlog() in R represents the nautral log.\n\n\n\nThen, visualize the relationship between divergence_time and transformed_parsim. Add a regression line to your visualization.\nWrite a 1-2 sentence description of what you observe in the visualization.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-9",
    "href": "lab/lab-5.html#question-9",
    "title": "Lab 5",
    "section": "Question 9",
    "text": "Question 9\nWhich variable is the strongest individual predictor of parasite similarity between species?\nTo answer this question, begin by fitting a linear regression model to each pair of variables. Do not report the model outputs in a tidy format but save each one as dt_model, dist_model, BM_model, and prec_model, respectively.\n\ndivergence_time and transformed_parsim\ndistance and transformed_parsim\nBMdiff and transformed_parsim\nprecdiff and transformed_parsim\n\n\nReport the slopes for each of these models. Use proper notation.\nTo answer the question of interest, would it be useful to compare the slopes in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-5.html#question-10",
    "href": "lab/lab-5.html#question-10",
    "title": "Lab 5",
    "section": "Question 10",
    "text": "Question 10\nNow, what if we calculated \\(R^2\\) to help answer our question? To compare the explanatory power of each individual predictor, we will look at \\(R^2\\) between the models. \\(R^2\\) is a measure of how much of the variability in the response variable is explained by the model.\nAs you may have guessed from the name \\(R^2\\) can be calculated by squaring the correlation when we have a simple linear regression model. The correlation r takes values -1 to 1, therefore, \\(R^2\\) takes values 0 to 1. Intuitively, if r=1 or −1, then \\(R^2\\)=1, indicating the model is a perfect fit for the data. If r≈0 then \\(R^2\\)≈0, indicating the model is a very bad fit for the data.\nYou can calculate \\(R^2\\) using the glance function. For example, you can calculate \\(R^2\\) for dt_model using the code glance(dt_model)$r.squared.\n\nCalculate and report \\(R^2\\) for each model fit in the previous exercise.\nTo answer our question of interest, would it be useful to compare the \\(R^2\\) in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "lab/lab-0.html",
    "href": "lab/lab-0.html",
    "title": "Lab 0",
    "section": "",
    "text": "This lab will walk you through setting up the course technology, which consists of the following:\nVersion control software like Git and GitHub is indispensable in modern data science practice, and learning how to use it is one of the things that distinguishes STA 199 from a similar course like STA 101. At a minimum, version control helps prevent your files from looking like this:\nWe’ve all been there, but it’s time to kick the habit.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#access-r-and-rstudio",
    "href": "lab/lab-0.html#access-r-and-rstudio",
    "title": "Lab 0",
    "section": "1. Access R and RStudio",
    "text": "1. Access R and RStudio\nInstead of asking you to download any new programs onto your computer, we host everything pre-packaged for you in the cloud. You just have to login through your web browser, and you’re ready to go:\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 to log into the Docker container. You should now see the RStudio environment.\n\nGo to https://cmgr.oit.duke.edu/containers and under Reservations available click on reserve STA 198-199 to reserve a container for yourself.\n\n\n\n\n\n\nNote\n\n\n\nA container is a self-contained instance of RStudio for you, and you alone. You will do all of your computing in your container.\n\n\nOnce you’ve reserved the container you’ll see that it will show up under My reservations.\nTo launch your container click on it under My reservations, then click Login, and then Start.1\n\n\n\n\n\n\nWarning\n\n\n\nPlease double and triple check that you have reserved the STA 198-199 container and not some other. The various containers differ in the software they include, so if you reserve something else, you may be missing something we need.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#create-a-github-account",
    "href": "lab/lab-0.html#create-a-github-account",
    "title": "Lab 0",
    "section": "2. Create a GitHub account",
    "text": "2. Create a GitHub account\nGo to https://github.com/ and walk through the steps for creating an account. You do not have to use your Duke email address, but I recommend doing so.2\n\n\n\n\n\n\nNote\n\n\n\nYou’ll need to choose a user name. I recommend reviewing the user name advice at https://happygitwithr.com/github-acct#username-advice before choosing a username.\n\n\n\n\n\n\n\n\nWhat if I already have a GitHub account?\n\n\n\n\n\nIf you already have a GitHub account, you do not need to create a new one for this course. Just log in to that account to make sure you still remember your username and password. If you are unsure of your login credentials, carefully follow GitHub’s instructions for recovering this information. If you accumulate too many failed login attempts, you will be locked out of your account for the day, which will make it difficult for you to complete the rest of this lab.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#set-up-your-ssh-key",
    "href": "lab/lab-0.html#set-up-your-ssh-key",
    "title": "Lab 0",
    "section": "3. Set up your SSH key",
    "text": "3. Set up your SSH key\nYou will authenticate GitHub using SSH (Secure Shell Protocol – it doesn’t really matter what this means for the purpose of this course). Below is an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nGo back to your RStudio container and type credentials::ssh_setup_github() into your console.\nR will ask “No SSH key found. Generate one now?” You should click 1 for yes.\nYou will generate a key. R will then ask “Would you like to open a browser now?” You should click 1 for yes.\nYou may be asked to provide your GitHub username and password to log into GitHub. After entering this information, you should paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta199).\n\nYou can find more detailed instructions here if you’re interested.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#configure-git-to-introduce-yourself",
    "href": "lab/lab-0.html#configure-git-to-introduce-yourself",
    "title": "Lab 0",
    "section": "4. Configure Git to introduce yourself",
    "text": "4. Configure Git to introduce yourself\nNext, you need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\n\n\n\n\n\n\nNote\n\n\n\nYou’ll hear about 📦 packages a lot in the context of R – basically they’re how developers write functions and bundle them to distribute to the community (and more on this later too!).\n\n\nType the following lines of code in the console in RStudio filling in your name and the address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\"\n)\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"John Zito\", \n  user.email = \"johnczito@gmail.com\"\n)\n\nI used my gmail because that is the one I used to create my GitHub account. You should also be using the email address you used to create your GitHub account, it’s ok if it isn’t your Duke email.\n\n\n\n\n\n\nHow do I know if I did it right?\n\n\n\n\n\nWhen you input the usethis::use_git_config(...) command into the console and hit enter/return, it will appear as if nothing happened. To verify that everything worked, you can briefly switch over to the Terminal tab (should be to the right of Console) and type the commands git config user.name and git config user.email. If all is well, these will return whatever text you originally provided. If you notice a mistake or typo, you can just go back to the Console and rerun usethis::use_git_config(...) with modified inputs.\n\n\n\n\n\n\n\n\n\nNeed a recap? Watch this video!\n\n\n\n\n\nThe following video walks you through the steps outlined in the SSH key generation and Git configuration sections above.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#babys-first-repo",
    "href": "lab/lab-0.html#babys-first-repo",
    "title": "Lab 0",
    "section": "5. Baby’s first repo",
    "text": "5. Baby’s first repo\nA GitHub repository (repo) is a collection of files hosted on GitHub. Repos are the main way we will distribute files to you during the semester. When you copy the files in a repo to your local computing environment (your container, in this case), that’s called “cloning”. So, let’s clone our first repo:\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo hello-world.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\n\nYou will need to get used to these steps, because you’ll probably clone at least one new repo every week.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#hello-sta-199",
    "href": "lab/lab-0.html#hello-sta-199",
    "title": "Lab 0",
    "section": "6. Hello STA 199!",
    "text": "6. Hello STA 199!\nFill out the course “Getting to know you” survey on Canvas: https://canvas.duke.edu/courses/50057/quizzes/30406.\nWe will use the information collected in this survey for a variety of goals, from inviting you to the course GitHub organization (more on that later) to getting to know you as a person and your course goals and concerns.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#footnotes",
    "href": "lab/lab-0.html#footnotes",
    "title": "Lab 0",
    "section": "Footnotes",
    "text": "Footnotes\n\nYes, it’s too many steps. I don’t know why! But it works, and you’ll get used to it. Trust me, it beats downloading and installing everything you need on your computers!↩︎\nGitHub has some perks for students you can take advantage of later in the course or in your future work, and it helps to have a .edu address to get verified as a student.↩︎",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-3.html",
    "href": "lab/lab-3.html",
    "title": "Lab 3",
    "section": "",
    "text": "This lab gives you more practice with data wrangling and data pipelines, with an emphasis on mastering the subtleties of group_by, as well as introducing pivoting to the mix.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you have not yet done those, you should go back and review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nBe able to pivot/reshape data using tidyr\n\nContinue developing your data wrangling skills using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-3 repo from GitHub, open your lab-3.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#learning-objectives",
    "href": "lab/lab-3.html#learning-objectives",
    "title": "Lab 3",
    "section": "",
    "text": "By the end of the lab, you will…\n\nBe able to pivot/reshape data using tidyr\n\nContinue developing your data wrangling skills using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#getting-started",
    "href": "lab/lab-3.html#getting-started",
    "title": "Lab 3",
    "section": "",
    "text": "Log in to RStudio, clone your lab-3 repo from GitHub, open your lab-3.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#packages",
    "href": "lab/lab-3.html#packages",
    "title": "Lab 3",
    "section": "",
    "text": "In this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#guidelines",
    "href": "lab/lab-3.html#guidelines",
    "title": "Lab 3",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#part-1",
    "href": "lab/lab-3.html#part-1",
    "title": "Lab 3",
    "section": "Part 1",
    "text": "Part 1\nAll about group_by()!\nUse the following data frame for Question 1 and Question 2:\n\ndf &lt;- tibble(\n  var_1 = c(50, 20, 70, 10, 100, 30, 40, 80, 120, 60, 90, 110),\n  var_2 = c(\"Pizza\", \"Burger\", \"Pizza\", \"Pizza\", \"Burger\", \"Burger\",\n            \"Burger\", \"Pizza\", \"Burger\", \"Pizza\", \"Pizza\", \"Burger\"),\n  var_3 = c(\"Apple\", \"Apple\", \"Pear\", \"Banana\", \"Pear\", \"Banana\",\n            \"Apple\", \"Apple\", \"Pear\", \"Pear\", \"Banana\", \"Banana\")\n)\n\ndf\n\n# A tibble: 12 × 3\n   var_1 var_2  var_3 \n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; \n 1    50 Pizza  Apple \n 2    20 Burger Apple \n 3    70 Pizza  Pear  \n 4    10 Pizza  Banana\n 5   100 Burger Pear  \n 6    30 Burger Banana\n 7    40 Burger Apple \n 8    80 Pizza  Apple \n 9   120 Burger Pear  \n10    60 Pizza  Pear  \n11    90 Pizza  Banana\n12   110 Burger Banana\n\n\nQuestion 1\nGrouping by a single variable.\na. What does the following code chunk do? Run it, analyze the result, and articulate in words what arrange() does.\n\ndf |&gt;\n  arrange(var_2)\n\nb. What does the following code chunk do? Run it, analyze the result, and articulate in words what group_by() does. Also, comment on how it’s different from the arrange() in part (b).\n\ndf |&gt;\n  group_by(var_2)\n\nc. What does the following code chunk do? Run it, analyze the result, and articulate in words what the pipeline does.\n\ndf |&gt;\n  group_by(var_2) |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\nd. Compare this behavior to the following code chunk. Run it, analyze the result, and articulate in words what the pipeline does, and how it’s behavior is different from part (c).\n\ndf |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\nQuestion 2\nGrouping by two variables.\na. How many levels does var_2 have? How many levels does var_3 have? How many possible combinations are there of the levels of var_2 and var_3?\nb. Write some code that uses basic arithmetic operations to manually compute the average value of var_1 among all the rows that have Burger-Apple. Do the same thing for the rows that have Burger-Banana.\nc. You’re probably sick of that, right? What does the following code chunk do? Run it, analyze the result, and articulate in words what the pipeline does and how it compared to part (b). Then, comment on what the message says.\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\nd. What does the following code chunk do? Run it, analyze the result, and articulate in words what the pipeline does, especially mentioning what the .groups argument does. How is the output different from the one in part (c)?\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1), .groups = \"drop\")\n\ne. What do the following pipelines do? Run both, analyze their results, and articulate in words what each pipeline does. How are the outputs of the two pipelines different?\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1), .groups = \"drop\")\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  mutate(mean_var_1 = mean(var_1))\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answers for Questions 1 and 2”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#part-2",
    "href": "lab/lab-3.html#part-2",
    "title": "Lab 3",
    "section": "Part 2",
    "text": "Part 2\nInflation across the world\nFor this part of the analysis you will work with inflation data from various countries in the world over the last 30 years.\n\ncountry_inflation &lt;- read_csv(\"data/country-inflation.csv\")\n\nQuestion 3\nGet to know the data.\n\nglimpse() at the country_inflation data frame and answer the following questions based on the output. How many rows does country_inflation have and what does each row represent? How many columns does country_inflation have and what does each column represent?\nDisplay a list of the unique countries included in the dataset. Hint: Another word for “unique” is distinct().\n\n\n\n\n\n\n\nTip\n\n\n\nA function that can be useful for part (b) is pull(). Check out its documentation for examples of usage.\n\n\nQuestion 4\nWhich countries had the top three highest inflation rates in 2023? Your output should be a data frame with two columns, country and 2023, with inflation rates in descending order, and three rows for the top three countries. Briefly comment on how the inflation rates for these countries compare to the inflation rate for United States in that year.\n\n\n\n\n\n\nTips\n\n\n\n\nYou might find the command slice_head helpful here.\nColumn names that are numbers are not considered “proper” in R, therefore to select them you’ll need to surround them with backticks, e.g. select( ` 1993 ` ).\n\n\n\nQuestion 5\nIn a single pipeline,\n\ncalculate the ratio of the inflation in 2023 and inflation in 1993 for each country and store this information in a new column called inf_ratio,\nselect the variables country and inf_ratio, and\nstore the result in a new data frame called country_inflation_ratios.\n\nThen, in two separate pipelines,\n\narrange country_inflation_ratios in increasing order of inf_ratio and\narrange country_inflation_ratios in decreasing order of inf_ratio.\n\nWhich country’s inflation increase is the largest over this time period and by how much? Which country’s inflation decrease is the largest over this time period and by how much?\n\n\n\n\n\n\nTip\n\n\n\nFor this question you’ll once again need to use variables whose names are numbers (years) in your pipeline. Make sure to surround the names of such variables with backticks (`).\n\n\nQuestion 6\nReshape (pivot) country_inflation such that each row represents a country/year combination, with columns country, year, and annual_inflation. Then, display the resulting data frame and state how many rows and columns it has.\nRequirements:\n\nYour code must use one of pivot_longer() or pivot_wider(). There are other ways you can do this reshaping move in R, but this question requires solving this problem by pivoting.\nIn your pivot_*() function, you must use names_transform = as.numeric as an argument to transform the variable type to numeric as you pivot the data so that in the resulting data frame the year variable is numeric.\nThe resulting data frame must be saved as something other than country_inflation so you (1) can refer to this data frame later in your analysis and (2) do not overwrite country_inflation. Use a short but informative name.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe remaining questions require the use of the pivoted data frame.\n\n\n\nIf you haven’t yet done so, now is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n\nQuestion 7\nUse a separate, single pipeline to answer each of the following questions.\nRequirement: Your code must use the filter() function for each part, not arrange().\n\nWhat is the highest inflation rate observed between 1993 and 2023? The output of the pipeline should be a data frame with one row and three columns. In addition to code and output, your response should include a single sentence stating the country and year.\nWhat is the lowest inflation rate observed between 1993 and 2023? The output of the pipeline should be a data frame with one row and three columns. In addition to code and output, your response should include a single sentence stating the country and year.\nPutting (a) and (b) together: What are the highest and the lowest inflation rates observed between 1993 and 2023? The output of the pipeline should be a data frame with two rows and three columns.\nQuestion 8\na. Create a vector called countries_of_interest which contains the names of up to five countries you want to visualize the inflation rates for over the years. For example, if these countries are Türkiye and United States, you can express this as follows:\n\ncountries_of_interest &lt;- c(\"Türkiye\", \"United States\")\n\nIf they are Türkiye, United States, and Chile, you can express this as follows:\n\ncountries_of_interest &lt;- c(\n  \"Türkiye\", \"United States\", \"Chile\"\n)\n\nSo on and so forth… Then, in 1-2 sentences, state why you chose these countries.\n\n\n\n\n\n\nNote\n\n\n\nYour countries_of_interest should consist of no more than five countries. Make sure that the spelling of your countries matches how they appear in the dataset.\n\n\nb. In a single pipeline, filter your reshaped dataset to include only the countries_of_interest from part (a), and save the resulting data frame with a new name so you (1) can refer to this data frame later in your analysis and (2) do not overwrite the data frame you’re starting with. Use a short but informative name. Then, in a new pipeline, find the distinct() countries in the data frame you created.\n\n\n\n\n\n\nTip\n\n\n\nThe number of distinct countries in the filtered data frame you created in part (b) should equal the number of countries you chose in part (a). If it doesn’t, you might have misspelled a country name or made a mistake in filtering for these countries. Go back and correct your work.\n\n\nQuestion 9\nUsing your data frame from the previous question, create a plot of annual inflation vs. year for these countries. Then, in a few sentences, describe the patterns you observe in the plot, particularly focusing on anything you find surprising or not surprising, based on your knowledge (or lack thereof) of these countries economies.\nRequirements for the plot:\n\nData should be represented with points as well as lines connecting the points for each country.\nEach country should be represented by a different color line and different color and shape points.\nAxes and legend should be properly labeled.\nThe plot should have an appropriate title (and optionally a subtitle).\nPlot should be customized in at least one way – you could use a different than default color scale, or different than default theme, or some other customization.\n\n\nNow is another good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#submission",
    "href": "lab/lab-3.html#submission",
    "title": "Lab 3",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered “on time”.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#grading-and-feedback",
    "href": "lab/lab-3.html#grading-and-feedback",
    "title": "Lab 3",
    "section": "Grading and feedback",
    "text": "Grading and feedback\n\nSome of the questions will be graded for accuracy.\nSome will be graded for completion.\n\nThere are also workflow points:\n\nfor coding style;\nfor committing at least three times as you work through your lab;\nfor pushing your final rendered PDF into your lab repo before the deadline (in addition to uploading it to Gradescope);\nfor overall organization.\n\n\nYou’ll receive feedback on your lab on Gradescope within a week.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html",
    "href": "ae/ae-07-durham-climate-factors.html",
    "title": "AE 07: Durham climate + factors",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html#getting-started",
    "href": "ae/ae-07-durham-climate-factors.html#getting-started",
    "title": "AE 07: Durham climate + factors",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe will use the tidyverse package in this application exercise.\n\nlibrary(tidyverse)\n\nData\nThe data come from https://www.usclimatedata.com/climate/durham/north-carolina/united-states/usnc0192 and are stored as durham-climate.csv in the data folder.\n\ndurham_climate &lt;- read_csv(\"data/durham-climate.csv\")\n\nAnd let’s take a look at the data.\n\ndurham_climate\n\n# A tibble: 12 × 4\n   month     avg_high_f avg_low_f precipitation_in\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n 1 January           49        28             4.45\n 2 February          53        29             3.7 \n 3 March             62        37             4.69\n 4 April             71        46             3.43\n 5 May               79        56             4.61\n 6 June              85        65             4.02\n 7 July              89        70             3.94\n 8 August            87        68             4.37\n 9 September         81        60             4.37\n10 October           71        47             3.7 \n11 November          62        37             3.39\n12 December          53        30             3.43"
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html#reorder",
    "href": "ae/ae-07-durham-climate-factors.html#reorder",
    "title": "AE 07: Durham climate + factors",
    "section": "Reorder",
    "text": "Reorder\nWhat’s wrong with the following plot?\nMonths are out of order.\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 2,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  )\n\n\n\n\n\n\n\nFix the plot.\n\ndurham_climate &lt;- durham_climate |&gt;\n  mutate(month = fct_relevel(month, month.name))\n\nggplot(\n  durham_climate,\n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 2,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  )"
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html#recode-and-reorder",
    "href": "ae/ae-07-durham-climate-factors.html#recode-and-reorder",
    "title": "AE 07: Durham climate + factors",
    "section": "Recode and reorder",
    "text": "Recode and reorder\nUpdate the plot above, coloring points based on season. Additionally:\n\nMake sure the legend is on top of the plot and the seasons appear in the legend in the order they appear in the plot (Winter, Spring, Summer, Fall).\n\nUse \"circle filled\" as the shape for points, set their size to 3 points, outline (stroke) to 1 point, and fill them in with the following colors:\n\nWinter: lightskyblue1\n\nSpring: chartreuse3\n\nSummer: gold2\n\nFall: lightsalmon4\n\n\n\n\n\ndurham_climate &lt;- durham_climate |&gt;\n  mutate(\n    season = case_when(\n      month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      month %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n      month %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n      month %in% c(\"September\", \"October\", \"November\") ~ \"Fall\",\n    ),\n    season = fct_relevel(season, \"Winter\", \"Spring\", \"Summer\", \"Fall\")\n  )\n\nggplot(\n  durham_climate,\n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 3, stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\",\n    fill = \"Season\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html#pivot",
    "href": "ae/ae-07-durham-climate-factors.html#pivot",
    "title": "AE 07: Durham climate + factors",
    "section": "Pivot",
    "text": "Pivot\nOverlay lines for both high and low temperatures on the same plot. Additionally, use different colors for the two lines – a darker color for high and a lighter color for low temperatures.\n\ndurham_climate |&gt;\n  pivot_longer(\n    cols = c(avg_high_f, avg_low_f),\n    names_to = \"temp_type\",\n    names_prefix = \"avg_\",\n    values_to = \"avg_temp_f\"\n  ) |&gt;\n  mutate(temp_type = str_remove(temp_type, \"_f\")) |&gt;\n  ggplot(aes(x = month, y = avg_temp_f, group = temp_type, color = temp_type)) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 3, stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) +\n  scale_color_manual(\n    values = c(\n      \"high\" = \"gray20\",\n      \"low\" = \"gray70\"\n    )\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average temperature (F)\",\n    title = \"Durham climate\",\n    fill = \"Season\",\n    color = \"Type\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "ae/ae-09-modeling-fish.html",
    "href": "ae/ae-09-modeling-fish.html",
    "title": "AE 9: Modelling fish",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\n\n\nFor this application exercise, we will work with data on fish. The dataset we will use, called fish, is on two common fish species in fish market sales.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nfish &lt;- read_csv(\"data/fish.csv\")\n\nThe data dictionary is below:\n\n\nvariable\ndescription\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\nVisualizing the model\nWe’re going to investigate the relationship between the weights and heights of fish.\n\nCreate an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n\n\n\n\n\n\n\nIf you were to draw a a straight line to best represent the relationship between the heights and weights of fish, where would it go? Why?\n\nStart from the bottom and go up. Identify the first and last point and draw a line through most the others.\n\nNow, let R draw the line for you. Refer to the documentation at https://ggplot2.tidyverse.org/reference/geom_smooth.html. Specifically, refer to the method section.\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. lengths of fish\",\n    x = \"Head-to-tail lentgh (cm)\",\n    y = \"Weight of fish (grams)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWhat types of questions can this plot help answer?\n\nIs there a relationship between fish heights and weights of fish?\n\nWe can use this line to make predictions. Predict what you think the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm. Which prediction is considered extrapolation?\n\nAt 10 cm, we estimate a weight of 375 grams. At 15 cm, we estimate a weight of 600 grams At 20 cm, we estimate a weight of 975 grams. 20 cm would be considered extrapolation.\n\nWhat is a residual?\n\nDifference between predicted and observed.\nModel fitting\n\n\nDemo: Fit a model to predict fish weights from their heights.\n\n\nfish_hw_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ height, data = fish)\n\nfish_hw_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = weight ~ height, data = data)\n\nCoefficients:\n(Intercept)       height  \n    -288.42        60.92  \n\n\n\n\nYour turn (3 minutes): Predict what the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm using this model.\n\n\nx &lt;- c(10, 15, 20)\n-288 + 60.92 * x\n\n[1] 321.2 625.8 930.4\n\n\n\n\nDemo: Calculate predicted weights for all fish in the data and visualize the residuals under this model.\n\n\nfish_hw_aug &lt;- augment(fish_hw_fit, new_data = fish)\n\nggplot(fish_hw_aug, aes(x = height, y = weight)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +  \n  geom_segment(aes(xend = height, yend = .pred), color = \"gray\") +  \n  geom_point(aes(y = .pred), shape = \"circle open\") + \n  theme_minimal() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    subtitle = \"Residuals\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nModel summary\n\n\nDemo: Display the model summary including estimates for the slope and intercept along with measurements of uncertainty around them. Show how you can extract these values from the model output.\n\n\nfish_hw_tidy &lt;- tidy(fish_hw_fit)\nfish_hw_tidy\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -288.      34.0      -8.49 1.83e-11\n2 height          60.9      2.64     23.1  2.40e-29\n\n\n\n\nDemo: Write out your model using mathematical notation.\n\n\\(\\widehat{weight} = -288 + 60.9 \\times height\\)\nCorrelation\nWe can also assess correlation between two quantitative variables.\n\nWhat is correlation? What are values correlation can take?\n\nStrength and direction of a linear relationship. It’s bounded by -1 and 1.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\nDemo: What is the correlation between heights and weights of fish?\n\n\nfish |&gt;\n  summarize(r = cor(height, weight))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.954\n\n\nAdding a third variable\n\n\nDemo: Does the relationship between heights and weights of fish change if we take into consideration species? Plot two separate straight lines for the Bream and Roach species.\n\n\nggplot(fish, \n       aes(x = height, y = weight, color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nFitting other models\n\n\nDemo: We can fit more models than just a straight line. Change the following code below to read method = \"loess\". What is different from the plot created before?\n\n\nggplot(fish, \n       aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"loess\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "ae/ae-14-forest-classification.html",
    "href": "ae/ae-14-forest-classification.html",
    "title": "AE 14: Forest classification",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this application exercise, we will\nWe will use tidyverse and tidymodels for data exploration and modeling, respectively, and the forested package for the data.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)\nRemember from the lecture that the forested dataset contains information on whether a plot is forested (Yes) or not (No) as well as numerical and categorical features of that plot.\nglimpse(forested)\n\nRows: 7,107\nColumns: 19\n$ forested         &lt;fct&gt; Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005,…\n$ elevation        &lt;dbl&gt; 881, 113, 164, 299, 806, 736, 636, 224, 52, 2240, 104…\n$ eastness         &lt;dbl&gt; 90, -25, -84, 93, 47, -27, -48, -65, -62, -67, 96, -4…\n$ northness        &lt;dbl&gt; 43, 96, 53, 34, -88, -96, 87, -75, 78, -74, -26, 86, …\n$ roughness        &lt;dbl&gt; 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 190, 95, 212…\n$ tree_no_tree     &lt;fct&gt; Tree, Tree, Tree, No tree, Tree, Tree, No tree, Tree,…\n$ dew_temp         &lt;dbl&gt; 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6.39, 6.50,…\n$ precip_annual    &lt;dbl&gt; 466, 1710, 1297, 2545, 609, 539, 702, 1195, 1312, 103…\n$ temp_annual_mean &lt;dbl&gt; 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61, 10.45, 10…\n$ temp_annual_min  &lt;dbl&gt; -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.76, 1.11, …\n$ temp_annual_max  &lt;dbl&gt; 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 14.23, 15.3…\n$ temp_january_min &lt;dbl&gt; -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, 5.54, 6.20…\n$ vapor_min        &lt;dbl&gt; 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 172, 162, 70…\n$ vapor_max        &lt;dbl&gt; 1194, 938, 754, 1164, 1254, 1331, 1275, 944, 892, 549…\n$ canopy_cover     &lt;dbl&gt; 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74, 66, 83, 6…\n$ lon              &lt;dbl&gt; -118.6865, -123.0825, -122.3468, -121.9144, -117.8841…\n$ lat              &lt;dbl&gt; 48.69537, 47.07991, 48.77132, 45.80776, 48.07396, 48.…\n$ land_type        &lt;fct&gt; Tree, Tree, Tree, Tree, Tree, Tree, Non-tree vegetati…"
  },
  {
    "objectID": "ae/ae-14-forest-classification.html#fit",
    "href": "ae/ae-14-forest-classification.html#fit",
    "title": "AE 14: Forest classification",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on a subset of predictors of your choice. Name the model forested_custom_fit and display a tidy output of the model.\n\nforested_custom_fit &lt;- logistic_reg() |&gt;\n  fit(forested ~ elevation + tree_no_tree + lat + lon + temp_annual_mean, data = forested_train)\n\ntidy(forested_custom_fit)\n\n# A tibble: 6 × 5\n  term                 estimate std.error statistic   p.value\n  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)         48.2       6.06         7.96  1.71e- 15\n2 elevation           -0.000311  0.000384    -0.811 4.17e-  1\n3 tree_no_treeNo tree  3.35      0.0925      36.3   4.02e-288\n4 lat                 -0.313     0.0642      -4.87  1.09e-  6\n5 lon                  0.311     0.0288      10.8   3.81e- 27\n6 temp_annual_mean     0.270     0.0819       3.30  9.78e-  4"
  },
  {
    "objectID": "ae/ae-14-forest-classification.html#predict",
    "href": "ae/ae-14-forest-classification.html#predict",
    "title": "AE 14: Forest classification",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\nforested_custom_aug &lt;- augment(forested_custom_fit, new_data = forested_test)\n\nforested_custom_aug\n\n# A tibble: 1,777 × 22\n   .pred_class .pred_Yes .pred_No forested  year elevation eastness northness\n   &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes            0.877    0.123  Yes       2005       113      -25        96\n 2 Yes            0.829    0.171  Yes       2005       736      -27       -96\n 3 Yes            0.855    0.145  Yes       2005       224      -65       -75\n 4 Yes            0.957    0.0431 Yes       2003      1031      -49        86\n 5 Yes            0.728    0.272  No        2005      1713      -66        75\n 6 Yes            0.982    0.0175 Yes       2014      1612       30       -95\n 7 No             0.0765   0.924  No        2014       507       44       -89\n 8 Yes            0.889    0.111  Yes       2014       940      -93        35\n 9 Yes            0.659    0.341  No        2014       246       22       -97\n10 No             0.0877   0.912  No        2014       419       86       -49\n# ℹ 1,767 more rows\n# ℹ 14 more variables: roughness &lt;dbl&gt;, tree_no_tree &lt;fct&gt;, dew_temp &lt;dbl&gt;,\n#   precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, land_type &lt;fct&gt;"
  },
  {
    "objectID": "ae/ae-14-forest-classification.html#evaluate",
    "href": "ae/ae-14-forest-classification.html#evaluate",
    "title": "AE 14: Forest classification",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\nforested_custom_aug |&gt;\n  count(.pred_class, forested) |&gt;\n  arrange(forested) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = round(n / sum(n), 2),\n    decision = case_when(\n      .pred_class == \"Yes\" & forested == \"Yes\" ~ \"True positive\",\n      .pred_class == \"Yes\" & forested == \"No\" ~ \"False positive\",\n      .pred_class == \"No\" & forested == \"Yes\" ~ \"False negative\",\n      .pred_class == \"No\" & forested == \"No\" ~ \"True negative\"\n    )\n  )\n\n# A tibble: 4 × 5\n# Groups:   forested [2]\n  .pred_class forested     n     p decision      \n  &lt;fct&gt;       &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 Yes         Yes        864  0.9  True positive \n2 No          Yes         98  0.1  False negative\n3 Yes         No         124  0.15 False positive\n4 No          No         691  0.85 True negative \n\n\nAnother commonly used display of this information is a confusion matrix. Create this using the conf_mat() function. You will need to review the documentation for the function to determine how to use it.\n\nconf_mat(\n  forested_custom_aug, \n  truth = forested, \n  estimate = .pred_class\n)\n\n          Truth\nPrediction Yes  No\n       Yes 864 124\n       No   98 691"
  },
  {
    "objectID": "ae/ae-14-forest-classification.html#sensitivity-specificity-roc-curve",
    "href": "ae/ae-14-forest-classification.html#sensitivity-specificity-roc-curve",
    "title": "AE 14: Forest classification",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\nforested_custom_roc &lt;- roc_curve(forested_custom_aug, \n                                 truth = forested, \n                                 .pred_Yes, \n                                 event_level = \"first\")\n\nforested_custom_roc\n\n# A tibble: 1,779 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1  -Inf          0                 1\n 2     0.0186     0                 1\n 3     0.0202     0.00123           1\n 4     0.0204     0.00245           1\n 5     0.0207     0.00368           1\n 6     0.0227     0.00491           1\n 7     0.0286     0.00613           1\n 8     0.0298     0.00736           1\n 9     0.0299     0.00859           1\n10     0.0300     0.00982           1\n# ℹ 1,769 more rows\n\n\n\nggplot(forested_custom_roc, aes(x = 1 - specificity, y = sensitivity)) +\n  geom_path() +\n  geom_abline(lty = 3) +\n  coord_equal()"
  },
  {
    "objectID": "ae/ae-14-forest-classification.html#fit-1",
    "href": "ae/ae-14-forest-classification.html#fit-1",
    "title": "AE 14: Forest classification",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on all predictors available. Name the model forested_full_fit and display a tidy output of the model.\n\nforested_full_fit &lt;- logistic_reg() |&gt;\n  fit(forested ~ ., data = forested_train)\n\ntidy(forested_full_fit)\n\n# A tibble: 20 × 5\n   term                             estimate std.error statistic  p.value\n   &lt;chr&gt;                               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                  -12.1        32.6       -0.371   7.11e- 1\n 2 year                           0.00456     0.0152     0.299   7.65e- 1\n 3 elevation                     -0.00277     0.000639  -4.33    1.47e- 5\n 4 eastness                      -0.000910    0.000734  -1.24    2.15e- 1\n 5 northness                      0.00208     0.000745   2.79    5.26e- 3\n 6 roughness                     -0.00399     0.00146   -2.73    6.29e- 3\n 7 tree_no_treeNo tree            1.25        0.136      9.23    2.61e-20\n 8 dew_temp                      -0.125       0.176     -0.712   4.76e- 1\n 9 precip_annual                 -0.0000895   0.000100  -0.895   3.71e- 1\n10 temp_annual_mean              -7.30       12.4       -0.587   5.57e- 1\n11 temp_annual_min                0.819       0.103      7.93    2.20e-15\n12 temp_annual_max                2.59        6.22       0.417   6.77e- 1\n13 temp_january_min               3.34        6.21       0.538   5.91e- 1\n14 vapor_min                      0.00000990  0.00353    0.00280 9.98e- 1\n15 vapor_max                      0.00925     0.00132    7.00    2.62e-12\n16 canopy_cover                  -0.0446      0.00366  -12.2     4.18e-34\n17 lon                           -0.0953      0.0559    -1.71    8.80e- 2\n18 lat                            0.0748      0.109      0.683   4.94e- 1\n19 land_typeNon-tree vegetation  -0.735       0.282     -2.61    9.05e- 3\n20 land_typeTree                 -1.58        0.297     -5.33    9.93e- 8"
  },
  {
    "objectID": "ae/ae-14-forest-classification.html#predict-1",
    "href": "ae/ae-14-forest-classification.html#predict-1",
    "title": "AE 14: Forest classification",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\nforested_full_aug &lt;- augment(forested_full_fit, new_data = forested_test)\n\nforested_full_aug\n\n# A tibble: 1,777 × 22\n   .pred_class .pred_Yes .pred_No forested  year elevation eastness northness\n   &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes            0.930    0.0700 Yes       2005       113      -25        96\n 2 Yes            0.918    0.0822 Yes       2005       736      -27       -96\n 3 No             0.428    0.572  Yes       2005       224      -65       -75\n 4 Yes            0.972    0.0280 Yes       2003      1031      -49        86\n 5 Yes            0.633    0.367  No        2005      1713      -66        75\n 6 Yes            0.980    0.0201 Yes       2014      1612       30       -95\n 7 No             0.0436   0.956  No        2014       507       44       -89\n 8 Yes            0.845    0.155  Yes       2014       940      -93        35\n 9 No             0.0141   0.986  No        2014       246       22       -97\n10 No             0.0386   0.961  No        2014       419       86       -49\n# ℹ 1,767 more rows\n# ℹ 14 more variables: roughness &lt;dbl&gt;, tree_no_tree &lt;fct&gt;, dew_temp &lt;dbl&gt;,\n#   precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, land_type &lt;fct&gt;"
  },
  {
    "objectID": "ae/ae-14-forest-classification.html#evaluate-1",
    "href": "ae/ae-14-forest-classification.html#evaluate-1",
    "title": "AE 14: Forest classification",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\nforested_full_aug |&gt;\n  count(.pred_class, forested) |&gt;\n  arrange(forested) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = round(n / sum(n), 2),\n    decision = case_when(\n      .pred_class == \"Yes\" & forested == \"Yes\" ~ \"True positive\",\n      .pred_class == \"Yes\" & forested == \"No\" ~ \"False positive\",\n      .pred_class == \"No\" & forested == \"Yes\" ~ \"False negative\",\n      .pred_class == \"No\" & forested == \"No\" ~ \"True negative\"\n    )\n  )\n\n# A tibble: 4 × 5\n# Groups:   forested [2]\n  .pred_class forested     n     p decision      \n  &lt;fct&gt;       &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 Yes         Yes        876  0.91 True positive \n2 No          Yes         86  0.09 False negative\n3 Yes         No          85  0.1  False positive\n4 No          No         730  0.9  True negative"
  },
  {
    "objectID": "ae/ae-14-forest-classification.html#sensitivity-specificity-roc-curve-1",
    "href": "ae/ae-14-forest-classification.html#sensitivity-specificity-roc-curve-1",
    "title": "AE 14: Forest classification",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\nforested_full_roc &lt;- roc_curve(forested_full_aug, \n                               truth = forested, \n                               .pred_Yes, \n                               event_level = \"first\")\n\nforested_full_roc\n\n# A tibble: 1,779 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 -Inf           0                 1\n 2    0.00106     0                 1\n 3    0.00107     0.00123           1\n 4    0.00217     0.00245           1\n 5    0.00287     0.00368           1\n 6    0.00290     0.00491           1\n 7    0.00290     0.00613           1\n 8    0.00309     0.00736           1\n 9    0.00321     0.00859           1\n10    0.00323     0.00982           1\n# ℹ 1,769 more rows\n\n\n\nggplot(forested_full_roc, aes(x = 1 - specificity, y = sensitivity)) +\n  geom_path() +\n  geom_abline(lty = 3) +\n  coord_equal()"
  },
  {
    "objectID": "ae/ae-01-meet-the-penguins.html",
    "href": "ae/ae-01-meet-the-penguins.html",
    "title": "AE 01: Meet the penguins",
    "section": "",
    "text": "For this application exercise, we’ll use the tidyverse and palmerpenguins packages.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\nThe dataset we will visualize is called penguins. Let’s glimpse() at it.\n\n\nYour turn: Replace #add code here with the code for “glimpse”ing at the data penguins data frame – glimpse(penguins). Render the document and view the output.\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\n\n\nDemo: First, replace the blank below with the number of rows in the penguins data frame based on the output of the chunk below. Then, replace it with “inline code” and render again.\n\n\nnrow(penguins)\n\n[1] 344\n\n\nThere are 344 penguins in the penguins data frame."
  },
  {
    "objectID": "ae/ae-06-taxes-join.html",
    "href": "ae/ae-06-taxes-join.html",
    "title": "AE 06: Sales taxes + data joining",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#getting-started",
    "href": "ae/ae-06-taxes-join.html#getting-started",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are available in the data folder:\n\nsales-taxes.csv\nus-regions.csv\n\n\nsales_taxes &lt;- read_csv(\"data/sales-taxes.csv\")\nus_regions &lt;- read_csv(\"data/us-regions.csv\")\n\nAnd let’s take a look at the data.\n\nglimpse(sales_taxes)\n\nRows: 51\nColumns: 5\n$ state              &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"Califo…\n$ state_tax_rate     &lt;dbl&gt; 0.0400, 0.0000, 0.0560, 0.0650, 0.0725, 0.0290, 0.0…\n$ avg_local_tax_rate &lt;dbl&gt; 0.0529, 0.0182, 0.0278, 0.0295, 0.0160, 0.0491, 0.0…\n$ combined_rate      &lt;dbl&gt; 0.0929, 0.0182, 0.0838, 0.0945, 0.0885, 0.0781, 0.0…\n$ max_local_tax_rate &lt;dbl&gt; 0.0750, 0.0785, 0.0530, 0.0613, 0.0475, 0.0830, 0.0…\n\nglimpse(us_regions)\n\nRows: 50\nColumns: 2\n$ state_name &lt;chr&gt; \"Maine\", \"New Hampshire\", \"Vermont\", \"Massachusetts\", \"Rhod…\n$ region     &lt;chr&gt; \"Northeast\", \"Northeast\", \"Northeast\", \"Northeast\", \"Northe…"
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#sales-tax-in-swing-states-if_else",
    "href": "ae/ae-06-taxes-join.html#sales-tax-in-swing-states-if_else",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Sales tax in swing states: if_else\n",
    "text": "Sales tax in swing states: if_else\n\nCreate new swing_state variable using if_else:\n\nlist_of_swing_states &lt;- c(\"Arizona\", \"Georgia\", \"Michigan\", \"Nevada\", \n                          \"North Carolina\", \"Pennsylvania\", \"Wisconsin\")\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    swing_state = if_else(state %in% list_of_swing_states,\n                          \"Swing\",\n                          \"Non-swing\")) |&gt;\n  relocate(swing_state)\n\nsales_taxes\n\n# A tibble: 51 × 6\n   swing_state state       state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;       &lt;chr&gt;                &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Non-swing   Alabama             0.04               0.0529        0.0929\n 2 Non-swing   Alaska              0                  0.0182        0.0182\n 3 Swing       Arizona             0.056              0.0278        0.0838\n 4 Non-swing   Arkansas            0.065              0.0295        0.0945\n 5 Non-swing   California          0.0725             0.016         0.0885\n 6 Non-swing   Colorado            0.029              0.0491        0.0781\n 7 Non-swing   Connecticut         0.0635             0             0.0635\n 8 Non-swing   Delaware            0                  0             0     \n 9 Non-swing   Florida             0.06               0.01          0.07  \n10 Swing       Georgia             0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;\n\n\nSummarize to find the mean sales tax in each type of state:\n\nsales_taxes |&gt;\n  group_by(swing_state) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 2 × 2\n  swing_state mean_state_tax\n  &lt;chr&gt;                &lt;dbl&gt;\n1 Non-swing           0.0504\n2 Swing               0.0546"
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#sales-tax-in-coastal-states-case_when",
    "href": "ae/ae-06-taxes-join.html#sales-tax-in-coastal-states-case_when",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Sales tax in coastal states: case_when\n",
    "text": "Sales tax in coastal states: case_when\n\nCreate new coast variable using case_when:\n\npacific_coast &lt;- c(\"Alaska\", \"Washington\", \"Oregon\", \"California\", \"Hawaii\")\n\natlantic_coast &lt;- c(\n  \"Connecticut\", \"Delaware\", \"Georgia\", \"Florida\", \"Maine\", \"Maryland\", \n  \"Massachusetts\", \"New Hampshire\", \"New Jersey\", \"New York\", \n  \"North Carolina\", \"Rhode Island\", \"South Carolina\", \"Virginia\"\n)\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    coast = case_when(\n      state %in% pacific_coast ~ \"Pacific\",\n      state %in% atlantic_coast ~ \"Atlantic\",\n      .default = \"Neither\"\n    )\n  ) |&gt;\n  relocate(coast)\n\nsales_taxes\n\n# A tibble: 51 × 7\n   coast    swing_state state    state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Neither  Non-swing   Alabama          0.04               0.0529        0.0929\n 2 Pacific  Non-swing   Alaska           0                  0.0182        0.0182\n 3 Neither  Swing       Arizona          0.056              0.0278        0.0838\n 4 Neither  Non-swing   Arkansas         0.065              0.0295        0.0945\n 5 Pacific  Non-swing   Califor…         0.0725             0.016         0.0885\n 6 Neither  Non-swing   Colorado         0.029              0.0491        0.0781\n 7 Atlantic Non-swing   Connect…         0.0635             0             0.0635\n 8 Atlantic Non-swing   Delaware         0                  0             0     \n 9 Atlantic Non-swing   Florida          0.06               0.01          0.07  \n10 Atlantic Swing       Georgia          0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;\n\n\nSummarize to find the mean sales tax in each type of state:\n\nsales_taxes |&gt;\n  group_by(coast) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 3 × 2\n  coast    mean_state_tax\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Atlantic         0.0484\n2 Neither          0.0545\n3 Pacific          0.0355"
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#sales-tax-in-us-regions-joining",
    "href": "ae/ae-06-taxes-join.html#sales-tax-in-us-regions-joining",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Sales tax in US regions: joining",
    "text": "Sales tax in US regions: joining\nJoin the sales tax data with region data and save the joined data frame as a new data frame, not overwriting either data frame that goes into the join.\n\nsales_taxes_regions &lt;- sales_taxes |&gt;\n  full_join(us_regions, \n            by = join_by(state == state_name)) |&gt;\n  relocate(region)\n\nsales_taxes_regions\n\n# A tibble: 51 × 8\n   region    coast    swing_state state       state_tax_rate avg_local_tax_rate\n   &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;                &lt;dbl&gt;              &lt;dbl&gt;\n 1 South     Neither  Non-swing   Alabama             0.04               0.0529\n 2 West      Pacific  Non-swing   Alaska              0                  0.0182\n 3 West      Neither  Swing       Arizona             0.056              0.0278\n 4 South     Neither  Non-swing   Arkansas            0.065              0.0295\n 5 West      Pacific  Non-swing   California          0.0725             0.016 \n 6 West      Neither  Non-swing   Colorado            0.029              0.0491\n 7 Northeast Atlantic Non-swing   Connecticut         0.0635             0     \n 8 South     Atlantic Non-swing   Delaware            0                  0     \n 9 South     Atlantic Non-swing   Florida             0.06               0.01  \n10 South     Atlantic Swing       Georgia             0.04               0.0338\n# ℹ 41 more rows\n# ℹ 2 more variables: combined_rate &lt;dbl&gt;, max_local_tax_rate &lt;dbl&gt;\n\n\nCalculate the average sales tax of states in each region. What is surprising in the output?\n\nsales_taxes_regions |&gt;\n  group_by(region) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 5 × 2\n  region    mean_state_tax\n  &lt;chr&gt;              &lt;dbl&gt;\n1 Midwest           0.0569\n2 Northeast         0.0530\n3 South             0.0523\n4 West              0.0416\n5 &lt;NA&gt;              0.06  \n\n\nIdentify the state with NA for region.\n\nsales_taxes_regions |&gt;\n  filter(is.na(region)) |&gt;\n  select(state)\n\n# A tibble: 1 × 1\n  state               \n  &lt;chr&gt;               \n1 District of Columbia\n\n\nApply a fix for the NA in region, and calculate the mean sales taxes for regions again. Display the results in ascending order of mean sales tax.\n\nsales_taxes_regions |&gt;\n  mutate(\n    region = if_else(state == \"District of Columbia\", \"Northeast\", region)\n  ) |&gt;\n  group_by(region) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 4 × 2\n  region    mean_state_tax\n  &lt;chr&gt;              &lt;dbl&gt;\n1 Midwest           0.0569\n2 Northeast         0.0537\n3 South             0.0523\n4 West              0.0416"
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#render-commit-and-push",
    "href": "ae/ae-06-taxes-join.html#render-commit-and-push",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html",
    "href": "ae/ae-03-gerrymander-explore-I.html",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html#getting-started",
    "href": "ae/ae-03-gerrymander-explore-I.html#getting-started",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\n\nData\nThe data are available in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…\n\n\nSince this dataset is shipped with a package, it has documentation that you can access via ?gerrymander. The flip18 variable is categorical with three levels:\n\n-1: control of the district flipped from Democrats to Republicans between 2016 and 2018;\n0: the district did not flip. If Democrats controlled it in 2016, they kept it in 2018. If Republicans controlled it in 2016, they kept it in 2018;\n1: control of the district flipped from Republicans to Democrats between 2016 and 2018."
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html#districts-at-the-tails",
    "href": "ae/ae-03-gerrymander-explore-I.html#districts-at-the-tails",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "Districts at the tails",
    "text": "Districts at the tails\nMake side-by-side box plots of percent of vote received by Trump in 2016 Presidential Election by prevalence of gerrymandering. Identify any Congressional Districts that are potential outliers. Are they different from the rest of the Congressional Districts due to high support or low support for Trump in the 2016 Presidential Election? Which state are they in? Which city are they in?\n\nggplot(gerrymander, aes(x = trump16, y = gerry)) +\n  geom_boxplot() + \n  labs(\n    x = \"% vote for Trump in 2016\",\n    y = \"Extent of gerrymandering in district\"\n  )\n\n\n\n\n\n\n\nThe outliers are:\n\ngerrymander |&gt;\n  filter(gerry == \"low\" & trump16 &lt; 10)\n\n# A tibble: 2 × 12\n  district last_name first_name party16 clinton16 trump16 dem16 state party18\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n1 NY-13    Espaillat Adriano    D            92.3     5.4     1 NY    D      \n2 NY-15    Serrano   Jose       D            93.8     4.9     1 NY    D      \n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html#flips",
    "href": "ae/ae-03-gerrymander-explore-I.html#flips",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "Flips",
    "text": "Flips\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\n\n\n\n\nHint\n\n\n\nCalculate the conditional distribution of prevalance of gerrymandering based on whether a Democrat was able to flip the seat in the 2018 election.\n\n\nThis code gives you a bar chart counting how many districts fall into each level of flip18, and then divides each bar according to the prevalence of gerrymandering in the districts:\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar()\n\n\n\n\n\n\n\nHowever, because the total number of counts is different in the three groups, it’s hard to directly compare the information about gerrmandering. So, this code normalizes each bar so that you can compare by eye:\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nThis code gives you the raw numbers that underpin the plot:\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132\n\n\nBased on this information, which party would you say benefited from gerrymandering more in the 2018 midterms?"
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html#render-commit-and-push",
    "href": "ae/ae-03-gerrymander-explore-I.html#render-commit-and-push",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html",
    "href": "ae/ae-04-gerrymander-explore-II.html",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#getting-started",
    "href": "ae/ae-04-gerrymander-explore-II.html#getting-started",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\nlibrary(ggbeeswarm)\n\nData\nThe data are availale in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#congressional-districts-per-state",
    "href": "ae/ae-04-gerrymander-explore-II.html#congressional-districts-per-state",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Congressional districts per state",
    "text": "Congressional districts per state\nWhich state has the most congressional districts? How many congressional districts are there in this state?\n\ngerrymander |&gt;\n  count(state, sort = TRUE)\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 CA       53\n 2 TX       36\n 3 FL       27\n 4 NY       27\n 5 IL       18\n 6 PA       18\n 7 OH       16\n 8 GA       14\n 9 MI       14\n10 NC       13\n# ℹ 40 more rows"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#gerrymandering-and-flipping",
    "href": "ae/ae-04-gerrymander-explore-II.html#gerrymandering-and-flipping",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Gerrymandering and flipping",
    "text": "Gerrymandering and flipping\nIs a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering? Support your answer with a visualization and summary statistics.\n\ngerrymander |&gt;\n  mutate(flip18 = as.factor(flip18)) |&gt;\n  ggplot(aes(x = gerry, fill = flip18)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\ngerrymander |&gt;\n  count(gerry, flip18) |&gt;\n  group_by(gerry) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   gerry [3]\n  gerry flip18     n      p\n  &lt;fct&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1 low       -1     2 0.0323\n2 low        0    52 0.839 \n3 low        1     8 0.129 \n4 mid       -1     3 0.0111\n5 mid        0   242 0.896 \n6 mid        1    25 0.0926\n7 high       0    98 0.951 \n8 high       1     5 0.0485"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#aesthetic-mappings",
    "href": "ae/ae-04-gerrymander-explore-II.html#aesthetic-mappings",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\nRecreate the following visualization, and then improve it.\n\n\nggplot(gerrymander, aes(x = gerry, y = clinton16)) +\n  geom_beeswarm(color = \"gray50\", alpha = 0.5) +\n  geom_boxplot(aes(color = gerry), alpha = 0.5) +\n  theme_minimal()"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#render-commit-and-push",
    "href": "ae/ae-04-gerrymander-explore-II.html#render-commit-and-push",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-13-spam-filter.html",
    "href": "ae/ae-13-spam-filter.html",
    "title": "AE 13: building a spam filter",
    "section": "",
    "text": "In this application exercise, we will\nTo illustrate logistic regression, we will build a spam filter from email data.\nThe data come from incoming emails in David Diez’s (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nglimpse(email)\n\nRows: 3,921\nColumns: 21\n$ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         &lt;dttm&gt; 2012-01-01 01:16:41, 2012-01-01 02:03:59, 2012-01-01 11:…\n$ image        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       &lt;dbl&gt; 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ inherit      &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     &lt;dbl&gt; 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     &lt;dbl&gt; 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  &lt;int&gt; 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess &lt;dbl&gt; 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       &lt;fct&gt; big, small, small, small, none, none, big, small, small, …\nThe variables we’ll use in this analysis are\nGoal: Use the number of exclamation points in an email to predict whether or not it is spam."
  },
  {
    "objectID": "ae/ae-13-spam-filter.html#exercise-1",
    "href": "ae/ae-13-spam-filter.html#exercise-1",
    "title": "AE 13: building a spam filter",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet’s start with some exploratory analysis:\n\nCreate a density plot to investigate the relationship between spam and exclaim_mess.\n\n\nggplot(email, aes(x = exclaim_mess, fill = spam)) + \n  geom_density()\n\n\n\n\n\n\n\n\nAdditionally, calculate the mean number of exclamation points for both spam and non-spam emails.\n\n\nemail |&gt;\n  group_by(spam) |&gt;\n  summarize(mean_ep = mean(exclaim_mess))\n\n# A tibble: 2 × 2\n  spam  mean_ep\n  &lt;fct&gt;   &lt;dbl&gt;\n1 0        6.51\n2 1        7.32"
  },
  {
    "objectID": "ae/ae-13-spam-filter.html#exericse-2",
    "href": "ae/ae-13-spam-filter.html#exericse-2",
    "title": "AE 13: building a spam filter",
    "section": "Exericse 2",
    "text": "Exericse 2\nVisualize a linear model fit for these data:\n\nggplot(email, aes(x = exclaim_mess, y = as.numeric(spam) - 1)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") +\n  labs(\n    x = \"# of exclamation marks in email\",\n    y = \"e-mail type\"\n  ) +\n  scale_y_continuous(breaks = c(0, 1),\n                   labels = c(\"legit (0)\", \"spam (1)\"))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nIs the linear model a good fit for the data? Why or why not?\nAns: Heavens no."
  },
  {
    "objectID": "ae/ae-13-spam-filter.html#exercise-3",
    "href": "ae/ae-13-spam-filter.html#exercise-3",
    "title": "AE 13: building a spam filter",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nFit the logistic regression model using the number of exclamation points to predict the probability an email is spam:\n\n\nlog_fit &lt;- logistic_reg() |&gt;\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(log_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n\n\n\nAdd your estimates to the fitted equation below\n\n\\[\\log\\Big(\\frac{\\hat{p}}{1-\\hat{p}}\\Big) = -2.27 + 0.00027 \\times exclaim\\_mess\\]\n\nHow does the code above differ from previous code we’ve used to fit regression models?\n\nAns: linear_reg is changed to logistic_reg. Things are otherwise unchanged."
  },
  {
    "objectID": "ae/ae-13-spam-filter.html#exercise-4",
    "href": "ae/ae-13-spam-filter.html#exercise-4",
    "title": "AE 13: building a spam filter",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhat is the probability the email is spam if it contains 10 exclamation points? Answer the question using the predict() function.\n\n\nnew_email &lt;- tibble(\n  exclaim_mess = 10\n  )\n\npredict(log_fit, new_data = new_email, type = \"prob\")\n\n# A tibble: 1 × 2\n  .pred_0 .pred_1\n    &lt;dbl&gt;   &lt;dbl&gt;\n1   0.906  0.0937\n\n\n\nA probability is nice, but we want an actual decision. Classify the darn email.\n\n\npredict(log_fit, new_data = new_email, type = \"class\")\n\n# A tibble: 1 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n\n\nThe default behavior is to threshold the probabilities by 0.5."
  },
  {
    "objectID": "ae/ae-13-spam-filter.html#exercise-5",
    "href": "ae/ae-13-spam-filter.html#exercise-5",
    "title": "AE 13: building a spam filter",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nFit a model with all variables in the dataset as predictors.\n\n\nlog_fit2 &lt;- logistic_reg() |&gt;\n  fit(spam ~ ., data = email)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n\nIf you used this model to classify the emails in the dataset, how would it do? Use the fitted model to classify each email in the dataset, and then calculate the classification error rates (TP, TN, FP, FN).\n\n\nlog_aug &lt;- augment(log_fit2, email)\n\n\nlog_aug |&gt;\n  count(spam, .pred_class) |&gt;\n  group_by(spam) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   spam [2]\n  spam  .pred_class     n       p\n  &lt;fct&gt; &lt;fct&gt;       &lt;int&gt;   &lt;dbl&gt;\n1 0     0            3521 0.991  \n2 0     1              33 0.00929\n3 1     0             299 0.815  \n4 1     1              68 0.185"
  },
  {
    "objectID": "ae/ae-10-modeling-penguins.html",
    "href": "ae/ae-10-modeling-penguins.html",
    "title": "AE 10: Modelling penguins",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\n\n\nIn this application exercise we will be studying penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\nPlease read the following context and take a glimpse at the data set before we get started.\n\nThis data set comprising various measurements of three different penguin species, namely Adelie, Gentoo, and Chinstrap. The rigorous study was conducted in the islands of the Palmer Archipelago, Antarctica. These data were collected from 2007 to 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data set is called penguins.\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nOur goal is to understand better how various body measurements and attributes of penguins relate to their body mass. First, we are going to investigate the relationship between a penguins’ flipper lengths and their body masses.\n\n\nQuestion: Based on our research focus, which variable is the response variable?\n\nBody mass.\n\n\nDemo: Visualize the relationship between flipper length and body mass of penguins.\n\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nCorrelation\n\n\nYour turn (5 minutes):\n\n\nWhat is correlation? What values can correlation take?\nStrength and direction of a linear relationship. It’s bounded by -1 and 1.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\n\n\n\nDemo: What is the correlation between flipper length and body mass of penguins?\n\n\n# option 1\npenguins |&gt;\n  summarize(r = cor(flipper_length_mm, body_mass_g, use = \"complete.obs\"))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.871\n\n# option 2\npenguins |&gt;\n  drop_na(flipper_length_mm, body_mass_g) |&gt;\n  summarize(r = cor(flipper_length_mm, body_mass_g))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.871\n\n\nDefining, fitting, and summarizing a model\n\n\nDemo: Write the population model below that explains the relationship between body mass and flipper length.\n\n\\[\nbody~mass = \\beta_0 + \\beta_1 \\times flipper~length + \\epsilon\n\\]\n\n\nDemo: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\nbm_fl_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\ntidy(bm_fl_fit)\n\n# A tibble: 2 × 5\n  term              estimate std.error statistic   p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\n\\[\n\\widehat{body~mass} = -5781 + 49.7 \\times flipper~length\n\\]\n\n\nYour turn: Interpret the slope and the intercept in the context of the data.\n\nIntercept: Penguins with 0 flipper length are expected, on average, to weigh -5,781 grams.\nSlopes: For each additional millimeter of a penguin;s flipper length, the weight of their penguin is expected to be higher, on average, by 49.7 grams.\n\n\nYour turn: Recreate the visualization from above, this time adding a regression line to the visualization geom_smooth(method = \"lm\").\n\n\nggplot(\n  penguins,\n  aes(x = flipper_length_mm, y = body_mass_g)\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nDemo: What is the estimated body mass for a penguin with a flipper length of 210?\n\n\npenguin_flipper_210 &lt;- tibble(flipper_length_mm = 210)\n\nbm_fl_fit |&gt;\n  predict(new_data = penguin_flipper_210)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 4653.\n\n\n\n\nYour turn: What is the estimated body mass for a penguin with a flipper length of 100?\n\nBut we shouldn’t do this prediction based on this model since 100 mm is outside of the range of the data (extrapolation).\n\npenguin_flipper_100 &lt;- tibble(flipper_length_mm = 100)\n\nbm_fl_fit |&gt;\n  predict(new_data = penguin_flipper_100)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 -812.\n\n\nAnother model\n\n\nDemo: A different researcher wants to look at body weight of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\nPredictor is categorical.\n\n\nDemo: Make an appropriate visualization to investigate this relationship below. Additionally, calculate the mean body mass by island.\n\n\nggplot(penguins, aes(x = island, y = body_mass_g)) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\npenguins |&gt;\n  group_by(island) |&gt;\n  summarize(mean_bm = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 3 × 2\n  island    mean_bm\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Biscoe      4716.\n2 Dream       3713.\n3 Torgersen   3706.\n\n\n\n\nDemo: Change the geom of your previous plot to geom_point(). Use this plot to think about how R models these data.\n\n\nggplot(penguins, aes(x = island, y = body_mass_g)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nYour turn: Fit the linear regression model and display the results. Write the estimated model output below.\n\n\nbm_island_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ island, data = penguins)\n\ntidy(bm_island_fit)\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        4716.      48.5      97.3 8.93e-250\n2 islandDream       -1003.      74.2     -13.5 1.42e- 33\n3 islandTorgersen   -1010.     100.      -10.1 4.66e- 21\n\n\n\n\nDemo: Interpret each coefficient in context of the problem.\n\nIntercept: Penguins from Biscoe island are expected to weigh, on average, 4,716 grams.\n\nSlopes:\n\nPenguins from Dream island are expected to weigh, on average, 1,003 grams less than those from Biscoe island.\nPenguins from Torgersen island are expected to weigh, on average, 1,010 grams less than those from Biscoe island.\n\n\n\n\nDemo: What is the estimated body weight of a penguin on Biscoe island? What are the estimated body weights of penguins on Dream and Torgersen islands?\n\n\nthree_penguins &lt;- tibble(\n  island = c(\"Biscoe\", \"Dream\", \"Torgersen\")\n)\nbm_island_fit |&gt;\n  predict(new_data = three_penguins)\n\n# A tibble: 3 × 1\n  .pred\n  &lt;dbl&gt;\n1 4716.\n2 3713.\n3 3706."
  },
  {
    "objectID": "ae/ae-11-modeling-penguins-multi.html",
    "href": "ae/ae-11-modeling-penguins-multi.html",
    "title": "AE 11: Modelling penguins with multiple predictors",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this application exercise we will continue to study penguins. The data can be found in the palmerpenguins package and we will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "ae/ae-11-modeling-penguins-multi.html#additive-vs.-interaction-models",
    "href": "ae/ae-11-modeling-penguins-multi.html#additive-vs.-interaction-models",
    "title": "AE 11: Modelling penguins with multiple predictors",
    "section": "Additive vs. interaction models",
    "text": "Additive vs. interaction models\n\n\nYour turn: Run the two chunks of code below and create two separate plots. How are the two plots different than each other? Which plot does the model we fit above represent?\n\n# Plot A\nggplot(\n  penguins, \n  aes(x = flipper_length_mm, y = body_mass_g, color = island)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Plot A - Interaction model\") +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n# Plot B\nbm_fl_island_aug &lt;- augment(bm_fl_island_fit, new_data = penguins)\nggplot(\n  bm_fl_island_aug, \n  aes(x = flipper_length_mm, y = body_mass_g, color = island)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(aes(y = .pred), method = \"lm\") +\n  labs(title = \"Plot B - Additive model\") +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range (`stat_smooth()`).\nRemoved 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nPlot B represents the model we fit.\n\n\nYour turn: Interpret the slope coefficient for flipper length in the context of the data and the research question.\n\nFor every 1 millimeter the flipper is longer, we expect body mass to be higher, on average, by 44.5 grams, holding all else (the island) constant. In other words, this is true for penguins in a given island, regardless of the island.\n\n\nDemo: Predict the body mass of a Dream island penguin with a flipper length of 200 mm based on the additive model.\n\n\npenguin_200_Dream &lt;- tibble(\n  flipper_length_mm = 200,\n  island = \"Dream\"\n)\n\npredict(bm_fl_island_fit, new_data = penguin_200_Dream)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 4021.\n\n\n\n\nReview: Look back at Plot B. What assumption does the additive model make about the slopes between flipper length and body mass for each of the three islands?\n\nThe additive model assumes the same slope between body mass and flipper length for all three islands.\n\n\nDemo: Now fit the interaction model represented in Plot A and write the estimated regression model.\n\n\nbm_fl_island_int_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ flipper_length_mm * island, data = penguins)\n\ntidy(bm_fl_island_int_fit)\n\n# A tibble: 6 × 5\n  term                              estimate std.error statistic  p.value\n  &lt;chr&gt;                                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                        -5464.     431.      -12.7  2.51e-30\n2 flipper_length_mm                     48.5      2.05     23.7  1.66e-73\n3 islandDream                         3551.     969.        3.66 2.89e- 4\n4 islandTorgersen                     3218.    1680.        1.92 5.62e- 2\n5 flipper_length_mm:islandDream        -19.4      4.94     -3.93 1.03e- 4\n6 flipper_length_mm:islandTorgersen    -17.4      8.73     -1.99 4.69e- 2\n\n\n\\[\n\\widehat{body~mass} = -5464 \\\\\n+ 48.5 \\times flipper~length \\\\\n+ 3551 \\times Dream + 3218 \\times Torgersen \\\\\n- 19.4 \\times flipper~length*Dream - 17.4 \\times flipper~length*Torgersen\n\\]\n\n\nReview: What does modeling body mass with an interaction effect get us that without doing so does not?\n\nThe interaction effect allows us to model the rate of change in estimated body mass as flipper length increases as different in the three islands.\n\n\nYour turn: Predict the body mass of a Dream island penguin with a flipper length of 200 mm based on the interaction model.\n\n\npredict(bm_fl_island_int_fit, new_data = penguin_200_Dream)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 3915."
  },
  {
    "objectID": "ae/ae-11-modeling-penguins-multi.html#choosing-a-model",
    "href": "ae/ae-11-modeling-penguins-multi.html#choosing-a-model",
    "title": "AE 11: Modelling penguins with multiple predictors",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\nglance(bm_fl_island_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.774         0.772  383.      386. 7.60e-109     3 -2517. 5045. 5064.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(bm_fl_island_int_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.786         0.783  374.      246. 4.55e-110     5 -2508. 5031. 5057.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables)."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html",
    "href": "ae/ae-02-bechdel-dataviz.html",
    "title": "AE 02: Bechdel + data visualization",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key.\nIn this mini-analysis, we use the data from the FiveThirtyEight story “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women.”\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#getting-started",
    "href": "ae/ae-02-bechdel-dataviz.html#getting-started",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are stored as a CSV (comma-separated values) file in your repository’s data folder. Let’s read it from there and save it as an object called bechdel.\n\nbechdel &lt;- read_csv(\"data/bechdel.csv\")\n\nGet to know the data\nWe can use the glimpse() function to get an overview (or “glimpse”) of the data.\n\nglimpse(bechdel)\n\nRows: 1,615\nColumns: 7\n$ title       &lt;chr&gt; \"21 & Over\", \"Dredd 3D\", \"12 Years a Slave\", \"2 Guns\", \"42…\n$ year        &lt;dbl&gt; 2013, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n$ gross_2013  &lt;dbl&gt; 67878146, 55078343, 211714070, 208105475, 190040426, 18416…\n$ budget_2013 &lt;dbl&gt; 13000000, 45658735, 20000000, 61000000, 40000000, 22500000…\n$ roi         &lt;dbl&gt; 5.221396, 1.206305, 10.585703, 3.411565, 4.751011, 0.81851…\n$ binary      &lt;chr&gt; \"FAIL\", \"PASS\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"P…\n$ clean_test  &lt;chr&gt; \"notalk\", \"ok\", \"notalk\", \"notalk\", \"men\", \"men\", \"notalk\"…\n\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a movie.\n\nHow many observations (rows) are in the data set?\n\nThere are 1615 movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are 7 columns in the dataset.\nVariables of interest\nThe variables we’ll focus on are the following:\n\n\nroi: Return on investment, calculated as the ratio of the gross to budget.\n\nclean_test: Bechdel test result:\n\n\nok = passes test\ndubious\n\nmen = women only talk about men\n\nnotalk = women don’t talk to each other\n\nnowomen = fewer than two women\n\n\n\nbinary: Bechdel Test PASS vs FAIL binary\n\nWe will also use the year of release in data prep and title of movie to take a deeper look at some outliers.\nThere are a few other variables in the dataset, but we won’t be using them in this analysis."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#film-finances",
    "href": "ae/ae-02-bechdel-dataviz.html#film-finances",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Film finances",
    "text": "Film finances\nThis code visualizes the distribution of film budgets in the dataset:\n\nggplot(bechdel, aes(x = budget_2013)) + \n  geom_histogram() + \n  labs(x = \"2013 USD\",\n       title = \"Film budgets (1990 - 2013)\")\n\n\n\n\n\n\n\nThis distribution is right-skewed, and unimodal. We can get a sense of the center and spread with the following summary statistics:\n\nbechdel |&gt;\n  summarise(\n    mean = mean(budget_2013),\n    median = median(budget_2013),\n    sd = sd(budget_2013),\n    iqr = IQR(budget_2013)\n  )\n\n# A tibble: 1 × 4\n       mean   median        sd      iqr\n      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 57035015. 37878971 55976978. 67848653\n\n\nA scatterplot visualizes the relationship between a film’s budget and its earnings:\n\nggplot(bechdel, aes(x = budget_2013, y = gross_2013)) + \n  geom_point() + \n  geom_smooth() + \n  labs(x = \"Budget (2013 USD)\",\n       y = \"Gross (2013 USD)\",\n       title = \"Film finances (1990 - 2013)\")\n\n\n\n\n\n\n\nThe relationship is positive, fairly linear (the curve in the trend seems due mostly to the effect of the two outliers), and moderately strong.\nThe two films with especially high grosses are:\n\nbechdel |&gt; \n  filter(gross_2013 &gt; 3e9)\n\n# A tibble: 2 × 7\n  title    year gross_2013 budget_2013   roi binary clean_test\n  &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 Avatar   2009 3848295959   461435929  8.34 FAIL   men       \n2 Titanic  1997 4127821329   290247625 14.2  PASS   ok"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#bechdel-test-results",
    "href": "ae/ae-02-bechdel-dataviz.html#bechdel-test-results",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Bechdel test results",
    "text": "Bechdel test results\nVisualizing data with ggplot2\n\nggplot2 is the package and ggplot() is the function in this package that is used to create a plot.\n\n\nggplot() creates the initial base coordinate system, and we will add layers to that base. We first specify the data set we will use with data = bechdel.\n\n\nggplot(data = bechdel)\n\n\n\n\n\n\n\n\nThe mapping argument is paired with an aesthetic (aes()), which tells us how the variables in our data set should be mapped to the visual properties of the graph.\n\n\nggplot(data = bechdel, mapping = aes(x = clean_test))\n\n\n\n\n\n\n\nAs we previously mentioned, we often omit the names of the first two arguments in R functions. So you’ll often see this written as:\n\nggplot(bechdel, aes(x = clean_test))\n\n\n\n\n\n\n\nNote that the result is exactly the same.\n\nThe geom_xx function specifies the type of plot we want to use to represent the data. In the code below, we use geom_point which creates a plot where each observation is represented by a point.\n\n\nggplot(bechdel, aes(x = clean_test)) +\n  geom_bar()\n\n\n\n\n\n\n\nWhat types of movies are more common, those that pass or do not pass the test?\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#return-on-investment",
    "href": "ae/ae-02-bechdel-dataviz.html#return-on-investment",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nLet’s take a look at return-on-investment (ROI) for movies that do and do not pass the Bechdel test.\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\nggplot(bechdel, aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n  )\n\nWarning: Removed 15 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n# A tibble: 3 × 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen   \n\n\nStep 2 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi &lt; ___ to get a better view of how the medians across the categories compare.\n\nggplot(bechdel, aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n  ) +\n  coord_cartesian(ylim = c(0, 16))\n\nWarning: Removed 15 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-12-modeling-loans.html",
    "href": "ae/ae-12-modeling-loans.html",
    "title": "AE 12: Modelling loan interest rates",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this application exercise we will be studying loan interest rates. The dataset is one you’ve come across before in your reading – the dataset about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nBefore we use the dataset, we’ll make a few transformations to it.\nAdd response here.\nloans &lt;- loans_full_schema |&gt;\n  mutate(\n    credit_util = total_credit_utilized / total_credit_limit,\n    bankruptcy = as.factor(if_else(public_record_bankrupt == 0, 0, 1)),\n    verified_income = droplevels(verified_income),\n    homeownership = str_to_title(homeownership),\n    homeownership = fct_relevel(homeownership, \"Rent\", \"Mortgage\", \"Own\")\n  ) |&gt;\n  rename(credit_checks = inquiries_last_12m) |&gt;\n  select(\n    interest_rate, loan_amount, verified_income, \n    debt_to_income, credit_util, bankruptcy, term, \n    credit_checks, issue_month, homeownership\n  )\nHere is a glimpse at the data:\nglimpse(loans)\n\nRows: 10,000\nColumns: 10\n$ interest_rate   &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, …\n$ loan_amount     &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 2…\n$ verified_income &lt;fct&gt; Verified, Not Verified, Source Verified, Not Verified,…\n$ debt_to_income  &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, …\n$ credit_util     &lt;dbl&gt; 0.54759517, 0.15003472, 0.66134832, 0.19673228, 0.7549…\n$ bankruptcy      &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, …\n$ term            &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, 60, 60, 36, 60…\n$ credit_checks   &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8, 6, 0, 0, 4, 6, …\n$ issue_month     &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-2018, Mar-2018, Jan-…\n$ homeownership   &lt;fct&gt; Mortgage, Rent, Rent, Rent, Rent, Own, Mortgage, Mortg…"
  },
  {
    "objectID": "ae/ae-12-modeling-loans.html#main-effects-model",
    "href": "ae/ae-12-modeling-loans.html#main-effects-model",
    "title": "AE 12: Modelling loan interest rates",
    "section": "Main effects model",
    "text": "Main effects model\n\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, without an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\nrate_util_home_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util + homeownership, data = loans)\n\ntidy(rate_util_home_fit)\n\n# A tibble: 4 × 5\n  term                  estimate std.error statistic   p.value\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              9.93      0.140    70.8   0        \n2 credit_util              5.34      0.207    25.7   2.20e-141\n3 homeownershipMortgage    0.696     0.121     5.76  8.71e-  9\n4 homeownershipOwn         0.128     0.155     0.827 4.08e-  1\n\n\n\\[\n\\widehat{interest~rate} = 9.93 + 5.34 \\times credit~util + 0.696 \\times Mortgage + 0.128 \\times Own\n\\]\n\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.93 + 5.34 \\times credit~util\\)\n\nMortgage: \\(\\widehat{interest~rate} = 10.626 + 5.34 \\times credit~util\\)\n\nOwn: \\(\\widehat{interest~rate} = 10.058 + 5.34 \\times credit~util\\)\n\n\n\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nThe same."
  },
  {
    "objectID": "ae/ae-12-modeling-loans.html#interaction-effects-model",
    "href": "ae/ae-12-modeling-loans.html#interaction-effects-model",
    "title": "AE 12: Modelling loan interest rates",
    "section": "Interaction effects model",
    "text": "Interaction effects model\n\n\nDemo: Fit a model to predict interest rate from credit utilization and homeownership, with an interaction effect between the two predictors. Display the summary output and write out the estimated regression equation.\n\n\nrate_util_home_int_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util * homeownership, data = loans)\n\ntidy(rate_util_home_int_fit)\n\n# A tibble: 6 × 5\n  term                              estimate std.error statistic  p.value\n  &lt;chr&gt;                                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                          9.44      0.199     47.5  0       \n2 credit_util                          6.20      0.325     19.1  1.01e-79\n3 homeownershipMortgage                1.39      0.228      6.11 1.04e- 9\n4 homeownershipOwn                     0.697     0.316      2.20 2.75e- 2\n5 credit_util:homeownershipMortgage   -1.64      0.457     -3.58 3.49e- 4\n6 credit_util:homeownershipOwn        -1.06      0.590     -1.80 7.24e- 2\n\n\n\\[\n\\widehat{interest~rate} = 9.44 + 6.20 \\times credit~util + 1.39 \\times Mortgage + 0.697 \\times Own - 1.64 \\times credit_util:Mortgage - 1.06 \\times credit_util:Own\n\\]\n\n\nDemo: Write the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.44 + 6.20 \\times credit~util\\)\n\nMortgage: \\(\\widehat{interest~rate} = 10.83 + 4.56 \\times credit~util\\)\n\nOwn: \\(\\widehat{interest~rate} = 10.137 + 5.14 \\times credit~util\\)\n\n\n\n\nQuestion: How does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nDifferent."
  },
  {
    "objectID": "ae/ae-12-modeling-loans.html#choosing-a-model",
    "href": "ae/ae-12-modeling-loans.html#choosing-a-model",
    "title": "AE 12: Modelling loan interest rates",
    "section": "Choosing a model",
    "text": "Choosing a model\nRule of thumb: Occam’s Razor - Don’t overcomplicate the situation! We prefer the simplest best model.\n\nglance(rate_util_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0648        0.0647  4.84      693. 1.18e-147     1 -29944. 59893. 59915.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(rate_home_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1   0.00649       0.00629  4.99      32.6 7.35e-15     2 -30253. 60514. 60543.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(rate_util_home_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0682        0.0679  4.83      244. 1.25e-152     3 -29926. 59861. 59897.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(rate_util_home_int_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0694        0.0689  4.83      149. 4.79e-153     5 -29919. 59852. 59903.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nReview: What is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables).\n\n\nQuestion: Based on the adjusted \\(R^2\\)s of the four models we’ve seen so far, which one do we prefer?\n\nThe interaction effects model, though just barely."
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html",
    "href": "ae/ae-05-majors-tidy.html",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html#getting-started",
    "href": "ae/ae-05-majors-tidy.html#getting-started",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are available in the data folder.\n\nstatsci &lt;- read_csv(\"data/statsci.csv\")\n\nRows: 4 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): degree\ndbl (14): 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAnd let’s take a look at the data.\n\nstatsci\n\n# A tibble: 4 × 15\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statist…     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist…      2      2      4      1      3      6      3      4      4      1\n3 Statist…      2      6      1     NA      5      6      6      8      8     17\n4 Statist…      5      9      4     13     10     17     24     21     26     27\n# ℹ 4 more variables: `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;, `2024` &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html#pivoting",
    "href": "ae/ae-05-majors-tidy.html#pivoting",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "Pivoting",
    "text": "Pivoting\nPivot the statsci data frame longer such that\n\neach row represents a degree type / year combination,\n\nyear and number of graduates for that year are columns,\n\nyear is numerical,\n\nNAs in counts are replaced with 0s,\n\ndegree_type has levels BS, BS2, AB, and AB2 (in this order), and\nthe resulting data frame is saved as statsci_longer.\n\nReview the code below with your neighbor and come up with at least one question about the code.\n\nstatsci_longer &lt;- statsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n  )\n\nstatsci_longer\n\n# A tibble: 56 × 4\n   major               degree_type  year     n\n   &lt;chr&gt;               &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science AB2          2011     0\n 2 Statistical Science AB2          2012     1\n 3 Statistical Science AB2          2013     0\n 4 Statistical Science AB2          2014     0\n 5 Statistical Science AB2          2015     4\n 6 Statistical Science AB2          2016     4\n 7 Statistical Science AB2          2017     1\n 8 Statistical Science AB2          2018     0\n 9 Statistical Science AB2          2019     0\n10 Statistical Science AB2          2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html#plotting",
    "href": "ae/ae-05-majors-tidy.html#plotting",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "Plotting",
    "text": "Plotting\nStep 1: Basics\nLet’s start with a basic plot, nothing too fancy! Create a line plot of number of majors vs. year, where lines are colored by degree type, and the data are also represented as points on the lines.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\nWhat aspects of the plot need to be updated to go from the draft you created above to the goal plot from the slides.\n\nx-axis scale: need to go from 2012 to 2024 in increments of 2 years\nline colors\naxis labels: title, subtitle, x, y, caption\ntheme\nlegend position and border\nStep 2: Scales\nUpdate x-axis scale such that the years displayed go from 2012 to 2024 in increments of 2 years. Do this by adding on to your ggplot call from earlier.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2))\n\n\n\n\n\n\n\nStep 3: Colors\nUpdate line colors using the following level / color assignments. Once again, do this by adding on to your ggplot call from earlier.\n\n“BS” = “cadetblue4”\n“BS2” = “cadetblue3”\n“AB” = “lightgoldenrod4”\n“AB2” = “lightgoldenrod3”\n\nNote: A handy reference for named colors in R is http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf, though you can use HEX color codes as well.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  )\n\n\n\n\n\n\n\nStep 4: Labels and themes\nUpdate the plot labels (title, subtitle, x, y, and caption) and use theme_minimal(). Once again, do this by adding on to your ggplot call from earlier. Note: The link in the caption is https://registrar.duke.edu/registration/enrollment-statistics.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nStep 5: Legends and figure sizing via cell options\nFinally, adding to your pipeline you’ve developed so far, move the legend into the plot, make its background white, and its border gray. Additionally, in the cell options, set\n\n\nout-width: 100% – Output should span 100% of the width\n\nfig-width: 8 – Figure output should have a width of 8 inches\n\nfig-asp: 0.5 – Figure output should have an aspect ratio of 0.5, resulting in a height of 8 * 0.5 = 4 inches\n\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(0.1, 0.7),\n    legend.background = element_rect(fill = \"white\", color = \"gray\")\n  )"
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html#render-commit-and-push",
    "href": "ae/ae-05-majors-tidy.html#render-commit-and-push",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-08-age-gaps-sales-import.html",
    "href": "ae/ae-08-age-gaps-sales-import.html",
    "title": "AE 08: Age gaps + sales + import",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-08-age-gaps-sales-import.html#getting-started",
    "href": "ae/ae-08-age-gaps-sales-import.html#getting-started",
    "title": "AE 08: Age gaps + sales + import",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe will use the following two packages in this application exercise.\n\n\ntidyverse: For data import, wrangling, and visualization.\n\nreadxl: For importing data from Excel.\n\n\nlibrary(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "ae/ae-08-age-gaps-sales-import.html#part-1-hollywood-relationships",
    "href": "ae/ae-08-age-gaps-sales-import.html#part-1-hollywood-relationships",
    "title": "AE 08: Age gaps + sales + import",
    "section": "Part 1: Hollywood relationships",
    "text": "Part 1: Hollywood relationships\nLoad the data from age-gaps.csv in your data and assign it to age_gaps. Confirm that this new object appears in your Environment tab. Click on the name of the object in your Environment tab to pop open the data in the data viewer.\n\nage_gaps &lt;- read_csv(\"data/age-gaps.csv\")\n\nRows: 1155 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): movie_name, director, actor_1_name, actor_2_name, character_1_gend...\ndbl  (5): release_year, age_difference, couple_number, actor_1_age, actor_2_age\ndate (2): actor_1_birthdate, actor_2_birthdate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCreate a subset of the data frame for heterosexual relationships on screen.\n\nage_gaps_heterosexual &lt;- age_gaps |&gt;\n  filter(character_1_gender != character_2_gender)\n\nSplit the data for heterosexual relationships into three – where woman is older, where man is older, where they are the same age. Save these subsets as two appropriately named data frames. Remember: Use concise and evocative names. Confirm that these new objects appear in your Environment tab and that the sum of the number of observations in the two new data frames add to the number of observations in the original data frame.\n\nage_gaps_heterosexual &lt;- age_gaps_heterosexual |&gt;\n  mutate(\n    older = case_when(\n      character_1_gender == \"woman\" & actor_1_age &gt; actor_2_age ~ \"woman older\",\n      character_2_gender == \"woman\" & actor_2_age &gt; actor_1_age ~ \"woman older\",\n      character_1_gender == \"man\"   & actor_1_age &gt; actor_2_age ~ \"man older\",\n      character_2_gender == \"man\"   & actor_2_age &gt; actor_1_age ~ \"man older\",\n      actor_1_age == actor_2_age ~ \"same age\"\n    )\n  )\n\nwoman_older &lt;- age_gaps_heterosexual |&gt; filter(older == \"woman older\")\nman_older   &lt;- age_gaps_heterosexual |&gt; filter(older == \"man older\")\nsame_age    &lt;- age_gaps_heterosexual |&gt; filter(older == \"same age\")\n\n(nrow(woman_older) + nrow(man_older) + nrow(same_age)) == nrow(age_gaps_heterosexual)\n\n[1] TRUE\n\n\nWrite out the three new datasets you created into the data folder:\n\nwrite_csv(woman_older, file = \"data/woman-older.csv\")\nwrite_csv(man_older, file = \"data/man-older.csv\")\nwrite_csv(same_age, file = \"data/same-age.csv\")"
  },
  {
    "objectID": "ae/ae-08-age-gaps-sales-import.html#part-2-sales",
    "href": "ae/ae-08-age-gaps-sales-import.html#part-2-sales",
    "title": "AE 08: Age gaps + sales + import",
    "section": "Part 2: Sales",
    "text": "Part 2: Sales\nSales data are stored in an Excel file that looks like the following:\n\nRead in the Excel file called sales.xlsx from the data-raw/ folder such that it looks like the following.\n\n\nsales_raw &lt;- read_excel(\n  \"data/sales.xlsx\", \n  skip = 3,\n  col_names = c(\"id\", \"n\")\n  )\n\nStretch goal: Manipulate the sales data such such that it looks like the following.\n\n\nsales &lt;- sales_raw |&gt;\n  mutate(\n    is_brand_name = str_detect(id, \"Brand\"),\n    brand = if_else(is_brand_name, id, NA)\n  ) |&gt;\n  fill(brand) |&gt;\n  filter(!is_brand_name) |&gt;\n  select(brand, id, n)\n\nsales\n\n# A tibble: 7 × 3\n  brand   id    n    \n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;\n1 Brand 1 1234  8    \n2 Brand 1 8721  2    \n3 Brand 1 1822  3    \n4 Brand 2 3333  1    \n5 Brand 2 2156  3    \n6 Brand 2 3987  6    \n7 Brand 2 3216  5    \n\n\nWhy should we bother with writing code for reading the data in by skipping columns and assigning variable names as well as cleaning it up in multiple steps instead of opening the Excel file and editing the data in there to prepare it for a clean import?\nBecause the code allows us to struggle once and re-use for future datasets and leaves a transparent trail of our modifications while manipulating the data in Excel directly is neither reproducible nor reusable."
  },
  {
    "objectID": "ae/ae-15-duke-forest-bootstrap.html",
    "href": "ae/ae-15-duke-forest-bootstrap.html",
    "title": "AE 15: Houses in Duke Forest",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as reference only, it’s not designed to be an exhaustive key.\nIn this application exercise, we will use bootstrapping to construct confidence intervals."
  },
  {
    "objectID": "ae/ae-15-duke-forest-bootstrap.html#packages",
    "href": "ae/ae-15-duke-forest-bootstrap.html#packages",
    "title": "AE 15: Houses in Duke Forest",
    "section": "Packages",
    "text": "Packages\nWe will use tidyverse and tidymodels for data exploration and modeling, respectively, and the openintro package for the data, and the knitr package for formatting tables.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-15-duke-forest-bootstrap.html#data",
    "href": "ae/ae-15-duke-forest-bootstrap.html#data",
    "title": "AE 15: Houses in Duke Forest",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…"
  },
  {
    "objectID": "ae/ae-15-duke-forest-bootstrap.html#model",
    "href": "ae/ae-15-duke-forest-bootstrap.html#model",
    "title": "AE 15: Houses in Duke Forest",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-15-duke-forest-bootstrap.html#bootstrap-confidence-interval",
    "href": "ae/ae-15-duke-forest-bootstrap.html#bootstrap-confidence-interval",
    "title": "AE 15: Houses in Duke Forest",
    "section": "Bootstrap confidence interval",
    "text": "Bootstrap confidence interval\n1. Calculate the observed fit (slope)\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159.\n\n\n2. Take n bootstrap samples and fit models to each one.\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(20241115)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = n, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept  149083.\n 2         1 area          143.\n 3         2 intercept  226037.\n 4         2 area          110.\n 5         3 intercept   37464.\n 6         3 area          188.\n 7         4 intercept    7631.\n 8         4 area          208.\n 9         5 intercept  245406.\n10         5 area          104.\n# ℹ 190 more rows\n\n\n\nWhy do we set a seed before taking the bootstrap samples?\nMake a histogram of the bootstrap samples to visualize the bootstrap distribution.\n\n\nboot_fits |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n3. Compute the 95% confidence interval as the middle 95% of the bootstrap distribution\nFill in the code, then set eval: true .\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          79.9     207.\n2 intercept  -3694.   316939."
  },
  {
    "objectID": "ae/ae-15-duke-forest-bootstrap.html#changing-confidence-level",
    "href": "ae/ae-15-duke-forest-bootstrap.html#changing-confidence-level",
    "title": "AE 15: Houses in Duke Forest",
    "section": "Changing confidence level",
    "text": "Changing confidence level\nModify the code from Step 3 to create a 90% confidence interval.\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.90,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          94.7     203.\n2 intercept   8234.   284161.\n\n\nModify the code from Step 3 to create a 99% confidence interval.\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.99,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          64.2     211.\n2 intercept -19831.   370166.\n\n\n\nWhich confidence level produces the most accurate confidence interval (90%, 95%, 99%)? Explain\nWhich confidence level produces the most precise confidence interval (90%, 95%, 99%)? Explain\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "lab/lab-2.html",
    "href": "lab/lab-2.html",
    "title": "Lab 2",
    "section": "",
    "text": "In this lab, you’ll continue to hone your data science workflow and integrate what you learned so far in the course (data visualization) with what’s coming up (data wrangling).\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed Lab 0 and Lab 1 and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review them before starting with this one.\n\n\n\nBy the end of the lab, you will…\n\nBe able to create transform data using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH (this might already be selected by default; if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-2.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-2.qmd, update the author field to your name, render your document, and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository and, in your browser, confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\nImportant\n\n\n\nIf you encounter any issues with the above steps, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the tidyverse package, a collection of packages for performing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in the lecture, your plots should include an informative title, axes and legends should have human-readable labels and aesthetic choices should be carefully considered.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nAs you complete the lab and other assignments in this course, remember to develop a sound workflow for reproducible data analysis. This assignment will periodically remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#learning-objectives",
    "href": "lab/lab-2.html#learning-objectives",
    "title": "Lab 2",
    "section": "",
    "text": "By the end of the lab, you will…\n\nBe able to create transform data using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#getting-started",
    "href": "lab/lab-2.html#getting-started",
    "title": "Lab 2",
    "section": "",
    "text": "Go to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH (this might already be selected by default; if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-2.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-2.qmd, update the author field to your name, render your document, and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository and, in your browser, confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\nImportant\n\n\n\nIf you encounter any issues with the above steps, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#packages",
    "href": "lab/lab-2.html#packages",
    "title": "Lab 2",
    "section": "",
    "text": "In this lab, we will work with the tidyverse package, a collection of packages for performing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#guidelines",
    "href": "lab/lab-2.html#guidelines",
    "title": "Lab 2",
    "section": "",
    "text": "As we’ve discussed in the lecture, your plots should include an informative title, axes and legends should have human-readable labels and aesthetic choices should be carefully considered.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nAs you complete the lab and other assignments in this course, remember to develop a sound workflow for reproducible data analysis. This assignment will periodically remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-1",
    "href": "lab/lab-2.html#question-1",
    "title": "Lab 2",
    "section": "Question 1",
    "text": "Question 1\nDo some states have counties that tend to be geographically larger than others?\nTo explore this question, create side-by-side boxplots of area (area) of a county based on state (state). How do typical county area sizes compare across states? How do variabilities of county sizes compare across states? Which state has the single largest county? Identify the name of this county. You can use the data viewer to identify it interactively, you do not have to write code.\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nOnce again, make sure to commit and push all changed files so that your Git pane is empty afterwards.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-2",
    "href": "lab/lab-2.html#question-2",
    "title": "Lab 2",
    "section": "Question 2",
    "text": "Question 2\nDo some states have a higher percentage of their counties located in a metropolitan area?\nCreate a segmented bar chart with one bar per state and the bar filled with colors according to the value of metro – one color indicating Yes and the other color indicating No for whether a county is considered to be a metro area. The y-axis of the segmented barplot should range from 0 to 1, indicating proportions. Compare the percentage of counties in metro areas across the states based on this plot. Make sure to supplement your narrative with rough estimates of these percentages.\n\n\n\n\n\n\nHint\n\n\n\nFor this question, you should begin with the data wrangling pipeline below. We will learn more about data wrangling in the coming weeks, so this is a mini-preview. This pipeline creates a new variable called metro based on the value of the existing variable called inmetro. If the value of inmetro is equal to 1 (inmetro == 1), it sets the value of metro to \"Yes\", and if not, it sets the value of metro to \"No\". The resulting data frame is assigned back to midwest, overwriting the existing midwest data frame with a version that includes the new metro variable.\n\nmidwest &lt;- midwest |&gt;\n  mutate(metro = if_else(inmetro == 1, \"Yes\", \"No\"))\n\n\n\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nAnd once again, make sure to commit and push all changed files so that your Git pane is empty afterward. We keep repeating this because it’s important and because we see students forget to do this. So take a moment to make sure you’re following along with the version control instructions.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-3",
    "href": "lab/lab-2.html#question-3",
    "title": "Lab 2",
    "section": "Question 3",
    "text": "Question 3\nCalculate the number of counties in each state and display your results in descending order of number of counties. Which state has the highest number of counties, and how many? Which state has the lowest number, and how many?\n\n\n\n\n\n\nNote\n\n\n\nThe number of counties in a state can change over time, so the values you see in this output may not be true today.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 3”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-4",
    "href": "lab/lab-2.html#question-4",
    "title": "Lab 2",
    "section": "Question 4",
    "text": "Question 4\nWhile two counties in a given state can’t have the same name, some county names might be shared across states. A classmate says “Look at that, there is a county called ___ in each state in this dataset!” In a single pipeline, discover all counties that could fill in the blanks. Your response should be a data frame with only the county names that could fill in the blank and the number of times they appear in the data.\n\n\n\n\n\n\nTip\n\n\n\nYou will want to use the filter() function in your answer, which requires a logical condition to describe what you want to filter for. For example, filter(x &gt; 2) means filter for values of x greater than 2, and filter(y &lt;= 3) means filter for values of y less than or equal to 3.\nThe table below is a summary of logical operators and how to articulate them in R.\n\n\noperator\ndefinition\n\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to\n\n\nx & y\n\nx AND y\n\n\n\n\nx | y\n\n\nx OR y\n\n\n\nis.na(x)\ntest if x is NA\n\n\n\n!is.na(x)\ntest if x is not NA\n\n\n\nx %in% y\ntest if x is in y\n\n\n\n!(x %in% y)\ntest if x is not in y\n\n\n\n!x\nnot x\n\n\n\n\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 4”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-5",
    "href": "lab/lab-2.html#question-5",
    "title": "Lab 2",
    "section": "Question 5",
    "text": "Question 5\nReturn to the following box plot of population densities where you were asked to identify at least one outlier.\n\n\n\n\n\n\n\n\nIn this question, we want you to revisit this box plot and identify the counties described in each section.\na. The counties with a population density higher than 25,000. Your code must use the filter() function.\nb. The county with the highest population density. Your code must use the max() function.\nAnswer using a single data wrangling pipeline for each part. Your response should be a data frame with five columns: county name, state name, population density, total population, and area, in this order. If your response has multiple rows, the data frame should be arranged in descending order of population density.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 5”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-6",
    "href": "lab/lab-2.html#question-6",
    "title": "Lab 2",
    "section": "Question 6",
    "text": "Question 6\nIn Lab 1 you were also asked to describe the distribution of population densities. The following is one acceptable description that touches on the shape, center, and spread of this distribution. Calculate the values that should go into the blanks.\n\nThe distribution of population density of counties is unimodal and extremely right-skewed. A typical Midwestern county has population density of ____ people per unit area. The middle 50% of the counties have population densities between ___ to ___ people per unit area.\n\n\n\n\n\n\n\nTip\n\n\n\nThink about which measures of center and spread are appropriate for skewed distributions.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 6”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-7",
    "href": "lab/lab-2.html#question-7",
    "title": "Lab 2",
    "section": "Question 7",
    "text": "Question 7\nThis is the plot we ask for in Question 2:\n\n\n\n\n\n\n\n\nUse a single data pipeline to calculate the proportions that underlie this plot.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 7”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-8",
    "href": "lab/lab-2.html#question-8",
    "title": "Lab 2",
    "section": "Question 8",
    "text": "Question 8\nReturn to the following scatter plot of percentage below poverty vs. percentage of people with a college degree, where the color and shape of points are determined by state where you were asked to identify at least one county that is a clear outlier by name.\n\n\n\n\n\n\n\n\na. In a single pipeline, identify the observations marked in the orange square in the upper left corner. Your answer should be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nb. In a single pipeline, identify the observations marked in the red square in the plot above. Your answer should again be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nc. Bring your answers from part (a) and part (b) together! In a single pipeline, and a single filter() statement, identify the observations marked in the red and orange square in the plot above. Your answer should again be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nd. Create a new variable in midwest called potential_outlier. This variable should take on the value:\n\nYes if the point is one the ones you identified in part (c), i.e., one of the points marked in the squares in the plot above.\nNo otherwise.\n\nThen, display the updated midwest data frame, with county, state, percentage below poverty, percentage college educated, potential_outlier as the selected variables, arranged in descending order of potential_outlier.\ne. Recreate the visualization above, i.e., a scatterplot of the percentage below poverty vs. the percentage of people with a college degree. However, color the points by the newly created potential_outlier variable instead of the state.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 8”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-9",
    "href": "lab/lab-2.html#question-9",
    "title": "Lab 2",
    "section": "Question 9",
    "text": "Question 9\na. In a single pipeline, calculate the total population for each state and save the resulting data frame as state_population. Then, display the data frame, state_population, in descending order of total population.\nb. Then, in a separate pipeline, calculate the proportion of the total population in each state. Once again, display the results in descending order of proportion of population.\n\n\n\n\n\n\nTip\n\n\n\nIn answering parts (a) and (b), you’ll create two new variables, one for the total population and the other for the proportion of total proportion. Make sure to give them “reasonable” names – short but evocative.\n\n\nc. Which Midwestern state is most populous, and what percent of the Midwest population lives there? Which is the least populous and what percent lives there?\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 9”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-10",
    "href": "lab/lab-2.html#question-10",
    "title": "Lab 2",
    "section": "Question 10",
    "text": "Question 10\nCalculate the average percentage below poverty for each state and save the resulting data frame as state_poverty with the columns state and mean_percbelowpoverty.\nThen, in a new pipeline, display the state_poverty data frame in ascending order of mean_percbelowpoverty. Which state has the lowest average percentage below poverty across its counties? Which state has the highest average percentage below poverty across its counties?\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 10”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#submission",
    "href": "lab/lab-2.html#submission",
    "title": "Lab 2",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nTo be considered ” on time, ” you must turn in a PDF file to the Gradescope page by the submission deadline.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with each question. All the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#grading-and-feedback",
    "href": "lab/lab-2.html#grading-and-feedback",
    "title": "Lab 2",
    "section": "Grading and feedback",
    "text": "Grading and feedback\n\nSome of the questions will be graded for accuracy.\nSome will be graded for completion.\n\nThere are also workflow points:\n\nfor coding style;\nfor committing at least three times as you work through your lab;\nfor pushing your final rendered PDF into your lab repo before the deadline (in addition to uploading it to Gradescope);\nfor overall organization.\n\n\nYou’ll receive feedback on your lab on Gradescope within a week.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#footnotes",
    "href": "lab/lab-2.html#footnotes",
    "title": "Lab 2",
    "section": "Footnotes",
    "text": "Footnotes\n\nRemember, haikus, not novellas, when writing code!↩︎",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-1.html",
    "href": "lab/lab-1.html",
    "title": "Lab 1",
    "section": "",
    "text": "This lab will introduce you to the course computing workflow. The main goal is to reinforce our demo of R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\n\n\n\n\n\n\nNote\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface, commonly referred to as an integrated development environment or an IDE, for short.\n\n\nAn additional goal is to reinforce Git and GitHub, the version control, web hosting, and collaboration systems that we will be using throughout the course.\n\n\n\n\n\n\nNote\n\n\n\nGit is a version control system (like “Track Changes” features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\n\n\n\n\n\n\nWarning\n\n\n\nThis lab assumes that you have already completed Lab 0. If you have not, please\n\ngo back and do that first before proceeding and\nlet your TA know as they will need to set up a Lab 1 repository for you before you can complete this lab.\n\n\n\n\nBy the end of the lab, you will…\n\nBe familiar with the workflow using R, RStudio, Git, and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using Git and GitHub\nBe able to create data visualizations using ggplot2\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file.\n\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-1.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human-friendly data representation for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document.\nIf you get a popup window error, click “Try again”.\nExamine the rendered document and make sure your name is updated in the document.\n\n\n\nGo to the Git pane in RStudio. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. If you have rendered the document, you should also see its output, a PDF file, listed there.\n\n\nClick on it to select it in this list and then click on Diff.\nThis shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\n\n\nIf you’re happy with these changes, prepare the changes to be pushed to your remote repository.\n\nFirst, stage your changes by checking the appropriate box on the files you want to prepare.\nNext, write a meaningful commit message (for instance, “Updated author name”) in the Commit message box.\nFinally, click Commit. Note that every commit needs to have a commit message associated with it.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration (e.g., restoring a previous version of your document).\nIn the first few assignments, we will tell you exactly when to commit and, in some cases, what commit message to use. As the semester progresses, we will let you make these decisions.\n\n\n\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\n\nIn the Git pane, click on Push.\nThen, make sure all the changes went to GitHub. Go to your GitHub repo in your browser and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub, and you’re good to go!\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you don’t see your update, go back to Step 4. Remember that in order to push your changes to GitHub, you must have staged (checked boxes) your commit (with a commit message) to be pushed and then click on Push.\n\n\n\nIn this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.\n\n\nThe tidyverse is a meta-package. When you load it you get nine packages loaded for you:\n\n\ndplyr: for data wrangling\n\nforcats: for dealing with factors\n\nggplot2: for data visualization\n\nlubridate: for dealing with dates\n\npurrr: for iteration with functional programming\n\nreadr: for reading and writing data\n\nstringr: for string manipulation\n\ntibble: for modern, tidy data frames\n\ntidyr: for data tidying and rectangling\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#learning-objectives",
    "href": "lab/lab-1.html#learning-objectives",
    "title": "Lab 1",
    "section": "",
    "text": "By the end of the lab, you will…\n\nBe familiar with the workflow using R, RStudio, Git, and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using Git and GitHub\nBe able to create data visualizations using ggplot2",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#getting-started",
    "href": "lab/lab-1.html#getting-started",
    "title": "Lab 1",
    "section": "",
    "text": "Go to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file.\n\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-1.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human-friendly data representation for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document.\nIf you get a popup window error, click “Try again”.\nExamine the rendered document and make sure your name is updated in the document.\n\n\n\nGo to the Git pane in RStudio. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. If you have rendered the document, you should also see its output, a PDF file, listed there.\n\n\nClick on it to select it in this list and then click on Diff.\nThis shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\n\n\nIf you’re happy with these changes, prepare the changes to be pushed to your remote repository.\n\nFirst, stage your changes by checking the appropriate box on the files you want to prepare.\nNext, write a meaningful commit message (for instance, “Updated author name”) in the Commit message box.\nFinally, click Commit. Note that every commit needs to have a commit message associated with it.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration (e.g., restoring a previous version of your document).\nIn the first few assignments, we will tell you exactly when to commit and, in some cases, what commit message to use. As the semester progresses, we will let you make these decisions.\n\n\n\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\n\nIn the Git pane, click on Push.\nThen, make sure all the changes went to GitHub. Go to your GitHub repo in your browser and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub, and you’re good to go!\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you don’t see your update, go back to Step 4. Remember that in order to push your changes to GitHub, you must have staged (checked boxes) your commit (with a commit message) to be pushed and then click on Push.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#packages",
    "href": "lab/lab-1.html#packages",
    "title": "Lab 1",
    "section": "",
    "text": "In this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.\n\n\nThe tidyverse is a meta-package. When you load it you get nine packages loaded for you:\n\n\ndplyr: for data wrangling\n\nforcats: for dealing with factors\n\nggplot2: for data visualization\n\nlubridate: for dealing with dates\n\npurrr: for iteration with functional programming\n\nreadr: for reading and writing data\n\nstringr: for string manipulation\n\ntibble: for modern, tidy data frames\n\ntidyr: for data tidying and rectangling",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#guidelines",
    "href": "lab/lab-1.html#guidelines",
    "title": "Lab 1",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#part-1---lets-take-a-trip-to-the-midwest",
    "href": "lab/lab-1.html#part-1---lets-take-a-trip-to-the-midwest",
    "title": "Lab 1",
    "section": "Part 1 - Let’s take a trip to the Midwest!",
    "text": "Part 1 - Let’s take a trip to the Midwest!\nWe will use the midwest data frame for this lab. It is part of the ggplot2 R package, so the midwest data set is automatically loaded when you load the tidyverse package.\nThe data contains demographic characteristics of counties in the Midwest region of the United States.\nBecause the data set is part of the ggplot2 package, you can read documentation for the data set, including variable definitions by typing ?midwest in the Console or searching for midwest in the Help pane.\nQuestion 1\nVisualize the distribution of population density of counties using a histogram with geom_histogram() with four separate binwidths: a binwidth of 100, a binwidth of 1,000, a binwidth of 10,000, and a binwidth of 100,000. For example, you can create the first plot with:\n\nggplot(midwest, aes(x = popdensity)) +\n  geom_histogram(binwidth = 100) +\n  labs(\n    x = \"Population density\",\n    y = \"Count\",\n    title = \"Population density of Midwestern counties\",\n    subtitle = \"Binwidth = 100\"\n  )\n\n\n\n\n\n\n\nYou will need to make four different histograms. Make sure to set informative titles and axis labels for each of your plots. Then, comment on which binwidth is most appropriate for these data and why.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 1”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 2\nVisualize the distribution of population density of counties again, this time using a boxplot with geom_boxplot(). Make sure to set informative titles and axis labels for your plot. Then, using information as needed from the box plot as well as the histogram from Question 1, describe the distribution of population density of counties and comment on any potential outliers, making sure to identify at least one county that is a clear outlier by name in your narrative and commenting on whether it makes sense to you that this county is an outlier. You can use the data viewer to identify the outliers interactively, you do not have to write code to identify them.\n\n\n\n\n\n\nImportant\n\n\n\nIn describing a distribution, make sure to mention shape, center, spread, and any unusual observations.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 2”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 3\nUse geom_point to create a scatterplot of the percentage below poverty (percbelowpoverty on the y-axis) versus percentage of people with a college degree (percollege on the x-axis), where the color and shape of points are determined by state. Make sure to set informative titles, axis, and legend labels for your plot. First, describe the overall relationship between percentage of people with a college degree and percentage below poverty in Midwestern states, making sure to identify at least one county that is a clear outlier by name in your narrative. You can use the data viewer to identify the outliers interactively, you do not have to write code to identify them. Then, comment on whether you can identify how this relationship varies across states.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 3”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 4\nNow, let’s examine the relationship between the same two variables, once again using different colors and shapes to represent each state, and using a separate plot for each state, i.e., with faceting with facet_wrap(). In addition to points (geom_point()), represent the data with a smooth curve fit to the data with geom_smooth(), with the argument se = FALSE. Make sure to set informative titles, axis, and legend labels for your plot. Which plot do you prefer - this plot or the plot in Question 3? Briefly explain your choice.\n\n\n\n\n\n\nNote\n\n\n\nse = FALSE removes the confidence bands around the line. These bands show the uncertainty around the smooth curve. We’ll discuss uncertainty around estimates later in the course and bring these bands back then.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 4”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 5\nRecreate the plot below, and then give it a title. Then, identify at least one county that is a clear outlier in Wisconsin (WI) by name. You can use the data viewer to identify them interactively, you do not have to write code. Comment on the population composition of this county by investigating the percentage of other races living there.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe ggplot2 reference for themes will be helpful in determining the theme.\nThe size of the points is 2.\nThe transparency (alpha) of the points is 0.5.\nYou can put line breaks in labels with \\n.\n\n\n\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nAnd once again, make sure to commit and push all changed files so that your Git pane is empty afterward. We keep repeating this because it’s important and because we see students forget to do this. So take a moment to make sure you’re following along with the version control instructions.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#part-2---enough-about-the-midwest",
    "href": "lab/lab-1.html#part-2---enough-about-the-midwest",
    "title": "Lab 1",
    "section": "Part 2 - Enough about the Midwest!",
    "text": "Part 2 - Enough about the Midwest!\nIn this part we will use a new, more recent, and potentially more relevant dataset on counties in North Carolina.\nThis dataset is stored in a file called nc-county.csv in the data folder of your project/repository.\nYou can read this file into R with the following code:\n\nnc_county &lt;- read_csv(\"data/nc-county.csv\")\n\nThis will read the CSV (comma separated values) file from the data folder and store the dataset as a data frame called nc_county in R.\nThe variables in the dataset and their descriptions are as follows:\n\n\ncounty: Name of county.\n\nstate_abb: State abbreviation (NC).\n\nstate_name: State name (North Carolina).\n\nland_area_m2: Land area of county in meters-squared, based on the 2020 census.\n\nland_area_mi2: Land area of county in miles-squared, based on the 2020 census.\n\npopulation: Population of county, based on the 2020 census.\n\ndensity: Population density calculated as population divided by land area in miles-squared.\n\nIn addition to being more recent and more relevant, this dataset is also more complete in the sense that we know the units of population density: people per mile-squared!\nQuestion 6\nFirst, guess what the relationship between population density and land area might be – positive? negative? no relationship?\nThen, make a scatter plot of population density (density on the y-axis) vs. land area in miles-squared (land_area_mi2 on the x-axis). Make sure to set an informative title and axis labels for your plot. Describe the relationship. Was your guess correct?\nQuestion 7\nNow make a scatter plot of population density (density on the y-axis) vs. land area in meters-squared (land_area_m2 on the x-axis). Make sure to set an informative title and axis labels for your plot. Comment on how this scatterplot compares to the one in Exercise 6 — is the relationship displayed same or different. Explain why.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#part-3---potpourri-graded-for-a-good-faith-effort",
    "href": "lab/lab-1.html#part-3---potpourri-graded-for-a-good-faith-effort",
    "title": "Lab 1",
    "section": "Part 3 - Potpourri graded for a good faith effort",
    "text": "Part 3 - Potpourri graded for a good faith effort\nQuestion 8\nOne of the key reasons we care about data science and statistics in the first place is because they can help us make decisions under uncertainty. For example:\n\nWhen we save for retirement, we have to make a decision about what asset classes to invest in (stocks, bonds, real estate, etc) and in what proportions. We want to make the most stable and lucrative choice possible, accounting for the fact that we are uncertain about how the assets will ultimately perform. Data on past asset performance may help guide this decision;\nWhen insurance companies sell policies, they have to decide who to sell to and what sized premium to charge. They face uncertainty about how many policies will ultimately result in a claim (if it’s everyone, they’re ruined). In order to navigate this environment, they employ armies of actuaries to study historical data and help make decisions about profit, loss, and risk of ruin;\nGood barbecue cannot be made-to-order. A restaurant has to start preparing in the morning, before they know for certain how many folks will show up that day. If they prepare too little, they have to turn a lot of folks away and forfeit their money. If they prepare too much, it can go to waste. So a decision must be made under uncertainty, and it can be guided by historical data on demand, as it varies over the week and the year and during holidays and special events;\nThe manager of a presidential campaign must decide how to allocate the campaign’s resources to different states, counties, neighborhoods, types of media, etc. But these decisions are made before they know how the voters will ultimately behave, and so they try to resolve this uncertainty by analyzing all sorts of data: polling, prediction markets, social media sentiment, economic indicators, historical trends, etc.\nYou darn Duke students must decide what time you’re going to grab lunch at WU, subject to uncertainty about how long the lines will be. When you first matriculate, you might get burned a few times because you have no experience to base this decision on. By your senior year, you’ve accumulated a lot of data about the good and bad times at the different vendors, and how these vary across the days of the week and seasons of the year.\n\nYou get the idea. Now it’s your turn. Write a few paragraph describing an example from your everyday life where you have to make a decision under uncertainty (obviously, don’t recycle one of the examples above). What’s the decision? What are the sources of uncertainty? What is your decision-making process? What data, if it were available, could you consult to resolve some of this uncertainty and help you meet your objective?\n\n\n\n\n\n\nDon’t break my heart.\n\n\n\nThis is graded for completion, but JZ will read all of them. I am not interested in an example from ChatGPT’s everyday life where it has to make a decision under uncertainty. I want to know about you.\n\n\nQuestion 9\nData science is the process of turning messy, incomplete, imperfect data into knowledge, and statistics studies how we can quantify our uncertainty about that knowledge. To illustrate these ideas, we played a game on the first day of class; you were given data of various kinds about a celebrity (names vs pictures, clear pictures vs noisy ones), and you were asked to answer a simple question with a quantitative answer: how old is the person? The results of this exercise are memorialized in the lecture slides from that day, and I summarized some of the high-level lessons here.\nWrite a paragraph or two summarizing another lesson that we can learn from this game. It can be a generic, high-level lesson about the practice of data science and stats, like the ones I listed. It can be a lesson about the application itself that you took away from reviewing the substantive results. Or, you can cast your mind back to when you were guessing, and you can describe and evaluate your guessing process with the benefit of hindsight. What factors were you weighing and/or neglecting? Did you learn anything that could make you a better age-guesser in the future?\nAs you ponder this, note that you have access to the complete dataset of everyone’s guesses. Feel free to play around with it.\nQuestion 10\nDid you select your pages on Gradescope? You don’t need to write an answer for this question, if you select your pages when you upload your lab to Gradescope, you’ll get full points on this question. Otherwise, you’ll get a 0 on this question.2\nQuestion 11\nRecommend some music for us to listen to while we grade this.\n\n\n\n\n\n\nNote\n\n\n\nNot worth any points, but still important.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#submission",
    "href": "lab/lab-1.html#submission",
    "title": "Lab 1",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered “on time”.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#grading-and-feedback",
    "href": "lab/lab-1.html#grading-and-feedback",
    "title": "Lab 1",
    "section": "Grading and feedback",
    "text": "Grading and feedback\n\nSome of the questions will be graded for accuracy.\nSome will be graded for completion.\nQuestion 10 is just asking you to select your pages on Gradescope, and you get points for following the instructions!\nThere are also workflow points, for coding style, for committing at least three times as you work through your lab, and for overall organization.\nYou’ll receive feedback on your lab on Gradescope within a week.\n\nGood luck, and have fun with it!",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#footnotes",
    "href": "lab/lab-1.html#footnotes",
    "title": "Lab 1",
    "section": "Footnotes",
    "text": "Footnotes\n\nRemember, haikus not novellas when writing code!↩︎\nWe’re assigning points to this seemingly trivial task because not selecting your pages and questions will greatly slow down the grading. So we want to make sure you’re properly motivated to complete this task!↩︎",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-4.html",
    "href": "lab/lab-4.html",
    "title": "Lab 4",
    "section": "",
    "text": "In this lab, you’ll review topics you’ve worked with in previous labs, practice importing data, and dive into the concepts of data types and classes.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nLearn to read data in from Excel spreadsheets\nGain more experience with joining and pivoting data frames\nReview Quarto cell options\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-4 repo from GitHub, open your lab-4.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-4. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-4.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-4.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\nreadxl package for reading in Excel files,\n\njanitor package for cleaning up variable names, and\n\npalmerpenguins and datasauRus packages for some datasets\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(palmerpenguins)\nlibrary(datasauRus)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nStarting with this lab, you are expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#learning-objectives",
    "href": "lab/lab-4.html#learning-objectives",
    "title": "Lab 4",
    "section": "",
    "text": "By the end of the lab, you will…\n\nLearn to read data in from Excel spreadsheets\nGain more experience with joining and pivoting data frames\nReview Quarto cell options\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#getting-started",
    "href": "lab/lab-4.html#getting-started",
    "title": "Lab 4",
    "section": "",
    "text": "Log in to RStudio, clone your lab-4 repo from GitHub, open your lab-4.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-4. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-4.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-4.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#packages",
    "href": "lab/lab-4.html#packages",
    "title": "Lab 4",
    "section": "",
    "text": "In this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\nreadxl package for reading in Excel files,\n\njanitor package for cleaning up variable names, and\n\npalmerpenguins and datasauRus packages for some datasets\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(palmerpenguins)\nlibrary(datasauRus)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#guidelines",
    "href": "lab/lab-4.html#guidelines",
    "title": "Lab 4",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nStarting with this lab, you are expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-1---inflation-in-the-us",
    "href": "lab/lab-4.html#part-1---inflation-in-the-us",
    "title": "Lab 4",
    "section": "Part 1 - Inflation in the US",
    "text": "Part 1 - Inflation in the US\nThe OECD defines inflation as follows:\n\nInflation is a rise in the general level of prices of goods and services that households acquire for the purpose of consumption in an economy over a period of time.\nThe main measure of inflation is the annual inflation rate which is the movement of the Consumer Price Index (CPI) from one month/period to the same month/period of the previous year expressed as percentage over time.\nSource: OECD CPI FAQ\n\nCPI is broken down into 12 expenditures such as food, housing, health, etc. Your goal in this part is to create a time series plot of annual inflation for the US.\nThe data you will need to create this visualization is spread across two files:\n\n\nus-inflation.csv: Annual inflation rate for the US for 12 CPI expenditures. Each expenditure is identified by an ID number.\n\ncpi-expenditures.csv: A “lookup table” of CPI expenditure ID numbers and their descriptions.\n\nLet’s load both of these files.\n\nus_inflation &lt;- read_csv(\"data/us-inflation.csv\")\ncpi_expenditures &lt;- read_csv(\"data/cpi-expenditures.csv\")\n\nQuestion 1\na. How many columns and how many rows does the us_inflation dataset have? What are the variables in it? Which years do these data span? Write a brief (1-2 sentences) narrative summarizing this information.\nb. How many columns and how many rows does the cpi_expenditures dataset have? What are the variables in it? Write a brief (1-2 sentences) narrative summarizing this information.\nc. Create a new dataset by joining the us_inflation dataset with the cpi_expenditures dataset.\n\nDetermine which type of join is the most appropriate one and use that.\nNote that the two datasets don’t have a variable with a common name, though they do have variables that contain common information but are named differently. You will need to first figure out which variables those are, and then define the by argument and use the join_by() function to indicate these variables to join the datasets by.\nUse a short but informative name for the joined dataset, and do not overwrite either of the datasets that go into creating it.\n\nThen, find the number of rows and columns of the resulting dataset and report the names of its columns. Add a brief (1-2 sentences) narrative summarizing this information.\nQuestion 2\na. Create a vector called expenditures_of_interest which contains the descriptions or IDs of CPI expenditures you want to visualize. Your expenditures_of_interest should consist of no more than five expenditures. If you’re using descriptions, make sure that the spelling of your expenditures matches how they appear in the dataset. Then, in 1-2 sentences, state why you chose these expenditures.\nb. In a single pipeline, filter your joined dataset to include only the expenditures_of_interest from part (a), and save the resulting data frame with a new name so you (1) can refer to this data frame later in your analysis and (2) do not overwrite the data frame you’re starting with. Use a short but informative name. Then, in a new pipeline, find the distinct() expenditures in the data frame you created.\nQuestion 3\nUsing your data frame from the previous question, create a plot of annual inflation vs. year for these expenditures. Then, in a few sentences, describe the patterns you observe in the plot, particularly focusing on anything you find surprising or not surprising, based on your knowledge (or lack thereof) of inflation rates in the US over the last decade.\n\nData should be represented with points as well as lines connecting the points for each expenditure.\nEach expenditure should be represented by a different color line and different color and shape points.\nAxes and legend should be properly labeled.\nThe plot should have an appropriate title (and optionally a subtitle).\nPlot should be customized in at least one way – you could use a different than default color scale, or different than default theme, or some other customization.\nIf your legend has labels that are too long, you can try moving the legend to the bottom and stack the labels vertically. Hint: The legend.position and legend.direction arguments of the theme() functions will be useful.\n\n\nggplot(...) +\n  ... +\n  theme(\n    legend.position = \"bottom\", \n    legend.direction = \"vertical\"\n  )",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-2---mtcars",
    "href": "lab/lab-4.html#part-2---mtcars",
    "title": "Lab 4",
    "section": "Part 2 - mtcars\n",
    "text": "Part 2 - mtcars\n\nIn this part, you’ll work with one of the most basic and overused datasets in R: mtcars. The data in this dataset come from the 1974 Motor Trend US magazine (so, yes, they’re old!) and provide information on fuel efficiency and other car characteristics.\nQuestion 4\nSince the dataset is used in many code examples, it’s not unexpected that some analyses of the data are good and some not so much.\n\n\n\n\n\n\nTip\n\n\n\nFor both parts of this question, you should review the data dictionary that is in the documentation for the dataset which you can find at https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html or by typing ?mtcars in your Console.\n\n\na. You come across the following visualization of these data. First, determine what is wrong with this visualization and describe it in one sentence. Then, fix and improve the visualization. As part of your improvement, make sure your legend\n\nis on top of the plot,\nis informative, and\nlists levels in the order they appear in the plot.\n\n\nggplot(mtcars, aes(x = wt, y = mpg, color = am)) +\n  geom_point() +\n  labs(\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\"\n  )\n\n\n\n\n\n\n\nb. Update your plot from part (a) further, this time using different shaped points for cars with V-shaped and straight engines. Once again, some requirements for your legend – it should be informative and on the right of the plot.\nQuestion 5\nYour task is to make your plot from Question 4b as ugly and as ineffective as possible. Like, seriously. I want something that is apocalyptically heinous, loathsome, and rotten. Change colors, axes, fonts, themes, or anything else you can think of. You can also search online for other themes, fonts, etc. that you want to tweak. The sky is truly the limit. I want Sauron, Voldemort, Cruella de Vil, Count Dracula, and Regina George all nodding in approval at how horrendous your plot is.\nYou must make at least 5 updates to the plot, and your answer must include:\n\na list of the at least 5 updates you’ve made to your plot from Question 4b, and\n1-2 sentence explanation of why the plot you created is ugly (to you, at least) and ineffective.\n\nDid I mention that the plot should be bad? A prize will be awarded for the worst submission, so get crackin’!\n\n\n\n\n\n\nTip\n\n\n\nThe tidyverse documentation on themes may give you ideas about how you can alter the various features of the plot. Furthermore, the solutions for AEs 5 and 7 demo some of the advanced layers you can add to tweak colors and positioning and so on.\n\n\n\nRender, commit, and push your work so far. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-3---medical-marijuana-in-nc",
    "href": "lab/lab-4.html#part-3---medical-marijuana-in-nc",
    "title": "Lab 4",
    "section": "Part 3 - Medical marijuana in NC",
    "text": "Part 3 - Medical marijuana in NC\nSurveyUSA polled 900 NC adults between September 4-7, 2024. Of the 900 NC adults, 771 were identified by SurveyUSA as being registered to vote.1 The following question was asked to these 771 adults:\n\nShould the use of marijuana for medical use remain against the law in North Carolina? Or be legalized?\n\nResponses were broken down into the following categories:\n\n\nVariable\nLevels\n\n\n\nAge\n18-49; 50+\n\n\nOpinion\nRemain Against The Law; Be Made Legal; Not Sure\n\n\n\nOf the 771 responses, 391 were between the ages of 18-49. Of the individuals that are between 18-49, 59 individuals responded that they think medical marijuana should remain against the law, 292 said it should be made legal, and the remainder were not sure. Of the individuals that are 50+, 67 individuals responded that they think medical marijuana should remain against the law, 245 said it should be made legal, and the remainder were not sure.\nQuestion 6\n\nFill in the code below to create a two-way table that summarizes these data.\n\n\nsurvey_counts &lt;- tibble( \n  age = c(),\n  opinion = c(),\n  n = c()\n  )\n\nsurvey_counts |&gt;\n  pivot_wider( \n    names_from = ___,\n    values_from = ___\n  )\n\nFor parts b-d below, use a single pipeline starting with survey_counts, calculate the desired proportions, and make sure the result is an ungrouped data frame with a column for relevant counts, a column for relevant proportions, and a column for the groups you’re interested in.\n\nCalculate the proportions of 18-49 year olds and 50+ year-olds in this sample.\nCalculate the proportions of those who think medical marijuana should remain against the law, should be made legal, and who are not sure.\n\nCalculate the proportions of individuals in this sample who think medical marijuana should remain against the law, should be made legal, and who are not sure\n\namong those who are 18-49 years old and\namong those who are 50+ years old.\n\n\nQuestion 7\n\n\nCreate a visualization that can be used to evaluate the relationship between age and opinion on legalizing medical marijuana in North Carolina based on this survey’s results.\n\n\n\n\n\n\nTip\n\n\n\nYour visualization should display the proportions you calculated in Question 6d.\n\n\n\nBased on your calculations so far, as well as your visualization, write 1-2 sentences that describe the relationship, in this sample, between age and opinion on legalizing medical marijuana in North Carolina.\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-4---team-usa-at-the-olympics",
    "href": "lab/lab-4.html#part-4---team-usa-at-the-olympics",
    "title": "Lab 4",
    "section": "Part 4 - Team USA at the Olympics",
    "text": "Part 4 - Team USA at the Olympics\nFor this part, you’ll work with data from the rosters of Team USA from the 2020 and 2024 Olympics. The data come from https://www.teamusa.com and the rosters for the two games are in a single Excel file (team-usa.xlsx in your data folder), accross two separate spreadsheets within that file. Figure 1 shows screenshots of these spreadsheets.\n\n\n\n\n\n\nTeam USA 2020\n\n\n\n\n\nTeam USA 2024\n\n\n\n\n\nFigure 1: Excel file with two sheets for rosters of Team USA 2020 and 2024.\n\n\nYour goal is to answer questions about athletes who competed in both games and only one of the games.\nQuestion 8\n\nRead data from the two sheets of team-usa.xlsx as two separate data frames called team_usa_2020 and team_usa_2024.\n\n\n\n\n\n\n\nTip\n\n\n\nThe names of the sheets are shown in the screenshots in Figure 1, or you can use the excel_sheets() function to discover them. Additionally, note that the first row of the sheets contain a logo and a title describing the contents of the data, and not the header row containing variable names.\n\n\n\nRead the documentation for the clean_names() function from the janitor package at https://sfirke.github.io/janitor/reference/clean_names.html. Use this function to “clean” the variable names of team_usa_2020 and team_usa_2024 and save the data frames with the new variable names.\n\nCreate a new variable in both of the datasets called name that:\n\n\npaste()s together the first_name and last_name variables with a space in between and\nis the first variable in the resulting data frame.\n\n\nUsing the appropriate *_join() function, determine how many athletes participated in both Olympic Games?\n\n\n\n\n\n\n\nImportant\n\n\n\nYour answer to this question, based on the data frames you created, should be 0, even if it doesn’t make sense in context of actual Olympic athletes.\n\n\nQuestion 9\nIf you have even a passing knowledge of the Olympic Games, you might know that there are some athletes that participated in both the 2020 and 2024 games, e.g., Simone Biles, Katie Ledecky, etc.\n\nThe reason why athlete names didn’t match across the two data frames is that in one data frame, names are in UPPER CASE, and in the other, they’re in Title Case. Update the 2020 data frame to make name all upper case. Display the first 10 rows of team_usa_2020 with upper case names.\n\n\n\n\n\n\n\nImportant\n\n\n\nYour answer must use the str_to_upper() function.\n\n\n\nLet’s try that question again: How many athletes participated in both Olympic Games?\nHow many athletes participated in the 2020 Olympic Games but not the 2024 Olympic Games? How many athletes participated in the 2024 Olympic Games but not the 2020 Olympic Games?",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-5---back-to-basics-with-datasaurus",
    "href": "lab/lab-4.html#part-5---back-to-basics-with-datasaurus",
    "title": "Lab 4",
    "section": "Part 5 - back to basics with datasauRus",
    "text": "Part 5 - back to basics with datasauRus\nThe data frame you will be working with in this part is called datasaurus_dozen and it’s in the datasauRus package. This single data frame contains 13 datasets, designed to show us why data visualization is important and how summary statistics alone can be misleading. The different datasets are marked by the dataset variable, as shown in Figure 2.\n\n\n\n\n\nFigure 2: The `datasaurus_dozen` data frame stacks 13 datasets on top of each other. This figure shows the first three datasets.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf it’s confusing that the data frame is called datasaurus_dozen when it contains 13 datasets, you’re not alone! Have you heard of a baker’s dozen?\n\n\nHere is a peek at the top 10 rows of the dataset:\n\ndatasaurus_dozen\n\n# A tibble: 1,846 × 3\n   dataset     x     y\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 dino     55.4  97.2\n 2 dino     51.5  96.0\n 3 dino     46.2  94.5\n 4 dino     42.8  91.4\n 5 dino     40.8  88.3\n 6 dino     38.7  84.9\n 7 dino     35.6  79.9\n 8 dino     33.1  77.6\n 9 dino     29.0  74.5\n10 dino     26.2  71.4\n# ℹ 1,836 more rows\n\n\nQuestion 10\n\nIn a single pipeline, calculate the mean of x, mean of y, standard deviation of x, standard deviation of y, and the correlation between x and y for each level of the dataset variable. Then, in 1-2 sentences, comment on how these summary statistics compare across groups (datasets).\n\n\n\n\n\n\n\nTip\n\n\n\nThere are 13 groups but tibbles only print out 10 rows by default. To display all rows, add print(n = 13) as the last step of your pipeline.\n\n\n\nCreate a scatterplot of y versus x and color and facet it by dataset. Then, in 1-2 sentences, how these plots compare across groups (datasets). How does your response in this question compare to your response to the previous question and what does this say about using visualizations and summary statistics when getting to know a dataset?\n\n\n\n\n\n\n\nTip\n\n\n\nWhen you both color and facet by the same variable, you’ll end up with a redundant legend. Turn off the legend by adding show.legend = FALSE to the geom creating the legend.\n\n\n\nRender, commit, and push your changes. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-6---all-about-quarto",
    "href": "lab/lab-4.html#part-6---all-about-quarto",
    "title": "Lab 4",
    "section": "Part 6 - All about Quarto",
    "text": "Part 6 - All about Quarto\nQuestion 11\nYou have the following code chunk:\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nAdd the following code cell options, one at a time, and set each to false and then to true. After each value, render your document and observe its effect. Ultimately, choose the values that are the most appropriate for this code cell. Based on the behaviors you observe, describe what each code cell option does.\n\necho\nwarning\neval\nQuestion 12\n\nYou have the following code cell again.\n\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nAdd fig-width and fig-asp as code chunk options. Try setting fig-width to values between 1 and 10. Try setting fig-asp to values between 0.1 and 1. Re-render the document after each value and observe its effect. Ultimately, choose values that make the plot look visually pleasing in the rendered document. Based on the behavior you observe, describe what each chunk option does.\n\n\n\n\n\n\nTip\n\n\n\nNow that you’ve had more practice with figure sizing in Quarto documents, review all of the plots you made in this lab and adjust their widths and aspect rations to improve how they look in your rendered document.\n\n\nb. You have the following code cell, but look carefully, it’s not exactly the same!\n\ngplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nAdd error as a code chunk option and set it to false and then set it to true. After each value, render your document and observe its effect. Ultimately, choose the value that allows you to render your document without altering the code. Based on the behavior you observe, describe what this code chunk option does.\n\n\n\n\n\n\nTip\n\n\n\nReading the documentation might also be helpful.\n\n\n\nRender, commit, and push your work. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding.\n\n\n\n\nTeam USA 2020\nTeam USA 2024\nFigure 2: The `datasaurus_dozen` data frame stacks 13 datasets on top of each other. This figure shows the first three datasets.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#footnotes",
    "href": "lab/lab-4.html#footnotes",
    "title": "Lab 4",
    "section": "Footnotes",
    "text": "Footnotes\n\nFull survey results can be found at https://www.surveyusa.com/client/PollReport.aspx?g=c6995e17-3837-413e-ac98-3684e1c74dc1.↩︎",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-7.html",
    "href": "lab/lab-7.html",
    "title": "Lab 7",
    "section": "",
    "text": "All things logistic regression! This is a new statistical model we introduced for modeling a response variable that is binary (categorical with two levels) rather than numerical. If we can do that, then we can use the model for a special kind of prediction called classification.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nfit, interpret, predict with, and compare logistic regression models;\nwork with the ROC curve and the area under the ROC curve;\ncomplete a data science assessment.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-7 repo from GitHub, open your lab-7.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-7. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-7.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-7.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way;\n\ntidymodels package for modeling in a “tidy” way.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-7.html#learning-objectives",
    "href": "lab/lab-7.html#learning-objectives",
    "title": "Lab 7",
    "section": "",
    "text": "By the end of the lab, you will…\n\nfit, interpret, predict with, and compare logistic regression models;\nwork with the ROC curve and the area under the ROC curve;\ncomplete a data science assessment.\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub"
  },
  {
    "objectID": "lab/lab-7.html#getting-started",
    "href": "lab/lab-7.html#getting-started",
    "title": "Lab 7",
    "section": "",
    "text": "Log in to RStudio, clone your lab-7 repo from GitHub, open your lab-7.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-7. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-7.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-7.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding."
  },
  {
    "objectID": "lab/lab-7.html#packages",
    "href": "lab/lab-7.html#packages",
    "title": "Lab 7",
    "section": "",
    "text": "In this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way;\n\ntidymodels package for modeling in a “tidy” way.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document."
  },
  {
    "objectID": "lab/lab-7.html#guidelines",
    "href": "lab/lab-7.html#guidelines",
    "title": "Lab 7",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou are also expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc."
  },
  {
    "objectID": "lab/lab-7.html#question-1---data-preparation",
    "href": "lab/lab-7.html#question-1---data-preparation",
    "title": "Lab 7",
    "section": "Question 1 - data preparation",
    "text": "Question 1 - data preparation\n\nRead the data in with read_csv().\nTransform the is_canceled variable to be a factor with “not canceled” (0) as the first level and “canceled” (1) as the second level. Confirm that you were able to successfully transform the variable by running levels(hotels$is_canceled).\nSplit the data into training (75%) and testing (25%) sets. Report the number of rows in the testing and training sets. NOTE: use set.seed(555)."
  },
  {
    "objectID": "lab/lab-7.html#question-2---exploratory-analysis",
    "href": "lab/lab-7.html#question-2---exploratory-analysis",
    "title": "Lab 7",
    "section": "Question 2 - exploratory analysis",
    "text": "Question 2 - exploratory analysis\n\nIn a single pipeline, calculate the mean arrival dates (arrival_date_day_of_month) for reservations that were cancelled and reservations that were not cancelled in the training data.\nExplore attributes of bookings in the training data and summarize your findings in 5 bullet points. You must provide a visualization or summary supporting each finding. Note: This is not meant to be an exhaustive exploration. We anticipate a wide variety of answers to this question."
  },
  {
    "objectID": "lab/lab-7.html#question-3---fit-a-simple-model",
    "href": "lab/lab-7.html#question-3---fit-a-simple-model",
    "title": "Lab 7",
    "section": "Question 3 - fit a simple model",
    "text": "Question 3 - fit a simple model\n\nFit the appropriate model to predict whether a reservation was cancelled from arrival_date_day_of_month and display a tidy summary of the model output. Make sure you use only the training data.\nTypeset the fitted regression equation.\nInterpret the slope coefficient in the context of the data and the research question.\nCalculate the probability that a hotel reservation is cancelled if the arrival date is on the 26th of the month. Based on this probability, would you predict this booking would be cancelled or not cancelled. Explain your reasoning for your classification.\nUse the augment function to generate predictions for every observation in the test dataset, and make sure you store the results in a variable with an informative name.\nCompute the error rates (TPR, TNR, FPR, FNR) of the classifications you just produced.\nPlot the ROC curve for this model and the test data.\n\n\n\n\n\n\n\nTip\n\n\n\nSince the level of is_canceled we’re predicting is the second level, we need to set event_level = \"second\" when calculating the ROC curve."
  },
  {
    "objectID": "lab/lab-7.html#question-4---fit-an-alternative-model",
    "href": "lab/lab-7.html#question-4---fit-an-alternative-model",
    "title": "Lab 7",
    "section": "Question 4 - fit an alternative model",
    "text": "Question 4 - fit an alternative model\n\nFit the appropriate model to predict whether a reservation was cancelled from hotel, arrival_date_month, and lead_time, and display a tidy summary of the model output. Make sure you use only the training data.\nInterpret the intercept coefficient in the context of the data and the research question.\nUse the augment function to generate predictions for every observation in the test dataset, and make sure you store the results in a variable with an informative name.\nPlot the ROC curve for this model and the test data."
  },
  {
    "objectID": "lab/lab-7.html#question-5---selecting-a-model",
    "href": "lab/lab-7.html#question-5---selecting-a-model",
    "title": "Lab 7",
    "section": "Question 5 - selecting a model",
    "text": "Question 5 - selecting a model\n\nPlot the ROC curves of the models from Question 4 and Question 5 on the same plot, using different colors for each model and a legend that describes which model is represented with which color.\nCalculate the AUC (area under the curve) for each model using the roc_auc() function.\nBased on the results of parts a and b, which model do you prefer? Explain your reasoning."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 199 Introduction to Data Science and Statistical Thinking",
    "section": "",
    "text": "Below is a prospective outline for the course. Due dates are firm, but topics may change with advanced notice.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWEEK\nDATE\nPREPARE\nTOPIC\nMATERIALS\nDUE\n\n\n\n0\nWed, Jan 8\n\nLab 0: Hello, World!\nlab 0\nLab 0 @ End of Lab\n\n\n\nThu, Jan 9\n\nWelcome!\nslides 00\n\n\n\n1\nMon, Jan 13\n\nLab 1\nlab 1\n\n\n\n\nTue, Jan 14\n📗 r4ds - intro  📘 ims - chp 1  🎥 Meet the toolkit :: R and RStudio  🎥 Meet the toolkit :: Quarto  🎥 Code along :: First data viz with UN Votes\n\nMeet the Toolkit\nslides 01\n\n\n\n\nThu, Jan 16\n📗 r4ds - chp 1  📘 ims - chp 4  🎥 Visualizing data  🎥 Building a plot step-by-step with ggplot2  🎥 Grammar of graphics  🎥 Code along :: First look at Palmer Penguins\n\nData Vizualization\nslides 02\n\n\n\n2\nMon, Jan 20\n\nMLK Day - No Lab\n\n\n\n\n\nTue, Jan 21\n📗 r4ds - chp 2  📗 r4ds - chp 3.1-3.5  🎥 Grammar of data transformation  🎥 Code along :: Flights and pipes\n\nData Transformation\n\nslides 03 ae 02\n\n\n\n\n\nWed, Jan 22\n\n\n\nLab 1 @ 11:59 PM\n\n\n\nThu, Jan 23\n📗 r4ds - chp 3.6-3.7  🎥 Visualizing and summarizing categorical data  🎥 Visualizing and summarizing numerical data  🎥 Visualizing and summarizing relationships  🎥 Code along :: Star Wars characters\n\nData Exploration 1\n\nslides 04 ae 03\n\n\n\n\n3\nMon, Jan 27\n📗 r4ds - chp 4\n\nLab 2\nlab 2\n\n\n\n\nTue, Jan 28\n📘 ims - chp 5  📘 ims - chp 6  🎥 Code along :: Diving deeper with Palmer Penguins\n\nData Exploration 2\n\nslides 05 ae 04\n\n\n\n\n\nThu, Jan 30\n🎥 Tidy data  🎥 Tidying data  🎥 Code along :: Country populations over time  📗 r4ds - chp 5\n\nTidying data\n\nslides 06 ae 05\n\n\n\n\n4\nMon, Feb 3\n\nLab 3\nlab 3\nLab 2 @ 8:30AM\n\n\n\nTue, Feb 4\n🎥 Joining data  🎥 Code along :: Continent populations  📗 r4ds - chp 19.1-19.3\n\nJoining data\n\nslides 07 ae 06\n\n\n\n\n\nThu, Feb 6\n🎥 Data types  🎥 Data classes  🎥 Code along :: That’s my type  📗 r4ds - chp 16\n\nData types and classes\n\nslides 08 ae 07\n\n\n\n\n5\nMon, Feb 10\n\nLab 4\n\nlab 4 slides\n\nLab 3 @ 8:30AM\n\n\n\nTue, Feb 11\n🎥 Importing data  🎥 Code along :: Halving CO2 emissions  🎥 Code along :: Student survey  📗 r4ds - chp 7  📗 r4ds - chp 17.1 - 17.3\n\nImporting and recoding data\nslides 09\n\n\n\n\nThu, Feb 13\n\nMore practice\n\nslides 10 ae 08\n\n\n\n\n6\nMon, Feb 17\n\nExam Review\n\nLab 4 @ 8:30AM\n\n\n\nTue, Feb 18\n📕 mdsr - chp 8  📝 How to make a racist AI in R without really trying  🎥 Alberto Cairo - How charts lie  🎥 Joy Buolamwini - How I’m fighting bias in algorithms\n\nData science ethics\nslides 11\n\n\n\n\nThu, Feb 20\n\nSnow Day - No Class\n\n\n\n\n7\nMon, Feb 24\n\nMilestone 1\n\nproject milestone 1 slides\n\nTakehome 1 @ 8:30AM\n\n\n\nTue, Feb 25\n\nBatch A of practice problems Batch B of practice problems Kahoot\n\nMidterm 1\n\n\n\n\n\nThu, Feb 27\n🎥 The language of models  📘 ims - chp 7.1\n\nThe language of models\n\nslides 12ae 9\n\n\n\n\n\nFri, Feb 28\n\n\n\nPeer evaluation 1 due by 5:00 pm\n\n\n8\nMon, Mar 3\n\nMilestone 2\nproject milestone 2\n\n\n\n\nTue, Mar 4\n🎥 Fitting and interpreting models  🎥 Modeling nonlinear relationships  📘 ims - chp 7.2\n\nSimple linear regression\n\nslides 13 ae 10\n\n\n\n\n\nThu, Mar 6\n🎥 Models with multiple predictors  🎥 More models with multiple predictors  📘 ims - chp 8.1-8.2\n\nMultiple linear regression 1\n\nslides 14 ae 11\n\n\n\n\n\nFri, Mar 7\n\n\n\nMilestone 2 @ 5PM\n\n\n9\nMon, Mar 10\n\nSpring Break - No Lab\n\n\n\n\n\nTue, Mar 11\n\nSpring Break - No Lecture\n\n\n\n\n\nThu, Mar 13\n\nSpring Break - No Lecture\n\n\n\n\n10\nMon, Mar 17\n\nLab 5\n\nlab 5 slides\n\n\n\n\n\nTue, Mar 18\n📘 ims - chp 8.3-8.5\n\nMultiple linear regression 2\nslides 15\n\n\n\n\nThu, Mar 20\n🎥 Logistic regression\n\nModel selection\n\nslides 16 ae 12\n\n\n\n\n\nFri, Mar 21\n\n\n\nPeer evaluation 2 due by 5:00 pm\n\n\n11\nMon, Mar 24\n\nLab 6\nlab 6\nLab 5 @ 8:30AM\n\n\n\nTue, Mar 25\n📘 ims - chp 9\n\nLogistic regression 1\n\nslides 17 ae 13\n\n\n\n\n\nThu, Mar 27\n🎥 Prediction and overfitting\n\nLogistic regression 2\n\nslides 18 ae 14\n\n\n\n\n12\nMon, Mar 31\n\nLab 7\n\nlab 7 slides\n\nLab 6 @ 8:30AM\n\n\n\nTue, Apr 1\n🎥 Quantifying uncertainty  🎥 Bootstrapping  📘 ims - chp 12\n\nIntervals\n\nslides 19 ae 15\n\n\n\n\n\nThu, Apr 3\n📘 ims - chp 11\n\nHypothesis testing\n\nslides 20  ae 16\n\n\n\n\nFri, Apr 4\n\n\n\nMilestone 3 @ 5PM\n\n\n13\nMon, Apr 7\n\nExam Review\n\nLab 7 @ 8:30AM\n\n\n\nTue, Apr 8\n\nMore inference\n\n\n\n\n\nThu, Apr 10\npractice problems\nMidterm 2\n\n\n\n\n\nFri, Apr 11\n\n\n\nPeer evaluation 3 due by 5:00 pm\n\n\n14\nMon, Apr 14\n\nMilestone 4\n\nTakehome 2 @ 8:30AM  Milestone 4 @ End of Lab\n\n\n\nTue, Apr 15\n\nMore inference\n\n\n\n\n\nThu, Apr 17\n\nCommunication, Quarto\n\n\n\n\n15\nMon, Apr 21\n\nMilestone 5\n\n\n\n\n\nTue, Apr 22\n\nFarewell!\n\n\n\n\n\nWed, Apr 23\n\n\n\nMilestone 5 @ 5PM\n\n\n16\nMon, Apr 28\n\nfinals week - no lab\n\nPeer evaluation 4 due by 5:00 pm\n\n\n\nTue, Apr 29\nsee…everything above\nFinal (9AM - 12PM)",
    "crumbs": [
      "Syllabus",
      "Schedule"
    ]
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#while-you-wait",
    "href": "slides/15-linear-model-multiple-predictors-II.html#while-you-wait",
    "title": "Linear regression with a multiple predictors II",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-12-modeling-loans.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#mid-semester-evaluation",
    "href": "slides/15-linear-model-multiple-predictors-II.html#mid-semester-evaluation",
    "title": "Linear regression with a multiple predictors II",
    "section": "Mid-semester evaluation",
    "text": "Mid-semester evaluation\nPlease complete this ungraded, anonymous Canvas quiz before Wednesday night:\nhttps://canvas.duke.edu/courses/50057/quizzes/30407"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#ssmu-bookbagging-gbm-saturday-march-22",
    "href": "slides/15-linear-model-multiple-predictors-II.html#ssmu-bookbagging-gbm-saturday-march-22",
    "title": "Linear regression with a multiple predictors II",
    "section": "SSMU Bookbagging GBM Saturday March 22!",
    "text": "SSMU Bookbagging GBM Saturday March 22!\n\n\n\n\n\n\n\nGrab free food and chat with upperclass students about…\n\ncourse registration\nthe stats major\nDataFest\nvolunteering"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#project-clarifications",
    "href": "slides/15-linear-model-multiple-predictors-II.html#project-clarifications",
    "title": "Linear regression with a multiple predictors II",
    "section": "Project clarifications",
    "text": "Project clarifications\n\nNext Monday: your TA returns proposal feedback to you;\nUntil then: project repos are locked (can’t push or pull);\nIf you missed milestone 1, we’ll replace that score with your final peer eval score (so pull your weight!);\nWe will drop one of the first three peer evals;\nIf your group does not have plans to meet every week…make them!"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#question-how-do-we-concisely-summarize-the-association-between-two-variables",
    "href": "slides/15-linear-model-multiple-predictors-II.html#question-how-do-we-concisely-summarize-the-association-between-two-variables",
    "title": "Linear regression with a multiple predictors II",
    "section": "Question: how do we concisely summarize the association between two variables?",
    "text": "Question: how do we concisely summarize the association between two variables?"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#answer-simple-linear-regression",
    "href": "slides/15-linear-model-multiple-predictors-II.html#answer-simple-linear-regression",
    "title": "Linear regression with a multiple predictors II",
    "section": "Answer: simple linear regression!",
    "text": "Answer: simple linear regression!"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#answer-simple-linear-regression-1",
    "href": "slides/15-linear-model-multiple-predictors-II.html#answer-simple-linear-regression-1",
    "title": "Linear regression with a multiple predictors II",
    "section": "Answer: simple linear regression!",
    "text": "Answer: simple linear regression!\n\nmpg_wt_fit &lt;- linear_reg() |&gt;\n  fit(mpg ~ wt, data = mtcars)\n\ntidy(mpg_wt_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    37.3      1.88      19.9  8.24e-19\n2 wt             -5.34     0.559     -9.56 1.29e-10\n\n\n\\[\n\\widehat{mpg}=37.3 - 5.34\\times weight.\n\\]\nInterpretations\n\nWe predict that a car weighing zero pounds will have 37.28 MPG on average (makes no sense);\nWe predict that a 1000 pound increase in weight in associated with a 5.34 decrease in MGP, on average."
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#why-do-we-care-prediction",
    "href": "slides/15-linear-model-multiple-predictors-II.html#why-do-we-care-prediction",
    "title": "Linear regression with a multiple predictors II",
    "section": "Why do we care? Prediction!",
    "text": "Why do we care? Prediction!"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#why-do-we-care-prediction-1",
    "href": "slides/15-linear-model-multiple-predictors-II.html#why-do-we-care-prediction-1",
    "title": "Linear regression with a multiple predictors II",
    "section": "Why do we care? Prediction!",
    "text": "Why do we care? Prediction!\nYou can use the fitted model to generate predictions for yet-to-be-observed subjects:\n\nnew_car &lt;- tibble(\n  wt = 4.5\n)\n\npredict(mpg_wt_fit, new_data = new_car)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1  13.2"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#simple-linear-regression-for-those-darn-penguins",
    "href": "slides/15-linear-model-multiple-predictors-II.html#simple-linear-regression-for-those-darn-penguins",
    "title": "Linear regression with a multiple predictors II",
    "section": "Simple linear regression for those darn penguins",
    "text": "Simple linear regression for those darn penguins"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#how-do-we-predict-using-more-than-one-predictor",
    "href": "slides/15-linear-model-multiple-predictors-II.html#how-do-we-predict-using-more-than-one-predictor",
    "title": "Linear regression with a multiple predictors II",
    "section": "How do we predict using more than one predictor?",
    "text": "How do we predict using more than one predictor?\nBoth of these models use flipper_length_mm and island to predict body_mass_g:"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#the-additive-model-parallel-lines-one-for-each-island",
    "href": "slides/15-linear-model-multiple-predictors-II.html#the-additive-model-parallel-lines-one-for-each-island",
    "title": "Linear regression with a multiple predictors II",
    "section": "The additive model: parallel lines, one for each island",
    "text": "The additive model: parallel lines, one for each island\n\nbm_fl_island_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ flipper_length_mm + island, data = penguins)\n\ntidy(bm_fl_island_fit)\n\n# A tibble: 4 × 5\n  term              estimate std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)        -4625.     392.      -11.8  4.29e-27\n2 flipper_length_mm     44.5      1.87     23.9  1.65e-74\n3 islandDream         -262.      55.0      -4.77 2.75e- 6\n4 islandTorgersen     -185.      70.3      -2.63 8.84e- 3\n\n\n\\[\n\\begin{aligned}\n\\widehat{body~mass} = -4625 &+ 44.5 \\times flipper~length \\\\\n&- 262 \\times Dream \\\\\n&- 185 \\times Torgersen\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#where-do-the-three-lines-come-from",
    "href": "slides/15-linear-model-multiple-predictors-II.html#where-do-the-three-lines-come-from",
    "title": "Linear regression with a multiple predictors II",
    "section": "Where do the three lines come from?",
    "text": "Where do the three lines come from?\n\\[\n\\begin{aligned}\n\\widehat{body~mass} = -4625 &+ 44.5 \\times flipper~length \\\\\n&- 262 \\times Dream \\\\\n&- 185 \\times Torgersen\n\\end{aligned}\n\\]\n\nIf penguin is from Biscoe, Dream = 0 and Torgersen = 0:\n\n\n\\[\n\\begin{aligned}\n\\widehat{body~mass} = -4625 &+ 44.5 \\times flipper~length\n\\end{aligned}\n\\]\n\n\nIf penguin is from Dream, Dream = 1 and Torgersen = 0:\n\n\n\\[\n\\begin{aligned}\n\\widehat{body~mass} = -4887 &+ 44.5 \\times flipper~length\n\\end{aligned}\n\\]\n\n\nIf penguin is from Torgersen, Dream = 0 and Torgersen = 1:\n\n\n\\[\n\\begin{aligned}\n\\widehat{body~mass} = -4810 &+ 44.5 \\times flipper~length\n\\end{aligned}\n\\]\n\n\nEither way, same slope, so the lines are parallel."
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#the-interaction-model-different-lines-for-each-island",
    "href": "slides/15-linear-model-multiple-predictors-II.html#the-interaction-model-different-lines-for-each-island",
    "title": "Linear regression with a multiple predictors II",
    "section": "The interaction model: different lines for each island",
    "text": "The interaction model: different lines for each island\n\nbm_fl_island_int_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ flipper_length_mm * island, data = penguins)\n\ntidy(bm_fl_island_int_fit) |&gt; select(term, estimate)\n\n# A tibble: 6 × 2\n  term                              estimate\n  &lt;chr&gt;                                &lt;dbl&gt;\n1 (Intercept)                        -5464. \n2 flipper_length_mm                     48.5\n3 islandDream                         3551. \n4 islandTorgersen                     3218. \n5 flipper_length_mm:islandDream        -19.4\n6 flipper_length_mm:islandTorgersen    -17.4\n\n\n\n\\[\n\\begin{aligned}\n\\widehat{body~mass} = -5464 &+ 48.5 \\times flipper~length \\\\\n&+ 3551 \\times Dream \\\\\n&+ 3218 \\times Torgersen \\\\\n&- 19.4 \\times flipper~length*Dream \\\\\n&- 17.4 \\times flipper~length*Torgersen\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#where-do-the-three-lines-come-from-1",
    "href": "slides/15-linear-model-multiple-predictors-II.html#where-do-the-three-lines-come-from-1",
    "title": "Linear regression with a multiple predictors II",
    "section": "Where do the three lines come from?",
    "text": "Where do the three lines come from?\n\\[\n\\begin{aligned}\n\\small\\widehat{body~mass} = -5464 &+ 48.5 \\times flipper~length \\\\\n&+ 3551 \\times Dream \\\\\n&+ 3218 \\times Torgersen \\\\\n&- 19.4 \\times flipper~length*Dream \\\\\n&- 17.4 \\times flipper~length*Torgersen\n\\end{aligned}\n\\]\n\nIf penguin is from Biscoe, Dream = 0 and Torgersen = 0:\n\n\n\\[\n\\begin{aligned}\n\\widehat{body~mass} = -5464 &+ 48.5 \\times flipper~length\n\\end{aligned}\n\\]\n\n\nIf penguin is from Dream, Dream = 1 and Torgersen = 0:\n\n\n\\[\n\\begin{aligned}\n\\widehat{body~mass} &= (-5464 + 3551) + (48.5-19.4) \\times flipper~length\\\\\n&=-1913+29.1\\times flipper~length.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#prediction",
    "href": "slides/15-linear-model-multiple-predictors-II.html#prediction",
    "title": "Linear regression with a multiple predictors II",
    "section": "Prediction",
    "text": "Prediction\n\nnew_penguin &lt;- tibble(\n  flipper_length_mm = 200,\n  island = \"Torgersen\"\n)\n\npredict(bm_fl_island_int_fit, new_data = new_penguin)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 3980.\n\n\n\\[\n\\widehat{body~mass} = (-5464 + 3218) + (48.5-17.4) \\times 200.\n\\]"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#multiple-numerical-predictors",
    "href": "slides/15-linear-model-multiple-predictors-II.html#multiple-numerical-predictors",
    "title": "Linear regression with a multiple predictors II",
    "section": "Multiple numerical predictors",
    "text": "Multiple numerical predictors\n\nbm_fl_bl_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ flipper_length_mm + bill_length_mm, data = penguins)\n\ntidy(bm_fl_bl_fit)\n\n# A tibble: 3 × 5\n  term              estimate std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)       -5737.      308.      -18.6  7.80e-54\n2 flipper_length_mm    48.1       2.01     23.9  7.56e-75\n3 bill_length_mm        6.05      5.18      1.17 2.44e- 1\n\n\n\n\\[\n\\small\\widehat{body~mass}=-5736+48.1\\times flipper~length+6\\times bill~length\n\\]\n\n\nInterpretations:\n\n\nWe predict that the body mass of a penguin with zero flipper length and zero bill length will be -5736 grams, on average (makes no sense);\nHolding all other variables constant, for every additional millimeter in flipper length, we expect the body mass of penguins to be higher, on average, by 48.1 grams.\nHolding all other variables constant, for every additional millimeter in bill length, we expect the body mass of penguins to be higher, on average, by 6 grams."
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#prediction-1",
    "href": "slides/15-linear-model-multiple-predictors-II.html#prediction-1",
    "title": "Linear regression with a multiple predictors II",
    "section": "Prediction",
    "text": "Prediction\n\nnew_penguin &lt;- tibble(\n  flipper_length_mm = 200,\n  bill_length_mm = 45\n)\n\npredict(bm_fl_bl_fit, new_data = new_penguin)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1 4164.\n\n\n\\[\n\\widehat{body~mass}=-5736+48.1\\times 200+6\\times 45\n\\]"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#picture-its-not-pretty",
    "href": "slides/15-linear-model-multiple-predictors-II.html#picture-its-not-pretty",
    "title": "Linear regression with a multiple predictors II",
    "section": "Picture? It’s not pretty…",
    "text": "Picture? It’s not pretty…\n2 predictors + 1 response = 3 dimensions. Ick!"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#picture-its-not-pretty-1",
    "href": "slides/15-linear-model-multiple-predictors-II.html#picture-its-not-pretty-1",
    "title": "Linear regression with a multiple predictors II",
    "section": "Picture? It’s not pretty…",
    "text": "Picture? It’s not pretty…\nInstead of a line of best fit, it’s a plane of best fit. Double ick!"
  },
  {
    "objectID": "slides/15-linear-model-multiple-predictors-II.html#ae-12-modeling-loans",
    "href": "slides/15-linear-model-multiple-predictors-II.html#ae-12-modeling-loans",
    "title": "Linear regression with a multiple predictors II",
    "section": "ae-12-modeling-loans",
    "text": "ae-12-modeling-loans\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-12-modeling-loans.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/08-data-types-classes.html#while-you-wait",
    "href": "slides/08-data-types-classes.html#while-you-wait",
    "title": "Data types and classes",
    "section": "While you wait…",
    "text": "While you wait…\n\n\n\n\n&lt;p&gt;Loading…&lt;/p&gt;\n\n\nPrepare for today’s application exercise: ae-07-durham-climate-factors\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-07-durham-climate-factors.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/08-data-types-classes.html#regrade-request-policy",
    "href": "slides/08-data-types-classes.html#regrade-request-policy",
    "title": "Data types and classes",
    "section": "Regrade request policy",
    "text": "Regrade request policy\n\n\nConsidered for errors in grade calculation or if a correct answer was mistakenly marked as incorrect\n\nNot a mechanism for:\n\ndisputing the number of points deducted for an incorrect response\nasking for clarification on feedback (come to office hours instead)\n\n\nDue on Gradescope within a week after an assignment is returned\nThe entire assignment may be regraded, which could result in an adjustment in either direction\nNo regrade requests after the final exam has been administered"
  },
  {
    "objectID": "slides/08-data-types-classes.html#how-many-classes-do-you-have-on-tuesdays",
    "href": "slides/08-data-types-classes.html#how-many-classes-do-you-have-on-tuesdays",
    "title": "Data types and classes",
    "section": "How many classes do you have on Tuesdays?",
    "text": "How many classes do you have on Tuesdays?\n\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         How many classes do you have on Tues…¹ `What year are you?`\n   &lt;chr&gt;             &lt;chr&gt;                                  &lt;chr&gt;               \n 1 2/6/2025 11:33:57 3                                      Sophomore           \n 2 2/6/2025 11:37:39 3                                      First-year          \n 3 2/6/2025 11:40:55 2                                      Senior              \n 4 2/6/2025 11:42:05 3                                      First-year          \n 5 2/6/2025 11:42:46 3                                      Senior              \n 6 2/6/2025 11:43:28 3                                      Senior              \n 7 2/6/2025 11:44:41 3                                      First-year          \n 8 2/6/2025 11:44:49 3                                      First-year          \n 9 2/6/2025 11:44:51 2                                      Sophomore           \n10 2/6/2025 11:44:51 3                                      Sophomore           \n# ℹ 199 more rows\n# ℹ abbreviated name: ¹​`How many classes do you have on Tuesdays?`"
  },
  {
    "objectID": "slides/08-data-types-classes.html#rename-variables",
    "href": "slides/08-data-types-classes.html#rename-variables",
    "title": "Data types and classes",
    "section": "\nrename() variables",
    "text": "rename() variables\nTo make them easier to work with…\n\nsurvey &lt;- survey |&gt;\n  rename(\n    tue_classes = `How many classes do you have on Tuesdays?`,\n    year = `What year are you?`\n  )"
  },
  {
    "objectID": "slides/08-data-types-classes.html#variable-types",
    "href": "slides/08-data-types-classes.html#variable-types",
    "title": "Data types and classes",
    "section": "Variable types",
    "text": "Variable types\n\nWhat type of variable is tue_classes?\n\n\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         tue_classes year      \n   &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     \n 1 2/6/2025 11:33:57 3           Sophomore \n 2 2/6/2025 11:37:39 3           First-year\n 3 2/6/2025 11:40:55 2           Senior    \n 4 2/6/2025 11:42:05 3           First-year\n 5 2/6/2025 11:42:46 3           Senior    \n 6 2/6/2025 11:43:28 3           Senior    \n 7 2/6/2025 11:44:41 3           First-year\n 8 2/6/2025 11:44:49 3           First-year\n 9 2/6/2025 11:44:51 2           Sophomore \n10 2/6/2025 11:44:51 3           Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes.html#variable-types-1",
    "href": "slides/08-data-types-classes.html#variable-types-1",
    "title": "Data types and classes",
    "section": "Variable types",
    "text": "Variable types\n\nWhy isn’t the tue_classes column numeric?\n\n\nsurvey |&gt;\n  count(tue_classes)\n\n# A tibble: 13 × 2\n   tue_classes                  n\n   &lt;chr&gt;                    &lt;int&gt;\n 1 1                           10\n 2 2                           53\n 3 2 -3                         1\n 4 3                          104\n 5 3 classes                    1\n 6 4                           28\n 7 5                            3\n 8 Four                         1\n 9 TWO MANY                     1\n10 Three                        2\n11 Two                          3\n12 Two plus a chemistry lab     1\n13 three                        1"
  },
  {
    "objectID": "slides/08-data-types-classes.html#lets-clean-it-up",
    "href": "slides/08-data-types-classes.html#lets-clean-it-up",
    "title": "Data types and classes",
    "section": "Let’s clean it up",
    "text": "Let’s clean it up\nIt’s a huge pain in the rear:\n\nsurvey &lt;- survey |&gt;\n  mutate(\n    tue_classes = case_when(\n      tue_classes == \"2 -3\" ~ \"3\",\n      tue_classes == \"3 classes\" ~ \"3\",\n      tue_classes == \"Four\" ~ \"4\",\n      tue_classes == \"TWO MANY\" ~ \"2\",\n      tue_classes == \"Three\" ~ \"3\",\n      tue_classes == \"Two\" ~ \"2\",\n      tue_classes == \"Two plus a chemistry lab\" ~ \"3\",\n      tue_classes == \"three\" ~ \"3\",\n      .default = tue_classes\n    ),\n    tue_classes = as.numeric(tue_classes)\n  )\n\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         tue_classes year      \n   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;     \n 1 2/6/2025 11:33:57           3 Sophomore \n 2 2/6/2025 11:37:39           3 First-year\n 3 2/6/2025 11:40:55           2 Senior    \n 4 2/6/2025 11:42:05           3 First-year\n 5 2/6/2025 11:42:46           3 Senior    \n 6 2/6/2025 11:43:28           3 Senior    \n 7 2/6/2025 11:44:41           3 First-year\n 8 2/6/2025 11:44:49           3 First-year\n 9 2/6/2025 11:44:51           2 Sophomore \n10 2/6/2025 11:44:51           3 Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes.html#data-types-in-r",
    "href": "slides/08-data-types-classes.html#data-types-in-r",
    "title": "Data types and classes",
    "section": "Data types in R",
    "text": "Data types in R\n\nlogical\ndouble\ninteger\ncharacter\nand some more, but we won’t be focusing on those"
  },
  {
    "objectID": "slides/08-data-types-classes.html#logical-character",
    "href": "slides/08-data-types-classes.html#logical-character",
    "title": "Data types and classes",
    "section": "Logical & character",
    "text": "Logical & character\n\n\nlogical - Boolean values TRUE and FALSE\n\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\n\n\ncharacter - character strings\n\n\ntypeof(\"First-year\")\n\n[1] \"character\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#double-integer",
    "href": "slides/08-data-types-classes.html#double-integer",
    "title": "Data types and classes",
    "section": "Double & integer",
    "text": "Double & integer\n\n\ndouble - floating point numerical values (default numerical type)\n\n\ntypeof(2.5)\n\n[1] \"double\"\n\ntypeof(3)\n\n[1] \"double\"\n\n\n\n\ninteger - integer numerical values (indicated with an L)\n\n\ntypeof(3L)\n\n[1] \"integer\"\n\ntypeof(1:3)\n\n[1] \"integer\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#concatenation",
    "href": "slides/08-data-types-classes.html#concatenation",
    "title": "Data types and classes",
    "section": "Concatenation",
    "text": "Concatenation\nVectors can be constructed using the c() function.\n\nNumeric vector:\n\n\nc(1, 2, 3)\n\n[1] 1 2 3\n\n\n\n\nCharacter vector:\n\n\nc(\"Hello\", \"World!\")\n\n[1] \"Hello\"  \"World!\"\n\n\n\n\n\nVector made of vectors:\n\n\nc(c(\"hi\", \"hello\"), c(\"bye\", \"jello\"))\n\n[1] \"hi\"    \"hello\" \"bye\"   \"jello\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types",
    "href": "slides/08-data-types-classes.html#converting-between-types",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwith intention…\n\n\n\n\nx &lt;- 1:3\nx\n\n[1] 1 2 3\n\ntypeof(x)\n\n[1] \"integer\"\n\n\n\n\n\ny &lt;- as.character(x)\ny\n\n[1] \"1\" \"2\" \"3\"\n\ntypeof(y)\n\n[1] \"character\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types-1",
    "href": "slides/08-data-types-classes.html#converting-between-types-1",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwith intention…\n\n\n\n\nx &lt;- c(TRUE, FALSE)\nx\n\n[1]  TRUE FALSE\n\ntypeof(x)\n\n[1] \"logical\"\n\n\n\n\n\ny &lt;- as.numeric(x)\ny\n\n[1] 1 0\n\ntypeof(y)\n\n[1] \"double\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types-2",
    "href": "slides/08-data-types-classes.html#converting-between-types-2",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwithout intention…\n\n\nc(2, \"Just this one!\")\n\n[1] \"2\"              \"Just this one!\"\n\n\n\nR will happily convert between various types without complaint when different types of data are concatenated in a vector, and that’s not always a great thing!"
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types-3",
    "href": "slides/08-data-types-classes.html#converting-between-types-3",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwithout intention…\n\n\nc(FALSE, 3L)\n\n[1] 0 3\n\n\n\n\nc(1.2, 3L)\n\n[1] 1.2 3.0\n\n\n\n\n\nc(2L, \"two\")\n\n[1] \"2\"   \"two\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#explicit-vs.-implicit-coercion",
    "href": "slides/08-data-types-classes.html#explicit-vs.-implicit-coercion",
    "title": "Data types and classes",
    "section": "Explicit vs. implicit coercion",
    "text": "Explicit vs. implicit coercion\n\n\nExplicit coercion:\nWhen you call a function like as.logical(), as.numeric(), as.integer(), as.double(), or as.character().\n\n\nImplicit coercion:\nHappens when you use a vector in a specific context that expects a certain type of vector."
  },
  {
    "objectID": "slides/08-data-types-classes.html#data-classes-1",
    "href": "slides/08-data-types-classes.html#data-classes-1",
    "title": "Data types and classes",
    "section": "Data classes",
    "text": "Data classes\n\n\nVectors are like Lego building blocks\nWe stick them together to build more complicated constructs, e.g. representations of data\n\nThe class attribute relates to the S3 class of an object which determines its behaviour\n\nYou don’t need to worry about what S3 classes really mean, but you can read more about it here if you’re curious\n\n\nExamples: factors, dates, and data frames"
  },
  {
    "objectID": "slides/08-data-types-classes.html#factors",
    "href": "slides/08-data-types-classes.html#factors",
    "title": "Data types and classes",
    "section": "Factors",
    "text": "Factors\nR uses factors to handle categorical variables, variables that have a fixed and known set of possible values\n\nclass_years &lt;- factor(\n  c(\n    \"First-year\", \"Sophomore\", \"Sophomore\", \"Senior\", \"Junior\"\n    )\n  )\nclass_years\n\n[1] First-year Sophomore  Sophomore  Senior     Junior    \nLevels: First-year Junior Senior Sophomore\n\n\n\n\n\ntypeof(class_years)\n\n[1] \"integer\"\n\n\n\n\n\nclass(class_years)\n\n[1] \"factor\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#more-on-factors",
    "href": "slides/08-data-types-classes.html#more-on-factors",
    "title": "Data types and classes",
    "section": "More on factors",
    "text": "More on factors\nWe can think of factors like character (level labels) and an integer (level numbers) glued together\n\nglimpse(class_years)\n\n Factor w/ 4 levels \"First-year\",\"Junior\",..: 1 4 4 3 2\n\n\n\nas.integer(class_years)\n\n[1] 1 4 4 3 2"
  },
  {
    "objectID": "slides/08-data-types-classes.html#dates",
    "href": "slides/08-data-types-classes.html#dates",
    "title": "Data types and classes",
    "section": "Dates",
    "text": "Dates\n\ntoday &lt;- as.Date(\"2024-09-24\")\ntoday\n\n[1] \"2024-09-24\"\n\n\n\ntypeof(today)\n\n[1] \"double\"\n\n\n\nclass(today)\n\n[1] \"Date\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#more-on-dates",
    "href": "slides/08-data-types-classes.html#more-on-dates",
    "title": "Data types and classes",
    "section": "More on dates",
    "text": "More on dates\nWe can think of dates like an integer (the number of days since the origin, 1 Jan 1970) and an integer (the origin) glued together\n\nas.integer(today)\n\n[1] 19990\n\n\n\nas.integer(today) / 365 # roughly 55 yrs\n\n[1] 54.76712"
  },
  {
    "objectID": "slides/08-data-types-classes.html#data-frames",
    "href": "slides/08-data-types-classes.html#data-frames",
    "title": "Data types and classes",
    "section": "Data frames",
    "text": "Data frames\nWe can think of data frames like like vectors of equal length glued together\n\ndf &lt;- data.frame(x = 1:2, y = 3:4)\ndf\n\n  x y\n1 1 3\n2 2 4\n\n\n\n\n\ntypeof(df)\n\n[1] \"list\"\n\n\n\n\nclass(df)\n\n[1] \"data.frame\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#lists",
    "href": "slides/08-data-types-classes.html#lists",
    "title": "Data types and classes",
    "section": "Lists",
    "text": "Lists\nLists are a generic vector container; vectors of any type can go in them\n\nl &lt;- list(\n  x = 1:4,\n  y = c(\"hi\", \"hello\", \"jello\"),\n  z = c(TRUE, FALSE)\n)\nl\n\n$x\n[1] 1 2 3 4\n\n$y\n[1] \"hi\"    \"hello\" \"jello\"\n\n$z\n[1]  TRUE FALSE"
  },
  {
    "objectID": "slides/08-data-types-classes.html#lists-and-data-frames",
    "href": "slides/08-data-types-classes.html#lists-and-data-frames",
    "title": "Data types and classes",
    "section": "Lists and data frames",
    "text": "Lists and data frames\n\nA data frame is a special list containing vectors of equal length\n\n\ndf\n\n  x y\n1 1 3\n2 2 4\n\n\n\nWhen we use the pull() function, we extract a vector from the data frame\n\n\ndf |&gt;\n  pull(y)\n\n[1] 3 4"
  },
  {
    "objectID": "slides/08-data-types-classes.html#read-data-in-as-character-strings",
    "href": "slides/08-data-types-classes.html#read-data-in-as-character-strings",
    "title": "Data types and classes",
    "section": "Read data in as character strings",
    "text": "Read data in as character strings\n\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         tue_classes year      \n   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;     \n 1 2/6/2025 11:33:57           3 Sophomore \n 2 2/6/2025 11:37:39           3 First-year\n 3 2/6/2025 11:40:55           2 Senior    \n 4 2/6/2025 11:42:05           3 First-year\n 5 2/6/2025 11:42:46           3 Senior    \n 6 2/6/2025 11:43:28           3 Senior    \n 7 2/6/2025 11:44:41           3 First-year\n 8 2/6/2025 11:44:49           3 First-year\n 9 2/6/2025 11:44:51           2 Sophomore \n10 2/6/2025 11:44:51           3 Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes.html#but-coerce-when-plotting",
    "href": "slides/08-data-types-classes.html#but-coerce-when-plotting",
    "title": "Data types and classes",
    "section": "But coerce when plotting",
    "text": "But coerce when plotting\n\nggplot(survey, mapping = aes(x = year)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/08-data-types-classes.html#use-forcats-to-reorder-levels",
    "href": "slides/08-data-types-classes.html#use-forcats-to-reorder-levels",
    "title": "Data types and classes",
    "section": "Use forcats to reorder levels",
    "text": "Use forcats to reorder levels\n\nsurvey |&gt;\n  mutate(\n    year = fct_relevel(year, \"First-year\", \"Sophomore\", \"Junior\", \"Senior\")\n  ) |&gt;\n  ggplot(mapping = aes(x = year)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/08-data-types-classes.html#a-peek-into-forcats",
    "href": "slides/08-data-types-classes.html#a-peek-into-forcats",
    "title": "Data types and classes",
    "section": "A peek into forcats",
    "text": "A peek into forcats\nReordering levels by:\n\nfct_relevel(): hand\nfct_infreq(): frequency\nfct_reorder(): sorting along another variable\nfct_rev(): reversing\n\n…\n\nChanging level values by:\n\nfct_lump(): lumping uncommon levels together into “other”\nfct_other(): manually replacing some levels with “other”\n\n…"
  },
  {
    "objectID": "slides/11-ethics.html#basic-facts",
    "href": "slides/11-ethics.html#basic-facts",
    "title": "Data science ethics",
    "section": "Basic facts",
    "text": "Basic facts\nWorth 20% of your final grade; consists of two parts:\n\n\nIn-class: worth 70% of the Midterm 1 grade;\n\nThursday February 20 11:45 AM - 1:00 PM;\nTake note of your room assignment!\nAll multiple choice;\nBoth sides of one 8.5” x 11” sheet of notes.\n\n\n\nTake-home: worth 30% of the Midterm 1 grade.\n\nReleased Thursday February 20 at 1:00 PM;\nDue Monday February 24 at 8:30 AM;\nWorks just like a mini-lab, only zero collaboration."
  },
  {
    "objectID": "slides/11-ethics.html#last-weeks-advice",
    "href": "slides/11-ethics.html#last-weeks-advice",
    "title": "Data science ethics",
    "section": "Last week’s advice",
    "text": "Last week’s advice\nWhen the world was your oyster and you had nothing but time…\n\n\nPractice problems: released Thursday February 13;\n\nAttend lab: Kahoot on Monday February 17;\n\nOld labs: correct parts where you lost points;\n\nOld AEs: complete tasks we didn’t get to and compare with key;\n\nCode along: watch these videos specifically;\n\nTextbook: odd-numbered exercises in the back of Chs. 1, 4, 5, 6."
  },
  {
    "objectID": "slides/11-ethics.html#this-weeks-advice",
    "href": "slides/11-ethics.html#this-weeks-advice",
    "title": "Data science ethics",
    "section": "This week’s advice",
    "text": "This week’s advice\nNow that you only have forty-eight hours…\n\nStudy the Kahoot and the practice problems;\nStudy the Lab 4 solutions;\nSpend some serious time with your cheat sheet;\nStudy old AE keys, and work stuff we didn’t complete."
  },
  {
    "objectID": "slides/11-ethics.html#what-if-we-get-snowed-out",
    "href": "slides/11-ethics.html#what-if-we-get-snowed-out",
    "title": "Data science ethics",
    "section": "What if we get snowed out?",
    "text": "What if we get snowed out?\n\nIf classes are canceled: in-class exam is moved to 2/25;\nIf classes are not canceled: in-class exam is 2/20 as planned;\nTake-home exam is the same regardless;\nIf classes are canceled, Testing Center appointments are canceled, and we’ll cross that bridge when we come to it (it will be a mess)."
  },
  {
    "objectID": "slides/11-ethics.html#misrepresenting-data-science-results",
    "href": "slides/11-ethics.html#misrepresenting-data-science-results",
    "title": "Data science ethics",
    "section": "Misrepresenting data science results",
    "text": "Misrepresenting data science results\nSome common ways people do this, either intentionally or unintentionally, include:\n\n\nClaiming causality where it’s not in the scope of inference of the underlying study\nDistorting axes and scales to make the data tell a different story\nVisualizing spatial areas instead of human density for issues that depend on and affect humans\nOmitting uncertainty in reporting"
  },
  {
    "objectID": "slides/11-ethics.html#causality---time-coverage",
    "href": "slides/11-ethics.html#causality---time-coverage",
    "title": "Data science ethics",
    "section": "Causality - TIME coverage",
    "text": "Causality - TIME coverage\n\nHow plausible is the statement in the title of this article?\n\n\n\n\nAlice Park. Exercise Can Lower Risk of Some Cancers By 20%. Time Magazine. 16 May 2016."
  },
  {
    "objectID": "slides/11-ethics.html#causality---la-times-coverage",
    "href": "slides/11-ethics.html#causality---la-times-coverage",
    "title": "Data science ethics",
    "section": "Causality - LA Times coverage",
    "text": "Causality - LA Times coverage\n\nWhat does “research shows” mean?\n\n\n\n\nMelissa Healy. Exercising drives down risk for 13 cancers, research shows.\nLos Angeles Times. 16 May 2016."
  },
  {
    "objectID": "slides/11-ethics.html#causality---original-study",
    "href": "slides/11-ethics.html#causality---original-study",
    "title": "Data science ethics",
    "section": "Causality - Original study",
    "text": "Causality - Original study\nMoore, Steven C., et al. “Association of leisure-time physical activity with risk of 26 types of cancer in 1.44 million adults.” JAMA internal medicine 176.6 (2016): 816-825.\n\n\nVolunteers were asked about their physical activity level over the preceding year.\nHalf exercised less than about 150 minutes per week, half exercised more.\nCompared to the bottom 10% of exercisers, the top 10% had lower rates of esophageal, liver, lung, endometrial, colon, and breast cancer.\nResearchers found no association between exercising and 13 other cancers (e.g. pancreatic, ovarian, and brain).\n\nCarl Bergstrom and Jevin West. Calling Bullshit: The art of skepticism in a data-driven world.\nRandom House, 2020.\nSharon Begley. “Does exercise prevent cancer?”. StatNews. 16 May 2016."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---tax-cuts",
    "href": "slides/11-ethics.html#axes-and-scales---tax-cuts",
    "title": "Data science ethics",
    "section": "Axes and scales - Tax cuts",
    "text": "Axes and scales - Tax cuts\n\nWhat is the difference between these two pictures? Which presents a better way to represent these data?\n\n\n\n\nChristopher Ingraham. “You’ve been reading charts wrong. Here’s how a pro does it.”. The Washington Post. 14 October 2019."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---cost-of-gas",
    "href": "slides/11-ethics.html#axes-and-scales---cost-of-gas",
    "title": "Data science ethics",
    "section": "Axes and scales - Cost of gas",
    "text": "Axes and scales - Cost of gas\n\nWhat is wrong with this picture? How would you correct it?"
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---cost-of-gas-1",
    "href": "slides/11-ethics.html#axes-and-scales---cost-of-gas-1",
    "title": "Data science ethics",
    "section": "Axes and scales - Cost of gas",
    "text": "Axes and scales - Cost of gas\n\ndf &lt;- tibble(\n  date = ymd(c(\"2019-11-01\", \"2020-10-25\", \"2020-11-01\")),\n  cost = c(3.17, 3.51, 3.57)\n)\nggplot(df, aes(x = date, y = cost, group = 1)) +\n  geom_point() +\n  geom_line() +\n  geom_label(aes(label = cost), hjust = -0.25) +\n  labs(\n    title = \"Cost of gas\",\n    subtitle = \"National average\",\n    x = NULL, y = NULL, \n    caption = \"Source: AAA Fuel Gauge Report\"\n  ) +\n  scale_x_continuous(\n    breaks = ymd(c(\"2019-11-01\", \"2020-10-25\", \"2020-11-01\")), \n    labels = c(\"Last year\", \"Last week\", \"Current\"),\n    guide = guide_axis(angle = 90),\n    limits = ymd(c(\"2019-11-01\", \"2020-11-29\")),\n    minor_breaks = ymd(c(\"2019-11-01\", \"2020-10-25\", \"2020-11-01\"))\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---covid-in-ga",
    "href": "slides/11-ethics.html#axes-and-scales---covid-in-ga",
    "title": "Data science ethics",
    "section": "Axes and scales - COVID in GA",
    "text": "Axes and scales - COVID in GA\n\nWhat is wrong with this picture? How would you correct it?\n\n\n\n\nGeorgia Department of Public Health. 11 May 2020."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---covid-in-ga-1",
    "href": "slides/11-ethics.html#axes-and-scales---covid-in-ga-1",
    "title": "Data science ethics",
    "section": "Axes and scales - COVID in GA",
    "text": "Axes and scales - COVID in GA\n\n\n\nLucy D’Agostino McGowan. Graph detective. Live Free or Dichotomize. 17 May 2020."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---pp-services",
    "href": "slides/11-ethics.html#axes-and-scales---pp-services",
    "title": "Data science ethics",
    "section": "Axes and scales - PP services",
    "text": "Axes and scales - PP services\n\n\n\nWhat is wrong with this picture? How would you correct it?\n\n\n\n\n\n\n\nTimothy B. Lee. Whatever you think of Planned Parenthood, this is a terrible and dishonest chart. Vox. 29 September 2019."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---pp-services-1",
    "href": "slides/11-ethics.html#axes-and-scales---pp-services-1",
    "title": "Data science ethics",
    "section": "Axes and scales - PP services",
    "text": "Axes and scales - PP services\n\npp &lt;- tibble(\n  year = c(2006, 2006, 2013, 2013),\n  service = c(\"Abortion\", \"Cancer\", \"Abortion\", \"Cancer\"),\n  n = c(289750, 2007371, 327000, 935573)\n)\n\nggplot(pp, aes(x = year, y = n, color = service)) +\n  geom_point(size = 2) +\n  geom_line(linewidth = 1) +\n  geom_text(aes(label = n), nudge_y = 100000) +\n  geom_text(\n    aes(label = year), \n    nudge_y = 200000, \n    color = \"darkgray\"\n  ) +\n  labs(\n    title = \"Services provided by Planned Parenthood\",\n    caption = \"Source: Planned Parenthood\",\n    x = NULL,\n    y = NULL\n  ) +\n  scale_x_continuous(breaks = c(2006, 2013)) +\n  scale_y_continuous(labels = label_number(big.mark = \",\")) +\n  scale_color_manual(values = c(\"red\", \"purple\")) +\n  annotate(\n    geom = \"text\",\n    label = \"Abortions\",\n    x = 2009.5,\n    y = 400000,\n    color = \"red\"\n  ) +\n  annotate(\n    geom = \"text\",\n    label = \"Cancer screening\\nand prevention services\",\n    x = 2010.5,\n    y = 1600000, \n    color = \"purple\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/11-ethics.html#maps-and-areas---voting-map",
    "href": "slides/11-ethics.html#maps-and-areas---voting-map",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting map",
    "text": "Maps and areas - Voting map\n\nDo you recognize this map? What does it show?\n\n\n\n\nLazaro Gamio. “Election maps are telling you big lies about small things”. The Washington Post. 1 Nov 2016."
  },
  {
    "objectID": "slides/11-ethics.html#maps-and-areas---two-alternate-tales",
    "href": "slides/11-ethics.html#maps-and-areas---two-alternate-tales",
    "title": "Data science ethics",
    "section": "Maps and areas - Two alternate tales",
    "text": "Maps and areas - Two alternate tales\n\n\n\n\n\n\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/11-ethics.html#maps-and-areas---voting-percentages",
    "href": "slides/11-ethics.html#maps-and-areas---voting-percentages",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting percentages",
    "text": "Maps and areas - Voting percentages\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/11-ethics.html#maps-and-areas---voting-percentages-1",
    "href": "slides/11-ethics.html#maps-and-areas---voting-percentages-1",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting percentages",
    "text": "Maps and areas - Voting percentages\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/11-ethics.html#uncertainty---catalan-independence",
    "href": "slides/11-ethics.html#uncertainty---catalan-independence",
    "title": "Data science ethics",
    "section": "Uncertainty - Catalan independence",
    "text": "Uncertainty - Catalan independence\nOn December 19, 2014, the front page of Spanish national newspaper El País read “Catalan public opinion swings toward ‘no’ for independence, says survey”.\n\n\n\n\n\n\n\n\n\n\nAlberto Cairo. The truthful art: Data, charts, and maps for communication. New Riders, 2016."
  },
  {
    "objectID": "slides/11-ethics.html#uncertainty---catalan-independence-1",
    "href": "slides/11-ethics.html#uncertainty---catalan-independence-1",
    "title": "Data science ethics",
    "section": "Uncertainty - Catalan independence",
    "text": "Uncertainty - Catalan independence\n\n\n\n\n\n\n\n\n\n\nAlberto Cairo. “Uncertainty and Graphicacy: How Should Statisticians Journalists and Designers Reveal Uncertainty in Graphics for Public Consumption?”, Power from Statistics: Data Information and Knowledge, 2017."
  },
  {
    "objectID": "slides/11-ethics.html#california-proposition-25-2020",
    "href": "slides/11-ethics.html#california-proposition-25-2020",
    "title": "Data science ethics",
    "section": "California Proposition 25 (2020)",
    "text": "California Proposition 25 (2020)\nPopular referendum on 2018’s Senate Bill 10:\n\n\n\nYES: replace cash bail with ``risk assessment.’’\n\nDemocratic Party, Governor Gavin Newson, League of Women Voters of California, California Medical Association, Democracy for America (progressive PAC), etc.\n\n\n\nNO: keep the cash bail system.\n\nRepublican Party, American Bail Coalition, ACLU of Southern California, NAACP, California Asian Pacific Chamber of Commerce, etc.\n\n\nIf passed, each county would be empowered to develop a tool that predicts the risk of a suspect reoffending before trial.\nJudges would consult this prediction to make bail decisions."
  },
  {
    "objectID": "slides/11-ethics.html#what-might-risk-assessment-look-like",
    "href": "slides/11-ethics.html#what-might-risk-assessment-look-like",
    "title": "Data science ethics",
    "section": "What might “risk assessment” look like?",
    "text": "What might “risk assessment” look like?\nSomething we will study after spring break:\n\n\n\n\n\n\n\n\nAbove the line means high risk means no bail. Is this progress?"
  },
  {
    "objectID": "slides/11-ethics.html#what-happens-when-we-try-predictive-policing",
    "href": "slides/11-ethics.html#what-happens-when-we-try-predictive-policing",
    "title": "Data science ethics",
    "section": "What happens when we try “predictive policing”?",
    "text": "What happens when we try “predictive policing”?\n2016 ProPublica article on algorithm used for rating a defendant’s risk of future crime:\n\n\n\nIn forecasting who would re-offend, the algorithm made mistakes with black and white defendants at roughly the same rate but in very different ways.\n\nThe formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.\nWhite defendants were mislabeled as low risk more often than black defendants.\n\n\n\n\n\n\n\n\n\n\n\nSource: ProPublica"
  },
  {
    "objectID": "slides/11-ethics.html#notice-anything",
    "href": "slides/11-ethics.html#notice-anything",
    "title": "Data science ethics",
    "section": "Notice anything?",
    "text": "Notice anything?\n\n\n\nWhat is common among the defendants who were assigned a high/low risk score for reoffending?"
  },
  {
    "objectID": "slides/11-ethics.html#but-race-wasnt-in-my-model",
    "href": "slides/11-ethics.html#but-race-wasnt-in-my-model",
    "title": "Data science ethics",
    "section": "“But race wasn’t in my model”",
    "text": "“But race wasn’t in my model”\n\n\n\nHow can an algorithm that doesn’t use race as input data be racist?"
  },
  {
    "objectID": "slides/11-ethics.html#predicting-ethnicity",
    "href": "slides/11-ethics.html#predicting-ethnicity",
    "title": "Data science ethics",
    "section": "Predicting ethnicity",
    "text": "Predicting ethnicity\nImproving Ecological Inference by Predicting Individual Ethnicity from Voter Registration Record (Imran and Khan, 2016)\n\nIn both political behavior research and voting rights litigation, turnout and vote choice for different racial groups are often inferred using aggregate election results and racial composition. Over the past several decades, many statistical methods have been proposed to address this ecological inference problem. We propose an alternative method to reduce aggregation bias by predicting individual-level ethnicity from voter registration records. Building on the existing methodological literature, we use Bayes’s rule to combine the Census Bureau’s Surname List with various information from geocoded voter registration records. We evaluate the performance of the proposed methodology using approximately nine million voter registration records from Florida, where self-reported ethnicity is available. We find that it is possible to reduce the false positive rate among Black and Latino voters to 6% and 3%, respectively, while maintaining the true positive rate above 80%. Moreover, we use our predictions to estimate turnout by race and find that our estimates yields substantially less amounts of bias and root mean squared error than standard ecological inference estimates. We provide open-source software to implement the proposed methodology. The open-source software is available for implementing the proposed methodology."
  },
  {
    "objectID": "slides/11-ethics.html#wru-package",
    "href": "slides/11-ethics.html#wru-package",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\nThe said “source software” is the wru package: https://github.com/kosukeimai/wru.\n\nDo you have any ethical concerns about installing this package?"
  },
  {
    "objectID": "slides/11-ethics.html#wru-package-1",
    "href": "slides/11-ethics.html#wru-package-1",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\n\nWas the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nlibrary(wru)\npredict_race(voter.file = voters, surname.only = TRUE) |&gt;\n  select(surname, pred.whi, pred.bla, pred.his, pred.asi, pred.oth)\n\n      surname    pred.whi    pred.bla     pred.his    pred.asi    pred.oth\n1      Khanna 0.045110474 0.003067623 0.0068522723 0.860411906 0.084557725\n2        Imai 0.052645440 0.001334812 0.0558160072 0.719376581 0.170827160\n3      Rivera 0.043285692 0.008204605 0.9136195794 0.024316883 0.010573240\n4     Fifield 0.895405704 0.001911388 0.0337464844 0.011079323 0.057857101\n5        Zhou 0.006572555 0.001298962 0.0005388581 0.982365594 0.009224032\n6    Ratkovic 0.861236727 0.008212824 0.0095395642 0.011334635 0.109676251\n7     Johnson 0.543815322 0.344128607 0.0272403940 0.007405765 0.077409913\n8       Lopez 0.038939877 0.004920643 0.9318797791 0.012154125 0.012105576\n10 Wantchekon 0.330697188 0.194700665 0.4042849478 0.021379541 0.048937658\n9       Morse 0.866360147 0.044429853 0.0246568086 0.010219712 0.054333479"
  },
  {
    "objectID": "slides/11-ethics.html#wru-package-2",
    "href": "slides/11-ethics.html#wru-package-2",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\n\nme &lt;- tibble(surname = \"Zito\")\n\npredict_race(voter.file = me, surname.only = TRUE)\n\n  surname  pred.whi   pred.bla   pred.his    pred.asi   pred.oth\n1    Zito 0.9220001 0.00419631 0.03968994 0.009652312 0.02446131"
  },
  {
    "objectID": "slides/11-ethics.html#california-prop-25-did-not-pass",
    "href": "slides/11-ethics.html#california-prop-25-did-not-pass",
    "title": "Data science ethics",
    "section": "California Prop 25 did not pass",
    "text": "California Prop 25 did not pass\nThe cash bail system was retained:\n\n\nChoice\nVotes\nPercent\n\n\n\nYes\n7,232,380\n43.59%\n\n\nNo\n9,358,226\n56.41%\n\n\n\n\n\nreasonable people can debate if this outcome is good or bad;\nevery Californian was invited to decide whether statistics and data science should be deployed to make decisions with major social consequences. They opted out;\nThis vote was held in the pre-ChatGPT era. What would the outcome be today? Is the case for YES stronger or weaker?"
  },
  {
    "objectID": "slides/11-ethics.html#another-algorithmic-decision",
    "href": "slides/11-ethics.html#another-algorithmic-decision",
    "title": "Data science ethics",
    "section": "Another algorithmic decision…",
    "text": "Another algorithmic decision…\n Armies of stats PhDs go to work on these models. They have no training in the ethics of what they’re doing."
  },
  {
    "objectID": "slides/11-ethics.html#a-success-story",
    "href": "slides/11-ethics.html#a-success-story",
    "title": "Data science ethics",
    "section": "A success story?",
    "text": "A success story?\n\nData + Model to predict timing of menstrual cycle:\n\n\n\nA perfect microcosm of the themes of our course, and maybe one of the real triumphs of data and modeling improving modern life.\n\n\n…but what if you learned they were selling your data?"
  },
  {
    "objectID": "slides/11-ethics.html#data-privacy",
    "href": "slides/11-ethics.html#data-privacy",
    "title": "Data science ethics",
    "section": "Data privacy",
    "text": "Data privacy"
  },
  {
    "objectID": "slides/11-ethics.html#your-data",
    "href": "slides/11-ethics.html#your-data",
    "title": "Data science ethics",
    "section": "“Your” data",
    "text": "“Your” data\n\nEvery time we use apps, websites, and devices, our data is being collected and used or sold to others.\nMore importantly, decisions are made by law enforcement, financial institutions, and governments based on data that directly affect the lives of people."
  },
  {
    "objectID": "slides/11-ethics.html#privacy-of-your-data",
    "href": "slides/11-ethics.html#privacy-of-your-data",
    "title": "Data science ethics",
    "section": "Privacy of your data",
    "text": "Privacy of your data\n\nWhat pieces of data have you left on the internet today? Think through everything you’ve logged into, clicked on, checked in, either actively or automatically, that might be tracking you. Do you know where that data is stored? Who it can be accessed by? Whether it’s shared with others?"
  },
  {
    "objectID": "slides/11-ethics.html#sharing-your-data",
    "href": "slides/11-ethics.html#sharing-your-data",
    "title": "Data science ethics",
    "section": "Sharing your data",
    "text": "Sharing your data\n\nWhat are you OK with sharing?\n\n\n\n\n\nName\nAge\nEmail\nPhone Number\nList of every video you watch\nList of every video you comment on\n\n\n\n\n\nHow you type: speed, accuracy\nHow long you spend on different content\nList of all your private messages (date, time, person sent to)\nInfo about your photos (how it was taken, where it was taken (GPS), when it was taken)"
  },
  {
    "objectID": "slides/11-ethics.html#what-does-google-thinkknow-about-you",
    "href": "slides/11-ethics.html#what-does-google-thinkknow-about-you",
    "title": "Data science ethics",
    "section": "What does Google think/know about you?",
    "text": "What does Google think/know about you?\n\nHave you ever thought about why you’re seeing an ad on Google? Google it! Try to figure out if you have ad personalization on and how your ads are personalized."
  },
  {
    "objectID": "slides/11-ethics.html#your-browsing-history",
    "href": "slides/11-ethics.html#your-browsing-history",
    "title": "Data science ethics",
    "section": "Your browsing history",
    "text": "Your browsing history\n\nWhich of the following are you OK with your browsing history to be used towards?\n\n\n\nFor serving you targeted ads\nTo score you as a candidate for a job\nTo predict your race/ethnicity for voting purposes"
  },
  {
    "objectID": "slides/11-ethics.html#who-else-gets-to-use-your-data",
    "href": "slides/11-ethics.html#who-else-gets-to-use-your-data",
    "title": "Data science ethics",
    "section": "Who else gets to use your data?",
    "text": "Who else gets to use your data?\n\nSuppose you create a profile on a social media site and share your personal information on your profile. Who else gets to use that data?\n\n\n\nCompanies the social media company has a connection to?\nCompanies the social media company sells your data to?\nResearchers?"
  },
  {
    "objectID": "slides/11-ethics.html#aol-search-data-leak",
    "href": "slides/11-ethics.html#aol-search-data-leak",
    "title": "Data science ethics",
    "section": "AOL search data leak",
    "text": "AOL search data leak\n\n\n\nMichael Barbaro and Tom Zeller Jr. A Face Is Exposed for AOL Searcher No. 4417749.\nNew York Times. 9 August 2006."
  },
  {
    "objectID": "slides/11-ethics.html#ok-cupid-data-breach",
    "href": "slides/11-ethics.html#ok-cupid-data-breach",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nIn 2016, researchers published data of 70,000 OkCupid users—including usernames, political leanings, drug usage, and intimate sexual details\nResearchers didn’t release the real names and pictures of OKCupid users, but their identities could easily be uncovered from the details provided, e.g. usernames"
  },
  {
    "objectID": "slides/11-ethics.html#ok-cupid-data-breach-1",
    "href": "slides/11-ethics.html#ok-cupid-data-breach-1",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach"
  },
  {
    "objectID": "slides/11-ethics.html#ok-cupid-data-breach-2",
    "href": "slides/11-ethics.html#ok-cupid-data-breach-2",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nSome may object to the ethics of gathering and releasing this data. However, all the data found in the dataset are or were already publicly available, so releasing this dataset merely presents it in a more useful form.\nResearchers Emil Kirkegaard and Julius Daugbjerg Bjerrekær"
  },
  {
    "objectID": "slides/11-ethics.html#data-privacy-1",
    "href": "slides/11-ethics.html#data-privacy-1",
    "title": "Data science ethics",
    "section": "Data privacy",
    "text": "Data privacy\n\nIn analysis of data that individuals willingly shared publicly on a given platform (e.g. social media), how do you make sure you don’t violate reasonable expectations of privacy?"
  },
  {
    "objectID": "slides/11-ethics.html#faster-more-accurate-cancer-screening",
    "href": "slides/11-ethics.html#faster-more-accurate-cancer-screening",
    "title": "Data science ethics",
    "section": "Faster, more accurate cancer screening?",
    "text": "Faster, more accurate cancer screening?\nAugmenting doctors’ diagnostic capacity so that they make fewer mistakes, treat more people, and focus on other aspects of care:"
  },
  {
    "objectID": "slides/11-ethics.html#the-nobel-prize-last-year",
    "href": "slides/11-ethics.html#the-nobel-prize-last-year",
    "title": "Data science ethics",
    "section": "The Nobel Prize last year",
    "text": "The Nobel Prize last year\n\n\nAlphaFold2: “predicting 3D structures [of proteins] (\\(y\\)) directly from the primary amino acid sequence (\\(x\\)).”\n“researchers can now better understand antibiotic resistance and create images of enzymes that can decompose plastic.”"
  },
  {
    "objectID": "slides/11-ethics.html#how-charts-lie",
    "href": "slides/11-ethics.html#how-charts-lie",
    "title": "Data science ethics",
    "section": "How Charts Lie",
    "text": "How Charts Lie\n\n\n\n\nHow Charts Lie\nGetting Smarter about Visual Information\nby Alberto Cairo"
  },
  {
    "objectID": "slides/11-ethics.html#calling-bullshit",
    "href": "slides/11-ethics.html#calling-bullshit",
    "title": "Data science ethics",
    "section": "Calling Bullshit",
    "text": "Calling Bullshit\n\n\n\n\nCalling Bullshit\nThe Art of Skepticism in a\nData-Driven World\nby Carl Bergstrom and Jevin West"
  },
  {
    "objectID": "slides/11-ethics.html#machine-bias",
    "href": "slides/11-ethics.html#machine-bias",
    "title": "Data science ethics",
    "section": "Machine Bias",
    "text": "Machine Bias\n\n\n\n\nMachine Bias\nby Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner"
  },
  {
    "objectID": "slides/11-ethics.html#ethics-and-data-science",
    "href": "slides/11-ethics.html#ethics-and-data-science",
    "title": "Data science ethics",
    "section": "Ethics and Data Science",
    "text": "Ethics and Data Science\n\n\n\n\nEthics and Data Science\nby Mike Loukides, Hilary Mason, DJ Patil\n(Free Kindle download)"
  },
  {
    "objectID": "slides/11-ethics.html#weapons-of-math-destruction",
    "href": "slides/11-ethics.html#weapons-of-math-destruction",
    "title": "Data science ethics",
    "section": "Weapons of Math Destruction",
    "text": "Weapons of Math Destruction\n\n\n\n\nWeapons of Math Destruction\nHow Big Data Increases Inequality and Threatens Democracy\nby Cathy O’Neil"
  },
  {
    "objectID": "slides/11-ethics.html#algorithms-of-oppression",
    "href": "slides/11-ethics.html#algorithms-of-oppression",
    "title": "Data science ethics",
    "section": "Algorithms of Oppression",
    "text": "Algorithms of Oppression\n\n\n\n\nAlgorithms of Oppression\nHow Search Engines Reinforce Racism\nby Safiya Umoja Noble"
  },
  {
    "objectID": "slides/11-ethics.html#and-more-recently",
    "href": "slides/11-ethics.html#and-more-recently",
    "title": "Data science ethics",
    "section": "And more recently…",
    "text": "And more recently…\nHow AI discriminates and what that means for your Google habit\nA conversation with UCLA internet studies scholar Safiya Noble\nby Julia Busiek"
  },
  {
    "objectID": "slides/11-ethics.html#parting-thoughts",
    "href": "slides/11-ethics.html#parting-thoughts",
    "title": "Data science ethics",
    "section": "Parting thoughts",
    "text": "Parting thoughts\n\nAt some point during your data science learning journey you will learn tools that can be used unethically\nYou might also be tempted to use your knowledge in a way that is ethically questionable either because of business goals or for the pursuit of further knowledge (or because your boss told you to do so)\n\n\nHow do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#while-you-wait",
    "href": "slides/04-exploring-data-1.html#while-you-wait",
    "title": "Exploring data I",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-03-gerrymander-explore-I\n\nSwitch to your ae project in RStudio;\nMake sure all of your changes up to this point are committed (ie there’s nothing left in your Git pane);\nClick Pull to get today’s application exercise file: ae-03-gerrymander-explore-I.qmd.\nThen push. So Render &gt; Commit &gt; Pull &gt; Push.\nWait till the you’re prompted to work on the application exercise during class before editing the file.\n\n\n\n\n\n\n\nAEs are due by the end of class\n\n\nSuccessful completion means at least one commit + push by 2PM today"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#packages",
    "href": "slides/04-exploring-data-1.html#packages",
    "title": "Exploring data I",
    "section": "Packages",
    "text": "Packages\n\nFor the data: usdata\n\n\n\nlibrary(usdata)\n\n\nFor the analysis: tidyverse and ggthemes\n\n\n\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#data-gerrymander",
    "href": "slides/04-exploring-data-1.html#data-gerrymander",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\ngerrymander\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#what-is-gerrymandering",
    "href": "slides/04-exploring-data-1.html#what-is-gerrymandering",
    "title": "Exploring data I",
    "section": "What is gerrymandering?",
    "text": "What is gerrymandering?"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa",
    "href": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa",
    "title": "Exploring data I",
    "section": "JZ’s tour of the USA",
    "text": "JZ’s tour of the USA"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-1",
    "href": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-1",
    "title": "Exploring data I",
    "section": "JZ’s tour of the USA",
    "text": "JZ’s tour of the USA"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-2",
    "href": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-2",
    "title": "Exploring data I",
    "section": "JZ’s tour of the USA",
    "text": "JZ’s tour of the USA"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-3",
    "href": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-3",
    "title": "Exploring data I",
    "section": "JZ’s tour of the USA",
    "text": "JZ’s tour of the USA"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#data-gerrymander-1",
    "href": "slides/04-exploring-data-1.html#data-gerrymander-1",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\nWhat is a good first function to use to get to know a dataset?\n\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#data-gerrymander-2",
    "href": "slides/04-exploring-data-1.html#data-gerrymander-2",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\nRows: Congressional districts\n\nColumns:\n\nCongressional district and state\n2016 election: winning party, % for Clinton, % for Trump, whether a Democrat won the House election, name of election winner\n2018 election: winning party, whether a Democrat won the 2018 House election\nWhether a Democrat flipped the seat in the 2018 election\nPrevalence of gerrymandering: low, mid, and high"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#variable-types",
    "href": "slides/04-exploring-data-1.html#variable-types",
    "title": "Exploring data I",
    "section": "Variable types",
    "text": "Variable types\n\n\n\n\n\nVariable\nType\n\n\n\ndistrict\ncategorical, ID\n\n\nlast_name\ncategorical, ID\n\n\nfirst_name\ncategorical, ID\n\n\nparty16\ncategorical\n\n\nclinton16\nnumerical, continuous\n\n\ntrump16\nnumerical, continuous\n\n\n\n\n\n\n\nVariable\nType\n\n\n\ndem16\ncategorical\n\n\nstate\ncategorical\n\n\nparty18\ncategorical\n\n\ndem18\ncategorical\n\n\nflip18\ncategorical\n\n\ngerry\ncategorical, ordinal"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#univariate-analysis-1",
    "href": "slides/04-exploring-data-1.html#univariate-analysis-1",
    "title": "Exploring data I",
    "section": "Univariate analysis",
    "text": "Univariate analysis\nAnalyzing a single variable:\n\n\nNumerical: histogram, box plot, density plot, etc.\nCategorical: bar plot, pie chart, etc."
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-1",
    "href": "slides/04-exploring-data-1.html#histogram---step-1",
    "title": "Exploring data I",
    "section": "Histogram - Step 1",
    "text": "Histogram - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-2",
    "href": "slides/04-exploring-data-1.html#histogram---step-2",
    "title": "Exploring data I",
    "section": "Histogram - Step 2",
    "text": "Histogram - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-3",
    "href": "slides/04-exploring-data-1.html#histogram---step-3",
    "title": "Exploring data I",
    "section": "Histogram - Step 3",
    "text": "Histogram - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-4",
    "href": "slides/04-exploring-data-1.html#histogram---step-4",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 1)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-4-1",
    "href": "slides/04-exploring-data-1.html#histogram---step-4-1",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 100)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-4-2",
    "href": "slides/04-exploring-data-1.html#histogram---step-4-2",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 3)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-4-3",
    "href": "slides/04-exploring-data-1.html#histogram---step-4-3",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 5)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-5",
    "href": "slides/04-exploring-data-1.html#histogram---step-5",
    "title": "Exploring data I",
    "section": "Histogram - Step 5",
    "text": "Histogram - Step 5\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 5) +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = \"Count\"\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---step-1",
    "href": "slides/04-exploring-data-1.html#box-plot---step-1",
    "title": "Exploring data I",
    "section": "Box plot - Step 1",
    "text": "Box plot - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---step-2",
    "href": "slides/04-exploring-data-1.html#box-plot---step-2",
    "title": "Exploring data I",
    "section": "Box plot - Step 2",
    "text": "Box plot - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---step-3",
    "href": "slides/04-exploring-data-1.html#box-plot---step-3",
    "title": "Exploring data I",
    "section": "Box plot - Step 3",
    "text": "Box plot - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---alternative-step-2-3",
    "href": "slides/04-exploring-data-1.html#box-plot---alternative-step-2-3",
    "title": "Exploring data I",
    "section": "Box plot - Alternative Step 2 + 3",
    "text": "Box plot - Alternative Step 2 + 3\n\nggplot(gerrymander, aes(y = trump16)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---step-4",
    "href": "slides/04-exploring-data-1.html#box-plot---step-4",
    "title": "Exploring data I",
    "section": "Box plot - Step 4",
    "text": "Box plot - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_boxplot() +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = NULL\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-1",
    "href": "slides/04-exploring-data-1.html#density-plot---step-1",
    "title": "Exploring data I",
    "section": "Density plot - Step 1",
    "text": "Density plot - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-2",
    "href": "slides/04-exploring-data-1.html#density-plot---step-2",
    "title": "Exploring data I",
    "section": "Density plot - Step 2",
    "text": "Density plot - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-3",
    "href": "slides/04-exploring-data-1.html#density-plot---step-3",
    "title": "Exploring data I",
    "section": "Density plot - Step 3",
    "text": "Density plot - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-4",
    "href": "slides/04-exploring-data-1.html#density-plot---step-4",
    "title": "Exploring data I",
    "section": "Density plot - Step 4",
    "text": "Density plot - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"red\")"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-5",
    "href": "slides/04-exploring-data-1.html#density-plot---step-5",
    "title": "Exploring data I",
    "section": "Density plot - Step 5",
    "text": "Density plot - Step 5\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\")"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-6",
    "href": "slides/04-exploring-data-1.html#density-plot---step-6",
    "title": "Exploring data I",
    "section": "Density plot - Step 6",
    "text": "Density plot - Step 6\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 1)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-6-1",
    "href": "slides/04-exploring-data-1.html#density-plot---step-6-1",
    "title": "Exploring data I",
    "section": "Density plot - Step 6",
    "text": "Density plot - Step 6\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-6-2",
    "href": "slides/04-exploring-data-1.html#density-plot---step-6-2",
    "title": "Exploring data I",
    "section": "Density plot - Step 6",
    "text": "Density plot - Step 6\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0.5)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-7",
    "href": "slides/04-exploring-data-1.html#density-plot---step-7",
    "title": "Exploring data I",
    "section": "Density plot - Step 7",
    "text": "Density plot - Step 7\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0.5, linewidth = 2)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-8",
    "href": "slides/04-exploring-data-1.html#density-plot---step-8",
    "title": "Exploring data I",
    "section": "Density plot - Step 8",
    "text": "Density plot - Step 8\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0.5, linewidth = 2) +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = \"Density\"\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics",
    "href": "slides/04-exploring-data-1.html#summary-statistics",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  summarize(\n    mean_trump_perc = mean(trump16),\n    median_trump_perc = median(trump16),\n    sd = sd(trump16),\n    iqr = IQR(trump16),\n    q25 = quantile(trump16, 0.25),\n    q75 = quantile(trump16, 0.75)\n  )\n\n# A tibble: 1 × 6\n  mean_trump_perc median_trump_perc    sd   iqr   q25   q75\n            &lt;dbl&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1            45.9              48.7  16.8  23.3  34.8  58.1"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#distribution-of-votes-for-trump-in-the-2016-election",
    "href": "slides/04-exploring-data-1.html#distribution-of-votes-for-trump-in-the-2016-election",
    "title": "Exploring data I",
    "section": "Distribution of votes for Trump in the 2016 election",
    "text": "Distribution of votes for Trump in the 2016 election\n\nDescribe the distribution of percent of vote received by Trump in 2016 Presidential Election from Congressional Districts.\n\n\nShape: The distribution of votes for Trump in the 2016 election from Congressional Districts is unimodal and left-skewed.\nCenter: The percent of vote received by Trump in the 2016 Presidential Election from a typical Congressional Districts is 48.7%.\nSpread: In the middle 50% of Congressional Districts, 34.8% to 58.1% of voters voted for Trump in the 2016 Presidential Election.\nUnusual observations: -"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#bivariate-analysis-1",
    "href": "slides/04-exploring-data-1.html#bivariate-analysis-1",
    "title": "Exploring data I",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\nAnalyzing the relationship between two variables:\n\n\nNumerical + numerical: scatterplot\nNumerical + categorical: side-by-side box plots, violin plots, etc.\nCategorical + categorical: stacked bar plots\nUsing an aesthetic (e.g., fill, color, shape, etc.) or facets to represent the second variable in any plot"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#side-by-side-box-plots",
    "href": "slides/04-exploring-data-1.html#side-by-side-box-plots",
    "title": "Exploring data I",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    y = gerry\n    )\n  ) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-1",
    "href": "slides/04-exploring-data-1.html#summary-statistics-1",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  # do the following for each level of gerry\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 1 × 5\n    min   q25 median   q75   max\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   4.9  34.8   48.7  58.1  80.4"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-2",
    "href": "slides/04-exploring-data-1.html#summary-statistics-2",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  filter(gerry == \"low\") |&gt;\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 1 × 5\n    min   q25 median   q75   max\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   4.9  36.3   48.4  54.7  74.9"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-3",
    "href": "slides/04-exploring-data-1.html#summary-statistics-3",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  filter(gerry == \"mid\") |&gt;\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 1 × 5\n    min   q25 median   q75   max\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   6.8  34.8   48.0  57.9  79.9"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-4",
    "href": "slides/04-exploring-data-1.html#summary-statistics-4",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  filter(gerry == \"high\") |&gt;\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 1 × 5\n    min   q25 median   q75   max\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   9.2  33.5   50.5  60.8  80.4"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-5",
    "href": "slides/04-exploring-data-1.html#summary-statistics-5",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  group_by(gerry) |&gt;\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 3 × 6\n  gerry   min   q25 median   q75   max\n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 low     4.9  36.3   48.4  54.7  74.9\n2 mid     6.8  34.8   48.0  57.9  79.9\n3 high    9.2  33.5   50.5  60.8  80.4"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plots",
    "href": "slides/04-exploring-data-1.html#density-plots",
    "title": "Exploring data I",
    "section": "Density plots",
    "text": "Density plots\n\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    color = gerry\n    )\n  ) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#filled-density-plots",
    "href": "slides/04-exploring-data-1.html#filled-density-plots",
    "title": "Exploring data I",
    "section": "Filled density plots",
    "text": "Filled density plots\n\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    color = gerry,\n    fill = gerry\n    )\n  ) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#better-filled-density-plots",
    "href": "slides/04-exploring-data-1.html#better-filled-density-plots",
    "title": "Exploring data I",
    "section": "Better filled density plots",
    "text": "Better filled density plots\n\nggplot(\n  gerrymander, \n  aes(x = trump16, color = gerry, fill = gerry)\n  ) +\n  geom_density(alpha = 0.5)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#better-colors",
    "href": "slides/04-exploring-data-1.html#better-colors",
    "title": "Exploring data I",
    "section": "Better colors",
    "text": "Better colors\n\n\nggplot(\n  gerrymander, \n  aes(x = trump16, color = gerry, fill = gerry)\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#violin-plots",
    "href": "slides/04-exploring-data-1.html#violin-plots",
    "title": "Exploring data I",
    "section": "Violin plots",
    "text": "Violin plots\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#multiple-geoms",
    "href": "slides/04-exploring-data-1.html#multiple-geoms",
    "title": "Exploring data I",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_point() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#multiple-geoms-1",
    "href": "slides/04-exploring-data-1.html#multiple-geoms-1",
    "title": "Exploring data I",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#remove-legend",
    "href": "slides/04-exploring-data-1.html#remove-legend",
    "title": "Exploring data I",
    "section": "Remove legend",
    "text": "Remove legend\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  scale_color_colorblind() +\n  scale_fill_colorblind() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#multivariate-analysis-1",
    "href": "slides/04-exploring-data-1.html#multivariate-analysis-1",
    "title": "Exploring data I",
    "section": "Multivariate analysis",
    "text": "Multivariate analysis\nAnalyzing the relationship between multiple variables:\n\n\nIn general, one variable is identified as the outcome of interest\nThe remaining variables are predictors or explanatory variables\n\nPlots for exploring multivariate relationships are the same as those for bivariate relationships, but conditional on one or more variables\n\nConditioning can be done via faceting or aesthetic mappings (e.g., scatterplot of y vs. x1, colored by x2, faceted by x3)\n\n\n\nSummary statistics for exploring multivariate relationships are the same as those for bivariate relationships, but conditional on one or more variables\n\nConditioning can be done via grouping (e.g., correlation between y and x1, grouped by levels of x2 and x3)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#ae-03-gerrymander-explore-i",
    "href": "slides/04-exploring-data-1.html#ae-03-gerrymander-explore-i",
    "title": "Exploring data I",
    "section": "ae-03-gerrymander-explore-I",
    "text": "ae-03-gerrymander-explore-I\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-03-gerrymander-explore-I.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#outline",
    "href": "slides/02-grammar-of-data-visualization.html#outline",
    "title": "Grammar of data visualization",
    "section": "Outline",
    "text": "Outline\n\n\nLast time:\n\nWe introduced you to the course toolkit.\nYou cloned your ae repositories and started making some updates in your Quarto documents.\nYou did not commit and push your changes back.\n\n\n\n\n\n\nToday:\n\nYou will commit your changes from last time and push them to wrap up that application exercise.\nWe will introduce data visualization.\nYou will pull to get today’s application exercise file.\nYou will work on the new application exercise on data visualization, commit your changes, and push them."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#ae-01-meet-the-penguins",
    "href": "slides/02-grammar-of-data-visualization.html#ae-01-meet-the-penguins",
    "title": "Grammar of data visualization",
    "section": "ae-01-meet-the-penguins",
    "text": "ae-01-meet-the-penguins\n\nGo to RStudio, confirm that you’re in the ae project, and open the document ae-01-meet-the-penguins.qmd."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#tour-recap-quarto",
    "href": "slides/02-grammar-of-data-visualization.html#tour-recap-quarto",
    "title": "Grammar of data visualization",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#tour-recap-git-github",
    "href": "slides/02-grammar-of-data-visualization.html#tour-recap-git-github",
    "title": "Grammar of data visualization",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\nOnce we made changes to our Quarto document, we\n\nwent to the Git pane in RStudio\nstaged our changes by clicking the checkboxes next to the relevant files\ncommitted our changes with an informative commit message\n\npushed our changes to our application exercise repos\n\nif this failed, we pulled first to get the new application exercise files, and then pushed\n\n\nconfirmed on GitHub that we could see our changes pushed from RStudio"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#how-will-we-use-quarto",
    "href": "slides/02-grammar-of-data-visualization.html#how-will-we-use-quarto",
    "title": "Grammar of data visualization",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise, lab, project, etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#un-votes",
    "href": "slides/02-grammar-of-data-visualization.html#un-votes",
    "title": "Grammar of data visualization",
    "section": "UN Votes",
    "text": "UN Votes\n\nRemember this visualization from the videos?"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#let-see",
    "href": "slides/02-grammar-of-data-visualization.html#let-see",
    "title": "Grammar of data visualization",
    "section": "Let’ see…",
    "text": "Let’ see…\n\nhow the sausage is made!"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#load-packages",
    "href": "slides/02-grammar-of-data-visualization.html#load-packages",
    "title": "Grammar of data visualization",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(unvotes)\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#prepare-the-data",
    "href": "slides/02-grammar-of-data-visualization.html#prepare-the-data",
    "title": "Grammar of data visualization",
    "section": "Prepare the data",
    "text": "Prepare the data\n\nus_uk_tr_votes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\") |&gt;\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n  mutate(year = year(date)) |&gt;\n  group_by(country, year, issue) |&gt;\n  summarize(percent_yes = mean(vote == \"yes\"), .groups = \"drop\")\n\n\n\n\n\n\n\n\nNote\n\n\nLet’s leave these details aside for a bit, we’ll revisit this code at a later point in the semester. For now, let’s agree that we need to do some “data wrangling” to get the data into the right format for the plot we want to create. Just note that we called the data frame we’ll visualize us_uk_tr_votes."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#visualize-the-data",
    "href": "slides/02-grammar-of-data-visualization.html#visualize-the-data",
    "title": "Grammar of data visualization",
    "section": "Visualize the data",
    "text": "Visualize the data\n\nggplot(\n  us_uk_tr_votes, \n  mapping = aes(x = year, y = percent_yes, color = country)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  labs(\n    x = \"Year\", \n    y = \"% yes\", \n    color = \"Country\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#visualize-the-data-output",
    "href": "slides/02-grammar-of-data-visualization.html#visualize-the-data-output",
    "title": "Grammar of data visualization",
    "section": "Visualize the data",
    "text": "Visualize the data"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-1.-prepare-a-canvas-for-plotting",
    "href": "slides/02-grammar-of-data-visualization.html#step-1.-prepare-a-canvas-for-plotting",
    "title": "Grammar of data visualization",
    "section": "Step 1. Prepare a canvas for plotting",
    "text": "Step 1. Prepare a canvas for plotting\n\nggplot(data = us_uk_tr_votes)"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-2.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#step-2.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 2. Map variables to aesthetics",
    "text": "Step 2. Map variables to aesthetics\nMap year to the x aesthetic\n\nggplot(data = us_uk_tr_votes, mapping = aes(x = year))"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-3.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#step-3.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 3. Map variables to aesthetics",
    "text": "Step 3. Map variables to aesthetics\nMap percent_yes to the y aesthetic\n\nggplot(data = us_uk_tr_votes, mapping = aes(x = year, y = percent_yes))"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#mapping-and-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#mapping-and-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Mapping and aesthetics",
    "text": "Mapping and aesthetics\n\nAesthetics are visual properties of a plot\nIn the grammar of graphics, variables from the data frame are mapped to aesthetics"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#argument-names",
    "href": "slides/02-grammar-of-data-visualization.html#argument-names",
    "title": "Grammar of data visualization",
    "section": "Argument names",
    "text": "Argument names\nIt’s common practice in R to omit the names of first two arguments of a function:\n\n\nInstead of\n\nggplot(data = us_uk_tr_votes, mapping = aes(x = year, y = percent_yes))\n\nUse\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes))"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-4.-represent-data-on-your-canvas",
    "href": "slides/02-grammar-of-data-visualization.html#step-4.-represent-data-on-your-canvas",
    "title": "Grammar of data visualization",
    "section": "Step 4. Represent data on your canvas",
    "text": "Step 4. Represent data on your canvas\nwith a geom\n\nggplot(us_uk_tr_votes, mapping = aes(x = year, y = percent_yes)) +\n  geom_point()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-5.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#step-5.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 5. Map variables to aesthetics",
    "text": "Step 5. Map variables to aesthetics\nMap country to the color aesthetic\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-6.-represent-data-on-your-canvas",
    "href": "slides/02-grammar-of-data-visualization.html#step-6.-represent-data-on-your-canvas",
    "title": "Grammar of data visualization",
    "section": "Step 6. Represent data on your canvas",
    "text": "Step 6. Represent data on your canvas\nwith another geom\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#warnings-and-messages",
    "href": "slides/02-grammar-of-data-visualization.html#warnings-and-messages",
    "title": "Grammar of data visualization",
    "section": "Warnings and messages",
    "text": "Warnings and messages\n\nAdding geom_smooth() resulted in the following warning:\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nIt tells us the type of smoothing ggplot2 does under the hood when drawing the smooth curves that represent trends for each country.\n\n\n\n\nGoing forward we’ll suppress this warning to save some space."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-7.-split-plot-into-facets",
    "href": "slides/02-grammar-of-data-visualization.html#step-7.-split-plot-into-facets",
    "title": "Grammar of data visualization",
    "section": "Step 7. Split plot into facets",
    "text": "Step 7. Split plot into facets\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~issue)"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-8.-use-a-different-color-scale",
    "href": "slides/02-grammar-of-data-visualization.html#step-8.-use-a-different-color-scale",
    "title": "Grammar of data visualization",
    "section": "Step 8. Use a different color scale",
    "text": "Step 8. Use a different color scale\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~issue) +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-10.-apply-a-different-theme",
    "href": "slides/02-grammar-of-data-visualization.html#step-10.-apply-a-different-theme",
    "title": "Grammar of data visualization",
    "section": "Step 10. Apply a different theme",
    "text": "Step 10. Apply a different theme\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  theme_minimal()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-11.-add-labels",
    "href": "slides/02-grammar-of-data-visualization.html#step-11.-add-labels",
    "title": "Grammar of data visualization",
    "section": "Step 11. Add labels",
    "text": "Step 11. Add labels\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  theme_minimal() +\n  labs(x = \"Year\", y = \"% yes\", color = \"Country\")"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-12.-set-transparency-of-points",
    "href": "slides/02-grammar-of-data-visualization.html#step-12.-set-transparency-of-points",
    "title": "Grammar of data visualization",
    "section": "Step 12. Set transparency of points",
    "text": "Step 12. Set transparency of points\nwith alpha\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth() +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  theme_minimal() +\n  labs(x = \"Year\", y = \"% yes\", color = \"Country\")"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-13.-hide-standard-errors-of-curves",
    "href": "slides/02-grammar-of-data-visualization.html#step-13.-hide-standard-errors-of-curves",
    "title": "Grammar of data visualization",
    "section": "Step 13. Hide standard errors of curves",
    "text": "Step 13. Hide standard errors of curves\nwith se = FALSE\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  theme_minimal() +\n  labs(x = \"Year\", y = \"% yes\", color = \"Country\")"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#grammar-of-graphics",
    "href": "slides/02-grammar-of-data-visualization.html#grammar-of-graphics",
    "title": "Grammar of data visualization",
    "section": "Grammar of graphics",
    "text": "Grammar of graphics\n\n\nWe built a plot layer-by-layer\n\njust like described in the book The Grammar of Graphics and\nimplemented in the ggplot2 package, the data visualization package of the tidyverse."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#ae-02-bechdel-dataviz",
    "href": "slides/02-grammar-of-data-visualization.html#ae-02-bechdel-dataviz",
    "title": "Grammar of data visualization",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#recap",
    "href": "slides/02-grammar-of-data-visualization.html#recap",
    "title": "Grammar of data visualization",
    "section": "Recap",
    "text": "Recap\n\nConstruct plots with ggplot().\nLayers of ggplots are separated by +s.\nThe formula is (almost) always as follows:\n\n\nggplot(DATA, aes(x = X-VAR, y = Y-VAR, ...)) +\n  geom_XXX()"
  },
  {
    "objectID": "slides/12-language-models.html#while-you-wait",
    "href": "slides/12-language-models.html#while-you-wait",
    "title": "The language of models",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-09-modeling-fish.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/12-language-models.html#we-can-dream",
    "href": "slides/12-language-models.html#we-can-dream",
    "title": "The language of models",
    "section": "We can dream",
    "text": "We can dream"
  },
  {
    "objectID": "slides/12-language-models.html#anyone-want-to-argue",
    "href": "slides/12-language-models.html#anyone-want-to-argue",
    "title": "The language of models",
    "section": "Anyone want to argue?",
    "text": "Anyone want to argue?"
  },
  {
    "objectID": "slides/12-language-models.html#nailed-it",
    "href": "slides/12-language-models.html#nailed-it",
    "title": "The language of models",
    "section": "Nailed it",
    "text": "Nailed it"
  },
  {
    "objectID": "slides/12-language-models.html#work-on-the-ears-please",
    "href": "slides/12-language-models.html#work-on-the-ears-please",
    "title": "The language of models",
    "section": "Work on the ears please",
    "text": "Work on the ears please"
  },
  {
    "objectID": "slides/12-language-models.html#staaahp",
    "href": "slides/12-language-models.html#staaahp",
    "title": "The language of models",
    "section": "Staaahp",
    "text": "Staaahp"
  },
  {
    "objectID": "slides/12-language-models.html#no",
    "href": "slides/12-language-models.html#no",
    "title": "The language of models",
    "section": "No",
    "text": "No"
  },
  {
    "objectID": "slides/12-language-models.html#third-place-alex-brady",
    "href": "slides/12-language-models.html#third-place-alex-brady",
    "title": "The language of models",
    "section": "Third place: Alex Brady",
    "text": "Third place: Alex Brady\n\nggplot(mtcars, aes(x = wt, y = mpg, shape = factor(vs), color = factor(vs))) +\n  geom_point(size = 10, stroke = 5, alpha = 0.5) + \n  geom_smooth(size = 5) +\n  labs(\n    x = \"WEIGHT (1000 LBS)!!!IN OUNCES!!!?;)))\",\n    y = \"MPG?????? (MeTeRs pER gALLoN)!\",\n    title = \"~~~Weight vs MPG vs Engine Type of CARS!!!!&gt;&lt;%&#!~~~\",\n    shape = \"ugly engine type :(\",\n    color = \"Engine Thingy\"\n  ) +\n  scale_shape_manual(\n    values = c(0, 15),  \n    labels = c(\"V-SHAPED?!\", \"STRAIGHT??!!\")\n  ) +\n  scale_color_manual(\n    values = c(\"hotpink\", \"limegreen\"),\n    labels = c(\"HONK HONK\", \"BEEP BEEP\")\n  ) +\n    annotate(\"text\", x = 3, y = 25, label = \"VROOOOOOOMM!!!M!!!!!!!!!!!!!!\", \n             color = \"red\", size = 10, angle = 34) +\n  theme(\n       legend.position = \"bottom\",\n       legend.background = element_rect(fill = \"yellow\", color = \"red\"))"
  },
  {
    "objectID": "slides/12-language-models.html#second-place-jack-yi",
    "href": "slides/12-language-models.html#second-place-jack-yi",
    "title": "The language of models",
    "section": "Second place: Jack Yi",
    "text": "Second place: Jack Yi\n\nnew_mtcars &lt;- mtcars |&gt;\n  mutate(\n    am = as.character(am),\n    vs = as.character(vs)\n  )\nggplot(new_mtcars, aes(x = wt,\n                       y = mpg,\n                       shape = vs,\n                       linewidth = 69,\n                       label = \"i love john zito\"\n                       )\n  ) +\n  xlim(-1.1231, 5.384781472) +\n  ylim(-5.128312, 49.172836) +\n  geom_point(color = \"green3\") +\n  geom_line(color = \"pink3\") +\n  geom_area(color = \"brown4\") +\n  geom_quantile(linewidth = 2, color = \"yellow4\") +\n  geom_text(\n    size = new_mtcars$wt,\n    angle = new_mtcars$disp,\n    color = new_mtcars$hp\n  ) +\n  labs(\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\",\n  ) +\n  theme_void()"
  },
  {
    "objectID": "slides/12-language-models.html#first-place-jules-gates",
    "href": "slides/12-language-models.html#first-place-jules-gates",
    "title": "The language of models",
    "section": "First place: Jules Gates",
    "text": "First place: Jules Gates\n\nimg &lt;- readJPEG(\"images/12/images.jpeg\")\n\nfixed_mtcars &lt;- mtcars |&gt;\n  mutate(\n    am = factor(am, labels = c(\"Automatic\", \"Manual\")),\n    am = fct_relevel(am, \"Manual\", \"Automatic\"),\n    vs = factor(vs, labels = c(\"V-shaped\", \"Straight\")),\n    signs_m = ifelse(vs == \"V-shaped\", \"■ ■ ■\", \"■ ■ ■\")\n  )\n\nggplot(fixed_mtcars, aes(x = wt, y = mpg, color = am)) +\n  annotation_raster(img, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf) +\n  geom_text(aes(label = signs_m), size = 15) +\n  labs(\n    title = \"1v1 car weight and fuel efficiency\n    for various smurfmobiles\",\n    x = \"Weight (in mushroom houses)\",\n    y = \"Gallons (milk)\",\n    color = \"Transmission\"\n  ) +\n  scale_color_manual(\n    values = c(\"Automatic\" = \"blue\", \"Manual\" = \"blue\")\n  )  +\n  theme(\n    legend.position = \"top\",\n    plot.background = element_rect(fill = \"transparent\", color = NA),\n    text = element_text(size = 50, color = \"blue\")\n  )"
  },
  {
    "objectID": "slides/12-language-models.html#goals",
    "href": "slides/12-language-models.html#goals",
    "title": "The language of models",
    "section": "Goals",
    "text": "Goals\n\nWhat is a model?\nWhy do we model?\nWhat is correlation?"
  },
  {
    "objectID": "slides/12-language-models.html#lets-drive-a-tesla",
    "href": "slides/12-language-models.html#lets-drive-a-tesla",
    "title": "The language of models",
    "section": "Let’s drive a Tesla!",
    "text": "Let’s drive a Tesla!"
  },
  {
    "objectID": "slides/12-language-models.html#semi-or-garage",
    "href": "slides/12-language-models.html#semi-or-garage",
    "title": "The language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\ni love how Tesla thinks the wall in my garage is a semi. 😅\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/12-language-models.html#semi-or-garage-1",
    "href": "slides/12-language-models.html#semi-or-garage-1",
    "title": "The language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\nNew owner here. Just parked in my garage. Tesla thinks I crashed onto a semi.\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/12-language-models.html#car-or-trash",
    "href": "slides/12-language-models.html#car-or-trash",
    "title": "The language of models",
    "section": "Car or trash?",
    "text": "Car or trash?\n\nTesla calls Mercedes trash\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/12-language-models.html#leisure-commute-physical-activity-and-bp",
    "href": "slides/12-language-models.html#leisure-commute-physical-activity-and-bp",
    "title": "The language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\n\nRelation Between Leisure Time, Commuting, and Occupational Physical Activity With Blood Pressure in 125,402 Adults: The Lifelines Cohort\nByambasukh, Oyuntugs, Harold Snieder, and Eva Corpeleijn. “Relation between leisure time, commuting, and occupational physical activity with blood pressure in 125 402 adults: the lifelines cohort.” Journal of the American Heart Association 9.4 (2020): e014313."
  },
  {
    "objectID": "slides/12-language-models.html#leisure-commute-physical-activity-and-bp-1",
    "href": "slides/12-language-models.html#leisure-commute-physical-activity-and-bp-1",
    "title": "The language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\nBackground: Whether all domains of daily‐life moderate‐to‐vigorous physical activity (MVPA) are associated with lower blood pressure (BP) and how this association depends on age and body mass index remains unclear.\nMethods and Results: In the population‐based Lifelines cohort (N=125,402), MVPA was assessed by the Short Questionnaire to Assess Health‐Enhancing Physical Activity, a validated questionnaire in different domains such as commuting, leisure‐time, and occupational PA. BP was assessed using the last 3 of 10 measurements after 10 minutes’ rest in the supine position. Hypertension was defined as systolic BP ≥140 mm Hg and/or diastolic BP ≥90 mm Hg and/or use of antihypertensives. In regression analysis, higher commuting and leisure‐time but not occupational MVPA related to lower BP and lower hypertension risk. Commuting‐and‐leisure‐time MVPA was associated with BP in a dose‐dependent manner. β Coefficients (95% CI) from linear regression analyses were −1.64 (−2.03 to −1.24), −2.29 (−2.68 to −1.90), and finally −2.90 (−3.29 to −2.50) mm Hg systolic BP for the low, middle, and highest tertile of MVPA compared with “No MVPA” as the reference group after adjusting for age, sex, education, smoking and alcohol use. Further adjustment for body mass index attenuated the associations by 30% to 50%, but more MVPA remained significantly associated with lower BP and lower risk of hypertension. This association was age dependent. β Coefficients (95% CI) for the highest tertiles of commuting‐and‐leisure‐time MVPA were −1.67 (−2.20 to −1.15), −3.39 (−3.94 to −2.82) and −4.64 (−6.15 to −3.14) mm Hg systolic BP in adults &lt;40, 40 to 60, and &gt;60 years, respectively.\nConclusions: Higher commuting and leisure‐time but not occupational MVPA were significantly associated with lower BP and lower hypertension risk at all ages, but these associations were stronger in older adults."
  },
  {
    "objectID": "slides/12-language-models.html#modeling-cars",
    "href": "slides/12-language-models.html#modeling-cars",
    "title": "The language of models",
    "section": "Modeling cars",
    "text": "Modeling cars\n\n\nWhat is the relationship between cars’ weights and their mileage?\nWhat is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/12-language-models.html#modelling-cars",
    "href": "slides/12-language-models.html#modelling-cars",
    "title": "The language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nDescribe: What is the relationship between cars’ weights and their mileage?"
  },
  {
    "objectID": "slides/12-language-models.html#modelling-cars-1",
    "href": "slides/12-language-models.html#modelling-cars-1",
    "title": "The language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nPredict: What is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/12-language-models.html#modelling",
    "href": "slides/12-language-models.html#modelling",
    "title": "The language of models",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but there are many many other types of models too!)"
  },
  {
    "objectID": "slides/12-language-models.html#modelling-vocabulary",
    "href": "slides/12-language-models.html#modelling-vocabulary",
    "title": "The language of models",
    "section": "Modelling vocabulary",
    "text": "Modelling vocabulary\n\nPredictor (explanatory variable)\nOutcome (response variable)\nRegression line\n\nSlope\nIntercept\n\n\nCorrelation"
  },
  {
    "objectID": "slides/12-language-models.html#predictor-explanatory-variable",
    "href": "slides/12-language-models.html#predictor-explanatory-variable",
    "title": "The language of models",
    "section": "Predictor (explanatory variable)",
    "text": "Predictor (explanatory variable)\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/12-language-models.html#outcome-response-variable",
    "href": "slides/12-language-models.html#outcome-response-variable",
    "title": "The language of models",
    "section": "Outcome (response variable)",
    "text": "Outcome (response variable)\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/12-language-models.html#regression-line",
    "href": "slides/12-language-models.html#regression-line",
    "title": "The language of models",
    "section": "Regression line",
    "text": "Regression line"
  },
  {
    "objectID": "slides/12-language-models.html#regression-line-slope",
    "href": "slides/12-language-models.html#regression-line-slope",
    "title": "The language of models",
    "section": "Regression line: slope",
    "text": "Regression line: slope"
  },
  {
    "objectID": "slides/12-language-models.html#regression-line-intercept",
    "href": "slides/12-language-models.html#regression-line-intercept",
    "title": "The language of models",
    "section": "Regression line: intercept",
    "text": "Regression line: intercept"
  },
  {
    "objectID": "slides/12-language-models.html#correlation",
    "href": "slides/12-language-models.html#correlation",
    "title": "The language of models",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "slides/12-language-models.html#correlation-1",
    "href": "slides/12-language-models.html#correlation-1",
    "title": "The language of models",
    "section": "Correlation",
    "text": "Correlation\n\nRanges between -1 and 1.\nSame sign as the slope."
  },
  {
    "objectID": "slides/12-language-models.html#visualizing-the-model",
    "href": "slides/12-language-models.html#visualizing-the-model",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point()"
  },
  {
    "objectID": "slides/12-language-models.html#visualizing-the-model-1",
    "href": "slides/12-language-models.html#visualizing-the-model-1",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() + \n  geom_smooth()"
  },
  {
    "objectID": "slides/12-language-models.html#visualizing-the-model-2",
    "href": "slides/12-language-models.html#visualizing-the-model-2",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() + \n  geom_smooth(method = \"loess\")"
  },
  {
    "objectID": "slides/12-language-models.html#visualizing-the-model-3",
    "href": "slides/12-language-models.html#visualizing-the-model-3",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() + \n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/12-language-models.html#ae-09-modeling-fish",
    "href": "slides/12-language-models.html#ae-09-modeling-fish",
    "title": "The language of models",
    "section": "ae-09-modeling-fish",
    "text": "ae-09-modeling-fish\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-09-modeling-fish.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/10-more-practice.html#midterm-exam-1",
    "href": "slides/10-more-practice.html#midterm-exam-1",
    "title": "More practice",
    "section": "Midterm Exam 1",
    "text": "Midterm Exam 1\n\n\nIn-class (70%)\n\nThursday February 20 11:45 AM - 1:00 PM;\nAll multiple choice;\nYou should have gotten an email about room assignment;\n8.5” x 11” cheat sheet.\n\n\n\nTake-home (30%)\n\nReleased Thursday February 20 at 1:00 PM;\nDue Monday February 24 at 8:30 AM.\nBasically a mini lab;\nOpen resource (citation policies apply);\nNo collaboration.\n\n\n\nSee slides from 2/11 for more details."
  },
  {
    "objectID": "slides/10-more-practice.html#code-smell",
    "href": "slides/10-more-practice.html#code-smell",
    "title": "More practice",
    "section": "Code smell",
    "text": "Code smell\n\nOne way to look at smells is with respect to principles and quality: “Smells are certain structures in the code that indicate violation of fundamental design principles and negatively impact design quality”. Code smells are usually not bugs; they are not technically incorrect and do not prevent the program from functioning. Instead, they indicate weaknesses in design that may slow down development or increase the risk of bugs or failures in the future.\n\n\n\n\nSource: Code smell on Wikipedia"
  },
  {
    "objectID": "slides/10-more-practice.html#code-style",
    "href": "slides/10-more-practice.html#code-style",
    "title": "More practice",
    "section": "Code style",
    "text": "Code style\nFollow the Tidyverse style guide:\n\nSpaces before and line breaks after each + when building a ggplot\nSpaces before and line breaks after each |&gt; in a data transformation pipeline,\nProper indentation\nSpaces around = signs and spaces after commas\nLines should not span more than 80 characters, long lines should be broken up with each argument on its own line"
  },
  {
    "objectID": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks",
    "href": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks",
    "title": "More practice",
    "section": "Quotes VS no quotes VS backticks",
    "text": "Quotes VS no quotes VS backticks\n\n\ndf &lt;- tibble(\n  x = c(-2, -0.5, 0.5, 1, 2),\n  `2011` = c(-2, -0.5, 0.5, 1, 2)\n)\ndf\n\n# A tibble: 5 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  -2     -2  \n2  -0.5   -0.5\n3   0.5    0.5\n4   1      1  \n5   2      2"
  },
  {
    "objectID": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks-1",
    "href": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks-1",
    "title": "More practice",
    "section": "Quotes VS no quotes VS backticks",
    "text": "Quotes VS no quotes VS backticks\n\ndf &lt;- tibble(\n  x = c(-2, -0.5, 0.5, 1, 2),\n  `2011` = c(-2, -0.5, 0.5, 1, 2)\n)\n\nReferencing a column in a pipeline:\n\n\n\ndf |&gt;\n  filter(\"x\" &gt; 0)\n\n# A tibble: 5 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  -2     -2  \n2  -0.5   -0.5\n3   0.5    0.5\n4   1      1  \n5   2      2  \n\n\n\"x\" means the literal character string.\n\n\n\ndf |&gt;\n  filter(x &gt; 0)\n\n# A tibble: 3 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1   0.5    0.5\n2   1      1  \n3   2      2  \n\n\nx means the column name in df.\n\n\n\ndf |&gt;\n  filter(`x` &gt; 0)\n\n# A tibble: 3 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1   0.5    0.5\n2   1      1  \n3   2      2  \n\n\n`x` also means the column name in df."
  },
  {
    "objectID": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks-2",
    "href": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks-2",
    "title": "More practice",
    "section": "Quotes VS no quotes VS backticks",
    "text": "Quotes VS no quotes VS backticks\n\ndf &lt;- tibble(\n  x = c(-2, -0.5, 0.5, 1, 2),\n  `2011` = c(-2, -0.5, 0.5, 1, 2)\n)\n\nReferencing a column in a pipeline:\n\n\n\ndf |&gt;\n  filter(\"2011\" &gt; 0)\n\n# A tibble: 5 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  -2     -2  \n2  -0.5   -0.5\n3   0.5    0.5\n4   1      1  \n5   2      2  \n\n\n\"2011\" means the literal character string.\n\n\n\ndf |&gt;\n  filter(2011 &gt; 0)\n\n# A tibble: 5 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  -2     -2  \n2  -0.5   -0.5\n3   0.5    0.5\n4   1      1  \n5   2      2  \n\n\n2011 means the literal number.\n\n\n\ndf |&gt;\n  filter(`2011` &gt; 0)\n\n# A tibble: 3 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1   0.5    0.5\n2   1      1  \n3   2      2  \n\n\n`2011` means the column name in df."
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of",
    "href": "slides/10-more-practice.html#why-in-instead-of",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\n\nConsider adding a season column:\n\ndurham_climate\n\n# A tibble: 12 × 4\n   month     avg_high_f avg_low_f precipitation_in\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n 1 January           49        28             4.45\n 2 February          53        29             3.7 \n 3 March             62        37             4.69\n 4 April             71        46             3.43\n 5 May               79        56             4.61\n 6 June              85        65             4.02\n 7 July              89        70             3.94\n 8 August            87        68             4.37\n 9 September         81        60             4.37\n10 October           71        47             3.7 \n11 November          62        37             3.39\n12 December          53        30             3.43"
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of-1",
    "href": "slides/10-more-practice.html#why-in-instead-of-1",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\nConsider adding a season column:\n\ndurham_climate |&gt;\n  mutate(\n    season = if_else(\n      month ????? c(\"December\", \"January\", \"February\"),\n      \"Winter\",\n      \"Not Winter\"\n    )\n  )"
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of-2",
    "href": "slides/10-more-practice.html#why-in-instead-of-2",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\nConsider adding a season column:\n\ndurham_climate |&gt;\n  mutate(\n    season = if_else(\n      month %in% c(\"December\", \"January\", \"February\"),\n      \"Winter\",\n      \"Not Winter\"\n    )\n  )\n\n# A tibble: 12 × 5\n   month     avg_high_f avg_low_f precipitation_in season    \n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;     \n 1 January           49        28             4.45 Winter    \n 2 February          53        29             3.7  Winter    \n 3 March             62        37             4.69 Not Winter\n 4 April             71        46             3.43 Not Winter\n 5 May               79        56             4.61 Not Winter\n 6 June              85        65             4.02 Not Winter\n 7 July              89        70             3.94 Not Winter\n 8 August            87        68             4.37 Not Winter\n 9 September         81        60             4.37 Not Winter\n10 October           71        47             3.7  Not Winter\n11 November          62        37             3.39 Not Winter\n12 December          53        30             3.43 Winter"
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of-3",
    "href": "slides/10-more-practice.html#why-in-instead-of-3",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\nConsider adding a season column:\n\ndurham_climate |&gt;\n  mutate(\n    season = if_else(\n      month == c(\"December\", \"January\", \"February\"),\n      \"Winter\",\n      \"Not Winter\"\n    )\n  )\n\n# A tibble: 12 × 5\n   month     avg_high_f avg_low_f precipitation_in season    \n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;     \n 1 January           49        28             4.45 Not Winter\n 2 February          53        29             3.7  Not Winter\n 3 March             62        37             4.69 Not Winter\n 4 April             71        46             3.43 Not Winter\n 5 May               79        56             4.61 Not Winter\n 6 June              85        65             4.02 Not Winter\n 7 July              89        70             3.94 Not Winter\n 8 August            87        68             4.37 Not Winter\n 9 September         81        60             4.37 Not Winter\n10 October           71        47             3.7  Not Winter\n11 November          62        37             3.39 Not Winter\n12 December          53        30             3.43 Not Winter"
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of-4",
    "href": "slides/10-more-practice.html#why-in-instead-of-4",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\n\n\"January\" == c(\"December\", \"January\", \"February\")\n\n[1] FALSE  TRUE FALSE\n\n\"January\" %in% c(\"December\", \"January\", \"February\")\n\n[1] TRUE\n\n\n\n\n\n\n\n\nPunchline\n\n\nInside if_else or case_when your condition needs to result in a single value of TRUE or FALSE for each row. If it results in multiple values of TRUE/FALSE (a vector of TRUE/FALSE), you will not necessarily get an error or even a warning, but unexpected things could happen."
  },
  {
    "objectID": "slides/10-more-practice.html#task-1-prettifying-the-plot-from-ae-07",
    "href": "slides/10-more-practice.html#task-1-prettifying-the-plot-from-ae-07",
    "title": "More practice",
    "section": "Task 1: Prettifying the plot from ae-07",
    "text": "Task 1: Prettifying the plot from ae-07\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) + \n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#things-to-change",
    "href": "slides/10-more-practice.html#things-to-change",
    "title": "More practice",
    "section": "Things to change",
    "text": "Things to change\n\n\nReorder the months chronologically;\nFill the circles with season-specific colors;\nAdd a legend for these colors to the top of the plot;\nMake sure the legend is ordered chronologically by season."
  },
  {
    "objectID": "slides/10-more-practice.html#why-group-1",
    "href": "slides/10-more-practice.html#why-group-1",
    "title": "More practice",
    "section": "0. Why group = 1?",
    "text": "0. Why group = 1?\nWith it:\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#why-group-1-1",
    "href": "slides/10-more-practice.html#why-group-1-1",
    "title": "More practice",
    "section": "0. Why group = 1?",
    "text": "0. Why group = 1?\nWithout it (even though I have geom_line!):\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#why-group-1-2",
    "href": "slides/10-more-practice.html#why-group-1-2",
    "title": "More practice",
    "section": "0. Why group = 1?",
    "text": "0. Why group = 1?\nDon’t need group for numerical vs numerical:\n\nggplot(\n  durham_climate, \n  aes(x = avg_low_f, y = avg_high_f)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Average low temperature (F)\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#why-group-1-3",
    "href": "slides/10-more-practice.html#why-group-1-3",
    "title": "More practice",
    "section": "0. Why group = 1?",
    "text": "0. Why group = 1?\nDo need group for categorical vs numerical:\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#reorder-the-months-chronologically",
    "href": "slides/10-more-practice.html#reorder-the-months-chronologically",
    "title": "More practice",
    "section": "1. Reorder the months chronologically",
    "text": "1. Reorder the months chronologically\n\ndurham_climate |&gt;\n  mutate(\n    month = fct_relevel(month, month.name)\n  ) |&gt;\n  ggplot(\n    aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#fill-the-circles-with-season-specific-colors",
    "href": "slides/10-more-practice.html#fill-the-circles-with-season-specific-colors",
    "title": "More practice",
    "section": "2. Fill the circles with season-specific colors",
    "text": "2. Fill the circles with season-specific colors\n\ndurham_climate |&gt;\n  mutate(\n    month = fct_relevel(month, month.name),\n    season = case_when(\n      month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      month %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n      month %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n      month %in% c(\"September\", \"October\", \"November\") ~ \"Fall\",\n    )\n  ) |&gt;\n  ggplot(\n    aes(x = month, y = avg_high_f, group = 1)\n    ) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 4,\n    color = \"black\", stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) + \n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#add-legend-for-season-to-top-of-plot",
    "href": "slides/10-more-practice.html#add-legend-for-season-to-top-of-plot",
    "title": "More practice",
    "section": "3. Add legend for season to top of plot",
    "text": "3. Add legend for season to top of plot\n\ndurham_climate |&gt;\n  mutate(\n    month = fct_relevel(month, month.name),\n    season = case_when(\n      month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      month %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n      month %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n      month %in% c(\"September\", \"October\", \"November\") ~ \"Fall\",\n    )\n  ) |&gt;\n  ggplot(\n    aes(x = month, y = avg_high_f, group = 1)\n    ) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 4,\n    color = \"black\", stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) + \n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal() + \n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "slides/10-more-practice.html#order-legend-chronologically",
    "href": "slides/10-more-practice.html#order-legend-chronologically",
    "title": "More practice",
    "section": "4. Order legend chronologically",
    "text": "4. Order legend chronologically\n\ndurham_climate |&gt;\n  mutate(\n    month = fct_relevel(month, month.name),\n    season = case_when(\n      month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      month %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n      month %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n      month %in% c(\"September\", \"October\", \"November\") ~ \"Fall\",\n    ),\n    season = fct_relevel(season, \"Winter\", \"Spring\", \"Summer\", \"Fall\")\n  ) |&gt;\n  ggplot(\n    aes(x = month, y = avg_high_f, group = 1)\n    ) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 4,\n    color = \"black\", stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) + \n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal() + \n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "slides/10-more-practice.html#task-2-pivot-to-replicate-this",
    "href": "slides/10-more-practice.html#task-2-pivot-to-replicate-this",
    "title": "More practice",
    "section": "Task 2: pivot to replicate this…",
    "text": "Task 2: pivot to replicate this…\n\n\n\n\n\n\n\n\nGive it a shot in your ae-07-durham-climate-factors file. And don’t worry about prettification. Just get the two lines correct."
  },
  {
    "objectID": "slides/10-more-practice.html#task-3-recoding-and-writing-to-file",
    "href": "slides/10-more-practice.html#task-3-recoding-and-writing-to-file",
    "title": "More practice",
    "section": "Task 3: recoding and writing to file",
    "text": "Task 3: recoding and writing to file\n\nRead a CSV file\nSplit it into subsets based on features of the data\nWrite out subsets as CSV files\n\nWork on the first part in ae-08-age-gaps-sales-import.qmd."
  },
  {
    "objectID": "slides/10-more-practice.html#age-gap-in-hollywood-relationships",
    "href": "slides/10-more-practice.html#age-gap-in-hollywood-relationships",
    "title": "More practice",
    "section": "Age gap in Hollywood relationships",
    "text": "Age gap in Hollywood relationships\n\n\n\nWhat is the story in this visualization?"
  },
  {
    "objectID": "slides/10-more-practice.html#task-4-reading-in-from-excel-yuck",
    "href": "slides/10-more-practice.html#task-4-reading-in-from-excel-yuck",
    "title": "More practice",
    "section": "Task 4: reading in from excel (yuck!)",
    "text": "Task 4: reading in from excel (yuck!)\n\nUsing readr:\n\nMost commonly: read_csv()\n\nMaybe also: read_tsv(), read_delim(), etc.\n\n\n\n\n\nUsing readxl: read_excel()\n\n\n\n\n\nUsing googlesheets4: read_sheet() – We haven’t covered this in the videos, but might be useful for your projects"
  },
  {
    "objectID": "slides/10-more-practice.html#reading-excel-files",
    "href": "slides/10-more-practice.html#reading-excel-files",
    "title": "More practice",
    "section": "Reading Excel files",
    "text": "Reading Excel files\n\nRead an Excel file with non-tidy data\nTidy it up!\n\nWork on the second part in ae-08-age-gaps-sales-import.qmd."
  },
  {
    "objectID": "slides/10-more-practice.html#sales-data",
    "href": "slides/10-more-practice.html#sales-data",
    "title": "More practice",
    "section": "Sales data",
    "text": "Sales data\n\n\n\nAre these data tidy? Why or why not?"
  },
  {
    "objectID": "slides/10-more-practice.html#sales-data-1",
    "href": "slides/10-more-practice.html#sales-data-1",
    "title": "More practice",
    "section": "Sales data",
    "text": "Sales data\n\nWhat “data moves” do we need to go from the original, non-tidy data to this, tidy one?"
  },
  {
    "objectID": "slides/project-intro-slides.html#final-project",
    "href": "slides/project-intro-slides.html#final-project",
    "title": "STA 199 Final Project",
    "section": "Final Project",
    "text": "Final Project\n\n\nTeams of 4 - 5 pick a dataset and compose an original analysis using the course tools;\nFinal product:\n\nwritten report in Quarto;\nfive minute video presentation."
  },
  {
    "objectID": "slides/project-intro-slides.html#intermediate-graded-deadlines",
    "href": "slides/project-intro-slides.html#intermediate-graded-deadlines",
    "title": "STA 199 Final Project",
    "section": "Intermediate graded deadlines",
    "text": "Intermediate graded deadlines\n\n\nMilestone 1: meet your teams\n\ntoday!\n\nMilestone 2: propose two candidate datasets to work with\n\nFri Mar 07: proposal due\nMon Mar 24: TA returns feedback\n\nMilestone 3: demonstrate progress\n\nFri Apr 04\n\nMilestone 4: give peer review feedback to other teams\n\nMon Apr 14 in lab\n\nMilestone 5: submit final report and video\n\nWednesday April 23\n\n\n\n\n20% of the final course grade altogether."
  },
  {
    "objectID": "slides/project-intro-slides.html#along-the-way-peer-evaluation-of-teammates",
    "href": "slides/project-intro-slides.html#along-the-way-peer-evaluation-of-teammates",
    "title": "STA 199 Final Project",
    "section": "Along the way: peer evaluation of teammates",
    "text": "Along the way: peer evaluation of teammates\n\nPeer eval 1: Fri Feb 28 @ 5PM\nPeer eval 2: Fri Mar 21 @ 5PM\nPeer eval 3: Fri Apr 11 @ 5PM\nPeer eval 4: Mon Apr 28 @ 5PM\n\n\n\n\n\n\n\nNote\n\n\nBe on the look out for emails from TEAMMATES."
  },
  {
    "objectID": "slides/lab-5.html#question-how-do-we-concisely-summarize-the-association-between-two-variables",
    "href": "slides/lab-5.html#question-how-do-we-concisely-summarize-the-association-between-two-variables",
    "title": "Recap: simple linear regression",
    "section": "Question: how do we concisely summarize the association between two variables?",
    "text": "Question: how do we concisely summarize the association between two variables?"
  },
  {
    "objectID": "slides/lab-5.html#answer-simple-linear-regression",
    "href": "slides/lab-5.html#answer-simple-linear-regression",
    "title": "Recap: simple linear regression",
    "section": "Answer: simple linear regression!",
    "text": "Answer: simple linear regression!"
  },
  {
    "objectID": "slides/lab-5.html#answer-simple-linear-regression-1",
    "href": "slides/lab-5.html#answer-simple-linear-regression-1",
    "title": "Recap: simple linear regression",
    "section": "Answer: simple linear regression!",
    "text": "Answer: simple linear regression!\n\nmpg_wt_fit &lt;- linear_reg() |&gt;\n  fit(mpg ~ wt, data = mtcars)\n\ntidy(mpg_wt_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    37.3      1.88      19.9  8.24e-19\n2 wt             -5.34     0.559     -9.56 1.29e-10\n\n\n\\[\n\\widehat{mpg}=37.3 - 5.34\\times weight.\n\\]\nInterpretations\n\nWe predict that a car weighing zero pounds will have 37.28 MPG on average (makes no sense);\nWe predict that a 1000 pound increase in weight in associated with a 5.34 decrease in MGP, on average."
  },
  {
    "objectID": "slides/lab-5.html#why-do-we-care-prediction",
    "href": "slides/lab-5.html#why-do-we-care-prediction",
    "title": "Recap: simple linear regression",
    "section": "Why do we care? Prediction!",
    "text": "Why do we care? Prediction!"
  },
  {
    "objectID": "slides/lab-5.html#why-do-we-care-prediction-1",
    "href": "slides/lab-5.html#why-do-we-care-prediction-1",
    "title": "Recap: simple linear regression",
    "section": "Why do we care? Prediction!",
    "text": "Why do we care? Prediction!\nYou can use the fitted model to generate predictions for yet-to-be-observed subjects:\n\nnew_car &lt;- tibble(\n  wt = 3.5\n)\n\npredict(mpg_wt_fit, new_data = new_car)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1  18.6"
  },
  {
    "objectID": "slides/lab-5.html#does-increasing-the-minimum-wage-decrease-employment",
    "href": "slides/lab-5.html#does-increasing-the-minimum-wage-decrease-employment",
    "title": "Recap: simple linear regression",
    "section": "Does increasing the minimum wage decrease employment?",
    "text": "Does increasing the minimum wage decrease employment?\n\nThis is a hotly debated question in economics and public policy;\nECON 101 logic says that it might: if you make something more expensive (employing people), people do less of it.\nWhat do the actual data say?"
  },
  {
    "objectID": "slides/lab-5.html#classic-study-card-and-krueger-1994-aer",
    "href": "slides/lab-5.html#classic-study-card-and-krueger-1994-aer",
    "title": "Recap: simple linear regression",
    "section": "Classic study: Card and Krueger (1994 AER)",
    "text": "Classic study: Card and Krueger (1994 AER)\n\nIn 1992, NJ raised minimum wage. PA did not;\nFast-food restaurants along the NJ/PA border are probably very similar. Maybe the only difference is the change in wage policy;\nSo PA is like control and NJ is like the treatment;\nIf we compare employment before and after the policy change, maybe we can give the observed differences a causal interpretation. The increase in minimum wage caused employment to go up, down, or stay the same;\nThis is called a natural experiment. It’s a kind of observational study where you get very lucky and “nature” does the experimental control for you."
  },
  {
    "objectID": "slides/lab-5.html#classic-study-card-and-krueger-1994-aer-1",
    "href": "slides/lab-5.html#classic-study-card-and-krueger-1994-aer-1",
    "title": "Recap: simple linear regression",
    "section": "Classic study: Card and Krueger (1994 AER)",
    "text": "Classic study: Card and Krueger (1994 AER)"
  },
  {
    "objectID": "slides/17-logistic.html#while-you-wait",
    "href": "slides/17-logistic.html#while-you-wait",
    "title": "Logistic regression",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-13-spam-filter.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/17-logistic.html#thus-far",
    "href": "slides/17-logistic.html#thus-far",
    "title": "Logistic regression",
    "section": "Thus far…",
    "text": "Thus far…\nWe have been studying regression:\n\nWhat combinations of data types have we seen?\nWhat did the picture look like?"
  },
  {
    "objectID": "slides/17-logistic.html#recap-simple-linear-regression",
    "href": "slides/17-logistic.html#recap-simple-linear-regression",
    "title": "Logistic regression",
    "section": "Recap: simple linear regression",
    "text": "Recap: simple linear regression\nNumerical response and one numerical predictor:"
  },
  {
    "objectID": "slides/17-logistic.html#recap-simple-linear-regression-1",
    "href": "slides/17-logistic.html#recap-simple-linear-regression-1",
    "title": "Logistic regression",
    "section": "Recap: simple linear regression",
    "text": "Recap: simple linear regression\nNumerical response and one categorical predictor (two levels):"
  },
  {
    "objectID": "slides/17-logistic.html#recap-multiple-linear-regression",
    "href": "slides/17-logistic.html#recap-multiple-linear-regression",
    "title": "Logistic regression",
    "section": "Recap: multiple linear regression",
    "text": "Recap: multiple linear regression\nNumerical response; numerical and categorical predictors:"
  },
  {
    "objectID": "slides/17-logistic.html#today-a-binary-response",
    "href": "slides/17-logistic.html#today-a-binary-response",
    "title": "Logistic regression",
    "section": "Today: a binary response",
    "text": "Today: a binary response\n\\[\ny =\n\\begin{cases}\n1 & &&\\text{eg. Yes, Win, True, Heads, Success}\\\\\n0 & &&\\text{eg. No, Lose, False, Tails, Failure}.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/17-logistic.html#who-cares",
    "href": "slides/17-logistic.html#who-cares",
    "title": "Logistic regression",
    "section": "Who cares?",
    "text": "Who cares?\nIf we can model the relationship between predictors (\\(x\\)) and a binary response (\\(y\\)), we can use the model to do a special kind of prediction called classification."
  },
  {
    "objectID": "slides/17-logistic.html#example-is-the-e-mail-spam-or-not",
    "href": "slides/17-logistic.html#example-is-the-e-mail-spam-or-not",
    "title": "Logistic regression",
    "section": "Example: is the e-mail spam or not?",
    "text": "Example: is the e-mail spam or not?\n\\[\n\\mathbf{x}: \\text{word and character counts in an e-mail.}\n\\]\n\n\n\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{it's spam}\\\\\n0 & \\text{it's legit}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/17-logistic.html#example-is-it-cancer-or-not",
    "href": "slides/17-logistic.html#example-is-it-cancer-or-not",
    "title": "Logistic regression",
    "section": "Example: is it cancer or not?",
    "text": "Example: is it cancer or not?\n\\[\n\\mathbf{x}: \\text{features in a medical image.}\n\\]\n\n\n\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{it's cancer}\\\\\n0 & \\text{it's healthy}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/17-logistic.html#example-will-they-default",
    "href": "slides/17-logistic.html#example-will-they-default",
    "title": "Logistic regression",
    "section": "Example: will they default?",
    "text": "Example: will they default?\n\\[\n\\mathbf{x}: \\text{financial and demographic info about a loan applicant.}\n\\]\n\n\n\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{applicant is at risk of defaulting on loan}\\\\\n0 & \\text{applicant is safe}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/17-logistic.html#how-do-we-model-this-type-of-data",
    "href": "slides/17-logistic.html#how-do-we-model-this-type-of-data",
    "title": "Logistic regression",
    "section": "How do we model this type of data?",
    "text": "How do we model this type of data?"
  },
  {
    "objectID": "slides/17-logistic.html#straight-line-of-best-fit-is-a-little-silly",
    "href": "slides/17-logistic.html#straight-line-of-best-fit-is-a-little-silly",
    "title": "Logistic regression",
    "section": "Straight line of best fit is a little silly",
    "text": "Straight line of best fit is a little silly"
  },
  {
    "objectID": "slides/17-logistic.html#instead-s-curve-of-best-fit",
    "href": "slides/17-logistic.html#instead-s-curve-of-best-fit",
    "title": "Logistic regression",
    "section": "Instead: S-curve of best fit",
    "text": "Instead: S-curve of best fit\nInstead of modeling \\(y\\) directly, we model the probability that \\(y=1\\):\n\n\n\n\n\n\n\n\n\n“Given new email, what’s the probability that it’s spam?’’\n“Given new image, what’s the probability that it’s cancer?’’\n“Given new loan application, what’s the probability that they default?’’"
  },
  {
    "objectID": "slides/17-logistic.html#why-dont-we-model-y-directly",
    "href": "slides/17-logistic.html#why-dont-we-model-y-directly",
    "title": "Logistic regression",
    "section": "Why don’t we model y directly?",
    "text": "Why don’t we model y directly?\n\n\nRecall regression with a numerical response:\n\nOur models do not output guarantees for \\(y\\), they output predictions that describe behavior on average;\n\n\n\nSimilar when modeling a binary response:\n\nOur models cannot directly guarantee that \\(y\\) will be zero or one. The correct analog to “on average” for a 0/1 response is “what’s the probability?”"
  },
  {
    "objectID": "slides/17-logistic.html#so-what-is-this-s-curve-anyway",
    "href": "slides/17-logistic.html#so-what-is-this-s-curve-anyway",
    "title": "Logistic regression",
    "section": "So, what is this S-curve, anyway?",
    "text": "So, what is this S-curve, anyway?\nIt’s the logistic function:\n\\[\n\\text{Prob}(y = 1)\n=\n\\frac{e^{\\beta_0+\\beta_1x}}{1+e^{\\beta_0+\\beta_1x}}.\n\\]\nIf you set \\(p = \\text{Prob}(y = 1)\\) and do some algebra, you get the simple linear model for the log-odds:\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x.\n\\]\nThis is called the logistic regression model."
  },
  {
    "objectID": "slides/17-logistic.html#log-odds",
    "href": "slides/17-logistic.html#log-odds",
    "title": "Logistic regression",
    "section": "Log-odds?",
    "text": "Log-odds?\n\n\\(p = \\text{Prob}(y = 1)\\) is a probability. A number between 0 and 1;\n\\(p / (1 - p)\\) is the odds. A number between 0 and \\(\\infty\\);\n\n\n“The odds of this lecture going well are 10 to 1.”\n\n\nThe log odds \\(\\log(p / (1 - p))\\) is a number between \\(-\\infty\\) and \\(\\infty\\), which is suitable for the linear model."
  },
  {
    "objectID": "slides/17-logistic.html#probability-to-odds",
    "href": "slides/17-logistic.html#probability-to-odds",
    "title": "Logistic regression",
    "section": "Probability to odds",
    "text": "Probability to odds"
  },
  {
    "objectID": "slides/17-logistic.html#odds-to-log-odds",
    "href": "slides/17-logistic.html#odds-to-log-odds",
    "title": "Logistic regression",
    "section": "Odds to log odds",
    "text": "Odds to log odds"
  },
  {
    "objectID": "slides/17-logistic.html#logistic-regression",
    "href": "slides/17-logistic.html#logistic-regression",
    "title": "Logistic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x.\n\\]\n\nThe logit function \\(\\log(p / (1-p))\\) is an example of a link function that transforms the linear model to have an appropriate range;\nThis is an example of a generalized linear model;"
  },
  {
    "objectID": "slides/17-logistic.html#estimation",
    "href": "slides/17-logistic.html#estimation",
    "title": "Logistic regression",
    "section": "Estimation",
    "text": "Estimation\n\nWe estimate the parameters \\(\\beta_0,\\,\\beta_1\\) using maximum likelihood (don’t worry about it) to get the “best fitting” S-curve;\nThe fitted model is\n\n\\[\n\\log\\left(\\frac{\\widehat{p}}{1-\\widehat{p}}\\right)\n=\nb_0+b_1x.\n\\]"
  },
  {
    "objectID": "slides/17-logistic.html#todays-data",
    "href": "slides/17-logistic.html#todays-data",
    "title": "Logistic regression",
    "section": "Today’s data",
    "text": "Today’s data\n\nemail |&gt; dplyr::select(c(spam, dollar, viagra, winner, password, exclaim_mess)) |&gt; glimpse()\n\nRows: 3,921\nColumns: 6\n$ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       &lt;dbl&gt; 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ password     &lt;dbl&gt; 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ exclaim_mess &lt;dbl&gt; 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…"
  },
  {
    "objectID": "slides/17-logistic.html#fitting-a-logistic-model",
    "href": "slides/17-logistic.html#fitting-a-logistic-model",
    "title": "Logistic regression",
    "section": "Fitting a logistic model",
    "text": "Fitting a logistic model\n\nlogistic_fit &lt;- logistic_reg() |&gt;\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(logistic_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774\n\n\nFitted equation for the log-odds:\n\\[\n\\log\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)\n=\n-2.27\n+\n0.000272\\times exclaim~mess\n\\]"
  },
  {
    "objectID": "slides/17-logistic.html#interpreting-the-intercept",
    "href": "slides/17-logistic.html#interpreting-the-intercept",
    "title": "Logistic regression",
    "section": "Interpreting the intercept",
    "text": "Interpreting the intercept\nIf exclaim_mess = 0, then\n\\[\n\\hat{p}=\\widehat{P(y=1)}=\\frac{e^{-2.27}}{1+e^{-2.27}}\\approx 0.09.\n\\]\nSo, an email with no exclamation marks has a 9% chance of being spam."
  },
  {
    "objectID": "slides/17-logistic.html#interpreting-the-slope-is-tricky",
    "href": "slides/17-logistic.html#interpreting-the-slope-is-tricky",
    "title": "Logistic regression",
    "section": "Interpreting the slope is tricky",
    "text": "Interpreting the slope is tricky\nRecall:\n\\[\n\\log\\left(\\frac{\\widehat{p}}{1-\\widehat{p}}\\right)\n=\nb_0+b_1x.\n\\]\n\nAlternatively:\n\\[\n\\frac{\\widehat{p}}{1-\\widehat{p}}\n=\ne^{b_0+b_1x}\n=\n\\color{blue}{e^{b_0}e^{b_1x}}\n.\n\\]\n\n\nIf we increase \\(x\\) by one unit, we have:\n\\[\n\\frac{\\widehat{p}}{1-\\widehat{p}}\n=\ne^{b_0}e^{b_1(x+1)}\n=\ne^{b_0}e^{b_1x+b_1}\n=\n{\\color{blue}{e^{b_0}e^{b_1x}}}{\\color{red}{e^{b_1}}}\n.\n\\]\n\n\nA one unit increase in \\(x\\) is associated with a change in odds by a factor of \\(e^{b_1}\\). Gross!"
  },
  {
    "objectID": "slides/17-logistic.html#back-to-the-example",
    "href": "slides/17-logistic.html#back-to-the-example",
    "title": "Logistic regression",
    "section": "Back to the example…",
    "text": "Back to the example…\n\\[\n\\log\\left(\\frac{\\hat{p}}{1-\\hat{p}}\\right)\n=\n-2.27\n+\n0.000272\\times exclaim~mess\n\\]\nIf we add one exclamation mark to the model, we predict the odds of an email being spam to be higher by a factor of \\(e^{0.000272}\\approx 1.000272\\) on average."
  },
  {
    "objectID": "slides/17-logistic.html#logistic-regression---classification",
    "href": "slides/17-logistic.html#logistic-regression---classification",
    "title": "Logistic regression",
    "section": "Logistic regression -> classification?",
    "text": "Logistic regression -&gt; classification?"
  },
  {
    "objectID": "slides/17-logistic.html#step-0-fit-the-model",
    "href": "slides/17-logistic.html#step-0-fit-the-model",
    "title": "Logistic regression",
    "section": "Step 0: fit the model",
    "text": "Step 0: fit the model\nSelect a number \\(0 &lt; p^* &lt; 1\\):\n\n\n\n\n\n\n\n\n\nif \\(\\text{Prob}(y=1)\\leq p^*\\), then predict \\(\\widehat{y}=0\\);\nif \\(\\text{Prob}(y=1)&gt; p^*\\), then predict \\(\\widehat{y}=1\\)."
  },
  {
    "objectID": "slides/17-logistic.html#step-1-pick-a-threshold",
    "href": "slides/17-logistic.html#step-1-pick-a-threshold",
    "title": "Logistic regression",
    "section": "Step 1: pick a threshold",
    "text": "Step 1: pick a threshold\nSelect a number \\(0 &lt; p^* &lt; 1\\):\n\n\n\n\n\n\n\n\n\nif \\(\\text{Prob}(y=1)\\leq p^*\\), then predict \\(\\widehat{y}=0\\);\nif \\(\\text{Prob}(y=1)&gt; p^*\\), then predict \\(\\widehat{y}=1\\)."
  },
  {
    "objectID": "slides/17-logistic.html#step-2-find-the-decision-boundary",
    "href": "slides/17-logistic.html#step-2-find-the-decision-boundary",
    "title": "Logistic regression",
    "section": "Step 2: find the “decision boundary”",
    "text": "Step 2: find the “decision boundary”\nSolve for the x-value that matches the threshold:\n\n\n\n\n\n\n\n\n\nif \\(\\text{Prob}(y=1)\\leq p^*\\), then predict \\(\\widehat{y}=0\\);\nif \\(\\text{Prob}(y=1)&gt; p^*\\), then predict \\(\\widehat{y}=1\\)."
  },
  {
    "objectID": "slides/17-logistic.html#step-3-classify-a-new-arrival",
    "href": "slides/17-logistic.html#step-3-classify-a-new-arrival",
    "title": "Logistic regression",
    "section": "Step 3: classify a new arrival",
    "text": "Step 3: classify a new arrival\nA new person shows up with \\(x_{\\text{new}}\\). Which side of the boundary are they on?\n\n\n\n\n\n\n\n\n\nif \\(x_{\\text{new}} \\leq x^\\star\\), then \\(\\text{Prob}(y=1)\\leq p^*\\), so predict \\(\\widehat{y}=0\\) for the new person;\nif \\(x_{\\text{new}} &gt; x^\\star\\), then \\(\\text{Prob}(y=1)&gt; p^*\\), so predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/17-logistic.html#lets-change-the-threshold",
    "href": "slides/17-logistic.html#lets-change-the-threshold",
    "title": "Logistic regression",
    "section": "Let’s change the threshold",
    "text": "Let’s change the threshold\nA new person shows up with \\(x_{\\text{new}}\\). Which side of the boundary are they on?\n\n\n\n\n\n\n\n\n\nif \\(x_{\\text{new}} \\leq x^\\star\\), then \\(\\text{Prob}(y=1)\\leq p^*\\), so predict \\(\\widehat{y}=0\\) for the new person;\nif \\(x_{\\text{new}} &gt; x^\\star\\), then \\(\\text{Prob}(y=1)&gt; p^*\\), so predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/17-logistic.html#lets-change-the-threshold-1",
    "href": "slides/17-logistic.html#lets-change-the-threshold-1",
    "title": "Logistic regression",
    "section": "Let’s change the threshold",
    "text": "Let’s change the threshold\nA new person shows up with \\(x_{\\text{new}}\\). Which side of the boundary are they on?\n\n\n\n\n\n\n\n\n\nif \\(x_{\\text{new}} \\leq x^\\star\\), then \\(\\text{Prob}(y=1)\\leq p^*\\), so predict \\(\\widehat{y}=0\\) for the new person;\nif \\(x_{\\text{new}} &gt; x^\\star\\), then \\(\\text{Prob}(y=1)&gt; p^*\\), so predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/17-logistic.html#nothing-special-about-one-predictor",
    "href": "slides/17-logistic.html#nothing-special-about-one-predictor",
    "title": "Logistic regression",
    "section": "Nothing special about one predictor…",
    "text": "Nothing special about one predictor…\nTwo numerical predictors and one binary response:"
  },
  {
    "objectID": "slides/17-logistic.html#multiple-logistic-regression",
    "href": "slides/17-logistic.html#multiple-logistic-regression",
    "title": "Logistic regression",
    "section": "“Multiple” logistic regression",
    "text": "“Multiple” logistic regression\nOn the probability scale:\n\\[\n\\text{Prob}(y = 1)\n=\n\\frac{e^{\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m}}{1+e^{\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m}}.\n\\]\nFor the log-odds, a multiple linear regression:\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m.\n\\]"
  },
  {
    "objectID": "slides/17-logistic.html#decision-boundary-again",
    "href": "slides/17-logistic.html#decision-boundary-again",
    "title": "Logistic regression",
    "section": "Decision boundary, again",
    "text": "Decision boundary, again\nIt’s linear! Consider two numerical predictors:\n\n\n\n\n\n\n\n\n\nif new \\((x_1,\\,x_2)\\) below, \\(\\text{Prob}(y=1)\\leq p^*\\). Predict \\(\\widehat{y}=0\\) for the new person;\nif new \\((x_1,\\,x_2)\\) above, \\(\\text{Prob}(y=1)&gt; p^*\\). Predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/17-logistic.html#decision-boundary-again-1",
    "href": "slides/17-logistic.html#decision-boundary-again-1",
    "title": "Logistic regression",
    "section": "Decision boundary, again",
    "text": "Decision boundary, again\nIt’s linear! Consider two numerical predictors:\n\n\n\n\n\n\n\n\n\nif new \\((x_1,\\,x_2)\\) below, \\(\\text{Prob}(y=1)\\leq p^*\\). Predict \\(\\widehat{y}=0\\) for the new person;\nif new \\((x_1,\\,x_2)\\) above, \\(\\text{Prob}(y=1)&gt; p^*\\). Predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/17-logistic.html#decision-boundary-again-2",
    "href": "slides/17-logistic.html#decision-boundary-again-2",
    "title": "Logistic regression",
    "section": "Decision boundary, again",
    "text": "Decision boundary, again\nIt’s linear! Consider two numerical predictors:\n\n\n\n\n\n\n\n\n\nif new \\((x_1,\\,x_2)\\) below, \\(\\text{Prob}(y=1)\\leq p^*\\). Predict \\(\\widehat{y}=0\\) for the new person;\nif new \\((x_1,\\,x_2)\\) above, \\(\\text{Prob}(y=1)&gt; p^*\\). Predict \\(\\widehat{y}=1\\) for the new person."
  },
  {
    "objectID": "slides/17-logistic.html#note-the-classifier-isnt-perfect",
    "href": "slides/17-logistic.html#note-the-classifier-isnt-perfect",
    "title": "Logistic regression",
    "section": "Note: the classifier isn’t perfect",
    "text": "Note: the classifier isn’t perfect\n\n\n\n\n\n\n\n\n\nThere are blue points in the orange region: spam (1) emails misclassified as legit (0);\nThere are orange points in the blue region: legit (0) emails misclassified as spam (1)."
  },
  {
    "objectID": "slides/17-logistic.html#how-do-you-pick-the-threshold",
    "href": "slides/17-logistic.html#how-do-you-pick-the-threshold",
    "title": "Logistic regression",
    "section": "How do you pick the threshold?",
    "text": "How do you pick the threshold?\nTo balance out the two kinds of errors:\n\n\nHigh threshold &gt;&gt; Hard to classify as 1 &gt;&gt; FP less likely; FN more likely\nLow threshold &gt;&gt; Easy to classify as 1 &gt;&gt; FP more likely; FN less likely"
  },
  {
    "objectID": "slides/17-logistic.html#silly-examples",
    "href": "slides/17-logistic.html#silly-examples",
    "title": "Logistic regression",
    "section": "Silly examples",
    "text": "Silly examples\n\n\nSet p* = 0\n\nClassify every email as spam (1);\nNo false negatives, but a lot of false positives;\n\n\n\nSet p* = 1\n\nClassify every email as legit (0);\nNo false positives, but a lot of false negatives.\n\n\n\nYou pick a threshold in between to strike a balance. The exact number depends on context."
  },
  {
    "objectID": "slides/17-logistic.html#ae-13-spam-filter",
    "href": "slides/17-logistic.html#ae-13-spam-filter",
    "title": "Logistic regression",
    "section": "ae-13-spam-filter",
    "text": "ae-13-spam-filter\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-13-spam-filter.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#while-you-wait",
    "href": "slides/13-linear-model-single-predictor.html#while-you-wait",
    "title": "Linear models with a single predictor",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-10-modeling-penguins.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#spurious-correlations",
    "href": "slides/13-linear-model-single-predictor.html#spurious-correlations",
    "title": "Linear models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#spurious-correlations-1",
    "href": "slides/13-linear-model-single-predictor.html#spurious-correlations-1",
    "title": "Linear models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#data-prep",
    "href": "slides/13-linear-model-single-predictor.html#data-prep",
    "title": "Linear models with a single predictor",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\n\nRename the dataset as movie_scores\n\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#data-overview",
    "href": "slides/13-linear-model-single-predictor.html#data-overview",
    "title": "Linear models with a single predictor",
    "section": "Data overview",
    "text": "Data overview\n\nmovie_scores |&gt;\n  select(critics, audience)\n\n# A tibble: 146 × 2\n   critics audience\n     &lt;int&gt;    &lt;int&gt;\n 1      74       86\n 2      85       80\n 3      80       90\n 4      18       84\n 5      14       28\n 6      63       62\n 7      42       53\n 8      86       64\n 9      99       82\n10      89       87\n# ℹ 136 more rows"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#data-visualization",
    "href": "slides/13-linear-model-single-predictor.html#data-visualization",
    "title": "Linear models with a single predictor",
    "section": "Data visualization",
    "text": "Data visualization"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#regression-model-1",
    "href": "slides/13-linear-model-single-predictor.html#regression-model-1",
    "title": "Linear models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the outcome, \\(Y\\), and the predictor, \\(X\\).\n\\[\n\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#regression-model",
    "href": "slides/13-linear-model-single-predictor.html#regression-model",
    "title": "Linear models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{#325b74}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{#325b74}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{#325b74}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#simple-linear-regression",
    "href": "slides/13-linear-model-single-predictor.html#simple-linear-regression",
    "title": "Linear models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nUse simple linear regression to model the relationship between a quantitative outcome (\\(Y\\)) and a single quantitative predictor (\\(X\\)): \\[\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}\\]\n\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\epsilon\\): Error (residual)"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#simple-linear-regression-1",
    "href": "slides/13-linear-model-single-predictor.html#simple-linear-regression-1",
    "title": "Linear models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\\[\\Large{\\hat{Y} = b_0 + b_1 X}\\]\n\n\n\\(b_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(b_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\n\nNo error term!"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "href": "slides/13-linear-model-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "title": "Linear models with a single predictor",
    "section": "Choosing values for \\(b_1\\) and \\(b_0\\)\n",
    "text": "Choosing values for \\(b_1\\) and \\(b_0\\)"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#residuals",
    "href": "slides/13-linear-model-single-predictor.html#residuals",
    "title": "Linear models with a single predictor",
    "section": "Residuals",
    "text": "Residuals\n\n\n\n\n\n\n\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}\\]"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#least-squares-line",
    "href": "slides/13-linear-model-single-predictor.html#least-squares-line",
    "title": "Linear models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#least-squares-line-1",
    "href": "slides/13-linear-model-single-predictor.html#least-squares-line-1",
    "title": "Linear models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nmovies_fit &lt;- linear_reg() |&gt;\n  fit(audience ~ critics, data = movie_scores)\n\ntidy(movies_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#properties-of-least-squares-regression",
    "href": "slides/13-linear-model-single-predictor.html#properties-of-least-squares-regression",
    "title": "Linear models with a single predictor",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point (the coordinates corresponding to average \\(X\\) and average \\(Y\\)): \\(b_0 = \\bar{Y} - b_1~\\bar{X}\\)\nSlope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_Y}{s_X}\\)\nSum of the residuals is zero: \\(\\sum_{i = 1}^n \\epsilon_i = 0\\)\nResiduals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#interpreting-slope-intercept",
    "href": "slides/13-linear-model-single-predictor.html#interpreting-slope-intercept",
    "title": "Linear models with a single predictor",
    "section": "Interpreting slope & intercept",
    "text": "Interpreting slope & intercept\n\\[\\widehat{\\text{audience}} = 32.3 + 0.519 \\times \\text{critics}\\]\n\n\n\nSlope: For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\n\nIntercept: If the critics score is 0 points, we expect the audience score to be 32.3 points."
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#is-the-intercept-meaningful",
    "href": "slides/13-linear-model-single-predictor.html#is-the-intercept-meaningful",
    "title": "Linear models with a single predictor",
    "section": "Is the intercept meaningful?",
    "text": "Is the intercept meaningful?\n✅ The intercept is meaningful in context of the data if\n\nthe predictor can feasibly take values equal to or near zero or\nthe predictor has values near zero in the observed data\n\n\n🛑 Otherwise, it might not be meaningful!"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#ae-10-modeling-penguins",
    "href": "slides/13-linear-model-single-predictor.html#ae-10-modeling-penguins",
    "title": "Linear models with a single predictor",
    "section": "ae-10-modeling-penguins",
    "text": "ae-10-modeling-penguins\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-10-modeling-penguins.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#while-you-wait",
    "href": "slides/09-importing-recoding-data.html#while-you-wait",
    "title": "Importing and recoding data",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-08-age-gaps-sales-import.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file.\n\n\n\n\n\n\n\n\nAEs are due by the end of class\n\n\nSuccessful completion means at least one commit + push by 2PM today."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#midterm-exam-1",
    "href": "slides/09-importing-recoding-data.html#midterm-exam-1",
    "title": "Importing and recoding data",
    "section": "Midterm Exam 1",
    "text": "Midterm Exam 1\nWorth 20% of your final grade; consists of two parts:\n\n\nIn-class: worth 70% of the Midterm 1 grade;\n\nThursday February 20 11:45 AM - 1:00 PM\n\n\n\nTake-home: worth 30% of the Midterm 1 grade.\n\nReleased Thursday February 20 at 1:00 PM;\nDue Monday February 24 at 8:30 AM."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#in-class",
    "href": "slides/09-importing-recoding-data.html#in-class",
    "title": "Importing and recoding data",
    "section": "In-class",
    "text": "In-class\n\n\nAll multiple choice;\nYou will take it in Bio Sciences 111 (this room) or Physics 128;\nYou get both sides of one 8.5” x 11” note sheet that you and only you created (written, typed, iPad, etc);\nIf you do better on the final than you do on this, the final exam score will replace this.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nIf you have testing accommodations, make sure I get proper documentation from SDAO and make appointments in the Testing Center by Friday. The appointment should overlap substantially with our class time if possible."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#example-in-class-question",
    "href": "slides/09-importing-recoding-data.html#example-in-class-question",
    "title": "Importing and recoding data",
    "section": "Example in-class question",
    "text": "Example in-class question\nWhich command will replace a pre-existing column in a data frame with a new and improved version of itself?\n\ngroup_by\nsummarize\npivot_wider\ngeom_replace\nmutate"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#example-in-class-question-1",
    "href": "slides/09-importing-recoding-data.html#example-in-class-question-1",
    "title": "Importing and recoding data",
    "section": "Example in-class question",
    "text": "Example in-class question\n\n\n\ndf\n\n# A tibble: 6 × 2\n      x y      \n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 John   \n2     2 John   \n3     3 Cameron\n4     4 Zito   \n5     5 Zito   \n6     6 Zito   \n\n\n\n\ndf |&gt;\n  group_by(y) |&gt;\n  summarize(xbar = mean(x))\n\nHow many rows will this output have?\n\n1\n2\n3\n6\n11"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#example-in-class-question-2",
    "href": "slides/09-importing-recoding-data.html#example-in-class-question-2",
    "title": "Importing and recoding data",
    "section": "Example in-class question",
    "text": "Example in-class question\n\n\nWhich box plot is visualizing the same data as the histogram?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#what-should-i-put-on-my-cheat-sheet",
    "href": "slides/09-importing-recoding-data.html#what-should-i-put-on-my-cheat-sheet",
    "title": "Importing and recoding data",
    "section": "What should I put on my cheat sheet?",
    "text": "What should I put on my cheat sheet?\n\nAsk one of our undergrad TAs! They took the class. I didn’t.\n\n\ndescription of common functions;\ndescription of different visualizations: how to interpret, and what to use when;\ndoodles;\ncute words of affirmation.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nDon’t waste space on the details of any specific applications or datasets we’ve seen (penguins, Bechdel, gerrymandering, midwest, etc). Anything we want you to know about a particular application will be introduced from scratch within the exam."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#take-home",
    "href": "slides/09-importing-recoding-data.html#take-home",
    "title": "Importing and recoding data",
    "section": "Take-home",
    "text": "Take-home\n\n\nIt will be just like a lab, only shorter;\nCompletely open-resource, but citation policies apply;\nAbsolutely no collaboration of any kind;\nSeek help by posting privately on Ed;\nSubmit your final PDF to Gradescope in the usual way."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#reminder-conduct-policies",
    "href": "slides/09-importing-recoding-data.html#reminder-conduct-policies",
    "title": "Importing and recoding data",
    "section": "Reminder: conduct policies",
    "text": "Reminder: conduct policies\n\n\nUncited use of outside resources or inappropriate collaboration will result in a zero and be referred to the conduct office;\nIf a conduct violation of any kind is discovered, your final letter grade in the course will be permanently reduced (A- down to B+, B+ down to B, etc);\nIf folks share solutions, all students involved will be penalized equally, the sharer the same as the recipient.\n\n\n\n\n\n\n\n\n\nIt’s not personal.\n\n\nThese policies apply to everyone. I don’t care who your parents are, or what medical schools you are applying to in the fall. Grow up and act right."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#things-you-can-do-to-study",
    "href": "slides/09-importing-recoding-data.html#things-you-can-do-to-study",
    "title": "Importing and recoding data",
    "section": "Things you can do to study",
    "text": "Things you can do to study\n\n\n\nPractice problems: released Thursday February 13;\n\nAttend lab: review game on Monday February 17;\n\nOld labs: correct parts where you lost points;\n\nOld AEs: complete tasks we didn’t get to and compare with key;\n\nCode along: watch these videos specifically;\n\nTextbook: odd-numbered exercises in the back of Chs. 1, 4, 5, 6."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-and-statistical-thinking",
    "href": "slides/09-importing-recoding-data.html#data-science-and-statistical-thinking",
    "title": "Importing and recoding data",
    "section": "Data science and statistical thinking",
    "text": "Data science and statistical thinking\nBefore Midterm 1…\n\n\nData science: the real-world art of transforming messy, imperfect, incomplete data into knowledge;\n\nAfter Midterm 1…\n\n\nStatistics: the mathematical discipline of quantifying our uncertainty about that knowledge."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science",
    "href": "slides/09-importing-recoding-data.html#data-science",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-1",
    "href": "slides/09-importing-recoding-data.html#data-science-1",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science\n\n\n\nCollection: we won’t seriously study this!\n\n\nfor us: data importing (read_csv), and webscraping (next time);\n\nbut really: domain-specific issues of measurement, survey design, experimental design, etc;"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-collection",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-collection",
    "title": "Importing and recoding data",
    "section": "From last time: data collection",
    "text": "From last time: data collection\nI sent out my lil’ survey with Google Forms, downloaded the responses in a CSV, and read that sucker in:\n\n\n\n&lt;p&gt;Loading…&lt;/p&gt;\n\n\n\nsurvey &lt;- read_csv(\"data/survey-2025-02-06.csv\")\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         How many classes do you have on Tues…¹ `What year are you?`\n   &lt;chr&gt;             &lt;chr&gt;                                  &lt;chr&gt;               \n 1 2/6/2025 11:33:57 3                                      Sophomore           \n 2 2/6/2025 11:37:39 3                                      First-year          \n 3 2/6/2025 11:40:55 2                                      Senior              \n 4 2/6/2025 11:42:05 3                                      First-year          \n 5 2/6/2025 11:42:46 3                                      Senior              \n 6 2/6/2025 11:43:28 3                                      Senior              \n 7 2/6/2025 11:44:41 3                                      First-year          \n 8 2/6/2025 11:44:49 3                                      First-year          \n 9 2/6/2025 11:44:51 2                                      Sophomore           \n10 2/6/2025 11:44:51 3                                      Sophomore           \n# ℹ 199 more rows\n# ℹ abbreviated name: ¹​`How many classes do you have on Tuesdays?`"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-2",
    "href": "slides/09-importing-recoding-data.html#data-science-2",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science\n\n\nCollection: we won’t seriously study this!\n\n\nfor us: data importing (read_csv), and webscraping (next time);\n\nbut really: domain-specific issues of measurement, survey design, experimental design, etc;\n\n\n\n\n\n\nPreparation: cleaning, wrangling, and otherwise tidying the data so we can actually work with it.\n\n\nkeywords: mutate, fct_relevel, pivot_*, *_join"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-preparation",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-preparation",
    "title": "Importing and recoding data",
    "section": "From last time: data preparation",
    "text": "From last time: data preparation\n\nsurvey &lt;- survey |&gt;\n  rename(\n    tue_classes = `How many classes do you have on Tuesdays?`,\n    year = `What year are you?`\n  ) |&gt;\n  mutate(\n    tue_classes = case_when(\n      tue_classes == \"2 -3\" ~ \"3\",\n      tue_classes == \"3 classes\" ~ \"3\",\n      tue_classes == \"Four\" ~ \"4\",\n      tue_classes == \"TWO MANY\" ~ \"2\",\n      tue_classes == \"Three\" ~ \"3\",\n      tue_classes == \"Two\" ~ \"2\",\n      tue_classes == \"Two plus a chemistry lab\" ~ \"3\",\n      tue_classes == \"three\" ~ \"3\",\n      .default = tue_classes\n    ),\n    tue_classes = as.numeric(tue_classes),\n    year = fct_relevel(year, \"First-year\", \"Sophomore\", \"Junior\", \"Senior\")\n  ) |&gt;\n  select(tue_classes, year)\nsurvey\n\n# A tibble: 209 × 2\n   tue_classes year      \n         &lt;dbl&gt; &lt;fct&gt;     \n 1           3 Sophomore \n 2           3 First-year\n 3           2 Senior    \n 4           3 First-year\n 5           3 Senior    \n 6           3 Senior    \n 7           3 First-year\n 8           3 First-year\n 9           2 Sophomore \n10           3 Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-3",
    "href": "slides/09-importing-recoding-data.html#data-science-3",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science\n\n\nCollection: we won’t seriously study this!\n\n\nfor us: data importing (read_csv), and webscraping (next time);\n\nbut really: domain-specific issues of measurement, survey design, experimental design, etc;\n\n\n\nPreparation: cleaning, wrangling, and otherwise tidying the data so we can actually work with it.\n\n\nkeywords: mutate, fct_relevel, pivot_*, *_join\n\n\n\n\n\n\n\nAnalysis: finally transform the data into knowledge…\n\n\npictures: ggplot, geom_*, etc\n\nnumerical summaries: summarize, group_by, count, mean, median, sd, quantile, IQR, cor, etc"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-analysis",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-analysis",
    "title": "Importing and recoding data",
    "section": "From last time: data analysis",
    "text": "From last time: data analysis\nA human being can learn nothing from staring at this box:\n\nsurvey\n\n# A tibble: 209 × 2\n   tue_classes year      \n         &lt;dbl&gt; &lt;fct&gt;     \n 1           3 Sophomore \n 2           3 First-year\n 3           2 Senior    \n 4           3 First-year\n 5           3 Senior    \n 6           3 Senior    \n 7           3 First-year\n 8           3 First-year\n 9           2 Sophomore \n10           3 Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-1",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-1",
    "title": "Importing and recoding data",
    "section": "From last time: data analysis",
    "text": "From last time: data analysis\nPicture!\n\nggplot(survey, aes(x = tue_classes, fill = year)) + \n  geom_bar(position = \"dodge\")"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-2",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-2",
    "title": "Importing and recoding data",
    "section": "From last time: data analysis",
    "text": "From last time: data analysis\nBetter picture?\n\nggplot(survey, aes(x = tue_classes, fill = year)) + \n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-3",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-3",
    "title": "Importing and recoding data",
    "section": "From last time: data analysis",
    "text": "From last time: data analysis\nNumbers!\n\nsurvey |&gt;\n  count(tue_classes, year) |&gt;\n  group_by(tue_classes) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 17 × 4\n# Groups:   tue_classes [5]\n   tue_classes year           n   prop\n         &lt;dbl&gt; &lt;fct&gt;      &lt;int&gt;  &lt;dbl&gt;\n 1           1 Sophomore      4 0.4   \n 2           1 Junior         4 0.4   \n 3           1 Senior         2 0.2   \n 4           2 First-year    25 0.439 \n 5           2 Sophomore     19 0.333 \n 6           2 Junior         9 0.158 \n 7           2 Senior         4 0.0702\n 8           3 First-year    47 0.427 \n 9           3 Sophomore     46 0.418 \n10           3 Junior         9 0.0818\n11           3 Senior         8 0.0727\n12           4 First-year    18 0.621 \n13           4 Sophomore      9 0.310 \n14           4 Junior         1 0.0345\n15           4 Senior         1 0.0345\n16           5 First-year     2 0.667 \n17           5 Sophomore      1 0.333"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-4",
    "href": "slides/09-importing-recoding-data.html#data-science-4",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science\n\n\nCollection: we won’t seriously study this!\n\n\nfor us: data importing (read_csv), and webscraping (next time);\n\nbut really: domain-specific issues of measurement, survey design, experimental design, etc;\n\n\n\nPreparation: cleaning, wrangling, and otherwise tidying the data so we can actually work with it.\n\n\nkeywords: mutate, fct_relevel, pivot_*, *_join\n\n\n\n\nAnalysis: finally transform the data into knowledge…\n\n\npictures: ggplot, geom_*, etc\n\nnumerical summaries: summarize, group_by, count, mean, median, sd, quantile, iqr, cor, etc\n\n\n\n\nThe pictures and the summaries need to work together!"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet",
    "href": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet",
    "title": "Importing and recoding data",
    "section": "A cautionary tale: Anscombe’s quartet",
    "text": "A cautionary tale: Anscombe’s quartet\n\n\nDataset I\n\n\n    x     y\n1  10  8.04\n2   8  6.95\n3  13  7.58\n4   9  8.81\n5  11  8.33\n6  14  9.96\n7   6  7.24\n8   4  4.26\n9  12 10.84\n10  7  4.82\n11  5  5.68\n\n\n\nDataset II\n\n\n    x    y\n1  10 9.14\n2   8 8.14\n3  13 8.74\n4   9 8.77\n5  11 9.26\n6  14 8.10\n7   6 6.13\n8   4 3.10\n9  12 9.13\n10  7 7.26\n11  5 4.74\n\n\n\nDataset III\n\n\n    x     y\n1  10  7.46\n2   8  6.77\n3  13 12.74\n4   9  7.11\n5  11  7.81\n6  14  8.84\n7   6  6.08\n8   4  5.39\n9  12  8.15\n10  7  6.42\n11  5  5.73\n\n\n\nDataset IV\n\n\n    x     y\n1   8  6.58\n2   8  5.76\n3   8  7.71\n4   8  8.84\n5   8  8.47\n6   8  7.04\n7   8  5.25\n8  19 12.50\n9   8  5.56\n10  8  7.91\n11  8  6.89"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet-1",
    "href": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet-1",
    "title": "Importing and recoding data",
    "section": "A cautionary tale: Anscombe’s quartet",
    "text": "A cautionary tale: Anscombe’s quartet\n\nggplot(anscombe_tidy, aes(x, y)) +\n  geom_point() +\n  facet_wrap(~ set)"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet-2",
    "href": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet-2",
    "title": "Importing and recoding data",
    "section": "A cautionary tale: Anscombe’s quartet",
    "text": "A cautionary tale: Anscombe’s quartet\n\nggplot(anscombe_tidy, aes(x, y)) +\n  geom_point() +\n  facet_wrap(~ set) +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#if-you-only-looked-at-summary-statistics",
    "href": "slides/09-importing-recoding-data.html#if-you-only-looked-at-summary-statistics",
    "title": "Importing and recoding data",
    "section": "If you only looked at summary statistics…",
    "text": "If you only looked at summary statistics…\n\nanscombe_tidy |&gt;\n  group_by(set) |&gt;\n  summarize(\n    xbar = mean(x),\n    ybar = mean(y),\n    sx = sd(x),\n    sy = sd(y),\n    r = cor(x, y)\n  )\n\n# A tibble: 4 × 6\n  set    xbar  ybar    sx    sy     r\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 I         9  7.50  3.32  2.03 0.816\n2 II        9  7.50  3.32  2.03 0.816\n3 III       9  7.5   3.32  2.03 0.816\n4 IV        9  7.50  3.32  2.03 0.817"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#our-motto-abv",
    "href": "slides/09-importing-recoding-data.html#our-motto-abv",
    "title": "Importing and recoding data",
    "section": "Our motto: ABV!",
    "text": "Our motto: ABV!\n\nNo, not alcohol by volume…\n\n\n\n\n\nAlways!\n\nBe!\n\nVisualizing!"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#finish-up-ae-08-durham-climate-factors",
    "href": "slides/09-importing-recoding-data.html#finish-up-ae-08-durham-climate-factors",
    "title": "Importing and recoding data",
    "section": "Finish up: ae-08-durham-climate-factors\n",
    "text": "Finish up: ae-08-durham-climate-factors\n\n\n\nGo to your ae project in RStudio.\nOpen ae-08-durham-climate-factors.qmd and pick up at “Recode and reorder”."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#reading-rectangular-data",
    "href": "slides/09-importing-recoding-data.html#reading-rectangular-data",
    "title": "Importing and recoding data",
    "section": "Reading rectangular data",
    "text": "Reading rectangular data\n\nUsing readr:\n\nMost commonly: read_csv()\n\nMaybe also: read_tsv(), read_delim(), etc.\n\n\n\n\n\nUsing readxl: read_excel()\n\n\n\n\n\nUsing googlesheets4: read_sheet() – We haven’t covered this in the videos, but might be useful for your projects"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#goal-1-reading-and-writing-csv-files",
    "href": "slides/09-importing-recoding-data.html#goal-1-reading-and-writing-csv-files",
    "title": "Importing and recoding data",
    "section": "Goal 1: Reading and writing CSV files",
    "text": "Goal 1: Reading and writing CSV files\n\nRead a CSV file\nSplit it into subsets based on features of the data\nWrite out subsets as CSV files"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#age-gap-in-hollywood-relationships",
    "href": "slides/09-importing-recoding-data.html#age-gap-in-hollywood-relationships",
    "title": "Importing and recoding data",
    "section": "Age gap in Hollywood relationships",
    "text": "Age gap in Hollywood relationships\n\n\n\nWhat is the story in this visualization?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#ae-08-age-gaps-sales-import---part-1",
    "href": "slides/09-importing-recoding-data.html#ae-08-age-gaps-sales-import---part-1",
    "title": "Importing and recoding data",
    "section": "ae-08-age-gaps-sales-import - Part 1",
    "text": "ae-08-age-gaps-sales-import - Part 1\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-08-age-gaps-sales-import.qmd.\nWork through Part 1 of the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#goal-2-reading-excel-files",
    "href": "slides/09-importing-recoding-data.html#goal-2-reading-excel-files",
    "title": "Importing and recoding data",
    "section": "Goal 2: Reading Excel files",
    "text": "Goal 2: Reading Excel files\n\nRead an Excel file with non-tidy data\nTidy it up!"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#sales-data",
    "href": "slides/09-importing-recoding-data.html#sales-data",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\n\n\nAre these data tidy? Why or why not?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#sales-data-1",
    "href": "slides/09-importing-recoding-data.html#sales-data-1",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\nWhat “data moves” do we need to go from the original, non-tidy data to this, tidy one?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#ae-08-age-gaps-sales-import---part-2",
    "href": "slides/09-importing-recoding-data.html#ae-08-age-gaps-sales-import---part-2",
    "title": "Importing and recoding data",
    "section": "ae-08-age-gaps-sales-import - Part 2",
    "text": "ae-08-age-gaps-sales-import - Part 2\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-08-age-gaps-sales-import.qmd.\nWork through Part 2 of the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "syllabus/syllabus_materials.html",
    "href": "syllabus/syllabus_materials.html",
    "title": "Course materials",
    "section": "",
    "text": "All books are freely available online:\n\n[ims]: Mine Çetinkaya-Rundel and Jo Hardin. Introduction to Modern Statistics. 2nd edition. OpenIntro, 2024.\n[r4ds]: Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science. 2nd edition. O’Reilly, 2022.",
    "crumbs": [
      "Syllabus",
      "Materials"
    ]
  },
  {
    "objectID": "syllabus/syllabus_materials.html#textbooks",
    "href": "syllabus/syllabus_materials.html#textbooks",
    "title": "Course materials",
    "section": "",
    "text": "All books are freely available online:\n\n[ims]: Mine Çetinkaya-Rundel and Jo Hardin. Introduction to Modern Statistics. 2nd edition. OpenIntro, 2024.\n[r4ds]: Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science. 2nd edition. O’Reilly, 2022.",
    "crumbs": [
      "Syllabus",
      "Materials"
    ]
  },
  {
    "objectID": "syllabus/syllabus_materials.html#technology",
    "href": "syllabus/syllabus_materials.html#technology",
    "title": "Course materials",
    "section": "Technology",
    "text": "Technology\nYou will need to bring a laptop to all lectures and labs. Options for obtaining a laptop through the university are described here. Armed with your trusty laptop, you must be able to access the following:\n\nThis course page that you are on right now;\nR/RStudio as provided by the Duke Container Manager;\nCanvas, through which you can access…\n\nGradescope;\nEd Discussion;\n\nPanopto (for the lecture recordings);\nZoom (e.g. for remote office hours).\n\nIf access to technology becomes a concern for you during the semester, contact the instructor immediately to discuss options.",
    "crumbs": [
      "Syllabus",
      "Materials"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html",
    "href": "syllabus/syllabus_resources.html",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#course-costs",
    "href": "syllabus/syllabus_resources.html#course-costs",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#tech-support",
    "href": "syllabus/syllabus_resources.html#tech-support",
    "title": "University resources",
    "section": "Tech support",
    "text": "Tech support\nContact the Duke OIT Service Desk at oit.duke.edu/help.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#academic-support",
    "href": "syllabus/syllabus_resources.html#academic-support",
    "title": "University resources",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#accessibility",
    "href": "syllabus/syllabus_resources.html#accessibility",
    "title": "University resources",
    "section": "Accessibility",
    "text": "Accessibility\nIf any portion of the course is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students can engage with their courses and related assignments. Students should contact the SDAO to request or update accommodations under these circumstances.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#mental-health-and-well-being",
    "href": "syllabus/syllabus_resources.html#mental-health-and-well-being",
    "title": "University resources",
    "section": "Mental health and well-being",
    "text": "Mental health and well-being\nDuke is committed to holistic student well-being, including mental, emotional, and physical health. The university offers resources to help students manage daily stress, encourage intentional self-care, and access just-in-time support. If you find you need support, your mental and/or emotional health concerns are impacting your day-to-day activities and your academic performance, or you need someone to talk to, the resources below are available to you:\n\nDukeReach: DukeReach provides comprehensive outreach services to support students in managing all aspects of well-being, including referrals and follow-up services for students who are experiencing significant challenges related to mental health, physical health, social adjustment, and/or a variety of other stressors. You can reach the DukeReach team at dukereach@duke.edu.\nCounseling and Psychological Services (CAPS): CAPS services include individual and group counseling services, psychiatric services, and workshops. CAPS also provides referrals to off-campus resources for specialized care. You can reach CAPS at (919) 660-1000.\nTimelyCare: TimelyCare is an online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling.\nBC Fellows for Healthy Relationship: The BC Fellows meet with students individually and in groups, supporting the development of healthy relationships and building meaningful community in all areas of a student’s life.\nDukeLine: Students who want to connect anonymously with a Peer Coach can text 984-230-4888 from 5 to 11 p.m. daily. DukeLine offers in-the-moment anonymous, non-emergency text support from a peer.\nDuWell: DuWell provides Moments of Mindfulness (stress management and resilience building) and meditation programming (Koru workshop) to assist students in developing a daily emotional well-being practice. All are welcome, and no experience is necessary. You can reach DuWell at (919) 681-8421.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html",
    "href": "syllabus/syllabus_assignments.html",
    "title": "Assignments and grading",
    "section": "",
    "text": "Your final course grade will be calculated as follows:\nYour final letter grade will be determined based on these thresholds:",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#application-exercises-5",
    "href": "syllabus/syllabus_assignments.html#application-exercises-5",
    "title": "Assignments and grading",
    "section": "Application exercises (5%)",
    "text": "Application exercises (5%)\nDuring most lectures, we will work through an application exercise (AE) together. This is essentially a guided mini-lab that shows you how to implement the concepts introduced that day. On-time completion of at least 70% of AEs will result in full credit for the AE component of the final course grade. Here is what that means:\n\nAEs are due at 2PM ET on the day they are introduced;\nSubmit an AE by pushing your work to your GitHub repo;\nAEs are graded for completion; if you make a good faith attempt at all parts of the exercisem you get the credit.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can miss 30% of AEs before it starts affecting your final grade. This policy is meant to smooth over technical mishaps, absences due to illness, athletics, etc. So we generally will not grant extensions or exemptions for AEs. We just let the 30% policy do its thing;",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#labs-15",
    "href": "syllabus/syllabus_assignments.html#labs-15",
    "title": "Assignments and grading",
    "section": "Labs (15%)",
    "text": "Labs (15%)\nIn labs, you will apply what you have learned in the videos and during lectures to complete data analysis tasks. You may discuss lab assignments with other students; however, the lab should be completed and submitted individually. Lab assignments must be typed up using Quarto, all work must be pushed to your GitHub repository for the lab, and the lab’s PDF output must be submitted on Gradescope by the deadline. Labs are due at 8:30 am ET on the indicated due date (generally the Monday after the lab is first introduced).\n\n\n\n\n\n\nNote\n\n\n\nYour lowest lab score will be dropped. This policy will be applied to the gradebook at the end of the semester, after all labs have been graded/regraded, and before the final exam.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#midterm-exams-20-each",
    "href": "syllabus/syllabus_assignments.html#midterm-exams-20-each",
    "title": "Assignments and grading",
    "section": "Midterm Exams (20% each)",
    "text": "Midterm Exams (20% each)\nThere will be two midterm exams, each with two components:\n\nIn-class (70% of the grade): sit-down, in-person, “pencil-and-paper,” with no technology, and with no outside resources apart from a note sheet that you and only you have prepared (both sides of an 8.5” x 11” piece of paper);\nTake-home (30% of the grade): each in-class exam will end at 1:00 PM ET on a Thursday. You will then have until 8:00 AM ET the following Monday to work independently on the take-home. This will consist of a data analysis in R, and submission will be identical to our usual labs (Quarto &gt; PDF &gt; Gradescope). The take-home portion of the midterms is completely open resource, but the citation policies of the course still apply, and you are forbidden from discussing the exam with your peers in any way.\n\nUnless we indicate otherwise, you should assume that all course content and materials (videos, readings, lectures, labs, AEs, etc) are testable.\n\n\n\n\n\n\nWarning\n\n\n\nSee the course schedule for dates and times of the exams. Exam dates cannot be changed and no make-up exams will be given. If you cannot take the exams on these dates, you should drop this class.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#final-exam-20",
    "href": "syllabus/syllabus_assignments.html#final-exam-20",
    "title": "Assignments and grading",
    "section": "Final Exam (20%)",
    "text": "Final Exam (20%)\nOn Tuesday April 29 we have our final exam from 9AM ET to 12PM ET. This exam will be cumulative, and it will have the same format as the in-class components of the midterm exams. The final exam does not have a take-home portion.\n\n\n\n\n\n\nNote\n\n\n\nIf you do better on the final exam than you did on the in-class component of a midterm, we will replace your lowest in-class midterm exam score with your final exam score.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#final-project-20",
    "href": "syllabus/syllabus_assignments.html#final-project-20",
    "title": "Assignments and grading",
    "section": "Final project (20%)",
    "text": "Final project (20%)\nAfter the first midterm exam, we will assign you to teams of four or five within your lab section. Teams will select a dataset and conduct an original data analysis using the tools from the course. The project has various intermediate deadlines (“Milestones”) that contribute to the project grade, and on the last day of the semester (Wednesday April 23) teams will submit a final written report and a five minute video presentation summarizing the results of the analysis.\n\n\n\n\n\n\nWarning\n\n\n\nIf you do not complete the project, you will not receive a passing grade in this course.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "project/2-proposal.html",
    "href": "project/2-proposal.html",
    "title": "Proposal",
    "section": "",
    "text": "The goals of this milestone are as follows:\n\nDiscuss topics you’re interested in investigating and find data sets on those topics.\nIdentify 2 data sets you’re interested in potentially using for the project.\nGet these datasets into R.\nWrite up reasons and justifications for why you want to work with these datasets.\nReview your team contract.\n\n\n\n\n\n\n\nImportant\n\n\n\nYou must use one of the data sets in the proposal for the final project, unless instructed otherwise when given feedback.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#criteria-for-datasets",
    "href": "project/2-proposal.html#criteria-for-datasets",
    "title": "Proposal",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 500 observations.\nAt least 8 columns.\nAt least 6 of the columns must be useful and unique explanatory variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\nYou can curate one of your datasets via web scraping.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#resources-for-datasets",
    "href": "project/2-proposal.html#resources-for-datasets",
    "title": "Proposal",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nUNICEF Data\nGoogle Dataset Search\nData is Plural\nElection Studies\nUS Census Data\nWorld Bank Data\nCDC\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nHarvard Dataverse\nInternational Monetary Fund [See “Popular Datasets”]\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nResponsible Datasets in Context\nStatistics Canada\nTidyTuesday\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Government Data\nFRED Economic Data\nData.gov\nAwesome public datasets\nDurham Open Data Portal\nFiveThirtyEight",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#introduction-and-data",
    "href": "project/2-proposal.html#introduction-and-data",
    "title": "Proposal",
    "section": "Introduction and data",
    "text": "Introduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#research-question",
    "href": "project/2-proposal.html#research-question",
    "title": "Proposal",
    "section": "Research question",
    "text": "Research question\nYour research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#glimpse-of-data",
    "href": "project/2-proposal.html#glimpse-of-data",
    "title": "Proposal",
    "section": "Glimpse of data",
    "text": "Glimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the glimpse() function to provide a glimpse of the data set.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#data-dictionary",
    "href": "project/2-proposal.html#data-dictionary",
    "title": "Proposal",
    "section": "Data dictionary",
    "text": "Data dictionary\nFor each data set, add a data dictionary to the README.md file in the data folder describing each variable.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html",
    "href": "project/1-working-collaboratively.html",
    "title": "Working collaboratively",
    "section": "",
    "text": "Important\n\n\n\nYou must attend this lab in person and participate in the merge conflict activity to be eligible for the points for this milestone. Team members who are not in lab in person for this activity will not be eligible for these points, regardless of their contribution throughout the rest of the project.\nData science is a collaborative discipline. Pretty much no data scientist works alone, so neither should you! In this course you’ll collaborate with teammates on the project.\nThe first milestone of the project, today’s activity, will introduce you to the technical aspects of collaborating on a reproducible data science project that is version controlled by Git and hosted on GitHub in a repository shared by all teammates.\nYes, this means you and all of your teammates will be pushing to the same repository! Sometimes things will go swimmingly, and sometimes you’ll run into merge conflicts.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html#activity",
    "href": "project/1-working-collaboratively.html#activity",
    "title": "Working collaboratively",
    "section": "Activity",
    "text": "Activity\nSetup\n\nClone the project repo and open the about.qmd file.\nAssign the numbers 1, 2, 3, 4, and 5 to each of the team members. If your team has fewer than 5 people, some people will need to have multiple numbers.\nLet’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\nBefore starting\nEveryone should have the repo cloned and know which role number(s) they are.\nRole 1\n\nGo to about.qmd in your project repo. Change the [team name] to your actual team name.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\nRole 2\n\nChange the team name to some other word.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push. You should get an error.\nPull. Take a look at the document (about.qmd) with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nRender the project by clicking on Render in the Build tab.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\nRole 3\n\nChange the name of the first team member.\nRender the project by clicking on Render in the Build tab, commit, and push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\nRole 4\n\nChange the name of the first team member to something other than what the previous team member did.\nRender the project by clicking on Render in the Build tab, commit, and push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Render the project by clicking on Render in the Build tab, commit, and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\nRole 5\n\nChange the name of the rest of the team members and add descriptions for each person with the help of your team members. Role 5 should be the only one typing; the others should help verbally.\nRender the project by clicking on Render in the Build tab and commit. Discuss as a team what you expect to happen when you hit push. Should there be a merge conflict error or not?\nIf there is a merge conflict, fix it. If not, push your changes.\nEveryone\nPull, and observe the changes in your project.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "href": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "title": "Working collaboratively",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (render and push) before continuing your work. Never do new work while resolving a merge conflict.\nRender, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/tips-resources.html",
    "href": "project/tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "The project is very open ended. For instance, in creating a compelling visualization(s) of your data in R, there is no limit on what tools or packages you may use. You do not need to visualize all of the data at once. A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.\nBefore you finalize your write up, make sure the printing of code chunks is turned off with the option echo: false. In addition to code chunks, ensure all messages are turned off with the options warning: false and message: false.\nFinally, pay attention to details in your write-up and presentation. Neatness, coherency, and clarity will count."
  },
  {
    "objectID": "project/tips-resources.html#suppress-code-and-warnings",
    "href": "project/tips-resources.html#suppress-code-and-warnings",
    "title": "Project tips + resources",
    "section": "Suppress code and warnings",
    "text": "Suppress code and warnings\n\nInclude the following in the YAML of your report.qmd to suppress all code, warnings, and other messages.\n\nexecute:\n  echo: false\n  warning: false"
  },
  {
    "objectID": "project/tips-resources.html#headers",
    "href": "project/tips-resources.html#headers",
    "title": "Project tips + resources",
    "section": "Headers",
    "text": "Headers\nUse headers to clearly label each section. Make sure there is a space between the previous line and the header. Use appropriate header levels."
  },
  {
    "objectID": "project/tips-resources.html#references",
    "href": "project/tips-resources.html#references",
    "title": "Project tips + resources",
    "section": "References",
    "text": "References\nInclude all references in a section called “References” at the end of the report. This course does not have specific requirements for formatting citations and references. Optional: Use Quarto’s citation support for generating your reference. See Citations & Footnotes on the Quarto documentation for more on that."
  },
  {
    "objectID": "project/tips-resources.html#appendix",
    "href": "project/tips-resources.html#appendix",
    "title": "Project tips + resources",
    "section": "Appendix",
    "text": "Appendix\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”. The items in the appendix should be properly labeled. The appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix. We will not grade your appendix."
  },
  {
    "objectID": "project/tips-resources.html#resize-figures",
    "href": "project/tips-resources.html#resize-figures",
    "title": "Project tips + resources",
    "section": "Resize figures",
    "text": "Resize figures\nResize plots and figures, so you have more space for the narrative. Resize individual figures: Set fig-width and fig-height in chunk options, e.g.,\n#| echo: fenced\n#| label: code-cell-label\n#| fig-width: 5\n#| fig-asp: 0.628\nreplacing code-cell-label with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig-width and fig-asp options in the YAML header as shown below:\nexecute:\n  fig-width: 5\n  fig-asp: 0.628\nReplace the height and width values with values appropriate for your write up."
  },
  {
    "objectID": "project/tips-resources.html#arranging-plots",
    "href": "project/tips-resources.html#arranging-plots",
    "title": "Project tips + resources",
    "section": "Arranging plots",
    "text": "Arranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nThe patchwork package makes it easy to arrange plots in a grid."
  },
  {
    "objectID": "project/4-peer-review.html",
    "href": "project/4-peer-review.html",
    "title": "Peer review",
    "section": "",
    "text": "During the peer feedback process, you will be provided read-only access to your partner team’s GitHub repo. You will provide your feedback in the form of GitHub issues to your partner team’s GitHub repo.\nGoals\nThe goals of this milestone are as follows:\n\nReview others’ project drafts as a team and provide feedback\nPost issues on GitHub using an issue template\nLearn from others’ projects and improve your own project based on their strengths and weaknesses\nInstructions\nReview two other teams’ projects. As a team you should spend ~30 minutes on each team’s project.\n\nFind the names of the teams whose projects you’re reviewing below. You should already have access to this team’s repo.\nEach team member should go to the repo of the team you’re reviewing.\n\nThen,\n\n1-2 team members clone the team’s project and renders it to check for reproducibility.\n1-2 team members open the team’s project in their browser and starts reading through the project draft.\n1 team member opens an issue on the team’s repo using the peer review template.\nAll team members discuss the project based on the prompts on the issue template and one team member records the feedback and submits the issue.\n\n\n\nTo open an issue in the repo you’re reviewing, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical reasoning aspect of the project, but do feel free to comment on aspects beyond the reasoning as well.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation?\nWere you able to reproduce the project by clicking on Render Website once you cloned it? Were there any issues with reproducibility?\nProvide constructive feedback on any issues with file and/or code organization.\nWhat have you learned from this team’s project that you are considering implementing in your own project?\n(Optional) Any further comments or feedback?\n\n\nReview pairings\n\n\nL1 - 8:30 am\nL2 - 10:05 am\nL3 - 10:05 am\nL4 - 11:45 am\nL5 - 11:45 am\nL6 - 1:25 pm\nL7 - 1:25 pm\nL8 - 3:05 pm\nL9 - 3:05 pm\nL10 - 4:40 pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrading\nPeer reviews will be graded on the extent to which it comprehensively and constructively addresses the components of the reviewee’s team’s report.\nOnly the team members participating in the review during the lab session are eligible for points for the peer review. If you’re unable to make it to lab in person, you should arrange to virtually connect with your team during your lab session.\n\n0 points: No peer review\n1 point: Feedback provided is not constructive or actionable\n2-4 points: Feedback provided is not sufficiently thorough\n5 points: Peer review is constructive, actionable, and sufficiently thorough\n\n\n\n\n\n\n\nNote\n\n\n\nThe feedback issue will come from one team member on GitHub since you can’t collectively edit an issue. However it must represent the opinions of the entire team. It is not a single team member’s responsibility to provide feedback, they’re just the record keeper for the team.",
    "crumbs": [
      "Project",
      "Milestone 4"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html",
    "href": "exam/midterm-1-batch-B.html",
    "title": "Midterm 1 Practice Questions",
    "section": "",
    "text": "Solutions\n\n\n\n\n\nSee here.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#penguins",
    "href": "exam/midterm-1-batch-B.html#penguins",
    "title": "Midterm 1 Practice Questions",
    "section": "Penguins",
    "text": "Penguins\nThe penguins data set includes measurements for penguin species, including: flipper length, body mass, bill dimensions, and sex. The following table summarizes information on which species of penguins (Adelie, Gentoo, and Chinstrap) live on which islands (Biscoe, Dream, or Torgersen).\n\n\n\n\n\n\nIsland\nAdelie\nGentoo\nChinstrap\nTotal\n\n\n\nBiscoe\n44\n124\n0\n168\n\n\nDream\n56\n0\n68\n124\n\n\nTorgersen\n52\n0\n0\n52\n\n\nTotal\n152\n124\n68\n344\n\n\n\n\n\n\nQuestion 1\nWhich of the following plots is the result of the following code?\n\nggplot(penguins, aes(x = island, fill = species)) + \n  geom_bar()",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#nyc-flights",
    "href": "exam/midterm-1-batch-B.html#nyc-flights",
    "title": "Midterm 1 Practice Questions",
    "section": "NYC Flights",
    "text": "NYC Flights\nThe flights dataset includes characteristics of all flights departing from New York City airports (JFK, LGA, EWR) in 2013. Below is a peek at the first ten rows of the flights data.\n\nflights |&gt;\n  relocate(year, month, day, arr_delay, carrier)\n\n# A tibble: 336,776 × 19\n    year month   day arr_delay carrier dep_time sched_dep_time dep_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     1        11 UA           517            515         2\n 2  2013     1     1        20 UA           533            529         4\n 3  2013     1     1        33 AA           542            540         2\n 4  2013     1     1       -18 B6           544            545        -1\n 5  2013     1     1       -25 DL           554            600        -6\n 6  2013     1     1        12 UA           554            558        -4\n 7  2013     1     1        19 B6           555            600        -5\n 8  2013     1     1       -14 EV           557            600        -3\n 9  2013     1     1        -8 B6           557            600        -3\n10  2013     1     1         8 AA           558            600        -2\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_time &lt;int&gt;, sched_arr_time &lt;int&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nQuestion 2\nBased on this output, which of the following must be true about the flights data frame? Select all that are true.\n\nThe flights data frame is a tibble.\nThe flights data frame has 10 rows.\nThe flights data frame has 8 columns.\nThe carrier variable in the flights data frame is a character variable.\nThere are no missing data in the flights data frame.\nQuestion 3\nWhich of the following pipelines produce(s) the output shown below? Select all that apply.\n\n\n# A tibble: 336,776 × 5\n   arr_delay carrier  year month   day\n       &lt;dbl&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1      1272 HA       2013     1     9\n 2      1127 MQ       2013     6    15\n 3      1109 MQ       2013     1    10\n 4      1007 AA       2013     9    20\n 5       989 MQ       2013     7    22\n 6       931 DL       2013     4    10\n 7       915 DL       2013     3    17\n 8       895 DL       2013     7    22\n 9       878 AA       2013    12     5\n10       875 MQ       2013     5     3\n# ℹ 336,766 more rows\n\n\na.\n\nflights |&gt;\n  select(arr_delay, carrier, year, month, day) |&gt;\n  arrange(desc(arr_delay))\n\nb.\n\nflights |&gt;\n  select(arr_delay, carrier, year, month, day) |&gt;\n  arrange(arr_delay)\n\nc.\n\nflights |&gt;\n  select(arr_delay, carrier, year, month, day) |&gt;\n  arrange(year)\n\nd.\n\nflights |&gt;\n  arrange(desc(arr_delay)) |&gt;\n  select(arr_delay, carrier, year, month, day)\n\ne.\n\nflights |&gt;\n  arrange(desc(arr_delay)) |&gt;\n  select(day, month, year, arr_delay, carrier)",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#countries-and-populations",
    "href": "exam/midterm-1-batch-B.html#countries-and-populations",
    "title": "Midterm 1 Practice Questions",
    "section": "Countries and populations",
    "text": "Countries and populations\nWe have a small dataset of six countries and their populations:\n\npopulation\n\n# A tibble: 6 × 2\n  country       population\n  &lt;chr&gt;              &lt;dbl&gt;\n1 Curacao            150  \n2 Ecuador          18001  \n3 Iraq             44496. \n4 New Zealand       5124. \n5 Palau               18.0\n6 United States   333288. \n\n\nAnd another small dataset of five countries and the continent they’re in:\n\ncontinents\n\n# A tibble: 5 × 3\n  entity      code  continent    \n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        \n1 Angola      AGO   Africa       \n2 Curacao     CUW   North America\n3 Ecuador     ECU   South America\n4 Iraq        IRQ   Asia         \n5 New Zealand NZL   Oceania      \n\n\nYou join the two datasets with the following:\n\npopulation |&gt;\n  left_join(continents, by = join_by(country == entity))\n\nQuestion 4\nHow many rows will the resulting data frame have?\n\n4\n5\n6\n7\n8\nQuestion 5\nWhat will be the columns of the resulting data frame?\n\ncountry, population\ncountry, population, code, continent\nentity, code, continent\nentity, population, code, continent\ncountry, entity, population, code, continent",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#duke-forest-houses",
    "href": "exam/midterm-1-batch-B.html#duke-forest-houses",
    "title": "Midterm 1 Practice Questions",
    "section": "Duke Forest houses",
    "text": "Duke Forest houses\nThe duke_forest dataset includes information on prices and various other features (number of bedrooms, bathrooms, area, year built, type of cooling, type of heating, etc.) of houses in the Duke Forest neighborhood of Durham, NC.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…\n\n\nThe following summary table gives us some information about whether homes in this data set have garages and when they were built.\n\n\n\n\n\n\n\nBuilt earlier than 1950\nBuilt in 1950 or later\n\n\n\nGarage\n5\n33\n\n\nNo garage\n3\n57\n\n\n\n\n\n\nThe pipeline below produces a data frame with a fewer number of rows than duke_forest.\n\nduke_forest |&gt;\n  filter(parking == \"Garage\" _(1)_ year_built _(2)_ 1950) |&gt;\n  select(parking, year_built, price, area) |&gt;\n  _(3)_(price_per_sqfeet = price / area)\n\n\n\n# A tibble: 5 × 5\n  parking year_built  price  area price_per_sqfeet\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;\n1 Garage        1945 900000  2933            307. \n2 Garage        1938 265000  1300            204. \n3 Garage        1934 600000  2514            239. \n4 Garage        1941 412500  1661            248. \n5 Garage        1940 105000  1094             96.0\n\n\nQuestion 6\nWhich of the following goes in blanks (1) and (2)?\n\n\n\n(1)\n(2)\n\n\n\na.\n&\n&lt;\n\n\nb.\n|\n&lt;\n\n\nc.\n&\n&gt;=\n\n\nd.\n|\n&gt;=\n\n\ne.\n&\n!=\n\n\nQuestion 7\nWhich function or functions go into blank (3)? Select all that apply.\n\narrange()\nmutate()\nfilter()\nsummarize()\nslice()",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#law-order",
    "href": "exam/midterm-1-batch-B.html#law-order",
    "title": "Midterm 1 Practice Questions",
    "section": "Law & Order",
    "text": "Law & Order\nYou’ve heard of the tidyverse, now let’s visit the Law & Order-verse. Doink doink!1\nLaw & Order is a police procedural and legal drama television series that has been running since the 1990s. The Law & Order franchise includes a number of series such as Law & Order, Law & Order: SVU, Law & Order: Criminal Intent, etc.\nYou will work with data on average ratings for each season of three series from the Law & Order-verse – a subset of the data from the previous questions. Below is a peek at the first ten rows of the Law & Order data.\nThe plot below shows the distributions of average ratings of various Law & Order series across seasons.\n\n\n\n\n\n\n\n\nQuestion 8\nBased on the information from the side-by-side box plots, fill in the legend of the plot below with Law & Order series titles.\n\n\n\n\n\n\n\n\nQuestion 9\nThe following code calculates the standard deviations of average season ratings of the five Law & Order series. Unfortunately, the output is partially erased and replaced with blanks.\n\nlo_titles &lt;- c(\"Law & Order\", \"Law & Order: Criminal Intent\", \"Law & Order: SVU\")\n\nlaw_and_order |&gt;\n  filter(title %in% lo_titles) |&gt;\n  group_by(title) |&gt;\n  summarize(mean_av_rating = mean(av_rating), sd_av_rating = sd(av_rating))\n\n# A tibble: 5 × 3\n  title                         mean_av_rating sd_av_rating\n  &lt;chr&gt;                                  &lt;dbl&gt;        &lt;dbl&gt;\n1 Law & Order                            _(1)_        0.106\n2 Law & Order: Criminal Intent            8.20        0.129\n4 Law & Order: SVU                        8.67        _(2)_\nBased on the visualizations you’ve seen of these data so far, which of the following is true about the blanks in the output? Select all that are true.\n\nThe mean of average ratings (Blank 1) of Law & Order seasons is lower than the other two means.\nThe mean of average ratings (Blank 1) of Law & Order seasons is higher than the other two means.\nThe standard deviation of average ratings of Law & Order: SVU seasons (Blank 2) is lower than the other two standard deviations.\nThe standard deviation of average ratings of Law & Order: SVU seasons (Blank 2) is higher than the other two standard deviations.\nThe standard deviation of average ratings of Law & Order: SVU seasons (Blank 2) is between the other two standard deviations.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#romance-and-comedy",
    "href": "exam/midterm-1-batch-B.html#romance-and-comedy",
    "title": "Midterm 1 Practice Questions",
    "section": "Romance and comedy",
    "text": "Romance and comedy\nFinally, we focus on romance and comedy shows. We first filter the dataset for any shows that have romance or comedy as their genre (genre_1, genre_2, or genre_3) and then remove shows that have both of these genre labels. For the next two questions, we focus on these shows that we identify as either romance or comedy. We then calculate the mean of the average season ratings for each show, to obtain a single “mean average rating” value per show.\nThe plot below shows the distributions of mean average ratings of seasons of comedy and romance shows.\n\n\n\n\n\n\n\n\nQuestion 10\nWhich of the following statements is true about these distributions? Select all that are true.\n\nMean average ratings of romance shows are bimodal.\nMean average ratings of comedy are unimodal.\nMean average ratings of romance shows is left skewed.\nMean average ratings of comedy shows is right skewed.\nThere are more romance shows than comedy shows.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#imdb",
    "href": "exam/midterm-1-batch-B.html#imdb",
    "title": "Midterm 1 Practice Questions",
    "section": "IMDB",
    "text": "IMDB\nThe data for the next few questions come from the Internet Movie Database (IMDB). Specifically, the data are a random sample of movies released between 1980 and 2020.\n\nmovies &lt;- read_csv(\"data/movies.csv\")\n\nThe name of the data frame used for this analysis is movies, and it contains the variables shown in Table 1.\n\n\nTable 1: Data dictionary for movies\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\nname\nname of the movie\n\n\nrating\nrating of the movie (R, PG, etc.)\n\n\ngenre\nmain genre of the movie.\n\n\nruntime\nduration of the movie\n\n\nyear\nyear of release\n\n\nrelease_date\nrelease date (YYYY-MM-DD)\n\n\nrelease_country\nrelease country\n\n\nscore\nIMDB user rating\n\n\nvotes\nnumber of user votes\n\n\ndirector\nthe director\n\n\nwriter\nwriter of the movie\n\n\nstar\nmain actor/actress\n\n\ncountry\ncountry of origin\n\n\nbudget\nthe budget of a movie (some movies don’t have this, so it appears as 0)\n\n\ngross\nrevenue of the movie\n\n\ncompany\nthe production company\n\n\n\n\n\n\nThe first thirty rows of the movies data frame are shown in Table 2, with variable types suppressed (since we’ll ask about them later).\n\n\nTable 2\n\nFirst 30 rows of movies, with variable types suppressed.\n\n\n# A tibble: 500 × 16\n   name           score runtime genre     rating    release_country release_date\n 1 Blue City        4.4 83 mins Action    R         United States   1986-05-02  \n 2 Winter Sleep     8.1 196     Drama     Not Rated Turkey          2014-06-12  \n 3 Rang De Basan…   8.1 167     Comedy    Not Rated United States   2006-01-26  \n 4 Pokémon Detec…   6.6 104     Action    PG        United States   2019-05-10  \n 5 A Bad Moms Ch…   5.6 104     Comedy    R         United States   2017-11-01  \n 6 Replicas         5.5 107     Drama     PG-13     United States   2019-01-11  \n 7 Windy City       5.8 103     Drama     R         Uruguay         1986-01-01  \n 8 War for the P…   7.4 140     Action    PG-13     United States   2017-07-14  \n 9 Tales from th…   6.4 98      Crime     R         United States   1995-05-24  \n10 Fire with Fire   6.5 103     Drama     PG-13     United States   1986-05-09  \n11 Raising Helen    6   119     Comedy    PG-13     United States   2004-05-28  \n12 Feeling Minne…   5.4 99      Comedy    R         United States   1996-09-13  \n13 The Babe         5.9 115     Biography PG        United States   1992-04-17  \n14 The Real Blon…   6   105     Comedy    R         United States   1998-02-27  \n15 To vlemma tou…   7.6 176     Drama     Not Rated United States   1997-11-01  \n16 Going the Dis…   6.3 102     Comedy    R         United States   2010-09-03  \n17 Jung on zo       6.8 103     Action    R         Hong Kong       1993-06-24  \n18 Rita, Sue and…   6.5 93      Comedy    R         United Kingdom  1987-05-29  \n19 Phone Booth      7   81      Crime     R         United States   2003-04-04  \n20 Happy Death D…   6.6 96      Comedy    PG-13     United States   2017-10-13  \n21 Barely Legal     4.7 90      Comedy    R         Thailand        2006-05-25  \n22 Three Kings      7.1 114     Action    R         United States   1999-10-01  \n23 Menace II Soc…   7.5 97      Crime     R         United States   1993-05-26  \n24 Four Rooms       6.8 98      Comedy    R         United States   1995-12-25  \n25 Quartet          6.8 98      Comedy    PG-13     United States   2013-03-01  \n26 Tape             7.2 86      Drama     R         Denmark         2002-07-12  \n27 Marked for De…   6   93      Action    R         United States   1990-10-05  \n28 Congo            5.2 109     Action    PG-13     United States   1995-06-09  \n29 Stop-Loss        6.4 112     Drama     R         United States   2008-03-28  \n30 Con Air          6.9 115     Action    R         United States   1997-06-06  \n      budget     gross  votes  year director         writer        star         \n                                      \n 1  10000000   6947787   1100  1986 Michelle Manning Ross Macdona… Judd Nelson  \n 2        NA   4018705  48000  2014 Nuri Bilge Ceyl… Ebru Ceylan   Haluk Bilgin…\n 3        NA  10800778 115000  2006 Rakeysh Ompraka… Renzil D'Sil… Aamir Khan   \n 4 150000000 433921300 146000  2019 Rob Letterman    Dan Hernandez Ryan Reynolds\n 5  28000000 130560428  46000  2017 Jon Lucas        Jon Lucas     Mila Kunis   \n 6  30000000   9330075  34000  2018 Jeffrey Nachman… Chad St. John Keanu Reeves \n 7        NA    343890    262  1984 Armyan Bernstein Armyan Berns… John Shea    \n 8 150000000 490719763 235000  2017 Matt Reeves      Mark Bomback  Andy Serkis  \n 9   6000000  11837928   7400  1995 Rusty Cundieff   Rusty Cundie… Clarence Wil…\n10        NA   4636169   1500  1986 Duncan Gibbins   Bill Phillips Craig Sheffer\n11  50000000  49718611  36000  2004 Garry Marshall   Patrick J. C… Kate Hudson  \n12        NA   3124440  11000  1996 Steven Baigelman Steven Baige… Keanu Reeves \n13        NA  19930973   9300  1992 Arthur Hiller    John Fusco    John Goodman \n14        NA     83488   3900  1997 Tom DiCillo      Tom DiCillo   Matthew Modi…\n15        NA        NA   6400  1995 Theodoros Angel… Theodoros An… Harvey Keitel\n16  32000000  42059111  57000  2010 Nanette Burstein Geoff LaTuli… Drew Barrymo…\n17        NA   3741869   6100  1993 Kirk Wong        Tin Nam Chun  Jackie Chan  \n18        NA    124167   3600  1987 Alan Clarke      Andrea Dunbar Siobhan Finn…\n19  13000000  97837138 255000  2002 Joel Schumacher  Larry Cohen   Colin Farrell\n20   4800000 125479266 124000  2017 Christopher Lan… Scott Lobdell Jessica Rothe\n21        NA     83439   5900  2003 David Mickey Ev… David H. Ste… Erik von Det…\n22  75000000 107752036 163000  1999 David O. Russell John Ridley   George Cloon…\n23   3500000  27912072  54000  1993 Albert Hughes    Allen Hughes  Tyrin Turner \n24   4000000   4257354 100000  1995 Directors        Allison Ande… Tim Roth     \n25  11000000  59520298  19000  2012 Dustin Hoffman   Ronald Harwo… Maggie Smith \n26    100000    515900  19000  2001 Richard Linklat… Stephen Belb… Ethan Hawke  \n27  12000000  57968936  21000  1990 Dwight H. Little Michael Grais Steven Seagal\n28  50000000 152022101  43000  1995 Frank Marshall   Michael Cric… Laura Linney \n29  25000000  11212953  20000  2008 Kimberly Peirce  Mark Richard  Ryan Phillip…\n30  75000000 224012234 282000  1997 Simon West       Scott Rosenb… Nicolas Cage \n# ℹ 470 more rows\n# ℹ 2 more variables: company, country\n\n\n\n\n\nQuestion 11\nThe name and runtime variables are shown below, with the variable types suppressed.\nmovies |&gt;\n  select(name, runtime)\n\n\n\n\n\n# A tibble: 500 × 2\n  name                      runtime\n1 Blue City                 83 mins\n2 Winter Sleep              196    \n3 Rang De Basanti           167    \n4 Pokémon Detective Pikachu 104    \n5 A Bad Moms Christmas      104    \n6 Replicas                  107    \n# ℹ 494 more rows\n\n\n\n\nWhat is the type of the runtime variable?\n\nCharacter\nDouble\nFactor\nInteger\nLogical\n\n\n\n\nQuestion 12\nThe code below summarizes the data in a certain way.\n\nmovies |&gt;\n  summarize(sum(release_country == \"United States\"))\n\n# A tibble: 1 × 1\n  `sum(release_country == \"United States\")`\n                                      &lt;int&gt;\n1                                       435\n\n\nWhich of the following is TRUE about the code and its result? Select all that are true.\n\nEvaluates whether each release_country is equal to \"United States\" or not, which results in a logical variable.\nFilters out rows where release_country is not equal to \"United States\" and counts the remaining rows.\nSums the logical values, where each TRUE is considered a 1 and each FALSE is considered a 0.\nResults in a character vector.\nThe result shows there are 435 movies released in the United States.\nQuestion 13\nSuppose you want a visualization that shows the number of movies in the sample in each genre. Your first attempt is as follows.\n\nggplot(movies, aes(x = genre)) +\n  geom_bar()\n\n\n\n\n\n\n\nA friend of yours says that the visualization is difficult to read and they suggest using the following visualization instead.\n\n\n\n\n\n\n\n\nWhich of the following modifications would your friend have made to your code to create their version? Select all that apply.\n\nCombine movies in genres other than Comedy, Drama, Action, and Horror into a new level called \"Other\".\nReorder the levels in descending order of numbers of observations, except for the \"Other\" level.\nMap genre to the y aesthetic.\nAdd a title, x and y-axis labels, and a caption.\nFilter out all moves in genres other than Comedy, Drama, Action, and Horror before plotting.\nQuestion 14\nWhich of the following is TRUE about the code and its result? Select all that are true.\n\nmovies |&gt;\n  count(rating, genre) |&gt;\n  pivot_wider(names_from = genre, values_from = n, values_fill = 0)\n\n# A tibble: 6 × 6\n  rating    Other Drama Action Comedy Horror\n  &lt;fct&gt;     &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n1 G             5     1      1      1      0\n2 PG           38    13     10     18      0\n3 PG-13        19    25     35     35      0\n4 R            45    50     57     96     21\n5 NC-17         1     2      0      1      0\n6 Not Rated     4    11      4      6      1\n\n\n\nThe code counts how many movies are in each rating and genre combination.\nThe code sorts the results in descending order.\nEach row of the output is a movie.\nThe output shows that there are six distinct ratings in the dataset.\nThe code reduces the number of variables and observations in the movies data frame to six.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#footnotes",
    "href": "exam/midterm-1-batch-B.html#footnotes",
    "title": "Midterm 1 Practice Questions",
    "section": "Footnotes",
    "text": "Footnotes\n\n“Doink doink” is the scene and episode introductory sound on the Law & Order series. If you’ve never heard it, you’re not at any disadvantage for the exam. If you’ve ever heard it, good luck getting it out of your head!↩︎",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1.html",
    "href": "exam/midterm-1.html",
    "title": "Extra Practice for Midterm 1",
    "section": "",
    "text": "Midterm 1 begins Thursday February 20. During our usual class meeting that day, you will sit for the in-class portion of the exam. Then you have from 1:00 PM Thursday Feb 20 to 8:30 AM Monday Feb 24 to complete the take-home portion of the exam. If you seek extra practice to prepare for Midterm 1, here are four things you can do:\n\nCorrect old labs: look back at old labs and fix anything you lost points on;\nFinish old AEs: revisit old AEs and complete the tasks we didn’t get to in lecture (solutions are posted);\nWatch “Code along” videos: search the course schedule for the videos with “Code along” in the title and…code along! This repo has the files;\nWork textbook problems: we have invoked IMS Chs. 1, 4, 5, 6. There are exercises at the end of each chapter, and the back of the book includes solutions for the odd-numbered exercises.\n\nBeyond that, we have compiled below a set of practice problems that you can work. Solutions will be released on Tuesday February 18 at 1:00 PM."
  },
  {
    "objectID": "exam/kahoot-howto.html",
    "href": "exam/kahoot-howto.html",
    "title": "Kahoot How-to",
    "section": "",
    "text": "You should not need to make a Kahoot account to complete any of this, but if you do, I posted my login credentials on slack.\n\nMidterm 1: https://create.kahoot.it/share/sta-199-midterm-1-review/57954244-aef7-48b7-bc98-2f44202340fd\nMidterm 2: https://create.kahoot.it/share/sta-199-midterm-2/ea5539cb-566c-4f9e-aaef-1853113287d0\n\n\n1. Click the link and select “Host live”\nClick the link and you’ll see something like this, where you can quickly skim through the questions and answers:\n\nWhen you’re ready to go, click “Host live” and you will arrive at this screen:\n\n\n\n2. Randomizing questions/answers\nGo to the settings:\n\nYou must please randomize both the question and answer order.\n\n\n\n3. Team Mode\nThis is an option that you can choose to use or not depending on attendance and the personality of your section:\n\n\nIf you go this route, it would be good to have the lab helper write down the teams, because it may contain useful information for assigning the project groups. But this is not super important.\n\n\n4. Launch the game and play\nThe music is apparently part of the charm here, so make sure you’ve got that cranked to 11. Otherwise, you’re an MC and the game basically takes care of itself. You can either play it straight and discuss at the end, or you can stop in between questions and discuss the ones that folks found challenging."
  },
  {
    "objectID": "exam/midterm-1-batch-B-solns.html",
    "href": "exam/midterm-1-batch-B-solns.html",
    "title": "Midterm 1 Practice Questions B",
    "section": "",
    "text": "d\na, d\na, d\nc\nb\na\nb\n\n\n\n\n\n\n\n\na, d\nb, c, e\na\na, c, e\na, b, c, d\na, d"
  },
  {
    "objectID": "exam/midterm-2-practice.html",
    "href": "exam/midterm-2-practice.html",
    "title": "Midterm 2 Practice Questions",
    "section": "",
    "text": "In 2020, employees of Blizzard Entertainment circulated a spreadsheet to anonymously share salaries and recent pay increases amidst rising tension in the video game industry over wage disparities and executive compensation. (Source: Blizzard Workers Share Salaries in Revolt Over Pay)\nThe name of the data frame used for this analysis is blizzard_salary and the variables are:\n\npercent_incr: Raise given in July 2020, as percent increase with values ranging from 1 (1% increase to 21.5 (21.5% increase)\nsalary_type: Type of salary, with levels Hourly and Salaried\nannual_salary: Annual salary, in USD, with values ranging from $50,939 to $216,856.\nperformance_rating: Most recent review performance rating, with levels Poor, Successful, High, and Top. The Poor level is the lowest rating and the Top level is the highest rating.\n\nThe top ten rows of blizzard_salary are shown below:\n\n\n# A tibble: 409 × 4\n   percent_incr salary_type annual_salary performance_rating\n          &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n 1          1   Salaried               1  High              \n 2          1   Salaried               1  Successful        \n 3          1   Salaried               1  High              \n 4          1   Hourly             33987. Successful        \n 5         NA   Hourly             34798. High              \n 6         NA   Hourly             35360  &lt;NA&gt;              \n 7         NA   Hourly             37440  &lt;NA&gt;              \n 8          0   Hourly             37814. &lt;NA&gt;              \n 9          4   Hourly             41101. Top               \n10          1.2 Hourly             42328  &lt;NA&gt;              \n# ℹ 399 more rows\n\n\n\nYou fit a model for predicting raises (percent_incr) from salaries (annual_salary). We’ll call this model raise_1_fit. A tidy output of the model is shown below.\n\n\n# A tibble: 2 × 5\n  term           estimate  std.error statistic   p.value\n  &lt;chr&gt;             &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   1.87      0.432           4.33 0.0000194\n2 annual_salary 0.0000155 0.00000452      3.43 0.000669 \n\n\nWhich of the following is the best interpretation of the slope coefficient?\n\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.55%.\nFor every additional $1,000 of annual salary, the raise goes up by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.87%.\n\nYou then fit a model for predicting raises (percent_incr) from salaries (annual_salary) and performance ratings (performance_rating). We’ll call this model raise_2_fit. Which of the following is definitely true based on the information you have so far?\n\nIntercept of raise_2_fit is higher than intercept of raise_1_fit.\nSlope of raise_2_fit is higher than RMSE of raise_1_fit.\nAdjusted \\(R^2\\) of raise_2_fit is higher than adjusted \\(R^2\\) of raise_1_fit.\n\n\\(R^2\\) of raise_2_fit is higher \\(R^2\\) of raise_1_fit.\n\nThe tidy model output for the raise_2_fit model you fit is shown below.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic  p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                   3.55       0.508           6.99 1.99e-11\n2 annual_salary                 0.00000989 0.00000436      2.27 2.42e- 2\n3 performance_ratingPoor       -4.06       1.42           -2.86 4.58e- 3\n4 performance_ratingSuccessful -2.40       0.397          -6.05 4.68e- 9\n5 performance_ratingTop         2.99       0.715           4.18 3.92e- 5\n\n\nWhen your teammate sees this model output, they remark “The coefficient for performance_ratingSuccessful is negative, that’s weird. I guess it means that people who get successful performance ratings get lower raises.” How would you respond to your teammate?\n\nUltimately, your teammate decides they don’t like the negative slope coefficients in the model output you created (not that there’s anything wrong with negative slope coefficients!), does something else, and comes up with the following model output.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic    p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)                  -0.511      1.47          -0.347 0.729     \n2 annual_salary                 0.00000989 0.00000436     2.27  0.0242    \n3 performance_ratingSuccessful  1.66       1.42           1.17  0.242     \n4 performance_ratingHigh        4.06       1.42           2.86  0.00458   \n5 performance_ratingTop         7.05       1.53           4.60  0.00000644\n\n\nUnfortunately they didn’t write their code in a Quarto document, instead just wrote some code in the Console and then lost track of their work. They remember using the fct_relevel() function and doing something like the following:\n\nblizzard_salary &lt;- blizzard_salary |&gt;\n  mutate(performance_rating = fct_relevel(performance_rating, ___))\n\nWhat should they put in the blanks to get the same model output as above?\n\n“Poor”, “Successful”, “High”, “Top”\n“Successful”, “High”, “Top”\n“Top”, “High”, “Successful”, “Poor”\nPoor, Successful, High, Top\n\nSuppose we fit a model to predict percent_incr from annual_salary and salary_type. A tidy output of the model is shown below.\n\n\n# A tibble: 3 × 5\n  term                 estimate  std.error statistic p.value\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)         1.24      0.570           2.18 0.0300 \n2 annual_salary       0.0000137 0.00000464      2.96 0.00329\n3 salary_typeSalaried 0.913     0.544           1.68 0.0938 \n\n\nWhich of the following visualizations represent this model? Explain your reasoning.\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\n\n\n\n\n(c) Option 3\n\n\n\n\n\n\n\n\n\n(d) Option 4\n\n\n\n\n\n\nFigure 1: Visualizations of the relationship between percent increase, annual salary, and salary type\n\n\n\n\nSuppose you now fit a model to predict the natural log of percent increase, log(percent_incr), from performance rating. The model is called raise_4_fit.\nYou’re provided the following:\n\ntidy(raise_4_fit) |&gt;\n  select(term, estimate) |&gt;\n  mutate(exp_estimate = exp(estimate))\n\n# A tibble: 4 × 3\n  term                         estimate exp_estimate\n  &lt;chr&gt;                           &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)                     -7.15     0.000786\n2 performance_ratingSuccessful     6.93  1025.      \n3 performance_ratingHigh           8.17  3534.      \n4 performance_ratingTop            8.91  7438.      \n\n\nBased on this, which of the following is true?\na. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by 10.25% compared to the employees with Poor performance rating.\nb. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by 6.93% compared to the employees with Poor performance rating.\nc. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by a factor of 1025 compared to the employees with Poor performance rating.\nd. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by a factor of 6.93 compared to the employees with Poor performance rating.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-1",
    "href": "exam/midterm-2-practice.html#question-1",
    "title": "Midterm 2 Practice Questions",
    "section": "",
    "text": "You fit a model for predicting raises (percent_incr) from salaries (annual_salary). We’ll call this model raise_1_fit. A tidy output of the model is shown below.\n\n\n# A tibble: 2 × 5\n  term           estimate  std.error statistic   p.value\n  &lt;chr&gt;             &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   1.87      0.432           4.33 0.0000194\n2 annual_salary 0.0000155 0.00000452      3.43 0.000669 \n\n\nWhich of the following is the best interpretation of the slope coefficient?\n\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.55%.\nFor every additional $1,000 of annual salary, the raise goes up by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.87%.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-2",
    "href": "exam/midterm-2-practice.html#question-2",
    "title": "Midterm 2 Practice Questions",
    "section": "",
    "text": "You then fit a model for predicting raises (percent_incr) from salaries (annual_salary) and performance ratings (performance_rating). We’ll call this model raise_2_fit. Which of the following is definitely true based on the information you have so far?\n\nIntercept of raise_2_fit is higher than intercept of raise_1_fit.\nSlope of raise_2_fit is higher than RMSE of raise_1_fit.\nAdjusted \\(R^2\\) of raise_2_fit is higher than adjusted \\(R^2\\) of raise_1_fit.\n\n\\(R^2\\) of raise_2_fit is higher \\(R^2\\) of raise_1_fit.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-3",
    "href": "exam/midterm-2-practice.html#question-3",
    "title": "Midterm 2 Practice Questions",
    "section": "",
    "text": "The tidy model output for the raise_2_fit model you fit is shown below.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic  p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                   3.55       0.508           6.99 1.99e-11\n2 annual_salary                 0.00000989 0.00000436      2.27 2.42e- 2\n3 performance_ratingPoor       -4.06       1.42           -2.86 4.58e- 3\n4 performance_ratingSuccessful -2.40       0.397          -6.05 4.68e- 9\n5 performance_ratingTop         2.99       0.715           4.18 3.92e- 5\n\n\nWhen your teammate sees this model output, they remark “The coefficient for performance_ratingSuccessful is negative, that’s weird. I guess it means that people who get successful performance ratings get lower raises.” How would you respond to your teammate?",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-4",
    "href": "exam/midterm-2-practice.html#question-4",
    "title": "Midterm 2 Practice Questions",
    "section": "",
    "text": "Ultimately, your teammate decides they don’t like the negative slope coefficients in the model output you created (not that there’s anything wrong with negative slope coefficients!), does something else, and comes up with the following model output.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic    p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)                  -0.511      1.47          -0.347 0.729     \n2 annual_salary                 0.00000989 0.00000436     2.27  0.0242    \n3 performance_ratingSuccessful  1.66       1.42           1.17  0.242     \n4 performance_ratingHigh        4.06       1.42           2.86  0.00458   \n5 performance_ratingTop         7.05       1.53           4.60  0.00000644\n\n\nUnfortunately they didn’t write their code in a Quarto document, instead just wrote some code in the Console and then lost track of their work. They remember using the fct_relevel() function and doing something like the following:\n\nblizzard_salary &lt;- blizzard_salary |&gt;\n  mutate(performance_rating = fct_relevel(performance_rating, ___))\n\nWhat should they put in the blanks to get the same model output as above?\n\n“Poor”, “Successful”, “High”, “Top”\n“Successful”, “High”, “Top”\n“Top”, “High”, “Successful”, “Poor”\nPoor, Successful, High, Top",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-5",
    "href": "exam/midterm-2-practice.html#question-5",
    "title": "Midterm 2 Practice Questions",
    "section": "",
    "text": "Suppose we fit a model to predict percent_incr from annual_salary and salary_type. A tidy output of the model is shown below.\n\n\n# A tibble: 3 × 5\n  term                 estimate  std.error statistic p.value\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)         1.24      0.570           2.18 0.0300 \n2 annual_salary       0.0000137 0.00000464      2.96 0.00329\n3 salary_typeSalaried 0.913     0.544           1.68 0.0938 \n\n\nWhich of the following visualizations represent this model? Explain your reasoning.\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\n\n\n\n\n(c) Option 3\n\n\n\n\n\n\n\n\n\n(d) Option 4\n\n\n\n\n\n\nFigure 1: Visualizations of the relationship between percent increase, annual salary, and salary type",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-6",
    "href": "exam/midterm-2-practice.html#question-6",
    "title": "Midterm 2 Practice Questions",
    "section": "",
    "text": "Suppose you now fit a model to predict the natural log of percent increase, log(percent_incr), from performance rating. The model is called raise_4_fit.\nYou’re provided the following:\n\ntidy(raise_4_fit) |&gt;\n  select(term, estimate) |&gt;\n  mutate(exp_estimate = exp(estimate))\n\n# A tibble: 4 × 3\n  term                         estimate exp_estimate\n  &lt;chr&gt;                           &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)                     -7.15     0.000786\n2 performance_ratingSuccessful     6.93  1025.      \n3 performance_ratingHigh           8.17  3534.      \n4 performance_ratingTop            8.91  7438.      \n\n\nBased on this, which of the following is true?\na. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by 10.25% compared to the employees with Poor performance rating.\nb. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by 6.93% compared to the employees with Poor performance rating.\nc. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by a factor of 1025 compared to the employees with Poor performance rating.\nd. The model predicts that the percentage increase employees with Successful performance get, on average, is higher by a factor of 6.93 compared to the employees with Poor performance rating.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-7",
    "href": "exam/midterm-2-practice.html#question-7",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 7",
    "text": "Question 7\nPartial code for producing Figure 2 is given below. Which of the following goes in the blank on Line 2? Select all that apply.\n\nmovies |&gt;\n  mutate(runtime = ___) |&gt;\n  ggplot(aes(x = runtime, y = score)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE)\n  # additional code for annotating Blue City on the plot\n\n\ngrepl(\" mins\", runtime)\ngrep(\" mins\", runtime)\nstr_remove(runtime, \" mins\")\nas.numeric(str_remove(runtime, \" mins\"))\nna.rm(runtime)",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-8",
    "href": "exam/midterm-2-practice.html#question-8",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 8",
    "text": "Question 8\nBased on this model, order the three labeled movies in Figure 2 in decreasing order of the magnitude (absolute value) of their residuals.\n\nWinter Sleep&gt; Rang De Basanti &gt; Blue City\nWinter Sleep&gt; Blue City &gt; Rang De Basanti\nRang De Basanti &gt; Winter Sleep&gt; Blue City\nBlue City &gt; Winter Sleep &gt; Rang De Basanti\nBlue City &gt; Rang De Basanti &gt; Winter Sleep",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-9",
    "href": "exam/midterm-2-practice.html#question-9",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 9",
    "text": "Question 9\nThe R-squared for the model visualized in Figure 2 is 31%. Which of the following is the best interpretation of this value?\n\n31% of the variability in movie runtimes is explained by their scores.\n31% of the variability in movie scores is explained by their runtime.\nThe model accurately predicts scores of 31% of the movies in this sample.\nThe model accurately predicts scores of 31% of all movies.\nThe correlation between scores and runtimes of movies is 0.31.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-10",
    "href": "exam/midterm-2-practice.html#question-10",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 10",
    "text": "Question 10\nWhich of the following goes in __blank_1__?\n\nsummarize\nmutate\ngroup_by\narrange\nfilter",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-11",
    "href": "exam/midterm-2-practice.html#question-11",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 11",
    "text": "Question 11\nWhat can we say about the value that goes in __blank_2__?\n\nNA\nA value between 0 and 0.434.\nA value between 0.434 and 1.\nA value between 0 and -0.434.\nA value between -1 and -0.434.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-12",
    "href": "exam/midterm-2-practice.html#question-12",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 12",
    "text": "Question 12\nWhich of the following is TRUE about the intercept of score_runtime_rating_fit? Select all that are true.\n\nKeeping runtime constant, G-rated movies are predicted to score, on average, 4.525 points.\nKeeping runtime constant, movies without a rating are predicted to score, on average, 4.525 points.\nMovies without a rating that are 0 minutes in length are predicted to score, on average, 4.525 points.\nAll else held constant, movies that are 0 minutes in length are predicted to score, on average, 4.525 points.\nG-rated movies that are 0 minutes in length are predicted to score, on average, 4.525 points.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-13",
    "href": "exam/midterm-2-practice.html#question-13",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 13",
    "text": "Question 13\nWhich of the following is the best interpretation of the slope of runtime in score_runtime_rating_fit?\n\nAll else held constant, as runtime increases by 1 minute, the score of the movie increases by 0.021 points.\nFor G-rated movies, all else held constant, as runtime increases by 1 minute, the score of the movie increases by 0.021 points.\nAll else held constant, for each additional minute of runtime, movie scores will be higher by 0.021 points on average.\nG-rated movies that are 0 minutes in length are predicted to score 0.021 points on average.\nFor each higher level of rating, the movie scores go up by 0.021 points on average.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-14",
    "href": "exam/midterm-2-practice.html#question-14",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 14",
    "text": "Question 14\nFill in the blank:\n\nR-squared for score_runtime_rating_fit (the model predicting score from runtime and rating) _________ the R-squared the model score_runtime_fit (for predicting score from runtime alone).\n\n\nis less than\nis equal to\nis greater than\ncannot be compared (based on the information provided) to\nis both greater than and less than",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-15",
    "href": "exam/midterm-2-practice.html#question-15",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 15",
    "text": "Question 15\nThe model score_runtime_rating_fit (the model predicting score from runtime and rating) can be visualized as parallel lines for each level of rating. Which of the following is the equation of the line for R-rated movies?\n\n\\(\\widehat{score} = (4.525 - 0.257) + 0.021 \\times runtime\\)\n\\(score = (4.525 - 0.257) + 0.021 \\times runtime\\)\n\\(\\widehat{score} = 4.525 + (0.021 - 0.257) \\times runtime\\)\n\\(score = 4.525 + (0.021 - 0.257) \\times runtime\\)\n\\(\\widehat{score} = (4.525 + 0.021) - 0.257 \\times runtime\\)",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-16",
    "href": "exam/midterm-2-practice.html#question-16",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 16",
    "text": "Question 16\nWhich of the following is the definition of a regression model? Select all that apply.\na. \\(\\hat{y} = b_0 + b_1 X_1\\)\nb. \\(y = \\beta_0 + \\beta_1 X_1\\)\nc. \\(\\hat{y} = \\beta_0 + \\beta_1 X_1 + \\epsilon\\)\nd. \\(y = \\beta_0 + \\beta_1 X_1 + \\epsilon\\)",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-17",
    "href": "exam/midterm-2-practice.html#question-17",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 17",
    "text": "Question 17\nChoose the best answer.\nA survey based on a random sample of 2,045 American teenagers found that a 95% confidence interval for the mean number of texts sent per month was (1450, 1550). A valid interpretation of this interval is\n\n95% of all teens who text send between 1450 and 1550 text messages per month.\nIf a new survey with the same sample size were to be taken, there is a 95% chance that the mean number of texts in the sample would be between 1450 and 1550.\nWe are 95% confident that the mean number of texts per month of all American teens is between 1450 and 1550.\nWe are 95% confident that, were we to repeat this survey, the mean number of texts per month of those taking part in the survey would be between 1450 and 1550.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-18",
    "href": "exam/midterm-2-practice.html#question-18",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 18",
    "text": "Question 18\nDefine the term “parsimonious model”.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-19",
    "href": "exam/midterm-2-practice.html#question-19",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 19",
    "text": "Question 19\n\nWhat type of variable is spam? What percent of the emails are spam?\nWhat type of variable is dollar - number of times a dollar sign or the word “dollar” appeared in the email? Visualize and describe its distribution, supporting your description with the appropriate summary statistics.\nFit a logistic regression model predicting spam from dollar. Then, display the tidy output of the model.\n\nUsing this model and the predict() function, predict the probability the email is spam if it contains 5 dollar signs. Based on this probability, how does the model classify this email?\n\n\n\n\n\n\nNote\n\n\n\nTo obtain the predicted probability, you can set the type argument in predict() to \"prob\".",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-20",
    "href": "exam/midterm-2-practice.html#question-20",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 20",
    "text": "Question 20\n\nFit another logistic regression model predicting spam from dollar, winner (indicating whether “winner” appeared in the email), and urgent_subj (whether the word “urgent” is in the subject of the email). Then, display the tidy output of the model.\nUsing this model and the augment() function, classify each email in the email dataset as spam or not spam. Store the resulting data frame with an appropriate name and display the data frame as well.\n\nUsing your data frame from the previous part, determine, in a single pipeline, and using count(), the numbers of emails:\n\nthat are labelled as spam that are actually spam\nthat are not labelled as spam that are actually spam\nthat are labelled as spam that are actually not spam\nthat are not labelled as spam that are actually not spam\n\nStore the resulting data frame with an appropriate name and display the data frame as well.\n\nIn a single pipeline, and using mutate(), calculate the false positive and false negative rates. In addition to these numbers showing in your R output, you must write a sentence that explicitly states and identified the two rates.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "exam/midterm-2-practice.html#question-21",
    "href": "exam/midterm-2-practice.html#question-21",
    "title": "Midterm 2 Practice Questions",
    "section": "Question 21",
    "text": "Question 21\n\nFit another logistic regression model predicting spam from dollar and another variable you think would be a good predictor. Provide a 1-sentence justification for why you chose this variable. Display the tidy output of the model.\nUsing this model and the augment() function, classify each email in the email dataset as spam or not spam. Store the resulting data frame with an appropriate name and display the data frame as well.\n\nUsing your data frame from the previous part, determine, in a single pipeline, and using count(), the numbers of emails:\n\nthat are labelled as spam that are actually spam\nthat are not labelled as spam that are actually spam\nthat are labelled as spam that are actually not spam\nthat are not labelled as spam that are actually not spam\n\nStore the resulting data frame with an appropriate name and display the data frame as well.\n\nIn a single pipeline, and using mutate(), calculate the false positive and false negative rates. In addition to these numbers showing in your R output, you must write a sentence that explicitly states and identified the two rates.\nBased on the false positive and false negatives rates of this model, comment, in 1-2 sentences, on which model (one from Question 2 or Question 3) is preferable and why.",
    "crumbs": [
      "Exam practice",
      "Midterm 2"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html",
    "href": "computing/coding-principles-oh.html",
    "title": "Intro to Coding Principles",
    "section": "",
    "text": "library(tidyverse)",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#definition",
    "href": "computing/coding-principles-oh.html#definition",
    "title": "Intro to Coding Principles",
    "section": "Definition",
    "text": "Definition\nSo what even is a variable, in the first place? There are many possible definitions:\n\nAnything you assign!\nPractically speaking, variables are a way for you to store data without having to type it out every time.\nThey allow you to manipulate data with the help of pre-built functions (more on that later).\nThey can also be changed - hence the name “variable”.\n\nWhat are some examples of variables?\n\nThe simplest is a single value - like in math. I could say “x = 10”.\nIt might also be a vector - essentially a list of values. For example, I might just store every name in this class in a vector.\nMost frequently, your variables will be your entire data frames.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#assignment-saving",
    "href": "computing/coding-principles-oh.html#assignment-saving",
    "title": "Intro to Coding Principles",
    "section": "Assignment & Saving",
    "text": "Assignment & Saving\nOk, these seem pretty useful - so how do we use them? In math and most programming languages, you use the “=” operator. This is also possible to do in R:\n\nx = 10\nx\n\n[1] 10\n\n\nHowever, in R, we prefer to use the “&lt;-” operator, to avoid confusion between variable assignment and function arguments. Here’s how that looks:\n\ny &lt;- 15\ny\n\n[1] 15\n\n\nSaving Changes\nSuppose you run a function on a variable. By default, R will show you the output of this function, but it will not actually modify your variable. For example, let’s look at the midwest data set:\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow, let’s run a function that “changes” the data frame. We can use select() to look only at the county column:\n\nmidwest |&gt;\n  select(county)\n\n# A tibble: 437 × 1\n   county   \n   &lt;chr&gt;    \n 1 ADAMS    \n 2 ALEXANDER\n 3 BOND     \n 4 BOONE    \n 5 BROWN    \n 6 BUREAU   \n 7 CALHOUN  \n 8 CARROLL  \n 9 CASS     \n10 CHAMPAIGN\n# ℹ 427 more rows\n\n\nCool change! So, just to make sure, let’s look at the midwest data frame one more time.\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow wait a minute - what happened here? I clearly told it to select the county column, and it did! So why is it that, when I went to look at the midwest data frame again, it had all of the columns, not just the one that I selected?\nThe answer is that we never saved midwest back to a variable! By default, R will show the output, but not modify the data frame unless I want it to. Let’s look at a couple ways we can do that:\n\nmidwest &lt;- midwest |&gt;\n  select(county)\n\nmidwest\n\n# A tibble: 437 × 1\n   county   \n   &lt;chr&gt;    \n 1 ADAMS    \n 2 ALEXANDER\n 3 BOND     \n 4 BOONE    \n 5 BROWN    \n 6 BUREAU   \n 7 CALHOUN  \n 8 CARROLL  \n 9 CASS     \n10 CHAMPAIGN\n# ℹ 427 more rows\n\n\nThe first option is to simply overwrite the variable. This is useful if you’re never going to need those data in their original form - it saves you some confusion in that case.\nHowever, what if later on I decide I did need those data after all? Perhaps I wanted population density data. I go to try and find this variable in the midwest data set, because that’s where I know it’s stored…\n\nmidwest |&gt;\n  select(popdensity)\n\nError in `select()`:\n! Can't select columns that don't exist.\n✖ Column `popdensity` doesn't exist.\n\n\n…but the variable is gone! This is a common point of confusion for students in STA 199, so it’s important to understand what you’re doing whenever you modify your data in-place like this - you’re overwriting the existing data.\nWe have a couple of options here. If we were loading these data from a .csv file, we could go back to the top of the document. Or, we could do something more effective: Go to Environment, click the little broom icon, and select “yes”.\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow the second option: let’s try making the modification a little more carefully: saving the data to a new variable.\n\nmidwest_counties &lt;- midwest |&gt;\n  select(county)\n\nmidwest_counties\n\n# A tibble: 437 × 1\n   county   \n   &lt;chr&gt;    \n 1 ADAMS    \n 2 ALEXANDER\n 3 BOND     \n 4 BOONE    \n 5 BROWN    \n 6 BUREAU   \n 7 CALHOUN  \n 8 CARROLL  \n 9 CASS     \n10 CHAMPAIGN\n# ℹ 427 more rows\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow we have two data frames: the new data frame midwest_counties, which contains our modifications from the data pipeline above, and the original data frame midwest, which has not been changed. Both of these are useful operations, and you will undoubtedly use both this semester! However, keep this distinction in mind when you’re mutating your data - don’t remove anything you think you’ll need later.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#displaying-variables",
    "href": "computing/coding-principles-oh.html#displaying-variables",
    "title": "Intro to Coding Principles",
    "section": "Displaying Variables",
    "text": "Displaying Variables\nThe first several weeks of this course are dedicated to data cleaning, manipulation, and transformation. As a result, you will often be asked to display the resulting output of your code (and even if we don’t ask you to do this, it’s often a good idea to do so anyway).\nIn the previous section, I mentioned that by default, R will show the output of code but not modify your variables. The opposite is true if you save your changes: R will not display the output of your code.\n\nx &lt;- 10\n\nThere are many ways to display the output of your code in a quarto document. The first, and most common, is simply to write the name of the variable at the bottom of a code chunk:\n\ny &lt;- 30\ny\n\n[1] 30\n\n\nNote: Unlike many languages, R does not require the use of the print() function: While you can still use it, this is a very common artifact of AI-generated code, so if you use it we’re going to look a lot closer at the rest of your responses.\nThis first approach works well for small examples, but may not work as well for data frames:\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nThere are a couple of good workarounds for this! My personal favorite is to use the glimpse() function, which gives you important information on the data frame:\n\nglimpse(midwest)\n\nRows: 437\nColumns: 28\n$ PID                  &lt;int&gt; 561, 562, 563, 564, 565, 566, 567, 568, 569, 570,…\n$ county               &lt;chr&gt; \"ADAMS\", \"ALEXANDER\", \"BOND\", \"BOONE\", \"BROWN\", \"…\n$ state                &lt;chr&gt; \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"…\n$ area                 &lt;dbl&gt; 0.052, 0.014, 0.022, 0.017, 0.018, 0.050, 0.017, …\n$ poptotal             &lt;int&gt; 66090, 10626, 14991, 30806, 5836, 35688, 5322, 16…\n$ popdensity           &lt;dbl&gt; 1270.9615, 759.0000, 681.4091, 1812.1176, 324.222…\n$ popwhite             &lt;int&gt; 63917, 7054, 14477, 29344, 5264, 35157, 5298, 165…\n$ popblack             &lt;int&gt; 1702, 3496, 429, 127, 547, 50, 1, 111, 16, 16559,…\n$ popamerindian        &lt;int&gt; 98, 19, 35, 46, 14, 65, 8, 30, 8, 331, 51, 26, 17…\n$ popasian             &lt;int&gt; 249, 48, 16, 150, 5, 195, 15, 61, 23, 8033, 89, 3…\n$ popother             &lt;int&gt; 124, 9, 34, 1139, 6, 221, 0, 84, 6, 1596, 20, 7, …\n$ percwhite            &lt;dbl&gt; 96.71206, 66.38434, 96.57128, 95.25417, 90.19877,…\n$ percblack            &lt;dbl&gt; 2.57527614, 32.90043290, 2.86171703, 0.41225735, …\n$ percamerindan        &lt;dbl&gt; 0.14828264, 0.17880670, 0.23347342, 0.14932156, 0…\n$ percasian            &lt;dbl&gt; 0.37675897, 0.45172219, 0.10673071, 0.48691813, 0…\n$ percother            &lt;dbl&gt; 0.18762294, 0.08469791, 0.22680275, 3.69733169, 0…\n$ popadults            &lt;int&gt; 43298, 6724, 9669, 19272, 3979, 23444, 3583, 1132…\n$ perchsd              &lt;dbl&gt; 75.10740, 59.72635, 69.33499, 75.47219, 68.86152,…\n$ percollege           &lt;dbl&gt; 19.63139, 11.24331, 17.03382, 17.27895, 14.47600,…\n$ percprof             &lt;dbl&gt; 4.355859, 2.870315, 4.488572, 4.197800, 3.367680,…\n$ poppovertyknown      &lt;int&gt; 63628, 10529, 14235, 30337, 4815, 35107, 5241, 16…\n$ percpovertyknown     &lt;dbl&gt; 96.27478, 99.08714, 94.95697, 98.47757, 82.50514,…\n$ percbelowpoverty     &lt;dbl&gt; 13.151443, 32.244278, 12.068844, 7.209019, 13.520…\n$ percchildbelowpovert &lt;dbl&gt; 18.011717, 45.826514, 14.036061, 11.179536, 13.02…\n$ percadultpoverty     &lt;dbl&gt; 11.009776, 27.385647, 10.852090, 5.536013, 11.143…\n$ percelderlypoverty   &lt;dbl&gt; 12.443812, 25.228976, 12.697410, 6.217047, 19.200…\n$ inmetro              &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0…\n$ category             &lt;chr&gt; \"AAR\", \"LHR\", \"AAR\", \"ALU\", \"AAR\", \"AAR\", \"LAR\", …\n\n\nIn this output, we can see the total number of rows (437 observations) and columns (28 variables), the names of every variable, the variable types, and the first few entries in each column. Note: each column in your data frame is displayed as a row in the glimpse() output. Pay attention to the numbers at the top, and don’t get confused!\nIf you don’t need to display output in your pdf, running view() in the console can actually be very effective! This has the same effect as clicking on the name of a variable in the “Environment” pane in the top-right corner of your R studio. This will open up your data in a new tab, known as the “data viewer”, where you can look through columns, sort by clicking, and even apply filters. Running this in the console means you will be able to view it on your own computer as you work through the problem, but it will not be printed in your final pdf - the best of both worlds.\nIn Lab 1, we used the data viewer to identify outliers in the midwest population density. In the future, you will not be allowed to do this: We expect reproducible code, so you will need to use an assortment of dplyr commands to sort, filter, and select data for display. However, the data viewer can still be useful in a number of situations, so long as you’re careful about it!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#variable-examples",
    "href": "computing/coding-principles-oh.html#variable-examples",
    "title": "Intro to Coding Principles",
    "section": "Variable Examples",
    "text": "Variable Examples\n\nx &lt;- 10\nx\n\n[1] 10\n\ny &lt;- c(3, 5)\ny\n\n[1] 3 5\n\nz &lt;- midwest\nz\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#examples",
    "href": "computing/coding-principles-oh.html#examples",
    "title": "Intro to Coding Principles",
    "section": "Examples",
    "text": "Examples\nEvery column in a data frame will have a particular data type - sort of a way that R recognizes, classifies, and interacts with the data. Let’s look at an example, using the convenient glimpse function:\n\nglimpse(midwest)\n\nRows: 437\nColumns: 28\n$ PID                  &lt;int&gt; 561, 562, 563, 564, 565, 566, 567, 568, 569, 570,…\n$ county               &lt;chr&gt; \"ADAMS\", \"ALEXANDER\", \"BOND\", \"BOONE\", \"BROWN\", \"…\n$ state                &lt;chr&gt; \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"…\n$ area                 &lt;dbl&gt; 0.052, 0.014, 0.022, 0.017, 0.018, 0.050, 0.017, …\n$ poptotal             &lt;int&gt; 66090, 10626, 14991, 30806, 5836, 35688, 5322, 16…\n$ popdensity           &lt;dbl&gt; 1270.9615, 759.0000, 681.4091, 1812.1176, 324.222…\n$ popwhite             &lt;int&gt; 63917, 7054, 14477, 29344, 5264, 35157, 5298, 165…\n$ popblack             &lt;int&gt; 1702, 3496, 429, 127, 547, 50, 1, 111, 16, 16559,…\n$ popamerindian        &lt;int&gt; 98, 19, 35, 46, 14, 65, 8, 30, 8, 331, 51, 26, 17…\n$ popasian             &lt;int&gt; 249, 48, 16, 150, 5, 195, 15, 61, 23, 8033, 89, 3…\n$ popother             &lt;int&gt; 124, 9, 34, 1139, 6, 221, 0, 84, 6, 1596, 20, 7, …\n$ percwhite            &lt;dbl&gt; 96.71206, 66.38434, 96.57128, 95.25417, 90.19877,…\n$ percblack            &lt;dbl&gt; 2.57527614, 32.90043290, 2.86171703, 0.41225735, …\n$ percamerindan        &lt;dbl&gt; 0.14828264, 0.17880670, 0.23347342, 0.14932156, 0…\n$ percasian            &lt;dbl&gt; 0.37675897, 0.45172219, 0.10673071, 0.48691813, 0…\n$ percother            &lt;dbl&gt; 0.18762294, 0.08469791, 0.22680275, 3.69733169, 0…\n$ popadults            &lt;int&gt; 43298, 6724, 9669, 19272, 3979, 23444, 3583, 1132…\n$ perchsd              &lt;dbl&gt; 75.10740, 59.72635, 69.33499, 75.47219, 68.86152,…\n$ percollege           &lt;dbl&gt; 19.63139, 11.24331, 17.03382, 17.27895, 14.47600,…\n$ percprof             &lt;dbl&gt; 4.355859, 2.870315, 4.488572, 4.197800, 3.367680,…\n$ poppovertyknown      &lt;int&gt; 63628, 10529, 14235, 30337, 4815, 35107, 5241, 16…\n$ percpovertyknown     &lt;dbl&gt; 96.27478, 99.08714, 94.95697, 98.47757, 82.50514,…\n$ percbelowpoverty     &lt;dbl&gt; 13.151443, 32.244278, 12.068844, 7.209019, 13.520…\n$ percchildbelowpovert &lt;dbl&gt; 18.011717, 45.826514, 14.036061, 11.179536, 13.02…\n$ percadultpoverty     &lt;dbl&gt; 11.009776, 27.385647, 10.852090, 5.536013, 11.143…\n$ percelderlypoverty   &lt;dbl&gt; 12.443812, 25.228976, 12.697410, 6.217047, 19.200…\n$ inmetro              &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0…\n$ category             &lt;chr&gt; \"AAR\", \"LHR\", \"AAR\", \"ALU\", \"AAR\", \"AAR\", \"LAR\", …\n\n\nNext to the data, we can see various designations - &lt;int&gt;, &lt;dbl&gt;, &lt;chr&gt;, etc. These are data types. But what exactly is the difference?\nDouble/Numeric\nThe dbl data type, which is the default implementation of the numeric class, stands for double - meaning “double-precision floating-point format”. It’s pretty clear that double is an easier word to remember! This allows you to store numbers with a lot of decimal points (but not infinite!). For example, let’s look at \\(\\pi\\), which is built in as pi in R:\n\npi\n\n[1] 3.141593\n\ntypeof(pi)\n\n[1] \"double\"\n\n\nHere, we use the typeof() function to determine what data type R is using to store our variables. In this case, we can see that R stores pi as a double variable, which is the default for all numeric variables. In general, whenever you work with numbers, they will be doubles, and for purposes of STA 199 there is no issue with this.\nInteger\nThe int data type means integer - as in, the mathematical concept of an integer. All data represented as integers will be whole numbers. This data type is not capable of storing decimal places, so if you try to do decimal operations with it, R will implicitly cast it to another data type. Implicitly means that it does this without us telling it to. Let’s take a look at a couple of examples:\n\na &lt;- 3\ntypeof(a)\n\n[1] \"double\"\n\n\nBy default, R will treat all numbers as the numeric class. If you want to explicitly tell R that your number is an integer, follow the number with “L”:\n\na &lt;- 3L\ntypeof(a)\n\n[1] \"integer\"\n\n\nNow, let’s say we want to divide this number by 2:\n\nb &lt;- a / 2\ntypeof(b)\n\n[1] \"double\"\n\n\nSince 3 is not divisible by 2, the output is a decimal. However, since we have performed a decimal operation, rather than trying to guess whether to round up or down, R simply implicitly casts it back to numeric.\nLogical/Boolean\nWhile there isn’t an example in this data frame, there is a data type called logical - which represents true/false.\n\nc &lt;- TRUE\ntypeof(c)\n\n[1] \"logical\"\n\n\nIn R, you need to type out TRUE/FALSE in all caps for it to be recognized. Under the hood, R stores these values as “FALSE = 0” and “TRUE = 1”, which means that if you want to find the percentage of TRUE in your data, you can just take the average:\n\nd &lt;- c(TRUE, FALSE, TRUE)\nmean(d)\n\n[1] 0.6666667\n\n\nCharacter/String\nThe character data type represents all characters and strings in R. Unlike some languages, R does not differentiate between these. In general, strings are used to represent words and categorical data, for example:\n\nplace &lt;- \"Durham, NC\"\ntypeof(place)\n\n[1] \"character\"\n\n\nIn order for R to recognize a variable as a string, it needs to be wrapped in quotation marks. Single or double quotation marks are acceptable:\n\nnew_place &lt;- 'Cincinnati'\ntypeof(new_place)\n\n[1] \"character\"\n\n\nHowever, missing quotation marks will generate an error:\n\nanother_place &lt;- Timbuktu\n\nError in eval(expr, envir, enclos): object 'Timbuktu' not found\n\n\nIn this case, since Timbuktu is not wrapped in quotation marks, R is looking for a pre-existing object - a variable or a function - called Timbuktu. Since no such object exists, R throws an error, and will refuse to compile your document (unless you force it to).\nThere is another important point of caution here. Sometimes, when you load in a data frame, there will be columns that should be represented as numbers, but are accidentally represented as strings. If you’re not careful, this can have consequences. For example, consider the following:\n\n0 == 00\n\n[1] TRUE\n\n\"0\" == \"00\"\n\n[1] FALSE\n\n\nIn R, the numbers 0 and 00 represent the same thing! However, when they are strings, they do not. R treats numbers differently than it does strings, so it’s important to pay attention to which one you are actually implementing. You might also run into issues with some of your operations - for example, if you try to take the average of a column of strings, R has no idea what to do and will throw an error.\nNote: pay attention to the usage of two equal signs here, rather than just one. Why did we do this? (More on this shortly.)",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#casting",
    "href": "computing/coding-principles-oh.html#casting",
    "title": "Intro to Coding Principles",
    "section": "Casting",
    "text": "Casting\nSo what is the solution to this problem? The answer is called casting, which means changing the data type. You do this using the as.character(), as.numeric(), and as.logical() commands. Let’s look at an example:\n\ne &lt;- \"00\"\ntypeof(e)\n\n[1] \"character\"\n\ne\n\n[1] \"00\"\n\ne &lt;- as.numeric(e)\ntypeof(e)\n\n[1] \"double\"\n\ne\n\n[1] 0\n\ne &lt;- as.logical(e)\ntypeof(e)\n\n[1] \"logical\"\n\ne\n\n[1] FALSE\n\ne &lt;- as.character(e)\ntypeof(e)\n\n[1] \"character\"\n\ne\n\n[1] \"FALSE\"\n\ne &lt;- as.numeric(e) # What happened?\n\nWarning: NAs introduced by coercion\n\ne\n\n[1] NA\n\n\nBe mindful with your casting - you can lose information along the way!\nNote: NA is a specific type in R. It essentially means “nothing” or “there was an error”. You cannot use == to check whether a value is NA. Instead, you must use is.na(). Similarly, you may come across NULL, which essentially means “this memory has not been declared”. To check for NULL, you must use is.null().",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#equals",
    "href": "computing/coding-principles-oh.html#equals",
    "title": "Intro to Coding Principles",
    "section": "Equals",
    "text": "Equals\nThe first Boolean operator is “equals”. This is a place where it is easy to get confused. We use the single equals sign, =, to denote assignment - essentially, telling R “this thing takes this value.” We use the double equals sign, ==, to denote comparison - essentially, asking R “are these two values equal?” It is important to keep these two things distinct - if you want to check equality, or filter for a specific value, you always need to use the double equals sign!\n\nmidwest |&gt;\n  filter(county = \"Cook\")\n\nError in `filter()`:\n! We detected a named input.\nℹ This usually means that you've used `=` instead of `==`.\nℹ Did you mean `county == \"Cook\"`?\n\n\nHere’s an example of where a single equals sign is incorrect, and R returns an error. Fortunately, it has a very helpful suggestion in the error message! Let’s replace that with the double equals:\n\nmidwest |&gt;\n  filter(county == \"Cook\")\n\n# A tibble: 0 × 28\n# ℹ 28 variables: PID &lt;int&gt;, county &lt;chr&gt;, state &lt;chr&gt;, area &lt;dbl&gt;,\n#   poptotal &lt;int&gt;, popdensity &lt;dbl&gt;, popwhite &lt;int&gt;, popblack &lt;int&gt;,\n#   popamerindian &lt;int&gt;, popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;, …\n\n\nNow there’s no error message, but we also didn’t return any values. Why did this happen? When I use ==, I am checking whether these two strings are exactly equivalent, and that includes being case sensitive. If I view the data in the data frame, I see that all of the county names are actually in all caps. I can fix the string in my example…\n\nmidwest |&gt;\n  filter(county == \"COOK\")\n\n# A tibble: 1 × 28\n    PID county state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   576 COOK   IL    0.058  5105067     88018.  3204947  1317147         10289\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\n…and finally find Chicago!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#and",
    "href": "computing/coding-principles-oh.html#and",
    "title": "Intro to Coding Principles",
    "section": "And",
    "text": "And\nThe second Boolean operator is “and”. We use this when we want multiple conditions to be true. In R, to denote and, we use the single ampersand & (in some other languages, you use a double ampersand). When R sees this, it checks both statements, and only returns TRUE if both statements are true. Let’s look at an example, again using filter():\n\nmidwest |&gt;\n  filter(state == \"IL\")\n\n# A tibble: 102 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 92 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nUsing our == operator, we can find all of the counties in Illinois. Now, let’s find only the ones with a population density over 30,000:\n\nmidwest |&gt;\n  filter(state == \"IL\" & popdensity &gt;= 30000)\n\n# A tibble: 2 × 28\n    PID county  state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   576 COOK    IL    0.058  5105067     88018.  3204947  1317147         10289\n2   582 DU PAGE IL    0.02    781666     39083.   714905    15462           962\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow, the filter() statement is returning all of the rows from this data frame where BOTH the state is “IL” AND the population density is \\(\\geq\\) 30,000.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#or",
    "href": "computing/coding-principles-oh.html#or",
    "title": "Intro to Coding Principles",
    "section": "Or",
    "text": "Or\nThe third Boolean operator is “or”. We use this when we want at least one condition to be true. In R, to denote or, we use the vertical line | (again, in some other languages, you use a double line). When R sees this, it checks both statements, and returns TRUE if either (or both) of the statements are true. Let’s go back to our example:\n\nmidwest |&gt;\n  filter(state == \"IL\" | popdensity &gt;= 30000) |&gt;\n  arrange(desc(popdensity))\n\n# A tibble: 107 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   576 COOK    IL    0.058  5105067     88018.  3204947  1317147         10289\n 2  3021 MILWAU… WI    0.015   959275     63952.   718918   195470          6994\n 3  1278 WAYNE   MI    0.035  2111687     60334.  1212007   849109          8048\n 4  2026 CUYAHO… OH    0.026  1412140     54313.  1025756   350185          2533\n 5   582 DU PAGE IL    0.02    781666     39083.   714905    15462           962\n 6   711 MARION  IN    0.023   797159     34659.   615039   169654          1698\n 7  2039 HAMILT… OH    0.025   866228     34649.   672972   181145          1204\n 8   609 LAKE    IL    0.028   516418     18444.   450666    34771          1198\n 9   605 KANE    IL    0.029   317471     10947.   269675    19006           620\n10   661 Winneb… IL    0.03    252913      8430.   222439    23256           651\n# ℹ 97 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow, R returns all of the rows that are in Illinois, as well as all of the rows that are not in Illinois, but have a population density of at least 30,000.\nNote: Keep in mind that | is not exclusive. That means that | will return true if only one condition is true, but it will also return true if both conditions are true. If you want exactly one condition to be true, look up the operator XOR.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#not",
    "href": "computing/coding-principles-oh.html#not",
    "title": "Intro to Coding Principles",
    "section": "Not",
    "text": "Not\nThe fourth Boolean operator is “not”. We use this when we want to exclude certain values from the data or prevent something from happening. In R, to denote not, we use the exclamation mark !. Specifically, you place the !, also known as a bang sign, in front of the statement that you want to be false. The most frequent use of this is to say “not equals”, which is denoted != (note that it is only one equals sign now, not two!) Let’s look at an example:\n\nmidwest |&gt;\n  filter(state != \"IL\") |&gt;\n  arrange(desc(popdensity))\n\n# A tibble: 335 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1  3021 MILWAU… WI    0.015   959275     63952.   718918   195470          6994\n 2  1278 WAYNE   MI    0.035  2111687     60334.  1212007   849109          8048\n 3  2026 CUYAHO… OH    0.026  1412140     54313.  1025756   350185          2533\n 4   711 MARION  IN    0.023   797159     34659.   615039   169654          1698\n 5  2039 HAMILT… OH    0.025   866228     34649.   672972   181145          1204\n 6  2033 FRANKL… OH    0.034   961437     28278.   783714   152840          2056\n 7  1246 MACOMB  MI    0.028   717400     25621.   693686    10400          2639\n 8  2056 LUCAS   OH    0.021   462361     22017.   380155    68456          1164\n 9  2085 SUMMIT  OH    0.024   514990     21458.   446902    61185          1065\n10  2065 MONTGO… OH    0.027   573809     21252.   463551   101817          1065\n# ℹ 325 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nIn these data, all rows from Illinois have been removed. You can check this by commenting out the filter line, and observing the difference, or just noting that Cook County, IL (home of Chicago, the densest city in the midwest) is absent!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#combining-boolean-operators",
    "href": "computing/coding-principles-oh.html#combining-boolean-operators",
    "title": "Intro to Coding Principles",
    "section": "Combining Boolean Operators",
    "text": "Combining Boolean Operators\nYou can also combine multiple Boolean operators in more complex logical statements. We will not look at any examples here, because they can get very confusing, very quickly (and are generally unnecessary for this course). However, if you do want to combine Boolean operators, here are some things to keep in mind:\n\nParentheses: Just like in math, any statements that you put in parentheses will execute first. If I say “A and B or C”, it’s unclear exactly what I mean. If I would accept either (A and B) or (A and C), I would write A & (B | C), meaning I need at least one of B or C to be true. If I would accept either (A and B) or C, I would write (A & B) | C, meaning I need either (A and B) or C to be true.\nOrder of operations: Pay attention to the order in which your statements evaluate! If I write !(A & B), that means I need at least one of A or B to be false. If I write !A & !B, that means I need both A and B to be false. This can get confusing, so it’s best to write out your logic fully and work through a few examples by hand (or avoid layering these operators entirely).",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#definition-1",
    "href": "computing/coding-principles-oh.html#definition-1",
    "title": "Intro to Coding Principles",
    "section": "Definition",
    "text": "Definition\nWhat is a function? A function is, essentially, a block of code that does something (so that you don’t have to implement it!). A function will always have a name, followed by open and closed parentheses (). Some functions do not take arguments. However, if they do, these arguments will go within the parentheses. Once R sees an opening parenthesis, it will not execute the code until it sees a closing parenthesis. Beware - when you start layering functions, such as using aes() inside of ggplot(), you need to pay attention to what your parentheses are around and make sure that they all close!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#arguments",
    "href": "computing/coding-principles-oh.html#arguments",
    "title": "Intro to Coding Principles",
    "section": "Arguments",
    "text": "Arguments\nArguments are the commands that you give to a function that tell it what to do. Most functions take at least one argument, and some can take arbitrarily many. Functions have a default order for (some of) their arguments. If you know this order, you do not have to explicitly name the arguments. If not, you must list them explicitly. Here are two examples:\n\n# Named Arguments\nggplot(\n  data = midwest, \n  mapping = aes(x = poptotal, y = popdensity, color = percwhite)\n  ) +\n  geom_point()\n\n\n\n\n\n\n# Unnamed Arguments\nggplot(\n  midwest, \n  aes(poptotal, popdensity, percwhite)\n  ) +\n  geom_point()\n\n\n\n\n\n\n\nIn ggplot, the first two arguments are always data and mapping, so it is common to drop these. However, in the second plot here, we lost our fill aesthetic. Why?\nWhen we look at the aes() documentation, we see that x is the first named argument and y is the second, but after that there are no named arguments. That means, while you can add more aesthetics, you must name them explicitly, since they do not appear by default.\nArguments Requiring Quotes\nIn R, you will sometimes need to pass a function an argument that is from a list of options. In this case, you need to wrap it in quotation marks (can anyone tell me why?) Let’s take a look at the following function, and try to identify arguments with and without quotes:\n\nggplot(midwest, aes(\n                    x = state,\n                    y = poptotal,\n                    fill = county\n                  )) +\n  geom_col(position = \"stack\") +\n  theme(legend.position = \"none\") # STA 199 students are not allowed to do this\n\n\n\n\n\n\n\nIn this case, we can pass in x = state, y = poptotal, and fill = county without quotation marks, because R knows we are referencing columns in a data frame, which are actual objects in our environment. However, we pass in position = \"stack\" with quotation marks. To see why, let’s look at what happens when we drop our quotes:\n\nggplot(midwest, aes(\n                    x = state,\n                    y = poptotal,\n                    fill = county\n                  )) +\n  geom_col(position = stack) +\n  theme(legend.position = \"none\") # STA 199 students are not allowed to do this\n\nError in `check_subclass()`:\n! `x` must be either a string or a &lt;Position&gt; object, not a function.\n\n\nThe argument for position is looking for either a string or a &lt;Position&gt; object. Since we don’t know what &lt;Position&gt; objects are, it’s clear that we should be giving it a string. R needs to find this argument in a list: we could say position = \"dodge\" or position = \"fill\", so long as we include quotation marks, since those are on the list of accepted arguments.\n\nggplot(midwest, aes(\n                    x = state,\n                    y = poptotal,\n                    fill = county\n                  )) +\n  geom_col(position = \"fill\") +\n  theme(legend.position = \"none\") # STA 199 students are not allowed to do this\n\n\n\n\n\n\n\nPipe Operator\nMany times in this class, you will see the symbol |&gt; used. This is known as the pipe operator, and it allows us to have a so-called “data pipeline”. This helps make code a lot more readable! Let’s take a look at why:\n\nhead(arrange(mutate(select(filter(midwest, state == \"IL\"), county, state, area, poptotal, inmetro), inmetro = as.logical(inmetro)), desc(poptotal)), 10)\n\n# A tibble: 10 × 5\n   county    state  area poptotal inmetro\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt; &lt;lgl&gt;  \n 1 COOK      IL    0.058  5105067 TRUE   \n 2 DU PAGE   IL    0.02    781666 TRUE   \n 3 LAKE      IL    0.028   516418 TRUE   \n 4 WILL      IL    0.05    357313 TRUE   \n 5 KANE      IL    0.029   317471 TRUE   \n 6 ST CLAIR  IL    0.04    262852 TRUE   \n 7 Winnebago IL    0.03    252913 TRUE   \n 8 MADISON   IL    0.045   249238 TRUE   \n 9 MCHENRY   IL    0.036   183241 TRUE   \n10 PEORIA    IL    0.038   182827 TRUE   \n\n\nTechnically, we can write our code in this manner! Strictly speaking, under the hood, the pipe operator is reconstructing your code into this format. However, this is nearly impossible to read (I’ve been coding in R for years, and I still ran into multiple errors trying to write this).\nWith the pipe operator, we can skip this and execute each function on its own line. Every pipeline starts with a data frame or equivalent object, so that R knows what we are operating on. By default, the pipe operator “pipes” your data into the first argument of a function - which, in the tidyverse, is almost always the “data” argument. This lets us write our data in a much neater pipeline, where you can see step-by-step what is happening to the data:\n\nmidwest |&gt;   # Operate on the midwest data frame\n  filter(state == \"IL\") |&gt;   # Filter for only the counties in Illinois\n  select(county, state, area, poptotal, inmetro) |&gt;   # Select only these five columns, and drop all others\n  mutate(inmetro = as.logical(inmetro)) |&gt;   # Cast inmetro to a logical type\n  arrange(desc(poptotal)) |&gt;   # Arrange the data frame by poptotal in descending order\n  head(10)   # Select the top 10 rows\n\n# A tibble: 10 × 5\n   county    state  area poptotal inmetro\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt; &lt;lgl&gt;  \n 1 COOK      IL    0.058  5105067 TRUE   \n 2 DU PAGE   IL    0.02    781666 TRUE   \n 3 LAKE      IL    0.028   516418 TRUE   \n 4 WILL      IL    0.05    357313 TRUE   \n 5 KANE      IL    0.029   317471 TRUE   \n 6 ST CLAIR  IL    0.04    262852 TRUE   \n 7 Winnebago IL    0.03    252913 TRUE   \n 8 MADISON   IL    0.045   249238 TRUE   \n 9 MCHENRY   IL    0.036   183241 TRUE   \n10 PEORIA    IL    0.038   182827 TRUE   \n\n\nMuch better, right? Remember, whenever you’re using the pipe operator (or the +, in ggplot, which is different!), you should start a new line of code. As long as you have a pipe operator, R is expecting another function, so it won’t execute only part of your code.\nNote: In this class, we focus on the base R pipe, which is denoted by |&gt;. However, when you’re debugging on the internet, you may come across the symbol %&gt;%, which is the magrittr pipe. There are some technical differences in these that generally go beyond the scope of this class, but they essentially serve the same purpose. Don’t be scared by the magrittr pipe when you’re doing your debugging!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#definition-2",
    "href": "computing/coding-principles-oh.html#definition-2",
    "title": "Intro to Coding Principles",
    "section": "Definition",
    "text": "Definition\nEvery time we start programming in this class, we run library(tidyverse). Why do we do this?\nLibraries are collections of functions, and running them means that we are loading those functions into our current R session. If you try to open up a fresh R session and run ggplot() immediately, you will get an error, because that function is not found. However, with the library, you can load in everything that you need, all at once. The tidyverse is especially cool, because it is actually a collection of libraries - libraryception!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#environment",
    "href": "computing/coding-principles-oh.html#environment",
    "title": "Intro to Coding Principles",
    "section": "Environment",
    "text": "Environment\nYour environment in R is basically the current instance of your program. When you run a library, it is part of your environment until you restart R, meaning you can call any of its functions at any time. When you create a variable, it is part of your environment until you restart R, meaning you can reference those variables at any time.\nWhen you use the containers, they do not regularly restart R. This can be a problem sometimes, when old code gets tangled up with new code! It is my personal recommendation that you (at a minimum) restart R and clear your environment every time you start a new project (AE, lab, etc). You can restart R by going to Session -&gt; Restart R, and clear your environment by going to the environment pane and clicking the broom icon.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#rendering-quarto",
    "href": "computing/coding-principles-oh.html#rendering-quarto",
    "title": "Intro to Coding Principles",
    "section": "Rendering Quarto",
    "text": "Rendering Quarto\nWhen you click the “Render” button for your .qmd file, what happens? R executes a program, called a “compiler”, that runs your entire .qmd file in a new environment. In other words, if you have loaded a library, or edited a variable, or done any number of things in the console (or even later in the .qmd file) without saving them in the .qmd file, and then you try to render, you will get an error because that function/variable/etc has not been defined in the rendering environment. This forces you to write reproducible code, and it’s the first thing to think about when you run into errors while rendering!\nAside: LaTeX\nWhen you click “Render”, if you are rendering to a .pdf file, R uses a tool called LaTeX to pull all of your code together. LaTeX is a very cool program, which allows you to input all sorts of things: Greek letters, formatted exponents, etc. If you want to insert such things, place code between dollar signs: For example, to write the Greek letter \\(\\gamma\\), you would input $\\gamma$ in your quarto document. You can google LaTeX for more information!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#documentation",
    "href": "computing/coding-principles-oh.html#documentation",
    "title": "Intro to Coding Principles",
    "section": "Documentation",
    "text": "Documentation\nUnless you have a function and its usage entirely memorized, you are going to be reading documentation. Documentation is useful, but it is dense, and can be hard to parse. Let’s look at an example of how we can look through documentation.\n\n?if_else\n\n?geom_point",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#errors",
    "href": "computing/coding-principles-oh.html#errors",
    "title": "Intro to Coding Principles",
    "section": "Errors",
    "text": "Errors\nUnless you are the Roman God of Programming (and even then, I’m not too sure), you are going to encounter errors in your programming. These are completely natural, and nothing to be ashamed of - sometimes I write partial code, just to see where it will catch errors. However, some error messages are easier to understand than others. Let’s look through a couple of examples of common errors, and what I would do to interpret and fix them.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#example-1",
    "href": "computing/coding-principles-oh.html#example-1",
    "title": "Intro to Coding Principles",
    "section": "Example 1",
    "text": "Example 1\n\nmidwest |&gt;\n  sumarize(avg_pop_dens = mean(popdensity))\n\nError in sumarize(midwest, avg_pop_dens = mean(popdensity)): could not find function \"sumarize\"\n\n\n\n\n\n\n\n\nWhat’s wrong with this code?\n\n\n\n\n\nIn this case, we just have a simple spelling error! It may seem trivial, but this will constitute at least half of the errors that you have. Make this the first thing you check - you will never meet a programmer who doesn’t have a story of the time they spent at least 30 minutes debugging a function, just to realize it was a typo all along.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#example-2",
    "href": "computing/coding-principles-oh.html#example-2",
    "title": "Intro to Coding Principles",
    "section": "Example 2",
    "text": "Example 2\n\nggplot(midwest, aes(x = poptotal, y = popdensity,)) |&gt;\n  geom_point() |&gt;\n  labs(x = \"Total Population\", y = \"Population Density\")\n\nError in `geom_point()`:\n! `mapping` must be created by `aes()`.\nℹ Did you use `%&gt;%` or `|&gt;` instead of `+`?\n\n\n\n\n\n\n\n\nWhat’s wrong with this code?\n\n\n\n\n\nThis one should be pretty obvious, since it’s a common enough error that R gives an extremely helpful error message. When you’re building a ggplot object, you use + rather than |&gt; to add additional lines!\nThere’s a second error here, that R knew well enough to handle here, but which could become an issue in more complicated code chunks. Did anyone spot it?",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#example-3",
    "href": "computing/coding-principles-oh.html#example-3",
    "title": "Intro to Coding Principles",
    "section": "Example 3",
    "text": "Example 3\n\nggplot(midwest, aes(x = state, y = poptotal, fill = state)) +\n  geom_bar() +\n  theme_bw() +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\", scale = 1e-6)) +\n  labs(\n    x = \"State\",\n    y = \"Total Population\\n(Millions)\",\n    title = \"Total Population by State\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    panel.grid.major.x = element_blank(),\n    legend.position = \"none\"\n  ) +\n  scale_fill_viridis_d()\n\nError in `geom_bar()`:\n! Problem while computing stat.\nℹ Error occurred in the 1st layer.\nCaused by error in `setup_params()`:\n! `stat_count()` must only have an x or y aesthetic.\n\n\nThere’s a lot going on here, so it might not be obvious at first where the issue is! The error has something to do with the function stat_count(), but that’s not a function we used (explicitly) anywhere in this code. This is why you should iterate on your code, running it intermittently, so that you can catch errors when they pop up.\nMy first thought would be to run rlang::last_trace(), as suggested by the error message. This is sometimes helpful - it can reference certain functions and even lines of code, especially when you’re executing something more complex. Frequently, though, it’s too complicated to understand. In this case, I would certainly say I can’t make any sense of that.\nMy next thought is to google the error message. It can be a little tricky to know what to google from the error message. You want to look for anything that seems general enough that other people might have asked, but specific enough that it will apply to your situation. Let’s go line by line:\n\n“Error in geom_bar()”: Probably too general to bother googling. There are a lot of possible errors with geom_bar(), and it would take too long to look through them all to get to your specific problem!\n“Problem while computing stat.”: This is more helpful, because it gives a little more direction as to the source of the error, but it is still too general - what stat are we computing? What problem?\n“Error occured in the 1st layer”: This can be helpful for you, if you know the order of ggplot layers. However, it is probably not helpful to google, since people could have built their layers in a different order before encountering this error.\n“Caused by error in setup_params()”: Closer! This is getting more and more specific, and this might be good enough to google. However, it still doesn’t say what the error is, it just says that there was one.\n“stat_count() must only have an x or y aesthetic”: Bingo! This is the one we’re looking for, which tells us exactly what the issue is. Now, it may be possible to interpret manually, but let’s say you can’t. Here’s where we go now:\n\nI would copy-paste the entire final line into google. You don’t want to copy-paste the full error message, since that’s probably too specific, and you might not find any results. At the same time, you don’t want to copy-paste only a couple of words, since that might not be specific enough, and you could be stuck looking through a lot of links. If you google just that line, you are likely to find someone on stack exchange who has posted a question with this exact (or almost this exact) error message. You can also help your google out by throwing in some relevant key words:\n\nggplot\nR\nerror\n\nTake a couple minutes to google this, and see if you can figure out what’s wrong with the code! Then, remember to cite the source where you found this answer! In general, it’s okay to google your error messages for help, but not to use someone else’s solution without credit.\n\n\n\n\n\n\nWhat’s wrong with this code?\n\n\n\n\n\nI looked at https://stackoverflow.com/questions/61068031/error-stat-count-can-only-have-an-x-or-y-aesthetic for my answer. There’s a few different suggestions on this page, all of which could be useful! This page definitely suggests to me that the issue with my plot is in the geom_bar() line - which makes sense, since this is layer 1 of the plot. While they have a couple simple fixes, here’s the actual error I wrote: geom_bar() is expecting only one variable. If you want two variables, like this, you should use geom_col() instead.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  }
]