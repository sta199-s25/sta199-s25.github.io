[
  {
    "objectID": "computing/coding-access.html",
    "href": "computing/coding-access.html",
    "title": "Access RStudio",
    "section": "",
    "text": "In this class, you will always and everywhere access RStudio through the Duke Container Manager. This ensures that all of us are using the same version of all the software. If this were not the case, unexpected and difficult to diagnose/resolve coding incompatibilities could arise when you seek help from the teaching team or collaborate with your project partners. Nobody needs that, so please stick to the containers. Here is how you get in:\n\nGo here: https://cmgr.oit.duke.edu/containers. You may have to log in with your NetID at some point;\n(The first time you do this, you look for STA198-199 under “Reservations available” on the righthand side, and click “reserve STA198-199”. After you do that once, STA198-199 will appear under “My reservations” on the lefthand side forever more)\nClick STA198-199 under “My reservations”;\nLogin;\nStart. It may take a while, but then RStudio should launch in your browser.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/coding-cheatsheets.html",
    "href": "computing/coding-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://www.rstudio.com/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B-solns.html",
    "href": "exam/midterm-1-batch-B-solns.html",
    "title": "Midterm 1 Practice Questions B",
    "section": "",
    "text": "d\na, d\na, d\nc\nb\na\nb\n\n\n\n\n\n\n\n\na, d\nb, c, e\na\na, c, e\na, b, c, d\na, d"
  },
  {
    "objectID": "exam/final-review-A.html",
    "href": "exam/final-review-A.html",
    "title": "Final review",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "exam/midterm-1-batch-A.html",
    "href": "exam/midterm-1-batch-A.html",
    "title": "Midterm 1 Practice Questions",
    "section": "",
    "text": "Solutions\n\n\n\n\n\nSee here.\nIn 2020, employees of Blizzard Entertainment circulated a spreadsheet to anonymously share salaries and recent pay increases amidst rising tension in the video game industry over wage disparities and executive compensation. (Source: Blizzard Workers Share Salaries in Revolt Over Pay)\nThe name of the data frame used for this analysis is blizzard_salary and the variables are:\nThe top ten rows of blizzard_salary are shown below:\n# A tibble: 409 × 4\n   percent_incr salary_type annual_salary performance_rating\n          &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n 1          1   Salaried               1  High              \n 2          1   Salaried               1  Successful        \n 3          1   Salaried               1  High              \n 4          1   Hourly             33987. Successful        \n 5         NA   Hourly             34798. High              \n 6         NA   Hourly             35360  &lt;NA&gt;              \n 7         NA   Hourly             37440  &lt;NA&gt;              \n 8          0   Hourly             37814. &lt;NA&gt;              \n 9          4   Hourly             41101. Top               \n10          1.2 Hourly             42328  &lt;NA&gt;              \n# ℹ 399 more rows",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-1",
    "href": "exam/midterm-1-batch-A.html#question-1",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 1",
    "text": "Question 1\nWhich of the following is correct? Choose all that apply.\n\nThe blizzard_salary dataset has 399 rows.\nThe blizzard_salary dataset has 4 columns.\nEach row represents a Blizzard Entertainment worker who filled out the spreadsheet.\nThe percent_incr variable is numerical and discrete.\nThe salary_type variable is numerical.\nThe annual_salary variable is numerical.\nThe performance_rating variable is categorical and ordinal.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-2",
    "href": "exam/midterm-1-batch-A.html#question-2",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 2",
    "text": "Question 2\nFigure 1 (a) and Figure 1 (b) show the distributions of annual salaries of hourly and salaried workers. The two figures show the same data, with the facets organized across rows and across columns. Which of the two figures is better for comparing the median annual salaries of hourly and salaried workers. Explain your reasoning.\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\nFigure 1: Distribution of annual salaries of Blizzard employees",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-3",
    "href": "exam/midterm-1-batch-A.html#question-3",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 3",
    "text": "Question 3\nSuppose your teammate wrote the following code as part of their analysis of the data.\nThey then printed out the results shown below. Unfortunately one of the numbers got erased from the printout. It’s indicated with _____ below.\n# A tibble: 2 × 3\n  salary_type mean_annual_salary median_annual_salary\n  &lt;chr&gt;                    &lt;dbl&gt;                &lt;dbl&gt;\n1 Hourly                  63003.               54246.\n2 Salaried                90183.               _____\nWhich of the following is the best estimate for that erased value?\n\n30,000\n50,000\n80,000\n100,000",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-4",
    "href": "exam/midterm-1-batch-A.html#question-4",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 4",
    "text": "Question 4\nWhich distribution of annual salaries has a higher standard deviation?\n\nHourly workers\nSalaried workers\nRoughly the same",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-5",
    "href": "exam/midterm-1-batch-A.html#question-5",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 5",
    "text": "Question 5\nWhich of the following alternate plots would also be useful for visualizing the distributions of annual salaries of hourly and salaried workers? Choose all that apply.\na. Box plots\nb. Density plots\nc. Pie charts\nd. Waffle charts\ne. Histograms\nf. Scatterplots",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#questions-6-and-7",
    "href": "exam/midterm-1-batch-A.html#questions-6-and-7",
    "title": "Midterm 1 Practice Questions",
    "section": "Questions 6 and 7",
    "text": "Questions 6 and 7\nSuppose you made the bar plot shown in Figure 2 (a) to visualize the distribution of performance_rating and your teammate made the bar plot shown in Figure 2 (b).\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\nFigure 2: Distribution of performance rating\n\n\nYou made your bar plot without transforming the data in any way, while your friend did first transform the data with code like the following:\n\nblizzard_salary &lt;- blizzard_salary |&gt;\n  _(1)_(performance_rating = fct_relevel(performance_rating, _(2)_))\n\nQuestion 6: What goes in the blank (1)?\n\narrange()\nfilter()\nmutate()\nsummarize()\n\nQuestion 7: What goes in the blank (2)?\n\n\"Poor\", \"Successful\", \"High\", \"Top\"\n\"Successful\", \"High\", \"Top\"\n\"Top\", \"High\", \"Successful\", \"Poor\"\nPoor, Successful, High, Top",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#questions-8---10",
    "href": "exam/midterm-1-batch-A.html#questions-8---10",
    "title": "Midterm 1 Practice Questions",
    "section": "Questions 8 - 10",
    "text": "Questions 8 - 10\nFinally, another teammate creates the following two plots.\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\nFigure 3: Distribution of salary type by performance rating\n\n\nQuestion 8: Your teammate asks you for help deciding which one to use in the final report for visualizing the relationship between performance rating and salary type. In 1-3 sentences, can you help them make a decision, justify your choice, and write the narrative that should go with the plot?\nQuestion 9: A friend with a keen eye points out that the number of observations in Figure 3 (a) seems lower than the total number of observations in blizzard_salary. What might be going on here? Explain your reasoning.\nQuestion 10: Below are the proportions of performance ratings for hourly and salaried workers. Place these values in the corresponding segments in Figure 3 (b).\n\n\n# A tibble: 4 × 3\n  performance_rating Hourly Salaried\n  &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1 High                0.2     0.384 \n2 Successful          0.686   0.521 \n3 Top                 0.114   0.0760\n4 Poor                0       0.0190",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#questions-11-and-12",
    "href": "exam/midterm-1-batch-A.html#questions-11-and-12",
    "title": "Midterm 1 Practice Questions",
    "section": "Questions 11 and 12",
    "text": "Questions 11 and 12\nThe table below shows the distribution of salary_type and performance_rating.\n\n\n# A tibble: 2 × 6\n  salary_type  Poor Successful  High   Top  `NA`\n  &lt;chr&gt;       &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Hourly         NA         24     7     4    28\n2 Salaried        5        137   101    20    83\n\n\nThe pipeline below produces a data frame with a fewer number of rows than blizzard_salary.\n\nblizzard_salary |&gt;\n  filter(salary_type _(1)_ \"Hourly\" _(2)_ performance_rating == \"Poor\") |&gt;\n  _(3)_(annual_salary)\n\n\n\n# A tibble: 5 × 4\n  percent_incr salary_type annual_salary performance_rating\n         &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n1            0 Salaried            80000 Poor              \n2            3 Salaried            83000 Poor              \n3            0 Salaried           116000 Poor              \n4            0 Salaried           135219 Poor              \n5            0 Salaried           147500 Poor              \n\n\nQuestion 11: Which of the following goes in blanks (1) and (2)?\n\n\n\n(1)\n(2)\n\n\n\na.\n!=\n|\n\n\nb.\n==\n&\n\n\nc.\n!=\n&\n\n\nd.\n==\n|\n\n\n\nQuestion 12: Which function or functions go into blank (3)?\n\narrange()\nmutate()\norder()\nsort()",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-13",
    "href": "exam/midterm-1-batch-A.html#question-13",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 13",
    "text": "Question 13\nYou’re reviewing another team’s work and they made the following visualization:\n\n\n\n\n\n\n\n\nAnd they wrote the following interpretation for the relationship between annual salary and percent increase for Top performers:\n\nThe relationship is positive, having a higher salary results in a higher percent increase. There is one clear outlier.\n\nWhich of the following is/are the most accurate and helpful) peer review note for this interpretation. Choose all that apply.\n\nThe interpretation is complete and perfect, no changes needed!\nThe interpretation doesn’t mention the direction of the relationship.\nThe interpretation doesn’t mention the form of the relationship, which is linear.\nThe interpretation doesn’t mention the strength of the relationship, which is somewhat strong.\nThere isn’t a clear outlier in the plot. If any points stand out as potential outliers, more guidance should be given to the reader to identify them (e.g., salary and/or percent increase amount).\nThe interpretation is causal – we don’t know if the cause of the high percent increase is higher annual salary based on observational data. The causal direction might be the other way around, or there may be other factors contributing to the apparent relationship.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-14",
    "href": "exam/midterm-1-batch-A.html#question-14",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 14",
    "text": "Question 14\nBelow is some code and its output.\n```{r}\n# label=plot blizzard\n\nggplot(blizzard_salary,aes(x=performance_rating,y=percent_incr))+geom_boxplot()\nlabs(x=\"Performance rating\", y = \"Percent increase\")\n```\n\n\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n$x\n[1] \"Performance rating\"\n\n$y\n[1] \"Percent increase\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nPart 1: List at least 5 things that should be fixed or improved in the code.\nPart 2: What is the cause of the warning and what does it mean?",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#question-15",
    "href": "exam/midterm-1-batch-A.html#question-15",
    "title": "Midterm 1 Practice Questions",
    "section": "Question 15",
    "text": "Question 15\nYou’re working on a data analysis on salaries of Blizzard employees in a Quarto document in a project version controlled by Git. You create a plot and write up a paragraph describing any patterns in it. Then, your teammate says “render, commit, and push”.\nPart 1: What do they mean by each of these three steps. In 1-2 sentences for each, explain in your own words what they mean.\n\nRender:\n\n\nCommit:\n\n\nPush:\n\nPart 2: Your teammate is getting impatient and they interrupt you after you rendered and committed and say “I still can’t see your changes in our shared GitHub repo when I look at it in my web browser.” Which of the following answers is the most accurate?\n\nI rendered my document, you should be seeing my changes on GitHub when you look at it in your web browser.\nI committed my changes, you should be seeing my changes on GitHub when you look at it in your web browser.\nI didn’t yet push my changes, it’s expected that you are not seeing them on GitHub when you look at it in your web browser. Wait until I push, and check again.\nYou need to pull to see my changes on GitHub in the web browser.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A.html#bonus",
    "href": "exam/midterm-1-batch-A.html#bonus",
    "title": "Midterm 1 Practice Questions",
    "section": "Bonus",
    "text": "Bonus\nPick a concept we introduced in class so far that you’ve been struggling with and explain it in your own words.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch A"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-A-solns.html",
    "href": "exam/midterm-1-batch-A-solns.html",
    "title": "Midterm 1 Practice Questions A",
    "section": "",
    "text": "b, c, f, g -\n\nThe blizzard_salary dataset has 409 rows.\nThe percent_incr variable is numerical and continuous.\nThe salary_type variable is categorical.\n\nFigure 1 - A shared x-axis makes it easier to compare summary statistics for the variable on the x-axis.\nc - It’s a value higher than the median for hourly but lower than the mean for salaried.\nb - There is more variability around the mean compared to the hourly distribution.\na, b, e - Pie charts and waffle charts are for visualizing distributions of categorical data only. Scatterplots are for visualizing the relationship between two numerical variables.\nc - mutate() is used to create or modify a variable.\na - \"Poor\", \"Successful\", \"High\", \"Top\"\nb - Option 2. The plot in Option 1 shows the number of employees with a given performance rating for each salary type while the plot in Option 2 gives the proportion of employees with a given performance rating for each salary type. In order to assess the relationship between these variables (e.g., how much more likely is a Top rating among Salaried vs. Hourly workers), we need the proportions, not the counts.\nThere may be some NAs in these two variables that are not visible in the plot.\nThe proportions under Hourly would go in the Hourly bar, and those under Salaried would go in the Salaried bar.\nc - filter(salary_type != \"Hourly\" & performance_rating == \"Poor\") - There are 5 observations for “not Hourly” “and” Poor.\na - arrange() - The result is arranged in increasing order of annual_salary, which is the default for arrange().\nc, d, e, f.\nPart 1: The following should be fixed:\n\nThere should be a | after # before label\nThere should be a : after label, not =\nThere shouldn’t be a space in the chunk label, it should be plot-blizzard\nThere should be spaces after commas in the code\nThere should be spaces on both sides of = in the code\nThere should be a space before +\ngeom_boxplot() should be on the next line and indented\nThere should be a + at the end of the geom_boxplot() line\nlabs() should be indented\n\nPart 2: The warning is caused by NA in the data. It means that 39 observations were NAs and are not plotted/represented on the plot.\nPart 1:\n\nRender: Run all of the code and render all of the text in the document and produce an output.\nCommit: Take a snapshot of your changes in Git with an appropriate message.\nPush: Send your changes off to GitHub.\n\nPart 2: c - Rendering or committing isn’t sufficient to send your changes to your GitHub repository, a push is needed. A pull is also not needed to view the changes in the browser."
  },
  {
    "objectID": "project/description.html",
    "href": "project/description.html",
    "title": "Project description",
    "section": "",
    "text": "TL;DR: Ask a question you’re curious about and answer it with a dataset of your choice. This is your project in a nutshell.\nMay be too long, but please do read\nThe project for this course will consist of analysis on a dataset of your own choosing. The dataset may already exist, or you may collect your own data using a survey or by conducting an experiment. You can choose the data based on your teams’ interests or based on work in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this course (and beyond, if you like) and apply them to a novel dataset in a meaningful way.\nThe goal is not to do an exhaustive data analysis i.e., do not calculate every statistic and procedure you have learned for every variable, but rather let me know that you are proficient at asking meaningful questions and answering them with results of data analysis, that you are proficient in using R, and that you are proficient at interpreting and presenting the results. Focus on methods that help you begin to answer your research questions. You do not have to apply every statistical procedure we learned. Also, critique your own methods and provide suggestions for improving your analysis. Issues pertaining to the reliability and validity of your data, and appropriateness of the statistical analysis should be discussed here.\nThe project is very open ended. You should create some kind of compelling visualization(s) of this data in R. There is no limit on what tools or packages you may use but sticking to packages we learned in the course is required. You do not need to visualize all of the data at once. A single high-quality visualization will receive a much higher grade than a large number of poor-quality visualizations. Also pay attention to your presentation. Neatness, coherency, and clarity will count. All analyses must be done in RStudio, using R, and all components of the project must be reproducible (with the exception of the slide deck).\nYou will work on the project with your lab teams.\nThe four milestones for the final project are\n\nMilestone 1 - Working collaboratively\nMilestone 2 - Proposals, with three dataset ideas\nMilestone 3 - Improvement and progress\nMilestone 4 - Peer review, on another team’s project\nMilestone 5 - Presentation with slides and a reproducible project write-up of your analysis, with a draft along the way.\n\nYou will not be submitting anything on Gradescope for the project. Submission of these deliverables will happen on GitHub and feedback will be provided as GitHub issues that you need to engage with and close. The collection of the documents in your GitHub repo will create a webpage for your project. To create the webpage go to the Build tab in RStudio, and click on Render Website.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#reproducibility-organization",
    "href": "project/description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the write-up and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#teamwork",
    "href": "project/description.html#teamwork",
    "title": "Project description",
    "section": "Teamwork",
    "text": "Teamwork\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly and penalties may apply beyond the teamwork component of the grade.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project presentation deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#grading-summary",
    "href": "project/description.html#grading-summary",
    "title": "Project description",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/description.html#late-work-policy",
    "href": "project/description.html#late-work-policy",
    "title": "Project description",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Description"
    ]
  },
  {
    "objectID": "project/3-improvement-progress.html",
    "href": "project/3-improvement-progress.html",
    "title": "Improvement and progress",
    "section": "",
    "text": "By this point you’ve received feedback on your proposal and you should be working on incorporating that feedback to improve your project and making further progress on it. This milestone ensures you’re keeping on task and doing these things.\n\nGoals\nThe goals of this milestone are as follows:\n\nIncorporate feedback from your proposal\nMake progress on your project prior to the peer review\n\n\n\nInstructions\nEverybody on the team should have at least one commit to the project repo since milestone 2 was submitted. At the very least, these commits should:\n\nexplicitly closing issues opened as proposal feedback;\nload the data into the main project QMD file;\ngenerate one visualization of the data.\n\n\n\nGrading\nThis milestone will be graded for completion, not accuracy. We will check to see if the team has made commits to their repo since project milestone 2 and closed all issues that were opened as part of proposal feedback.\n\n0 points: No commits since project milestone 2\n1 point: not everyone has committed\n2-4 points: not all issues closed, no visualization, etc\n5 points: everyone committed, all issues closed, one figure generated.\n\n\n\n\n\n\n\nNote\n\n\n\nThere won’t be a lab session dedicated to this milestone. You are to work with your team outside of class time to complete this task.",
    "crumbs": [
      "Project",
      "Milestone 3"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html",
    "href": "project/5-writeup-presentation.html",
    "title": "Write-up and presentation",
    "section": "",
    "text": "Your written report must be completed in the index.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo: false in the YAML.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long (if it were to be printed). There is no minimum page requirement; however, you should comprehensively address all of the analysis in your report.\nTo check how many pages your report is, open it in your browser and go to File &gt; Print &gt; Save as PDF and review the number of pages.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\n\n\n\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The exploratory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you’ve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you’ve chosen to do modeling, describe the model(s) you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.\n\n\n\n\n\nThe write-up is worth 35 points, broken down as follows:\n\n\n\nTotal\n35 pts\n\n\n\n\nIntroduction/data\n4 pts\n\n\nMethodology\n10 pts\n\n\nResults\n15 pts\n\n\nDiscussion\n3 pts\n\n\nOrganization + formatting\n3 pts",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#expectations",
    "href": "project/5-writeup-presentation.html#expectations",
    "title": "Write-up and presentation",
    "section": "",
    "text": "Your written report must be completed in the index.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the printing of code chunks is off with the option echo: false in the YAML.\nThe mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be no more than 10 pages long (if it were to be printed). There is no minimum page requirement; however, you should comprehensively address all of the analysis in your report.\nTo check how many pages your report is, open it in your browser and go to File &gt; Print &gt; Save as PDF and review the number of pages.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#components",
    "href": "project/5-writeup-presentation.html#components",
    "title": "Write-up and presentation",
    "section": "",
    "text": "This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The exploratory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\n\nThis section includes a brief description of your analysis process. Explain the reasoning for the types of analyses you do, exploratory, inferential, or modeling. If you’ve chosen to do inference, make sure to include a justification for why that inferential approach is appropriate. If you’ve chosen to do modeling, describe the model(s) you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\n\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\nThe analysis results are clearly assesses and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\n\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\n\nThis is an assessment of the overall presentation and formatting of the written report.\n\n\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#grading",
    "href": "project/5-writeup-presentation.html#grading",
    "title": "Write-up and presentation",
    "section": "",
    "text": "The write-up is worth 35 points, broken down as follows:\n\n\n\nTotal\n35 pts\n\n\n\n\nIntroduction/data\n4 pts\n\n\nMethodology\n10 pts\n\n\nResults\n15 pts\n\n\nDiscussion\n3 pts\n\n\nOrganization + formatting\n3 pts",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#slides",
    "href": "project/5-writeup-presentation.html#slides",
    "title": "Write-up and presentation",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and record a presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides. If you choose this option, save the slides as PDF and upload it to your repo as presentation.pdf.\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe slide deck should be roughly 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#presentation",
    "href": "project/5-writeup-presentation.html#presentation",
    "title": "Write-up and presentation",
    "section": "Presentation",
    "text": "Presentation\nPresentations will be recorded and uploaded to Warpwire or YouTube. The presentation must be no longer than 5 minutes. During grading, we will stop watching your video at the 5-minute mark.\n\nRecording your presentation\nFor recording your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\n\n\nUploading your presentation\nOnce your video is ready, upload it to Warpwire or another video platform (e.g., YouTube).\nTo upload your video to Warpwire:\n\nClick the Warpwire tab on the course Canvas site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\n\nThe instructions should be a lot more straightforward for YouTube. See https://support.google.com/youtube/answer/57407?hl=en&co=GENIE.Platform%3DDesktop for step-by-step instructions. You can make it “Unlisted”, which means it will only be available to those you’ve shared the link with.\n\n\nSharing your presentation\nThis step is essential – if you don’t share your video by the deadline, it will be as if you haven’t recorded it in the first place.\nYou must share your video with the teaching team and with other students in the class.\n\nSharing with the teaching team (formal submission): Add a link to your video in your repo’s README.\nSharing with other students in the class: Post a link to your video on Ed Discussion. Title it “Your team name: Your project title” and use the “Presentation” tag.\n\nMake sure that your video is accessible to others. You should test this by sharing the link with a teammate or checking it in Incognito mode in your browser.",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "project/5-writeup-presentation.html#grading-1",
    "href": "project/5-writeup-presentation.html#grading-1",
    "title": "Write-up and presentation",
    "section": "Grading",
    "text": "Grading\nThe presentation is worth 25 points, broken down as follows:\n\n\n\nTotal\n25 pts\n\n\n\n\nSlides\n10 pts\n\n\nPresentation\n15 pts\n\n\n\n\nSlides\nAre the slides well organized, readable, not full of text, featuring figures with legible labels, legends, etc.?\n\n\nPresentation\n\nTime management: Did the team divide the time well amongst themselves or got cut off going over time?\nProfessionalism: How well did the team present? Does the presentation appear to be well practiced? Did everyone get a chance to say something meaningful about the project?\nTeamwork: Did the team present a unified story, or did it seem like independent pieces of work patched together?\nCreativity and critical thought: Is the project carefully thought out? Does it appear that time and effort went into the planning and implementation of the project?\nContent: Including, but not limited to the following:\n\nIs the question well articulated in the presentation?\nCan the question be answered with the data?\nDoes the analysis answer the question?\nAre the conclusion(s) made based on the analysis justifiable?\nAre the limitations carefully considered and articulated?",
    "crumbs": [
      "Project",
      "Milestone 5"
    ]
  },
  {
    "objectID": "syllabus/syllabus_team.html",
    "href": "syllabus/syllabus_team.html",
    "title": "Teaching team",
    "section": "",
    "text": "John Zito is Assistant Research Professor of Statistical Science at Duke University. He came to Duke in August 2024 after completing his PhD in statistics at Rice University. Prior to that he received a BA in mathematics from Kenyon College and spent a few years working in the Federal Reserve system.\nOffice Hours: Friday 1:00 PM - 3:00 PM in Old Chem 207.",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "syllabus/syllabus_team.html#instructor",
    "href": "syllabus/syllabus_team.html#instructor",
    "title": "Teaching team",
    "section": "",
    "text": "John Zito is Assistant Research Professor of Statistical Science at Duke University. He came to Duke in August 2024 after completing his PhD in statistics at Rice University. Prior to that he received a BA in mathematics from Kenyon College and spent a few years working in the Federal Reserve system.\nOffice Hours: Friday 1:00 PM - 3:00 PM in Old Chem 207.",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "syllabus/syllabus_team.html#teaching-assistants",
    "href": "syllabus/syllabus_team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Mug\n        \n         \n          Name\n        \n         \n          Role(s)\n        \n         \n          Lab Section\n        \n         \n          Office hours\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nMug\n\n\nName\n\n\nRole(s)\n\n\nLab Section\n\n\nOffice hours\n\n\n\n\n\n\n\n\n\nArboleda, Federico\n\n\nLab Leader\n\n\nM 3:05PM - 4:20PM (Sec 8)\n\n\n🔗\n\n\n\n\n\n\n\nBag, Devarpita\n\n\nLab Helper\n\n\nM 3:05PM - 4:20PM (Sec 9)\n\n\n🔗\n\n\n\n\n\n\n\nChen, Han\n\n\nLab Helper\n\n\nM 8:30AM - 9:45AM (Sec 1)\n\n\n🔗\n\n\n\n\n\n\n\nDey, Arijit\n\n\nLab Helper\n\n\nM 1:25PM - 2:40PM (Sec 7)\n\n\n🔗\n\n\n\n\n\n\n\nEason, Sonya\n\n\nLecture Helper\n\n\n\n\n\n🔗\n\n\n\n\n\n\n\nFahrer, Alexa\n\n\nLab Helper\n\n\nM 11:45AM - 1:00PM (Sec 4)\n\n\n🔗\n\n\n\n\n\n\n\nFan, Li\n\n\nLab Leader\n\n\nM 3:05PM - 4:20PM (Sec 9)\n\n\n🔗\n\n\n\n\n\n\n\nFenoglio, Domenic\n\n\nLab Leader\n\n\nM 11:45AM - 1:00PM (Sec 5)\n\n\n🔗\n\n\n\n\n\n\n\nHarris, Natasha\n\n\nLab Helper\n\n\nM 4:40PM - 5:55PM (Sec 10)\n\n\n🔗\n\n\n\n\n\n\n\nHealey-Parera, Julia\n\n\nLab Helper\n\n\nM 11:45AM - 1:00PM (Sec 5)\n\n\n🔗\n\n\n\n\n\n\n\nHodges, Avery\n\n\nLab Leader\n\n\nM 11:45AM - 1:00PM (Sec 4)\n\n\n🔗\n\n\n\n\n\n\n\nKing, Dav\n\n\nLab Leader\n\n\nM 1:25PM - 2:40PM (Sec 6)\n\n\n🔗\n\n\n\n\n\n\n\nLee, Hyunjin\n\n\nLab Helper\n\n\nM 10:05AM - 11:20AM (Sec 2)\n\n\n🔗\n\n\n\n\n\n\n\nMa, Liane\n\n\nLab Helper\n\n\nM 10:05AM - 11:20AM (Sec 3)\n\n\n🔗\n\n\n\n\n\n\n\nMittal, Netra\n\n\nLab Leader\n\n\nM 4:40PM - 5:55PM (Sec 10)\n\n\n🔗\n\n\n\n\n\n\n\nMurphy, Caitrin\n\n\nHead TA, Lab Leader\n\n\nM 8:30AM - 9:45AM (Sec 1)\n\n\n🔗\n\n\n\n\n\n\n\nObuya, Noah\n\n\nLecture Helper\n\n\n\n\n\n🔗\n\n\n\n\n\n\n\nSolarz, Katie\n\n\nLab Leader, Lecture Helper\n\n\nM 10:05AM - 11:20AM (Sec 2)\n\n\n🔗\n\n\n\n\n\n\n\nVasquez Tapia, Eduardo Alfonso\n\n\nLab Leader\n\n\nM 1:25PM - 2:40PM (Sec 7)\n\n\n🔗\n\n\n\n\n\n\n\nWang, Jasmine\n\n\nLab Leader\n\n\nM 10:05AM - 11:20AM (Sec 3)\n\n\n🔗\n\n\n\n\n\n\n\nWu, Sarah\n\n\nLab Helper\n\n\nM 3:05PM - 4:20PM (Sec 8)\n\n\n🔗\n\n\n\n\n\n\n\nZhang, Lisa\n\n\nLab Helper\n\n\nM 1:25PM - 2:40PM (Sec 6)\n\n\n🔗\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "syllabus/syllabus_team.html#course-coordinator",
    "href": "syllabus/syllabus_team.html#course-coordinator",
    "title": "Teaching team",
    "section": "Course coordinator",
    "text": "Course coordinator\n\nDr. Mary Knox (she/her) is the course coordinator for this course. You can contact her (at mary.knox@duke.edu) with any questions regarding accommodations, missed work, extensions, registration, etc.",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html",
    "href": "syllabus/syllabus_policies.html",
    "title": "Policies",
    "section": "",
    "text": "If you wish to ask content-related questions in writing, please do not do so via e-mail. Instead, please use the course discussion forum Ed Discussion. That way all members of the teaching team can see your question, and all students can benefit from the ensuing discussion. You are also encouraged to answer one another’s questions.\nIf you have questions about personal matters that may not be appropriate for the public course forum (e.g. illness, accommodations, etc), then please e-mail the instructor directly (john.zito@duke.edu).\n\n\n\n\n\n\nNote\n\n\n\nYou can ask questions anonymously on Ed. The teaching team will still know your identity, but your peers will not.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#communication",
    "href": "syllabus/syllabus_policies.html#communication",
    "title": "Policies",
    "section": "",
    "text": "If you wish to ask content-related questions in writing, please do not do so via e-mail. Instead, please use the course discussion forum Ed Discussion. That way all members of the teaching team can see your question, and all students can benefit from the ensuing discussion. You are also encouraged to answer one another’s questions.\nIf you have questions about personal matters that may not be appropriate for the public course forum (e.g. illness, accommodations, etc), then please e-mail the instructor directly (john.zito@duke.edu).\n\n\n\n\n\n\nNote\n\n\n\nYou can ask questions anonymously on Ed. The teaching team will still know your identity, but your peers will not.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#late-work-and-extensions",
    "href": "syllabus/syllabus_policies.html#late-work-and-extensions",
    "title": "Policies",
    "section": "Late work and extensions",
    "text": "Late work and extensions\nNo late work will be accepted for application exercises, exams, or projects. Labs may be submitted up to 3 days late. A 5% deduction will be applied for each 24-hour period during which the assignment is late.\nIf circumstances prevent you from completing a lab by the stated due date, you may email the course coordinator, Dr. Mary Knox, before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide an explanation. This waiver may only be used once a semester, so only use it for a truly extenuating circumstance.\nIf circumstances have a longer-term impact on your academic performance, please let your academic dean know. They can be a resource. Please let me know if you need help contacting your academic dean.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#regrade-requests",
    "href": "syllabus/syllabus_policies.html#regrade-requests",
    "title": "Policies",
    "section": "Regrade requests",
    "text": "Regrade requests\nIf you receive a graded assignment back, and you believe that some part of it was graded incorrectly, you may dispute the grade by submitting a regrade request in Gradescope. Note the following:\n\nYou have one week after you receive a grade to submit a regrade request;\nYou should submit separate regrade requests for each question you wish to dispute, not a single catch-all request;\nRequests will be considered if there was an error in the grade calculation or if a correct answer was mistakenly marked as incorrect;\nRequests to dispute the number of points deducted for an incorrect response will not be considered;\nRegrade requests are not a mechanism for asking for clarification on feedback. Those questions should be brought to office hours;\nNo grades will be changed after the final exam has been administered on Tuesday, April 29;\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you submit a regrade request for part of an assignment, we reserve the right to regrade the entire assignment. As such, a regrade request can result in your grade going up, staying the same, or going down if we determine that, in fact, the original grader was too lenient.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#attendance",
    "href": "syllabus/syllabus_policies.html#attendance",
    "title": "Policies",
    "section": "Attendance",
    "text": "Attendance\nWe are not tracking attendance, but success in this class and regular attendance are probably highly positively correlated. Furthermore, regular lecture attendance is necessary if you wish to earn full credit for the application exercises. Lastly, some components of the final project require you to complete activities with your teammates during lab. If you do not attend, you will forfeit these points.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#accommodations",
    "href": "syllabus/syllabus_policies.html#accommodations",
    "title": "Policies",
    "section": "Accommodations",
    "text": "Accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#collaboration",
    "href": "syllabus/syllabus_policies.html#collaboration",
    "title": "Policies",
    "section": "Collaboration",
    "text": "Collaboration\nOnly work that is clearly assigned as teamwork should be completed collaboratively.\n\nYou may discuss lab assignments with other students; however, you may not directly share (or copy) code or write-up with other students. For team assignments, you may collaborate freely within your team. You may discuss the assignment with other teams; however, you may not directly share (or copy) code or write-up with another team. Unauthorized sharing (or copying) of the code or write-up will be considered a violation for all students involved.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nCollaboration within teams is not only allowed but encouraged for the project. Communication between teams at a high level is also allowed; however, you may not share code or project components across teams.\nOn individual assignments, you may not directly share work (including code) with another student in this class; on team assignments, you may not directly share work (including code) with another team.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#use-of-outside-resources-including-ai",
    "href": "syllabus/syllabus_policies.html#use-of-outside-resources-including-ai",
    "title": "Policies",
    "section": "Use of outside resources, including AI",
    "text": "Use of outside resources, including AI\nYou may make use of any online resources (e.g. StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nYou should treat generative AI, such as ChatGPT, like other online resources. Two guiding principles govern how to use AI in this course:\n\nCognitive dimension: Working with AI should not reduce your thinking ability. We will practice using AI to facilitate—rather than hinder—learning.\nEthical dimension: Students using AI should be transparent about their use and ensure it aligns with academic integrity.\n\n\n AI tools for code: You may use the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. Furthermore, you should not directly copy-paste the prompt from an assignment into the chat.\n AI tools for narrative: Unless instructed otherwise, you may not use generative AI to generate a narrative that you then copy-paste verbatim into an assignment or edit and then insert into your assignment.\n\nIn general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content. Identifying AI-generated content is fairly straightforward. Any code identified as AI-generated but not cited as such and any narrative identified as AI-generated will be considered plagiarism and treated as such.\n\n\n\n\n\n\nCiting an LLM like ChatGPT\n\n\n\nHere are some general guidelines for citing AI-generated content. In this class, if you use something like ChatGPT to help you, you need to cite that by providing a direct link to the conversation you had with the bot, like this: https://chatgpt.com/share/677c4060-1d58-8008-8e47-5caa5556a825. You can generate such a link here:",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#academic-honesty",
    "href": "syllabus/syllabus_policies.html#academic-honesty",
    "title": "Policies",
    "section": "Academic honesty",
    "text": "Academic honesty\nAs a student in this course, you have agreed to uphold the Duke Community Standard and the practices specific to this course.\n\n\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically results in a zero for the relevant portion or the entire assignment, and will be reported to the Office of Student Conduct & Community Standards for further action. Furthermore:\n\nIf a conduct violation results in a zero on a lab, that zero will not be dropped;\nIf a conduct violation results in a zero on the in-class portion of a midterm, that zero will not be replaced with your final exam score;\nIf a conduct violation of any kind is discovered on any part of an exam, your final letter grade will be permanently reduced (A- down to B+, B+ down to B, etc);\nIf we discover that students are sharing and copying assignment solutions, all students involved will be penalized equally, the sharer the same as the recipient.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_faq.html",
    "href": "syllabus/syllabus_faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Syllabus",
      "FAQ"
    ]
  },
  {
    "objectID": "syllabus/syllabus_faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "href": "syllabus/syllabus_faq.html#how-do-i-export-my-assignment-pdf-from-rstudio-to-upload-to-gradescope",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder).",
    "crumbs": [
      "Syllabus",
      "FAQ"
    ]
  },
  {
    "objectID": "syllabus/syllabus_faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "syllabus/syllabus_faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions.",
    "crumbs": [
      "Syllabus",
      "FAQ"
    ]
  },
  {
    "objectID": "syllabus/syllabus_overview.html",
    "href": "syllabus/syllabus_overview.html",
    "title": "Course overview",
    "section": "",
    "text": "Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, and do so in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language.\nPrerequisites: none.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "syllabus/syllabus_overview.html#description",
    "href": "syllabus/syllabus_overview.html#description",
    "title": "Course overview",
    "section": "",
    "text": "Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, and do so in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language.\nPrerequisites: none.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "syllabus/syllabus_overview.html#meetings",
    "href": "syllabus/syllabus_overview.html#meetings",
    "title": "Course overview",
    "section": "Meetings",
    "text": "Meetings\n\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\nStaff\n\n\n\n\nLecture\nBiological Sciences 111\nTu Thu 11:45 AM - 01:00 PM\nJohn Z\nSonya\nTBD\n\n\nLab 01\nPerkins LINK 087 (Classroom 3)\nM 08:30 AM - 09:45 AM\nCaitrin\nHan\n\n\nLab 02\nPerkins LINK 087 (Classroom 3)\nM 10:05 AM - 11:20 AM\nKatie\nHyunjin\n\n\nLab 03\nPerkins LINK 071 (Classroom 5)\nM 10:05 AM - 11:20 AM\nJasmine\nLiane\n\n\nLab 04\nPerkins LINK 087 (Classroom 3)\nM 11:45 AM - 01:00 PM\nAvery\nAlexa\n\n\nLab 05\nPerkins LINK 071 (Classroom 5)\nM 11:45 AM - 01:00 PM\nDom\nJulia\n\n\nLab 06\nPerkins LINK 087 (Classroom 3)\nM 01:25 PM - 02:40 PM\nDav\nLisa\n\n\nLab 07\nPerkins LINK 071 (Classroom 5)\nM 01:25 PM - 02:40 PM\nEduardo\nArijit\n\n\nLab 08\nPerkins LINK 087 (Classroom 3)\nM 03:05 PM - 04:20 PM\nFederico\nSarah\n\n\nLab 09\nPerkins LINK 071 (Classroom 5)\nM 03:05 PM - 04:20 PM\nLi\nDevarpita\n\n\nLab 10\nPerkins LINK 087 (Classroom 3)\nM 04:40 PM - 05:55 PM\nNetra\nNatasha",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#while-you-wait",
    "href": "slides/13-linear-model-single-predictor.html#while-you-wait",
    "title": "Linear models with a single predictor",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-10-modeling-penguins.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#spurious-correlations",
    "href": "slides/13-linear-model-single-predictor.html#spurious-correlations",
    "title": "Linear models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#spurious-correlations-1",
    "href": "slides/13-linear-model-single-predictor.html#spurious-correlations-1",
    "title": "Linear models with a single predictor",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\nSource: tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#data-prep",
    "href": "slides/13-linear-model-single-predictor.html#data-prep",
    "title": "Linear models with a single predictor",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\n\nRename the dataset as movie_scores\n\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#data-overview",
    "href": "slides/13-linear-model-single-predictor.html#data-overview",
    "title": "Linear models with a single predictor",
    "section": "Data overview",
    "text": "Data overview\n\nmovie_scores |&gt;\n  select(critics, audience)\n\n# A tibble: 146 × 2\n   critics audience\n     &lt;int&gt;    &lt;int&gt;\n 1      74       86\n 2      85       80\n 3      80       90\n 4      18       84\n 5      14       28\n 6      63       62\n 7      42       53\n 8      86       64\n 9      99       82\n10      89       87\n# ℹ 136 more rows"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#data-visualization",
    "href": "slides/13-linear-model-single-predictor.html#data-visualization",
    "title": "Linear models with a single predictor",
    "section": "Data visualization",
    "text": "Data visualization"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#regression-model-1",
    "href": "slides/13-linear-model-single-predictor.html#regression-model-1",
    "title": "Linear models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the outcome, \\(Y\\), and the predictor, \\(X\\).\n\\[\n\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#regression-model",
    "href": "slides/13-linear-model-single-predictor.html#regression-model",
    "title": "Linear models with a single predictor",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{#325b74}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{#325b74}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{#325b74}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#simple-linear-regression",
    "href": "slides/13-linear-model-single-predictor.html#simple-linear-regression",
    "title": "Linear models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nUse simple linear regression to model the relationship between a quantitative outcome (\\(Y\\)) and a single quantitative predictor (\\(X\\)): \\[\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}\\]\n\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\epsilon\\): Error (residual)"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#simple-linear-regression-1",
    "href": "slides/13-linear-model-single-predictor.html#simple-linear-regression-1",
    "title": "Linear models with a single predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\\[\\Large{\\hat{Y} = b_0 + b_1 X}\\]\n\n\n\\(b_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(b_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\n\nNo error term!"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "href": "slides/13-linear-model-single-predictor.html#choosing-values-for-b_1-and-b_0",
    "title": "Linear models with a single predictor",
    "section": "Choosing values for \\(b_1\\) and \\(b_0\\)\n",
    "text": "Choosing values for \\(b_1\\) and \\(b_0\\)"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#residuals",
    "href": "slides/13-linear-model-single-predictor.html#residuals",
    "title": "Linear models with a single predictor",
    "section": "Residuals",
    "text": "Residuals\n\n\n\n\n\n\n\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}\\]"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#least-squares-line",
    "href": "slides/13-linear-model-single-predictor.html#least-squares-line",
    "title": "Linear models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#least-squares-line-1",
    "href": "slides/13-linear-model-single-predictor.html#least-squares-line-1",
    "title": "Linear models with a single predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\nmovies_fit &lt;- linear_reg() |&gt;\n  fit(audience ~ critics, data = movie_scores)\n\ntidy(movies_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#properties-of-least-squares-regression",
    "href": "slides/13-linear-model-single-predictor.html#properties-of-least-squares-regression",
    "title": "Linear models with a single predictor",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point (the coordinates corresponding to average \\(X\\) and average \\(Y\\)): \\(b_0 = \\bar{Y} - b_1~\\bar{X}\\)\nSlope has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_Y}{s_X}\\)\nSum of the residuals is zero: \\(\\sum_{i = 1}^n \\epsilon_i = 0\\)\nResiduals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#interpreting-slope-intercept",
    "href": "slides/13-linear-model-single-predictor.html#interpreting-slope-intercept",
    "title": "Linear models with a single predictor",
    "section": "Interpreting slope & intercept",
    "text": "Interpreting slope & intercept\n\\[\\widehat{\\text{audience}} = 32.3 + 0.519 \\times \\text{critics}\\]\n\n\n\nSlope: For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\n\nIntercept: If the critics score is 0 points, we expect the audience score to be 32.3 points."
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#is-the-intercept-meaningful",
    "href": "slides/13-linear-model-single-predictor.html#is-the-intercept-meaningful",
    "title": "Linear models with a single predictor",
    "section": "Is the intercept meaningful?",
    "text": "Is the intercept meaningful?\n✅ The intercept is meaningful in context of the data if\n\nthe predictor can feasibly take values equal to or near zero or\nthe predictor has values near zero in the observed data\n\n\n🛑 Otherwise, it might not be meaningful!"
  },
  {
    "objectID": "slides/13-linear-model-single-predictor.html#ae-10-modeling-penguins",
    "href": "slides/13-linear-model-single-predictor.html#ae-10-modeling-penguins",
    "title": "Linear models with a single predictor",
    "section": "ae-10-modeling-penguins",
    "text": "ae-10-modeling-penguins\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-10-modeling-penguins.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/project-intro-slides.html#final-project",
    "href": "slides/project-intro-slides.html#final-project",
    "title": "STA 199 Final Project",
    "section": "Final Project",
    "text": "Final Project\n\n\nTeams of 4 - 5 pick a dataset and compose an original analysis using the course tools;\nFinal product:\n\nwritten report in Quarto;\nfive minute video presentation."
  },
  {
    "objectID": "slides/project-intro-slides.html#intermediate-graded-deadlines",
    "href": "slides/project-intro-slides.html#intermediate-graded-deadlines",
    "title": "STA 199 Final Project",
    "section": "Intermediate graded deadlines",
    "text": "Intermediate graded deadlines\n\n\nMilestone 1: meet your teams\n\ntoday!\n\nMilestone 2: propose two candidate datasets to work with\n\nFri Mar 07: proposal due\nMon Mar 24: TA returns feedback\n\nMilestone 3: demonstrate progress\n\nFri Apr 04\n\nMilestone 4: give peer review feedback to other teams\n\nMon Apr 14 in lab\n\nMilestone 5: submit final report and video\n\nWednesday April 23\n\n\n\n\n20% of the final course grade altogether."
  },
  {
    "objectID": "slides/project-intro-slides.html#along-the-way-peer-evaluation-of-teammates",
    "href": "slides/project-intro-slides.html#along-the-way-peer-evaluation-of-teammates",
    "title": "STA 199 Final Project",
    "section": "Along the way: peer evaluation of teammates",
    "text": "Along the way: peer evaluation of teammates\n\nPeer eval 1: Fri Feb 28 @ 5PM\nPeer eval 2: Fri Mar 21 @ 5PM\nPeer eval 3: Fri Apr 11 @ 5PM\nPeer eval 4: Mon Apr 28 @ 5PM\n\n\n\n\n\n\n\nNote\n\n\nBe on the look out for emails from TEAMMATES."
  },
  {
    "objectID": "slides/12-language-models.html#while-you-wait",
    "href": "slides/12-language-models.html#while-you-wait",
    "title": "The language of models",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-09-modeling-fish.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/12-language-models.html#we-can-dream",
    "href": "slides/12-language-models.html#we-can-dream",
    "title": "The language of models",
    "section": "We can dream",
    "text": "We can dream"
  },
  {
    "objectID": "slides/12-language-models.html#anyone-want-to-argue",
    "href": "slides/12-language-models.html#anyone-want-to-argue",
    "title": "The language of models",
    "section": "Anyone want to argue?",
    "text": "Anyone want to argue?"
  },
  {
    "objectID": "slides/12-language-models.html#nailed-it",
    "href": "slides/12-language-models.html#nailed-it",
    "title": "The language of models",
    "section": "Nailed it",
    "text": "Nailed it"
  },
  {
    "objectID": "slides/12-language-models.html#work-on-the-ears-please",
    "href": "slides/12-language-models.html#work-on-the-ears-please",
    "title": "The language of models",
    "section": "Work on the ears please",
    "text": "Work on the ears please"
  },
  {
    "objectID": "slides/12-language-models.html#staaahp",
    "href": "slides/12-language-models.html#staaahp",
    "title": "The language of models",
    "section": "Staaahp",
    "text": "Staaahp"
  },
  {
    "objectID": "slides/12-language-models.html#no",
    "href": "slides/12-language-models.html#no",
    "title": "The language of models",
    "section": "No",
    "text": "No"
  },
  {
    "objectID": "slides/12-language-models.html#third-place-alex-brady",
    "href": "slides/12-language-models.html#third-place-alex-brady",
    "title": "The language of models",
    "section": "Third place: Alex Brady",
    "text": "Third place: Alex Brady\n\nggplot(mtcars, aes(x = wt, y = mpg, shape = factor(vs), color = factor(vs))) +\n  geom_point(size = 10, stroke = 5, alpha = 0.5) + \n  geom_smooth(size = 5) +\n  labs(\n    x = \"WEIGHT (1000 LBS)!!!IN OUNCES!!!?;)))\",\n    y = \"MPG?????? (MeTeRs pER gALLoN)!\",\n    title = \"~~~Weight vs MPG vs Engine Type of CARS!!!!&gt;&lt;%&#!~~~\",\n    shape = \"ugly engine type :(\",\n    color = \"Engine Thingy\"\n  ) +\n  scale_shape_manual(\n    values = c(0, 15),  \n    labels = c(\"V-SHAPED?!\", \"STRAIGHT??!!\")\n  ) +\n  scale_color_manual(\n    values = c(\"hotpink\", \"limegreen\"),\n    labels = c(\"HONK HONK\", \"BEEP BEEP\")\n  ) +\n    annotate(\"text\", x = 3, y = 25, label = \"VROOOOOOOMM!!!M!!!!!!!!!!!!!!\", \n             color = \"red\", size = 10, angle = 34) +\n  theme(\n       legend.position = \"bottom\",\n       legend.background = element_rect(fill = \"yellow\", color = \"red\"))"
  },
  {
    "objectID": "slides/12-language-models.html#second-place-jack-yi",
    "href": "slides/12-language-models.html#second-place-jack-yi",
    "title": "The language of models",
    "section": "Second place: Jack Yi",
    "text": "Second place: Jack Yi\n\nnew_mtcars &lt;- mtcars |&gt;\n  mutate(\n    am = as.character(am),\n    vs = as.character(vs)\n  )\nggplot(new_mtcars, aes(x = wt,\n                       y = mpg,\n                       shape = vs,\n                       linewidth = 69,\n                       label = \"i love john zito\"\n                       )\n  ) +\n  xlim(-1.1231, 5.384781472) +\n  ylim(-5.128312, 49.172836) +\n  geom_point(color = \"green3\") +\n  geom_line(color = \"pink3\") +\n  geom_area(color = \"brown4\") +\n  geom_quantile(linewidth = 2, color = \"yellow4\") +\n  geom_text(\n    size = new_mtcars$wt,\n    angle = new_mtcars$disp,\n    color = new_mtcars$hp\n  ) +\n  labs(\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\",\n  ) +\n  theme_void()"
  },
  {
    "objectID": "slides/12-language-models.html#first-place-jules-gates",
    "href": "slides/12-language-models.html#first-place-jules-gates",
    "title": "The language of models",
    "section": "First place: Jules Gates",
    "text": "First place: Jules Gates\n\nimg &lt;- readJPEG(\"images/12/images.jpeg\")\n\nfixed_mtcars &lt;- mtcars |&gt;\n  mutate(\n    am = factor(am, labels = c(\"Automatic\", \"Manual\")),\n    am = fct_relevel(am, \"Manual\", \"Automatic\"),\n    vs = factor(vs, labels = c(\"V-shaped\", \"Straight\")),\n    signs_m = ifelse(vs == \"V-shaped\", \"■ ■ ■\", \"■ ■ ■\")\n  )\n\nggplot(fixed_mtcars, aes(x = wt, y = mpg, color = am)) +\n  annotation_raster(img, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf) +\n  geom_text(aes(label = signs_m), size = 15) +\n  labs(\n    title = \"1v1 car weight and fuel efficiency\n    for various smurfmobiles\",\n    x = \"Weight (in mushroom houses)\",\n    y = \"Gallons (milk)\",\n    color = \"Transmission\"\n  ) +\n  scale_color_manual(\n    values = c(\"Automatic\" = \"blue\", \"Manual\" = \"blue\")\n  )  +\n  theme(\n    legend.position = \"top\",\n    plot.background = element_rect(fill = \"transparent\", color = NA),\n    text = element_text(size = 50, color = \"blue\")\n  )"
  },
  {
    "objectID": "slides/12-language-models.html#goals",
    "href": "slides/12-language-models.html#goals",
    "title": "The language of models",
    "section": "Goals",
    "text": "Goals\n\nWhat is a model?\nWhy do we model?\nWhat is correlation?"
  },
  {
    "objectID": "slides/12-language-models.html#lets-drive-a-tesla",
    "href": "slides/12-language-models.html#lets-drive-a-tesla",
    "title": "The language of models",
    "section": "Let’s drive a Tesla!",
    "text": "Let’s drive a Tesla!"
  },
  {
    "objectID": "slides/12-language-models.html#semi-or-garage",
    "href": "slides/12-language-models.html#semi-or-garage",
    "title": "The language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\ni love how Tesla thinks the wall in my garage is a semi. 😅\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/12-language-models.html#semi-or-garage-1",
    "href": "slides/12-language-models.html#semi-or-garage-1",
    "title": "The language of models",
    "section": "Semi or garage?",
    "text": "Semi or garage?\n\nNew owner here. Just parked in my garage. Tesla thinks I crashed onto a semi.\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/12-language-models.html#car-or-trash",
    "href": "slides/12-language-models.html#car-or-trash",
    "title": "The language of models",
    "section": "Car or trash?",
    "text": "Car or trash?\n\nTesla calls Mercedes trash\n\n\n\n\n\n\n\nSource: Reddit"
  },
  {
    "objectID": "slides/12-language-models.html#leisure-commute-physical-activity-and-bp",
    "href": "slides/12-language-models.html#leisure-commute-physical-activity-and-bp",
    "title": "The language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\n\nRelation Between Leisure Time, Commuting, and Occupational Physical Activity With Blood Pressure in 125,402 Adults: The Lifelines Cohort\nByambasukh, Oyuntugs, Harold Snieder, and Eva Corpeleijn. “Relation between leisure time, commuting, and occupational physical activity with blood pressure in 125 402 adults: the lifelines cohort.” Journal of the American Heart Association 9.4 (2020): e014313."
  },
  {
    "objectID": "slides/12-language-models.html#leisure-commute-physical-activity-and-bp-1",
    "href": "slides/12-language-models.html#leisure-commute-physical-activity-and-bp-1",
    "title": "The language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\nBackground: Whether all domains of daily‐life moderate‐to‐vigorous physical activity (MVPA) are associated with lower blood pressure (BP) and how this association depends on age and body mass index remains unclear.\nMethods and Results: In the population‐based Lifelines cohort (N=125,402), MVPA was assessed by the Short Questionnaire to Assess Health‐Enhancing Physical Activity, a validated questionnaire in different domains such as commuting, leisure‐time, and occupational PA. BP was assessed using the last 3 of 10 measurements after 10 minutes’ rest in the supine position. Hypertension was defined as systolic BP ≥140 mm Hg and/or diastolic BP ≥90 mm Hg and/or use of antihypertensives. In regression analysis, higher commuting and leisure‐time but not occupational MVPA related to lower BP and lower hypertension risk. Commuting‐and‐leisure‐time MVPA was associated with BP in a dose‐dependent manner. β Coefficients (95% CI) from linear regression analyses were −1.64 (−2.03 to −1.24), −2.29 (−2.68 to −1.90), and finally −2.90 (−3.29 to −2.50) mm Hg systolic BP for the low, middle, and highest tertile of MVPA compared with “No MVPA” as the reference group after adjusting for age, sex, education, smoking and alcohol use. Further adjustment for body mass index attenuated the associations by 30% to 50%, but more MVPA remained significantly associated with lower BP and lower risk of hypertension. This association was age dependent. β Coefficients (95% CI) for the highest tertiles of commuting‐and‐leisure‐time MVPA were −1.67 (−2.20 to −1.15), −3.39 (−3.94 to −2.82) and −4.64 (−6.15 to −3.14) mm Hg systolic BP in adults &lt;40, 40 to 60, and &gt;60 years, respectively.\nConclusions: Higher commuting and leisure‐time but not occupational MVPA were significantly associated with lower BP and lower hypertension risk at all ages, but these associations were stronger in older adults."
  },
  {
    "objectID": "slides/12-language-models.html#modeling-cars",
    "href": "slides/12-language-models.html#modeling-cars",
    "title": "The language of models",
    "section": "Modeling cars",
    "text": "Modeling cars\n\n\nWhat is the relationship between cars’ weights and their mileage?\nWhat is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/12-language-models.html#modelling-cars",
    "href": "slides/12-language-models.html#modelling-cars",
    "title": "The language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nDescribe: What is the relationship between cars’ weights and their mileage?"
  },
  {
    "objectID": "slides/12-language-models.html#modelling-cars-1",
    "href": "slides/12-language-models.html#modelling-cars-1",
    "title": "The language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nPredict: What is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/12-language-models.html#modelling",
    "href": "slides/12-language-models.html#modelling",
    "title": "The language of models",
    "section": "Modelling",
    "text": "Modelling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but there are many many other types of models too!)"
  },
  {
    "objectID": "slides/12-language-models.html#modelling-vocabulary",
    "href": "slides/12-language-models.html#modelling-vocabulary",
    "title": "The language of models",
    "section": "Modelling vocabulary",
    "text": "Modelling vocabulary\n\nPredictor (explanatory variable)\nOutcome (response variable)\nRegression line\n\nSlope\nIntercept\n\n\nCorrelation"
  },
  {
    "objectID": "slides/12-language-models.html#predictor-explanatory-variable",
    "href": "slides/12-language-models.html#predictor-explanatory-variable",
    "title": "The language of models",
    "section": "Predictor (explanatory variable)",
    "text": "Predictor (explanatory variable)\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/12-language-models.html#outcome-response-variable",
    "href": "slides/12-language-models.html#outcome-response-variable",
    "title": "The language of models",
    "section": "Outcome (response variable)",
    "text": "Outcome (response variable)\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/12-language-models.html#regression-line",
    "href": "slides/12-language-models.html#regression-line",
    "title": "The language of models",
    "section": "Regression line",
    "text": "Regression line"
  },
  {
    "objectID": "slides/12-language-models.html#regression-line-slope",
    "href": "slides/12-language-models.html#regression-line-slope",
    "title": "The language of models",
    "section": "Regression line: slope",
    "text": "Regression line: slope"
  },
  {
    "objectID": "slides/12-language-models.html#regression-line-intercept",
    "href": "slides/12-language-models.html#regression-line-intercept",
    "title": "The language of models",
    "section": "Regression line: intercept",
    "text": "Regression line: intercept"
  },
  {
    "objectID": "slides/12-language-models.html#correlation",
    "href": "slides/12-language-models.html#correlation",
    "title": "The language of models",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "slides/12-language-models.html#correlation-1",
    "href": "slides/12-language-models.html#correlation-1",
    "title": "The language of models",
    "section": "Correlation",
    "text": "Correlation\n\nRanges between -1 and 1.\nSame sign as the slope."
  },
  {
    "objectID": "slides/12-language-models.html#visualizing-the-model",
    "href": "slides/12-language-models.html#visualizing-the-model",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point()"
  },
  {
    "objectID": "slides/12-language-models.html#visualizing-the-model-1",
    "href": "slides/12-language-models.html#visualizing-the-model-1",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() + \n  geom_smooth()"
  },
  {
    "objectID": "slides/12-language-models.html#visualizing-the-model-2",
    "href": "slides/12-language-models.html#visualizing-the-model-2",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() + \n  geom_smooth(method = \"loess\")"
  },
  {
    "objectID": "slides/12-language-models.html#visualizing-the-model-3",
    "href": "slides/12-language-models.html#visualizing-the-model-3",
    "title": "The language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() + \n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/12-language-models.html#ae-09-modeling-fish",
    "href": "slides/12-language-models.html#ae-09-modeling-fish",
    "title": "The language of models",
    "section": "ae-09-modeling-fish",
    "text": "ae-09-modeling-fish\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-09-modeling-fish.qmd.\nWork through the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#outline",
    "href": "slides/02-grammar-of-data-visualization.html#outline",
    "title": "Grammar of data visualization",
    "section": "Outline",
    "text": "Outline\n\n\nLast time:\n\nWe introduced you to the course toolkit.\nYou cloned your ae repositories and started making some updates in your Quarto documents.\nYou did not commit and push your changes back.\n\n\n\n\n\n\nToday:\n\nYou will commit your changes from last time and push them to wrap up that application exercise.\nWe will introduce data visualization.\nYou will pull to get today’s application exercise file.\nYou will work on the new application exercise on data visualization, commit your changes, and push them."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#ae-01-meet-the-penguins",
    "href": "slides/02-grammar-of-data-visualization.html#ae-01-meet-the-penguins",
    "title": "Grammar of data visualization",
    "section": "ae-01-meet-the-penguins",
    "text": "ae-01-meet-the-penguins\n\nGo to RStudio, confirm that you’re in the ae project, and open the document ae-01-meet-the-penguins.qmd."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#tour-recap-quarto",
    "href": "slides/02-grammar-of-data-visualization.html#tour-recap-quarto",
    "title": "Grammar of data visualization",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#tour-recap-git-github",
    "href": "slides/02-grammar-of-data-visualization.html#tour-recap-git-github",
    "title": "Grammar of data visualization",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\nOnce we made changes to our Quarto document, we\n\nwent to the Git pane in RStudio\nstaged our changes by clicking the checkboxes next to the relevant files\ncommitted our changes with an informative commit message\n\npushed our changes to our application exercise repos\n\nif this failed, we pulled first to get the new application exercise files, and then pushed\n\n\nconfirmed on GitHub that we could see our changes pushed from RStudio"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#how-will-we-use-quarto",
    "href": "slides/02-grammar-of-data-visualization.html#how-will-we-use-quarto",
    "title": "Grammar of data visualization",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise, lab, project, etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#un-votes",
    "href": "slides/02-grammar-of-data-visualization.html#un-votes",
    "title": "Grammar of data visualization",
    "section": "UN Votes",
    "text": "UN Votes\n\nRemember this visualization from the videos?"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#let-see",
    "href": "slides/02-grammar-of-data-visualization.html#let-see",
    "title": "Grammar of data visualization",
    "section": "Let’ see…",
    "text": "Let’ see…\n\nhow the sausage is made!"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#load-packages",
    "href": "slides/02-grammar-of-data-visualization.html#load-packages",
    "title": "Grammar of data visualization",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(unvotes)\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#prepare-the-data",
    "href": "slides/02-grammar-of-data-visualization.html#prepare-the-data",
    "title": "Grammar of data visualization",
    "section": "Prepare the data",
    "text": "Prepare the data\n\nus_uk_tr_votes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\") |&gt;\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n  mutate(year = year(date)) |&gt;\n  group_by(country, year, issue) |&gt;\n  summarize(percent_yes = mean(vote == \"yes\"), .groups = \"drop\")\n\n\n\n\n\n\n\n\nNote\n\n\nLet’s leave these details aside for a bit, we’ll revisit this code at a later point in the semester. For now, let’s agree that we need to do some “data wrangling” to get the data into the right format for the plot we want to create. Just note that we called the data frame we’ll visualize us_uk_tr_votes."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#visualize-the-data",
    "href": "slides/02-grammar-of-data-visualization.html#visualize-the-data",
    "title": "Grammar of data visualization",
    "section": "Visualize the data",
    "text": "Visualize the data\n\nggplot(\n  us_uk_tr_votes, \n  mapping = aes(x = year, y = percent_yes, color = country)\n  ) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  labs(\n    x = \"Year\", \n    y = \"% yes\", \n    color = \"Country\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#visualize-the-data-output",
    "href": "slides/02-grammar-of-data-visualization.html#visualize-the-data-output",
    "title": "Grammar of data visualization",
    "section": "Visualize the data",
    "text": "Visualize the data"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-1.-prepare-a-canvas-for-plotting",
    "href": "slides/02-grammar-of-data-visualization.html#step-1.-prepare-a-canvas-for-plotting",
    "title": "Grammar of data visualization",
    "section": "Step 1. Prepare a canvas for plotting",
    "text": "Step 1. Prepare a canvas for plotting\n\nggplot(data = us_uk_tr_votes)"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-2.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#step-2.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 2. Map variables to aesthetics",
    "text": "Step 2. Map variables to aesthetics\nMap year to the x aesthetic\n\nggplot(data = us_uk_tr_votes, mapping = aes(x = year))"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-3.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#step-3.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 3. Map variables to aesthetics",
    "text": "Step 3. Map variables to aesthetics\nMap percent_yes to the y aesthetic\n\nggplot(data = us_uk_tr_votes, mapping = aes(x = year, y = percent_yes))"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#mapping-and-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#mapping-and-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Mapping and aesthetics",
    "text": "Mapping and aesthetics\n\nAesthetics are visual properties of a plot\nIn the grammar of graphics, variables from the data frame are mapped to aesthetics"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#argument-names",
    "href": "slides/02-grammar-of-data-visualization.html#argument-names",
    "title": "Grammar of data visualization",
    "section": "Argument names",
    "text": "Argument names\nIt’s common practice in R to omit the names of first two arguments of a function:\n\n\nInstead of\n\nggplot(data = us_uk_tr_votes, mapping = aes(x = year, y = percent_yes))\n\nUse\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes))"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-4.-represent-data-on-your-canvas",
    "href": "slides/02-grammar-of-data-visualization.html#step-4.-represent-data-on-your-canvas",
    "title": "Grammar of data visualization",
    "section": "Step 4. Represent data on your canvas",
    "text": "Step 4. Represent data on your canvas\nwith a geom\n\nggplot(us_uk_tr_votes, mapping = aes(x = year, y = percent_yes)) +\n  geom_point()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-5.-map-variables-to-aesthetics",
    "href": "slides/02-grammar-of-data-visualization.html#step-5.-map-variables-to-aesthetics",
    "title": "Grammar of data visualization",
    "section": "Step 5. Map variables to aesthetics",
    "text": "Step 5. Map variables to aesthetics\nMap country to the color aesthetic\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-6.-represent-data-on-your-canvas",
    "href": "slides/02-grammar-of-data-visualization.html#step-6.-represent-data-on-your-canvas",
    "title": "Grammar of data visualization",
    "section": "Step 6. Represent data on your canvas",
    "text": "Step 6. Represent data on your canvas\nwith another geom\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#warnings-and-messages",
    "href": "slides/02-grammar-of-data-visualization.html#warnings-and-messages",
    "title": "Grammar of data visualization",
    "section": "Warnings and messages",
    "text": "Warnings and messages\n\nAdding geom_smooth() resulted in the following warning:\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nIt tells us the type of smoothing ggplot2 does under the hood when drawing the smooth curves that represent trends for each country.\n\n\n\n\nGoing forward we’ll suppress this warning to save some space."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-7.-split-plot-into-facets",
    "href": "slides/02-grammar-of-data-visualization.html#step-7.-split-plot-into-facets",
    "title": "Grammar of data visualization",
    "section": "Step 7. Split plot into facets",
    "text": "Step 7. Split plot into facets\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~issue)"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-8.-use-a-different-color-scale",
    "href": "slides/02-grammar-of-data-visualization.html#step-8.-use-a-different-color-scale",
    "title": "Grammar of data visualization",
    "section": "Step 8. Use a different color scale",
    "text": "Step 8. Use a different color scale\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~issue) +\n  scale_color_colorblind()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-10.-apply-a-different-theme",
    "href": "slides/02-grammar-of-data-visualization.html#step-10.-apply-a-different-theme",
    "title": "Grammar of data visualization",
    "section": "Step 10. Apply a different theme",
    "text": "Step 10. Apply a different theme\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  theme_minimal()"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-11.-add-labels",
    "href": "slides/02-grammar-of-data-visualization.html#step-11.-add-labels",
    "title": "Grammar of data visualization",
    "section": "Step 11. Add labels",
    "text": "Step 11. Add labels\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  theme_minimal() +\n  labs(x = \"Year\", y = \"% yes\", color = \"Country\")"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-12.-set-transparency-of-points",
    "href": "slides/02-grammar-of-data-visualization.html#step-12.-set-transparency-of-points",
    "title": "Grammar of data visualization",
    "section": "Step 12. Set transparency of points",
    "text": "Step 12. Set transparency of points\nwith alpha\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth() +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  theme_minimal() +\n  labs(x = \"Year\", y = \"% yes\", color = \"Country\")"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#step-13.-hide-standard-errors-of-curves",
    "href": "slides/02-grammar-of-data-visualization.html#step-13.-hide-standard-errors-of-curves",
    "title": "Grammar of data visualization",
    "section": "Step 13. Hide standard errors of curves",
    "text": "Step 13. Hide standard errors of curves\nwith se = FALSE\n\nggplot(us_uk_tr_votes, aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(se = FALSE) +\n  facet_wrap(~issue) +\n  scale_color_colorblind() +\n  theme_minimal() +\n  labs(x = \"Year\", y = \"% yes\", color = \"Country\")"
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#grammar-of-graphics",
    "href": "slides/02-grammar-of-data-visualization.html#grammar-of-graphics",
    "title": "Grammar of data visualization",
    "section": "Grammar of graphics",
    "text": "Grammar of graphics\n\n\nWe built a plot layer-by-layer\n\njust like described in the book The Grammar of Graphics and\nimplemented in the ggplot2 package, the data visualization package of the tidyverse."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#ae-02-bechdel-dataviz",
    "href": "slides/02-grammar-of-data-visualization.html#ae-02-bechdel-dataviz",
    "title": "Grammar of data visualization",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/02-grammar-of-data-visualization.html#recap",
    "href": "slides/02-grammar-of-data-visualization.html#recap",
    "title": "Grammar of data visualization",
    "section": "Recap",
    "text": "Recap\n\nConstruct plots with ggplot().\nLayers of ggplots are separated by +s.\nThe formula is (almost) always as follows:\n\n\nggplot(DATA, aes(x = X-VAR, y = Y-VAR, ...)) +\n  geom_XXX()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#while-you-wait",
    "href": "slides/04-exploring-data-1.html#while-you-wait",
    "title": "Exploring data I",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-03-gerrymander-explore-I\n\nSwitch to your ae project in RStudio;\nMake sure all of your changes up to this point are committed (ie there’s nothing left in your Git pane);\nClick Pull to get today’s application exercise file: ae-03-gerrymander-explore-I.qmd.\nThen push. So Render &gt; Commit &gt; Pull &gt; Push.\nWait till the you’re prompted to work on the application exercise during class before editing the file.\n\n\n\n\n\n\n\nAEs are due by the end of class\n\n\nSuccessful completion means at least one commit + push by 2PM today"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#packages",
    "href": "slides/04-exploring-data-1.html#packages",
    "title": "Exploring data I",
    "section": "Packages",
    "text": "Packages\n\nFor the data: usdata\n\n\n\nlibrary(usdata)\n\n\nFor the analysis: tidyverse and ggthemes\n\n\n\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#data-gerrymander",
    "href": "slides/04-exploring-data-1.html#data-gerrymander",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\ngerrymander\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#what-is-gerrymandering",
    "href": "slides/04-exploring-data-1.html#what-is-gerrymandering",
    "title": "Exploring data I",
    "section": "What is gerrymandering?",
    "text": "What is gerrymandering?"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa",
    "href": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa",
    "title": "Exploring data I",
    "section": "JZ’s tour of the USA",
    "text": "JZ’s tour of the USA"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-1",
    "href": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-1",
    "title": "Exploring data I",
    "section": "JZ’s tour of the USA",
    "text": "JZ’s tour of the USA"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-2",
    "href": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-2",
    "title": "Exploring data I",
    "section": "JZ’s tour of the USA",
    "text": "JZ’s tour of the USA"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-3",
    "href": "slides/04-exploring-data-1.html#jzs-tour-of-the-usa-3",
    "title": "Exploring data I",
    "section": "JZ’s tour of the USA",
    "text": "JZ’s tour of the USA"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#data-gerrymander-1",
    "href": "slides/04-exploring-data-1.html#data-gerrymander-1",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\nWhat is a good first function to use to get to know a dataset?\n\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#data-gerrymander-2",
    "href": "slides/04-exploring-data-1.html#data-gerrymander-2",
    "title": "Exploring data I",
    "section": "Data: gerrymander\n",
    "text": "Data: gerrymander\n\n\nRows: Congressional districts\n\nColumns:\n\nCongressional district and state\n2016 election: winning party, % for Clinton, % for Trump, whether a Democrat won the House election, name of election winner\n2018 election: winning party, whether a Democrat won the 2018 House election\nWhether a Democrat flipped the seat in the 2018 election\nPrevalence of gerrymandering: low, mid, and high"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#variable-types",
    "href": "slides/04-exploring-data-1.html#variable-types",
    "title": "Exploring data I",
    "section": "Variable types",
    "text": "Variable types\n\n\n\n\n\nVariable\nType\n\n\n\ndistrict\ncategorical, ID\n\n\nlast_name\ncategorical, ID\n\n\nfirst_name\ncategorical, ID\n\n\nparty16\ncategorical\n\n\nclinton16\nnumerical, continuous\n\n\ntrump16\nnumerical, continuous\n\n\n\n\n\n\n\nVariable\nType\n\n\n\ndem16\ncategorical\n\n\nstate\ncategorical\n\n\nparty18\ncategorical\n\n\ndem18\ncategorical\n\n\nflip18\ncategorical\n\n\ngerry\ncategorical, ordinal"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#univariate-analysis-1",
    "href": "slides/04-exploring-data-1.html#univariate-analysis-1",
    "title": "Exploring data I",
    "section": "Univariate analysis",
    "text": "Univariate analysis\nAnalyzing a single variable:\n\n\nNumerical: histogram, box plot, density plot, etc.\nCategorical: bar plot, pie chart, etc."
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-1",
    "href": "slides/04-exploring-data-1.html#histogram---step-1",
    "title": "Exploring data I",
    "section": "Histogram - Step 1",
    "text": "Histogram - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-2",
    "href": "slides/04-exploring-data-1.html#histogram---step-2",
    "title": "Exploring data I",
    "section": "Histogram - Step 2",
    "text": "Histogram - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-3",
    "href": "slides/04-exploring-data-1.html#histogram---step-3",
    "title": "Exploring data I",
    "section": "Histogram - Step 3",
    "text": "Histogram - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-4",
    "href": "slides/04-exploring-data-1.html#histogram---step-4",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 1)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-4-1",
    "href": "slides/04-exploring-data-1.html#histogram---step-4-1",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 100)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-4-2",
    "href": "slides/04-exploring-data-1.html#histogram---step-4-2",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 3)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-4-3",
    "href": "slides/04-exploring-data-1.html#histogram---step-4-3",
    "title": "Exploring data I",
    "section": "Histogram - Step 4",
    "text": "Histogram - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 5)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#histogram---step-5",
    "href": "slides/04-exploring-data-1.html#histogram---step-5",
    "title": "Exploring data I",
    "section": "Histogram - Step 5",
    "text": "Histogram - Step 5\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_histogram(binwidth = 5) +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = \"Count\"\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---step-1",
    "href": "slides/04-exploring-data-1.html#box-plot---step-1",
    "title": "Exploring data I",
    "section": "Box plot - Step 1",
    "text": "Box plot - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---step-2",
    "href": "slides/04-exploring-data-1.html#box-plot---step-2",
    "title": "Exploring data I",
    "section": "Box plot - Step 2",
    "text": "Box plot - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---step-3",
    "href": "slides/04-exploring-data-1.html#box-plot---step-3",
    "title": "Exploring data I",
    "section": "Box plot - Step 3",
    "text": "Box plot - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---alternative-step-2-3",
    "href": "slides/04-exploring-data-1.html#box-plot---alternative-step-2-3",
    "title": "Exploring data I",
    "section": "Box plot - Alternative Step 2 + 3",
    "text": "Box plot - Alternative Step 2 + 3\n\nggplot(gerrymander, aes(y = trump16)) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#box-plot---step-4",
    "href": "slides/04-exploring-data-1.html#box-plot---step-4",
    "title": "Exploring data I",
    "section": "Box plot - Step 4",
    "text": "Box plot - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_boxplot() +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = NULL\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-1",
    "href": "slides/04-exploring-data-1.html#density-plot---step-1",
    "title": "Exploring data I",
    "section": "Density plot - Step 1",
    "text": "Density plot - Step 1\n\nggplot(gerrymander)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-2",
    "href": "slides/04-exploring-data-1.html#density-plot---step-2",
    "title": "Exploring data I",
    "section": "Density plot - Step 2",
    "text": "Density plot - Step 2\n\nggplot(gerrymander, aes(x = trump16))"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-3",
    "href": "slides/04-exploring-data-1.html#density-plot---step-3",
    "title": "Exploring data I",
    "section": "Density plot - Step 3",
    "text": "Density plot - Step 3\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-4",
    "href": "slides/04-exploring-data-1.html#density-plot---step-4",
    "title": "Exploring data I",
    "section": "Density plot - Step 4",
    "text": "Density plot - Step 4\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"red\")"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-5",
    "href": "slides/04-exploring-data-1.html#density-plot---step-5",
    "title": "Exploring data I",
    "section": "Density plot - Step 5",
    "text": "Density plot - Step 5\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\")"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-6",
    "href": "slides/04-exploring-data-1.html#density-plot---step-6",
    "title": "Exploring data I",
    "section": "Density plot - Step 6",
    "text": "Density plot - Step 6\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 1)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-6-1",
    "href": "slides/04-exploring-data-1.html#density-plot---step-6-1",
    "title": "Exploring data I",
    "section": "Density plot - Step 6",
    "text": "Density plot - Step 6\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-6-2",
    "href": "slides/04-exploring-data-1.html#density-plot---step-6-2",
    "title": "Exploring data I",
    "section": "Density plot - Step 6",
    "text": "Density plot - Step 6\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0.5)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-7",
    "href": "slides/04-exploring-data-1.html#density-plot---step-7",
    "title": "Exploring data I",
    "section": "Density plot - Step 7",
    "text": "Density plot - Step 7\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0.5, linewidth = 2)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plot---step-8",
    "href": "slides/04-exploring-data-1.html#density-plot---step-8",
    "title": "Exploring data I",
    "section": "Density plot - Step 8",
    "text": "Density plot - Step 8\n\nggplot(gerrymander, aes(x = trump16)) +\n  geom_density(color = \"firebrick\", fill = \"firebrick1\", alpha = 0.5, linewidth = 2) +\n  labs(\n    title = \"Percent of vote received by Trump in 2016 Presidential Election\",\n    subtitle = \"From each Congressional District\",\n    x = \"Percent of vote\",\n    y = \"Density\"\n  )"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics",
    "href": "slides/04-exploring-data-1.html#summary-statistics",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  summarize(\n    mean_trump_perc = mean(trump16),\n    median_trump_perc = median(trump16),\n    sd = sd(trump16),\n    iqr = IQR(trump16),\n    q25 = quantile(trump16, 0.25),\n    q75 = quantile(trump16, 0.75)\n  )\n\n# A tibble: 1 × 6\n  mean_trump_perc median_trump_perc    sd   iqr   q25   q75\n            &lt;dbl&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1            45.9              48.7  16.8  23.3  34.8  58.1"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#distribution-of-votes-for-trump-in-the-2016-election",
    "href": "slides/04-exploring-data-1.html#distribution-of-votes-for-trump-in-the-2016-election",
    "title": "Exploring data I",
    "section": "Distribution of votes for Trump in the 2016 election",
    "text": "Distribution of votes for Trump in the 2016 election\n\nDescribe the distribution of percent of vote received by Trump in 2016 Presidential Election from Congressional Districts.\n\n\nShape: The distribution of votes for Trump in the 2016 election from Congressional Districts is unimodal and left-skewed.\nCenter: The percent of vote received by Trump in the 2016 Presidential Election from a typical Congressional Districts is 48.7%.\nSpread: In the middle 50% of Congressional Districts, 34.8% to 58.1% of voters voted for Trump in the 2016 Presidential Election.\nUnusual observations: -"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#bivariate-analysis-1",
    "href": "slides/04-exploring-data-1.html#bivariate-analysis-1",
    "title": "Exploring data I",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\nAnalyzing the relationship between two variables:\n\n\nNumerical + numerical: scatterplot\nNumerical + categorical: side-by-side box plots, violin plots, etc.\nCategorical + categorical: stacked bar plots\nUsing an aesthetic (e.g., fill, color, shape, etc.) or facets to represent the second variable in any plot"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#side-by-side-box-plots",
    "href": "slides/04-exploring-data-1.html#side-by-side-box-plots",
    "title": "Exploring data I",
    "section": "Side-by-side box plots",
    "text": "Side-by-side box plots\n\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    y = gerry\n    )\n  ) +\n  geom_boxplot()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-1",
    "href": "slides/04-exploring-data-1.html#summary-statistics-1",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  # do the following for each level of gerry\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 1 × 5\n    min   q25 median   q75   max\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   4.9  34.8   48.7  58.1  80.4"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-2",
    "href": "slides/04-exploring-data-1.html#summary-statistics-2",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  filter(gerry == \"low\") |&gt;\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 1 × 5\n    min   q25 median   q75   max\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   4.9  36.3   48.4  54.7  74.9"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-3",
    "href": "slides/04-exploring-data-1.html#summary-statistics-3",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  filter(gerry == \"mid\") |&gt;\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 1 × 5\n    min   q25 median   q75   max\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   6.8  34.8   48.0  57.9  79.9"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-4",
    "href": "slides/04-exploring-data-1.html#summary-statistics-4",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  filter(gerry == \"high\") |&gt;\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 1 × 5\n    min   q25 median   q75   max\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   9.2  33.5   50.5  60.8  80.4"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#summary-statistics-5",
    "href": "slides/04-exploring-data-1.html#summary-statistics-5",
    "title": "Exploring data I",
    "section": "Summary statistics",
    "text": "Summary statistics\n\ngerrymander |&gt;\n  group_by(gerry) |&gt;\n  summarize(\n    min = min(trump16),\n    q25 = quantile(trump16, 0.25),\n    median = median(trump16),\n    q75 = quantile(trump16, 0.75),\n    max = max(trump16),\n  )\n\n# A tibble: 3 × 6\n  gerry   min   q25 median   q75   max\n  &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 low     4.9  36.3   48.4  54.7  74.9\n2 mid     6.8  34.8   48.0  57.9  79.9\n3 high    9.2  33.5   50.5  60.8  80.4"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#density-plots",
    "href": "slides/04-exploring-data-1.html#density-plots",
    "title": "Exploring data I",
    "section": "Density plots",
    "text": "Density plots\n\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    color = gerry\n    )\n  ) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#filled-density-plots",
    "href": "slides/04-exploring-data-1.html#filled-density-plots",
    "title": "Exploring data I",
    "section": "Filled density plots",
    "text": "Filled density plots\n\n\nggplot(\n  gerrymander, \n  aes(\n    x = trump16, \n    color = gerry,\n    fill = gerry\n    )\n  ) +\n  geom_density()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#better-filled-density-plots",
    "href": "slides/04-exploring-data-1.html#better-filled-density-plots",
    "title": "Exploring data I",
    "section": "Better filled density plots",
    "text": "Better filled density plots\n\nggplot(\n  gerrymander, \n  aes(x = trump16, color = gerry, fill = gerry)\n  ) +\n  geom_density(alpha = 0.5)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#better-colors",
    "href": "slides/04-exploring-data-1.html#better-colors",
    "title": "Exploring data I",
    "section": "Better colors",
    "text": "Better colors\n\n\nggplot(\n  gerrymander, \n  aes(x = trump16, color = gerry, fill = gerry)\n  ) +\n  geom_density(alpha = 0.5) +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#violin-plots",
    "href": "slides/04-exploring-data-1.html#violin-plots",
    "title": "Exploring data I",
    "section": "Violin plots",
    "text": "Violin plots\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#multiple-geoms",
    "href": "slides/04-exploring-data-1.html#multiple-geoms",
    "title": "Exploring data I",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_point() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#multiple-geoms-1",
    "href": "slides/04-exploring-data-1.html#multiple-geoms-1",
    "title": "Exploring data I",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  scale_color_colorblind() +\n  scale_fill_colorblind()"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#remove-legend",
    "href": "slides/04-exploring-data-1.html#remove-legend",
    "title": "Exploring data I",
    "section": "Remove legend",
    "text": "Remove legend\n\nggplot(\n  gerrymander, \n  aes(x = trump16, y = gerry, color = gerry)\n  ) +\n  geom_violin() +\n  geom_jitter() +\n  scale_color_colorblind() +\n  scale_fill_colorblind() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#multivariate-analysis-1",
    "href": "slides/04-exploring-data-1.html#multivariate-analysis-1",
    "title": "Exploring data I",
    "section": "Multivariate analysis",
    "text": "Multivariate analysis\nAnalyzing the relationship between multiple variables:\n\n\nIn general, one variable is identified as the outcome of interest\nThe remaining variables are predictors or explanatory variables\n\nPlots for exploring multivariate relationships are the same as those for bivariate relationships, but conditional on one or more variables\n\nConditioning can be done via faceting or aesthetic mappings (e.g., scatterplot of y vs. x1, colored by x2, faceted by x3)\n\n\n\nSummary statistics for exploring multivariate relationships are the same as those for bivariate relationships, but conditional on one or more variables\n\nConditioning can be done via grouping (e.g., correlation between y and x1, grouped by levels of x2 and x3)"
  },
  {
    "objectID": "slides/04-exploring-data-1.html#ae-03-gerrymander-explore-i",
    "href": "slides/04-exploring-data-1.html#ae-03-gerrymander-explore-i",
    "title": "Exploring data I",
    "section": "ae-03-gerrymander-explore-I",
    "text": "ae-03-gerrymander-explore-I\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-03-gerrymander-explore-I.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/11-ethics.html#basic-facts",
    "href": "slides/11-ethics.html#basic-facts",
    "title": "Data science ethics",
    "section": "Basic facts",
    "text": "Basic facts\nWorth 20% of your final grade; consists of two parts:\n\n\nIn-class: worth 70% of the Midterm 1 grade;\n\nThursday February 20 11:45 AM - 1:00 PM;\nTake note of your room assignment!\nAll multiple choice;\nBoth sides of one 8.5” x 11” sheet of notes.\n\n\n\nTake-home: worth 30% of the Midterm 1 grade.\n\nReleased Thursday February 20 at 1:00 PM;\nDue Monday February 24 at 8:30 AM;\nWorks just like a mini-lab, only zero collaboration."
  },
  {
    "objectID": "slides/11-ethics.html#last-weeks-advice",
    "href": "slides/11-ethics.html#last-weeks-advice",
    "title": "Data science ethics",
    "section": "Last week’s advice",
    "text": "Last week’s advice\nWhen the world was your oyster and you had nothing but time…\n\n\nPractice problems: released Thursday February 13;\n\nAttend lab: Kahoot on Monday February 17;\n\nOld labs: correct parts where you lost points;\n\nOld AEs: complete tasks we didn’t get to and compare with key;\n\nCode along: watch these videos specifically;\n\nTextbook: odd-numbered exercises in the back of Chs. 1, 4, 5, 6."
  },
  {
    "objectID": "slides/11-ethics.html#this-weeks-advice",
    "href": "slides/11-ethics.html#this-weeks-advice",
    "title": "Data science ethics",
    "section": "This week’s advice",
    "text": "This week’s advice\nNow that you only have forty-eight hours…\n\nStudy the Kahoot and the practice problems;\nStudy the Lab 4 solutions;\nSpend some serious time with your cheat sheet;\nStudy old AE keys, and work stuff we didn’t complete."
  },
  {
    "objectID": "slides/11-ethics.html#what-if-we-get-snowed-out",
    "href": "slides/11-ethics.html#what-if-we-get-snowed-out",
    "title": "Data science ethics",
    "section": "What if we get snowed out?",
    "text": "What if we get snowed out?\n\nIf classes are canceled: in-class exam is moved to 2/25;\nIf classes are not canceled: in-class exam is 2/20 as planned;\nTake-home exam is the same regardless;\nIf classes are canceled, Testing Center appointments are canceled, and we’ll cross that bridge when we come to it (it will be a mess)."
  },
  {
    "objectID": "slides/11-ethics.html#misrepresenting-data-science-results",
    "href": "slides/11-ethics.html#misrepresenting-data-science-results",
    "title": "Data science ethics",
    "section": "Misrepresenting data science results",
    "text": "Misrepresenting data science results\nSome common ways people do this, either intentionally or unintentionally, include:\n\n\nClaiming causality where it’s not in the scope of inference of the underlying study\nDistorting axes and scales to make the data tell a different story\nVisualizing spatial areas instead of human density for issues that depend on and affect humans\nOmitting uncertainty in reporting"
  },
  {
    "objectID": "slides/11-ethics.html#causality---time-coverage",
    "href": "slides/11-ethics.html#causality---time-coverage",
    "title": "Data science ethics",
    "section": "Causality - TIME coverage",
    "text": "Causality - TIME coverage\n\nHow plausible is the statement in the title of this article?\n\n\n\n\nAlice Park. Exercise Can Lower Risk of Some Cancers By 20%. Time Magazine. 16 May 2016."
  },
  {
    "objectID": "slides/11-ethics.html#causality---la-times-coverage",
    "href": "slides/11-ethics.html#causality---la-times-coverage",
    "title": "Data science ethics",
    "section": "Causality - LA Times coverage",
    "text": "Causality - LA Times coverage\n\nWhat does “research shows” mean?\n\n\n\n\nMelissa Healy. Exercising drives down risk for 13 cancers, research shows.\nLos Angeles Times. 16 May 2016."
  },
  {
    "objectID": "slides/11-ethics.html#causality---original-study",
    "href": "slides/11-ethics.html#causality---original-study",
    "title": "Data science ethics",
    "section": "Causality - Original study",
    "text": "Causality - Original study\nMoore, Steven C., et al. “Association of leisure-time physical activity with risk of 26 types of cancer in 1.44 million adults.” JAMA internal medicine 176.6 (2016): 816-825.\n\n\nVolunteers were asked about their physical activity level over the preceding year.\nHalf exercised less than about 150 minutes per week, half exercised more.\nCompared to the bottom 10% of exercisers, the top 10% had lower rates of esophageal, liver, lung, endometrial, colon, and breast cancer.\nResearchers found no association between exercising and 13 other cancers (e.g. pancreatic, ovarian, and brain).\n\nCarl Bergstrom and Jevin West. Calling Bullshit: The art of skepticism in a data-driven world.\nRandom House, 2020.\nSharon Begley. “Does exercise prevent cancer?”. StatNews. 16 May 2016."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---tax-cuts",
    "href": "slides/11-ethics.html#axes-and-scales---tax-cuts",
    "title": "Data science ethics",
    "section": "Axes and scales - Tax cuts",
    "text": "Axes and scales - Tax cuts\n\nWhat is the difference between these two pictures? Which presents a better way to represent these data?\n\n\n\n\nChristopher Ingraham. “You’ve been reading charts wrong. Here’s how a pro does it.”. The Washington Post. 14 October 2019."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---cost-of-gas",
    "href": "slides/11-ethics.html#axes-and-scales---cost-of-gas",
    "title": "Data science ethics",
    "section": "Axes and scales - Cost of gas",
    "text": "Axes and scales - Cost of gas\n\nWhat is wrong with this picture? How would you correct it?"
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---cost-of-gas-1",
    "href": "slides/11-ethics.html#axes-and-scales---cost-of-gas-1",
    "title": "Data science ethics",
    "section": "Axes and scales - Cost of gas",
    "text": "Axes and scales - Cost of gas\n\ndf &lt;- tibble(\n  date = ymd(c(\"2019-11-01\", \"2020-10-25\", \"2020-11-01\")),\n  cost = c(3.17, 3.51, 3.57)\n)\nggplot(df, aes(x = date, y = cost, group = 1)) +\n  geom_point() +\n  geom_line() +\n  geom_label(aes(label = cost), hjust = -0.25) +\n  labs(\n    title = \"Cost of gas\",\n    subtitle = \"National average\",\n    x = NULL, y = NULL, \n    caption = \"Source: AAA Fuel Gauge Report\"\n  ) +\n  scale_x_continuous(\n    breaks = ymd(c(\"2019-11-01\", \"2020-10-25\", \"2020-11-01\")), \n    labels = c(\"Last year\", \"Last week\", \"Current\"),\n    guide = guide_axis(angle = 90),\n    limits = ymd(c(\"2019-11-01\", \"2020-11-29\")),\n    minor_breaks = ymd(c(\"2019-11-01\", \"2020-10-25\", \"2020-11-01\"))\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---covid-in-ga",
    "href": "slides/11-ethics.html#axes-and-scales---covid-in-ga",
    "title": "Data science ethics",
    "section": "Axes and scales - COVID in GA",
    "text": "Axes and scales - COVID in GA\n\nWhat is wrong with this picture? How would you correct it?\n\n\n\n\nGeorgia Department of Public Health. 11 May 2020."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---covid-in-ga-1",
    "href": "slides/11-ethics.html#axes-and-scales---covid-in-ga-1",
    "title": "Data science ethics",
    "section": "Axes and scales - COVID in GA",
    "text": "Axes and scales - COVID in GA\n\n\n\nLucy D’Agostino McGowan. Graph detective. Live Free or Dichotomize. 17 May 2020."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---pp-services",
    "href": "slides/11-ethics.html#axes-and-scales---pp-services",
    "title": "Data science ethics",
    "section": "Axes and scales - PP services",
    "text": "Axes and scales - PP services\n\n\n\nWhat is wrong with this picture? How would you correct it?\n\n\n\n\n\n\n\nTimothy B. Lee. Whatever you think of Planned Parenthood, this is a terrible and dishonest chart. Vox. 29 September 2019."
  },
  {
    "objectID": "slides/11-ethics.html#axes-and-scales---pp-services-1",
    "href": "slides/11-ethics.html#axes-and-scales---pp-services-1",
    "title": "Data science ethics",
    "section": "Axes and scales - PP services",
    "text": "Axes and scales - PP services\n\npp &lt;- tibble(\n  year = c(2006, 2006, 2013, 2013),\n  service = c(\"Abortion\", \"Cancer\", \"Abortion\", \"Cancer\"),\n  n = c(289750, 2007371, 327000, 935573)\n)\n\nggplot(pp, aes(x = year, y = n, color = service)) +\n  geom_point(size = 2) +\n  geom_line(linewidth = 1) +\n  geom_text(aes(label = n), nudge_y = 100000) +\n  geom_text(\n    aes(label = year), \n    nudge_y = 200000, \n    color = \"darkgray\"\n  ) +\n  labs(\n    title = \"Services provided by Planned Parenthood\",\n    caption = \"Source: Planned Parenthood\",\n    x = NULL,\n    y = NULL\n  ) +\n  scale_x_continuous(breaks = c(2006, 2013)) +\n  scale_y_continuous(labels = label_number(big.mark = \",\")) +\n  scale_color_manual(values = c(\"red\", \"purple\")) +\n  annotate(\n    geom = \"text\",\n    label = \"Abortions\",\n    x = 2009.5,\n    y = 400000,\n    color = \"red\"\n  ) +\n  annotate(\n    geom = \"text\",\n    label = \"Cancer screening\\nand prevention services\",\n    x = 2010.5,\n    y = 1600000, \n    color = \"purple\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/11-ethics.html#maps-and-areas---voting-map",
    "href": "slides/11-ethics.html#maps-and-areas---voting-map",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting map",
    "text": "Maps and areas - Voting map\n\nDo you recognize this map? What does it show?\n\n\n\n\nLazaro Gamio. “Election maps are telling you big lies about small things”. The Washington Post. 1 Nov 2016."
  },
  {
    "objectID": "slides/11-ethics.html#maps-and-areas---two-alternate-tales",
    "href": "slides/11-ethics.html#maps-and-areas---two-alternate-tales",
    "title": "Data science ethics",
    "section": "Maps and areas - Two alternate tales",
    "text": "Maps and areas - Two alternate tales\n\n\n\n\n\n\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/11-ethics.html#maps-and-areas---voting-percentages",
    "href": "slides/11-ethics.html#maps-and-areas---voting-percentages",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting percentages",
    "text": "Maps and areas - Voting percentages\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/11-ethics.html#maps-and-areas---voting-percentages-1",
    "href": "slides/11-ethics.html#maps-and-areas---voting-percentages-1",
    "title": "Data science ethics",
    "section": "Maps and areas - Voting percentages",
    "text": "Maps and areas - Voting percentages\n\n\n\nAlberto Cairo. Visual Trumpery talk."
  },
  {
    "objectID": "slides/11-ethics.html#uncertainty---catalan-independence",
    "href": "slides/11-ethics.html#uncertainty---catalan-independence",
    "title": "Data science ethics",
    "section": "Uncertainty - Catalan independence",
    "text": "Uncertainty - Catalan independence\nOn December 19, 2014, the front page of Spanish national newspaper El País read “Catalan public opinion swings toward ‘no’ for independence, says survey”.\n\n\n\n\n\n\n\n\n\n\nAlberto Cairo. The truthful art: Data, charts, and maps for communication. New Riders, 2016."
  },
  {
    "objectID": "slides/11-ethics.html#uncertainty---catalan-independence-1",
    "href": "slides/11-ethics.html#uncertainty---catalan-independence-1",
    "title": "Data science ethics",
    "section": "Uncertainty - Catalan independence",
    "text": "Uncertainty - Catalan independence\n\n\n\n\n\n\n\n\n\n\nAlberto Cairo. “Uncertainty and Graphicacy: How Should Statisticians Journalists and Designers Reveal Uncertainty in Graphics for Public Consumption?”, Power from Statistics: Data Information and Knowledge, 2017."
  },
  {
    "objectID": "slides/11-ethics.html#california-proposition-25-2020",
    "href": "slides/11-ethics.html#california-proposition-25-2020",
    "title": "Data science ethics",
    "section": "California Proposition 25 (2020)",
    "text": "California Proposition 25 (2020)\nPopular referendum on 2018’s Senate Bill 10:\n\n\n\nYES: replace cash bail with ``risk assessment.’’\n\nDemocratic Party, Governor Gavin Newson, League of Women Voters of California, California Medical Association, Democracy for America (progressive PAC), etc.\n\n\n\nNO: keep the cash bail system.\n\nRepublican Party, American Bail Coalition, ACLU of Southern California, NAACP, California Asian Pacific Chamber of Commerce, etc.\n\n\nIf passed, each county would be empowered to develop a tool that predicts the risk of a suspect reoffending before trial.\nJudges would consult this prediction to make bail decisions."
  },
  {
    "objectID": "slides/11-ethics.html#what-might-risk-assessment-look-like",
    "href": "slides/11-ethics.html#what-might-risk-assessment-look-like",
    "title": "Data science ethics",
    "section": "What might “risk assessment” look like?",
    "text": "What might “risk assessment” look like?\nSomething we will study after spring break:\n\n\n\n\n\n\n\n\nAbove the line means high risk means no bail. Is this progress?"
  },
  {
    "objectID": "slides/11-ethics.html#what-happens-when-we-try-predictive-policing",
    "href": "slides/11-ethics.html#what-happens-when-we-try-predictive-policing",
    "title": "Data science ethics",
    "section": "What happens when we try “predictive policing”?",
    "text": "What happens when we try “predictive policing”?\n2016 ProPublica article on algorithm used for rating a defendant’s risk of future crime:\n\n\n\nIn forecasting who would re-offend, the algorithm made mistakes with black and white defendants at roughly the same rate but in very different ways.\n\nThe formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.\nWhite defendants were mislabeled as low risk more often than black defendants.\n\n\n\n\n\n\n\n\n\n\n\nSource: ProPublica"
  },
  {
    "objectID": "slides/11-ethics.html#notice-anything",
    "href": "slides/11-ethics.html#notice-anything",
    "title": "Data science ethics",
    "section": "Notice anything?",
    "text": "Notice anything?\n\n\n\nWhat is common among the defendants who were assigned a high/low risk score for reoffending?"
  },
  {
    "objectID": "slides/11-ethics.html#but-race-wasnt-in-my-model",
    "href": "slides/11-ethics.html#but-race-wasnt-in-my-model",
    "title": "Data science ethics",
    "section": "“But race wasn’t in my model”",
    "text": "“But race wasn’t in my model”\n\n\n\nHow can an algorithm that doesn’t use race as input data be racist?"
  },
  {
    "objectID": "slides/11-ethics.html#predicting-ethnicity",
    "href": "slides/11-ethics.html#predicting-ethnicity",
    "title": "Data science ethics",
    "section": "Predicting ethnicity",
    "text": "Predicting ethnicity\nImproving Ecological Inference by Predicting Individual Ethnicity from Voter Registration Record (Imran and Khan, 2016)\n\nIn both political behavior research and voting rights litigation, turnout and vote choice for different racial groups are often inferred using aggregate election results and racial composition. Over the past several decades, many statistical methods have been proposed to address this ecological inference problem. We propose an alternative method to reduce aggregation bias by predicting individual-level ethnicity from voter registration records. Building on the existing methodological literature, we use Bayes’s rule to combine the Census Bureau’s Surname List with various information from geocoded voter registration records. We evaluate the performance of the proposed methodology using approximately nine million voter registration records from Florida, where self-reported ethnicity is available. We find that it is possible to reduce the false positive rate among Black and Latino voters to 6% and 3%, respectively, while maintaining the true positive rate above 80%. Moreover, we use our predictions to estimate turnout by race and find that our estimates yields substantially less amounts of bias and root mean squared error than standard ecological inference estimates. We provide open-source software to implement the proposed methodology. The open-source software is available for implementing the proposed methodology."
  },
  {
    "objectID": "slides/11-ethics.html#wru-package",
    "href": "slides/11-ethics.html#wru-package",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\nThe said “source software” is the wru package: https://github.com/kosukeimai/wru.\n\nDo you have any ethical concerns about installing this package?"
  },
  {
    "objectID": "slides/11-ethics.html#wru-package-1",
    "href": "slides/11-ethics.html#wru-package-1",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\n\nWas the publication of this model ethical? Does the open-source nature of the code affect your answer? Is it ethical to use this software? Does your answer change depending on the intended use?\n\n\nlibrary(wru)\npredict_race(voter.file = voters, surname.only = TRUE) |&gt;\n  select(surname, pred.whi, pred.bla, pred.his, pred.asi, pred.oth)\n\n      surname    pred.whi    pred.bla     pred.his    pred.asi    pred.oth\n1      Khanna 0.045110474 0.003067623 0.0068522723 0.860411906 0.084557725\n2        Imai 0.052645440 0.001334812 0.0558160072 0.719376581 0.170827160\n3      Rivera 0.043285692 0.008204605 0.9136195794 0.024316883 0.010573240\n4     Fifield 0.895405704 0.001911388 0.0337464844 0.011079323 0.057857101\n5        Zhou 0.006572555 0.001298962 0.0005388581 0.982365594 0.009224032\n6    Ratkovic 0.861236727 0.008212824 0.0095395642 0.011334635 0.109676251\n7     Johnson 0.543815322 0.344128607 0.0272403940 0.007405765 0.077409913\n8       Lopez 0.038939877 0.004920643 0.9318797791 0.012154125 0.012105576\n10 Wantchekon 0.330697188 0.194700665 0.4042849478 0.021379541 0.048937658\n9       Morse 0.866360147 0.044429853 0.0246568086 0.010219712 0.054333479"
  },
  {
    "objectID": "slides/11-ethics.html#wru-package-2",
    "href": "slides/11-ethics.html#wru-package-2",
    "title": "Data science ethics",
    "section": "\nwru package",
    "text": "wru package\n\nme &lt;- tibble(surname = \"Zito\")\n\npredict_race(voter.file = me, surname.only = TRUE)\n\n  surname  pred.whi   pred.bla   pred.his    pred.asi   pred.oth\n1    Zito 0.9220001 0.00419631 0.03968994 0.009652312 0.02446131"
  },
  {
    "objectID": "slides/11-ethics.html#california-prop-25-did-not-pass",
    "href": "slides/11-ethics.html#california-prop-25-did-not-pass",
    "title": "Data science ethics",
    "section": "California Prop 25 did not pass",
    "text": "California Prop 25 did not pass\nThe cash bail system was retained:\n\n\nChoice\nVotes\nPercent\n\n\n\nYes\n7,232,380\n43.59%\n\n\nNo\n9,358,226\n56.41%\n\n\n\n\n\nreasonable people can debate if this outcome is good or bad;\nevery Californian was invited to decide whether statistics and data science should be deployed to make decisions with major social consequences. They opted out;\nThis vote was held in the pre-ChatGPT era. What would the outcome be today? Is the case for YES stronger or weaker?"
  },
  {
    "objectID": "slides/11-ethics.html#another-algorithmic-decision",
    "href": "slides/11-ethics.html#another-algorithmic-decision",
    "title": "Data science ethics",
    "section": "Another algorithmic decision…",
    "text": "Another algorithmic decision…\n Armies of stats PhDs go to work on these models. They have no training in the ethics of what they’re doing."
  },
  {
    "objectID": "slides/11-ethics.html#a-success-story",
    "href": "slides/11-ethics.html#a-success-story",
    "title": "Data science ethics",
    "section": "A success story?",
    "text": "A success story?\n\nData + Model to predict timing of menstrual cycle:\n\n\n\nA perfect microcosm of the themes of our course, and maybe one of the real triumphs of data and modeling improving modern life.\n\n\n…but what if you learned they were selling your data?"
  },
  {
    "objectID": "slides/11-ethics.html#data-privacy",
    "href": "slides/11-ethics.html#data-privacy",
    "title": "Data science ethics",
    "section": "Data privacy",
    "text": "Data privacy"
  },
  {
    "objectID": "slides/11-ethics.html#your-data",
    "href": "slides/11-ethics.html#your-data",
    "title": "Data science ethics",
    "section": "“Your” data",
    "text": "“Your” data\n\nEvery time we use apps, websites, and devices, our data is being collected and used or sold to others.\nMore importantly, decisions are made by law enforcement, financial institutions, and governments based on data that directly affect the lives of people."
  },
  {
    "objectID": "slides/11-ethics.html#privacy-of-your-data",
    "href": "slides/11-ethics.html#privacy-of-your-data",
    "title": "Data science ethics",
    "section": "Privacy of your data",
    "text": "Privacy of your data\n\nWhat pieces of data have you left on the internet today? Think through everything you’ve logged into, clicked on, checked in, either actively or automatically, that might be tracking you. Do you know where that data is stored? Who it can be accessed by? Whether it’s shared with others?"
  },
  {
    "objectID": "slides/11-ethics.html#sharing-your-data",
    "href": "slides/11-ethics.html#sharing-your-data",
    "title": "Data science ethics",
    "section": "Sharing your data",
    "text": "Sharing your data\n\nWhat are you OK with sharing?\n\n\n\n\n\nName\nAge\nEmail\nPhone Number\nList of every video you watch\nList of every video you comment on\n\n\n\n\n\nHow you type: speed, accuracy\nHow long you spend on different content\nList of all your private messages (date, time, person sent to)\nInfo about your photos (how it was taken, where it was taken (GPS), when it was taken)"
  },
  {
    "objectID": "slides/11-ethics.html#what-does-google-thinkknow-about-you",
    "href": "slides/11-ethics.html#what-does-google-thinkknow-about-you",
    "title": "Data science ethics",
    "section": "What does Google think/know about you?",
    "text": "What does Google think/know about you?\n\nHave you ever thought about why you’re seeing an ad on Google? Google it! Try to figure out if you have ad personalization on and how your ads are personalized."
  },
  {
    "objectID": "slides/11-ethics.html#your-browsing-history",
    "href": "slides/11-ethics.html#your-browsing-history",
    "title": "Data science ethics",
    "section": "Your browsing history",
    "text": "Your browsing history\n\nWhich of the following are you OK with your browsing history to be used towards?\n\n\n\nFor serving you targeted ads\nTo score you as a candidate for a job\nTo predict your race/ethnicity for voting purposes"
  },
  {
    "objectID": "slides/11-ethics.html#who-else-gets-to-use-your-data",
    "href": "slides/11-ethics.html#who-else-gets-to-use-your-data",
    "title": "Data science ethics",
    "section": "Who else gets to use your data?",
    "text": "Who else gets to use your data?\n\nSuppose you create a profile on a social media site and share your personal information on your profile. Who else gets to use that data?\n\n\n\nCompanies the social media company has a connection to?\nCompanies the social media company sells your data to?\nResearchers?"
  },
  {
    "objectID": "slides/11-ethics.html#aol-search-data-leak",
    "href": "slides/11-ethics.html#aol-search-data-leak",
    "title": "Data science ethics",
    "section": "AOL search data leak",
    "text": "AOL search data leak\n\n\n\nMichael Barbaro and Tom Zeller Jr. A Face Is Exposed for AOL Searcher No. 4417749.\nNew York Times. 9 August 2006."
  },
  {
    "objectID": "slides/11-ethics.html#ok-cupid-data-breach",
    "href": "slides/11-ethics.html#ok-cupid-data-breach",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nIn 2016, researchers published data of 70,000 OkCupid users—including usernames, political leanings, drug usage, and intimate sexual details\nResearchers didn’t release the real names and pictures of OKCupid users, but their identities could easily be uncovered from the details provided, e.g. usernames"
  },
  {
    "objectID": "slides/11-ethics.html#ok-cupid-data-breach-1",
    "href": "slides/11-ethics.html#ok-cupid-data-breach-1",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach"
  },
  {
    "objectID": "slides/11-ethics.html#ok-cupid-data-breach-2",
    "href": "slides/11-ethics.html#ok-cupid-data-breach-2",
    "title": "Data science ethics",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n\nSome may object to the ethics of gathering and releasing this data. However, all the data found in the dataset are or were already publicly available, so releasing this dataset merely presents it in a more useful form.\nResearchers Emil Kirkegaard and Julius Daugbjerg Bjerrekær"
  },
  {
    "objectID": "slides/11-ethics.html#data-privacy-1",
    "href": "slides/11-ethics.html#data-privacy-1",
    "title": "Data science ethics",
    "section": "Data privacy",
    "text": "Data privacy\n\nIn analysis of data that individuals willingly shared publicly on a given platform (e.g. social media), how do you make sure you don’t violate reasonable expectations of privacy?"
  },
  {
    "objectID": "slides/11-ethics.html#faster-more-accurate-cancer-screening",
    "href": "slides/11-ethics.html#faster-more-accurate-cancer-screening",
    "title": "Data science ethics",
    "section": "Faster, more accurate cancer screening?",
    "text": "Faster, more accurate cancer screening?\nAugmenting doctors’ diagnostic capacity so that they make fewer mistakes, treat more people, and focus on other aspects of care:"
  },
  {
    "objectID": "slides/11-ethics.html#the-nobel-prize-last-year",
    "href": "slides/11-ethics.html#the-nobel-prize-last-year",
    "title": "Data science ethics",
    "section": "The Nobel Prize last year",
    "text": "The Nobel Prize last year\n\n\nAlphaFold2: “predicting 3D structures [of proteins] (\\(y\\)) directly from the primary amino acid sequence (\\(x\\)).”\n“researchers can now better understand antibiotic resistance and create images of enzymes that can decompose plastic.”"
  },
  {
    "objectID": "slides/11-ethics.html#how-charts-lie",
    "href": "slides/11-ethics.html#how-charts-lie",
    "title": "Data science ethics",
    "section": "How Charts Lie",
    "text": "How Charts Lie\n\n\n\n\nHow Charts Lie\nGetting Smarter about Visual Information\nby Alberto Cairo"
  },
  {
    "objectID": "slides/11-ethics.html#calling-bullshit",
    "href": "slides/11-ethics.html#calling-bullshit",
    "title": "Data science ethics",
    "section": "Calling Bullshit",
    "text": "Calling Bullshit\n\n\n\n\nCalling Bullshit\nThe Art of Skepticism in a\nData-Driven World\nby Carl Bergstrom and Jevin West"
  },
  {
    "objectID": "slides/11-ethics.html#machine-bias",
    "href": "slides/11-ethics.html#machine-bias",
    "title": "Data science ethics",
    "section": "Machine Bias",
    "text": "Machine Bias\n\n\n\n\nMachine Bias\nby Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner"
  },
  {
    "objectID": "slides/11-ethics.html#ethics-and-data-science",
    "href": "slides/11-ethics.html#ethics-and-data-science",
    "title": "Data science ethics",
    "section": "Ethics and Data Science",
    "text": "Ethics and Data Science\n\n\n\n\nEthics and Data Science\nby Mike Loukides, Hilary Mason, DJ Patil\n(Free Kindle download)"
  },
  {
    "objectID": "slides/11-ethics.html#weapons-of-math-destruction",
    "href": "slides/11-ethics.html#weapons-of-math-destruction",
    "title": "Data science ethics",
    "section": "Weapons of Math Destruction",
    "text": "Weapons of Math Destruction\n\n\n\n\nWeapons of Math Destruction\nHow Big Data Increases Inequality and Threatens Democracy\nby Cathy O’Neil"
  },
  {
    "objectID": "slides/11-ethics.html#algorithms-of-oppression",
    "href": "slides/11-ethics.html#algorithms-of-oppression",
    "title": "Data science ethics",
    "section": "Algorithms of Oppression",
    "text": "Algorithms of Oppression\n\n\n\n\nAlgorithms of Oppression\nHow Search Engines Reinforce Racism\nby Safiya Umoja Noble"
  },
  {
    "objectID": "slides/11-ethics.html#and-more-recently",
    "href": "slides/11-ethics.html#and-more-recently",
    "title": "Data science ethics",
    "section": "And more recently…",
    "text": "And more recently…\nHow AI discriminates and what that means for your Google habit\nA conversation with UCLA internet studies scholar Safiya Noble\nby Julia Busiek"
  },
  {
    "objectID": "slides/11-ethics.html#parting-thoughts",
    "href": "slides/11-ethics.html#parting-thoughts",
    "title": "Data science ethics",
    "section": "Parting thoughts",
    "text": "Parting thoughts\n\nAt some point during your data science learning journey you will learn tools that can be used unethically\nYou might also be tempted to use your knowledge in a way that is ethically questionable either because of business goals or for the pursuit of further knowledge (or because your boss told you to do so)\n\n\nHow do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?"
  },
  {
    "objectID": "slides/08-data-types-classes.html#while-you-wait",
    "href": "slides/08-data-types-classes.html#while-you-wait",
    "title": "Data types and classes",
    "section": "While you wait…",
    "text": "While you wait…\n\n\n\n\n&lt;p&gt;Loading…&lt;/p&gt;\n\n\nPrepare for today’s application exercise: ae-07-durham-climate-factors\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-07-durham-climate-factors.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/08-data-types-classes.html#regrade-request-policy",
    "href": "slides/08-data-types-classes.html#regrade-request-policy",
    "title": "Data types and classes",
    "section": "Regrade request policy",
    "text": "Regrade request policy\n\n\nConsidered for errors in grade calculation or if a correct answer was mistakenly marked as incorrect\n\nNot a mechanism for:\n\ndisputing the number of points deducted for an incorrect response\nasking for clarification on feedback (come to office hours instead)\n\n\nDue on Gradescope within a week after an assignment is returned\nThe entire assignment may be regraded, which could result in an adjustment in either direction\nNo regrade requests after the final exam has been administered"
  },
  {
    "objectID": "slides/08-data-types-classes.html#how-many-classes-do-you-have-on-tuesdays",
    "href": "slides/08-data-types-classes.html#how-many-classes-do-you-have-on-tuesdays",
    "title": "Data types and classes",
    "section": "How many classes do you have on Tuesdays?",
    "text": "How many classes do you have on Tuesdays?\n\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         How many classes do you have on Tues…¹ `What year are you?`\n   &lt;chr&gt;             &lt;chr&gt;                                  &lt;chr&gt;               \n 1 2/6/2025 11:33:57 3                                      Sophomore           \n 2 2/6/2025 11:37:39 3                                      First-year          \n 3 2/6/2025 11:40:55 2                                      Senior              \n 4 2/6/2025 11:42:05 3                                      First-year          \n 5 2/6/2025 11:42:46 3                                      Senior              \n 6 2/6/2025 11:43:28 3                                      Senior              \n 7 2/6/2025 11:44:41 3                                      First-year          \n 8 2/6/2025 11:44:49 3                                      First-year          \n 9 2/6/2025 11:44:51 2                                      Sophomore           \n10 2/6/2025 11:44:51 3                                      Sophomore           \n# ℹ 199 more rows\n# ℹ abbreviated name: ¹​`How many classes do you have on Tuesdays?`"
  },
  {
    "objectID": "slides/08-data-types-classes.html#rename-variables",
    "href": "slides/08-data-types-classes.html#rename-variables",
    "title": "Data types and classes",
    "section": "\nrename() variables",
    "text": "rename() variables\nTo make them easier to work with…\n\nsurvey &lt;- survey |&gt;\n  rename(\n    tue_classes = `How many classes do you have on Tuesdays?`,\n    year = `What year are you?`\n  )"
  },
  {
    "objectID": "slides/08-data-types-classes.html#variable-types",
    "href": "slides/08-data-types-classes.html#variable-types",
    "title": "Data types and classes",
    "section": "Variable types",
    "text": "Variable types\n\nWhat type of variable is tue_classes?\n\n\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         tue_classes year      \n   &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     \n 1 2/6/2025 11:33:57 3           Sophomore \n 2 2/6/2025 11:37:39 3           First-year\n 3 2/6/2025 11:40:55 2           Senior    \n 4 2/6/2025 11:42:05 3           First-year\n 5 2/6/2025 11:42:46 3           Senior    \n 6 2/6/2025 11:43:28 3           Senior    \n 7 2/6/2025 11:44:41 3           First-year\n 8 2/6/2025 11:44:49 3           First-year\n 9 2/6/2025 11:44:51 2           Sophomore \n10 2/6/2025 11:44:51 3           Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes.html#variable-types-1",
    "href": "slides/08-data-types-classes.html#variable-types-1",
    "title": "Data types and classes",
    "section": "Variable types",
    "text": "Variable types\n\nWhy isn’t the tue_classes column numeric?\n\n\nsurvey |&gt;\n  count(tue_classes)\n\n# A tibble: 13 × 2\n   tue_classes                  n\n   &lt;chr&gt;                    &lt;int&gt;\n 1 1                           10\n 2 2                           53\n 3 2 -3                         1\n 4 3                          104\n 5 3 classes                    1\n 6 4                           28\n 7 5                            3\n 8 Four                         1\n 9 TWO MANY                     1\n10 Three                        2\n11 Two                          3\n12 Two plus a chemistry lab     1\n13 three                        1"
  },
  {
    "objectID": "slides/08-data-types-classes.html#lets-clean-it-up",
    "href": "slides/08-data-types-classes.html#lets-clean-it-up",
    "title": "Data types and classes",
    "section": "Let’s clean it up",
    "text": "Let’s clean it up\nIt’s a huge pain in the rear:\n\nsurvey &lt;- survey |&gt;\n  mutate(\n    tue_classes = case_when(\n      tue_classes == \"2 -3\" ~ \"3\",\n      tue_classes == \"3 classes\" ~ \"3\",\n      tue_classes == \"Four\" ~ \"4\",\n      tue_classes == \"TWO MANY\" ~ \"2\",\n      tue_classes == \"Three\" ~ \"3\",\n      tue_classes == \"Two\" ~ \"2\",\n      tue_classes == \"Two plus a chemistry lab\" ~ \"3\",\n      tue_classes == \"three\" ~ \"3\",\n      .default = tue_classes\n    ),\n    tue_classes = as.numeric(tue_classes)\n  )\n\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         tue_classes year      \n   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;     \n 1 2/6/2025 11:33:57           3 Sophomore \n 2 2/6/2025 11:37:39           3 First-year\n 3 2/6/2025 11:40:55           2 Senior    \n 4 2/6/2025 11:42:05           3 First-year\n 5 2/6/2025 11:42:46           3 Senior    \n 6 2/6/2025 11:43:28           3 Senior    \n 7 2/6/2025 11:44:41           3 First-year\n 8 2/6/2025 11:44:49           3 First-year\n 9 2/6/2025 11:44:51           2 Sophomore \n10 2/6/2025 11:44:51           3 Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes.html#data-types-in-r",
    "href": "slides/08-data-types-classes.html#data-types-in-r",
    "title": "Data types and classes",
    "section": "Data types in R",
    "text": "Data types in R\n\nlogical\ndouble\ninteger\ncharacter\nand some more, but we won’t be focusing on those"
  },
  {
    "objectID": "slides/08-data-types-classes.html#logical-character",
    "href": "slides/08-data-types-classes.html#logical-character",
    "title": "Data types and classes",
    "section": "Logical & character",
    "text": "Logical & character\n\n\nlogical - Boolean values TRUE and FALSE\n\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\n\n\ncharacter - character strings\n\n\ntypeof(\"First-year\")\n\n[1] \"character\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#double-integer",
    "href": "slides/08-data-types-classes.html#double-integer",
    "title": "Data types and classes",
    "section": "Double & integer",
    "text": "Double & integer\n\n\ndouble - floating point numerical values (default numerical type)\n\n\ntypeof(2.5)\n\n[1] \"double\"\n\ntypeof(3)\n\n[1] \"double\"\n\n\n\n\ninteger - integer numerical values (indicated with an L)\n\n\ntypeof(3L)\n\n[1] \"integer\"\n\ntypeof(1:3)\n\n[1] \"integer\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#concatenation",
    "href": "slides/08-data-types-classes.html#concatenation",
    "title": "Data types and classes",
    "section": "Concatenation",
    "text": "Concatenation\nVectors can be constructed using the c() function.\n\nNumeric vector:\n\n\nc(1, 2, 3)\n\n[1] 1 2 3\n\n\n\n\nCharacter vector:\n\n\nc(\"Hello\", \"World!\")\n\n[1] \"Hello\"  \"World!\"\n\n\n\n\n\nVector made of vectors:\n\n\nc(c(\"hi\", \"hello\"), c(\"bye\", \"jello\"))\n\n[1] \"hi\"    \"hello\" \"bye\"   \"jello\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types",
    "href": "slides/08-data-types-classes.html#converting-between-types",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwith intention…\n\n\n\n\nx &lt;- 1:3\nx\n\n[1] 1 2 3\n\ntypeof(x)\n\n[1] \"integer\"\n\n\n\n\n\ny &lt;- as.character(x)\ny\n\n[1] \"1\" \"2\" \"3\"\n\ntypeof(y)\n\n[1] \"character\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types-1",
    "href": "slides/08-data-types-classes.html#converting-between-types-1",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwith intention…\n\n\n\n\nx &lt;- c(TRUE, FALSE)\nx\n\n[1]  TRUE FALSE\n\ntypeof(x)\n\n[1] \"logical\"\n\n\n\n\n\ny &lt;- as.numeric(x)\ny\n\n[1] 1 0\n\ntypeof(y)\n\n[1] \"double\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types-2",
    "href": "slides/08-data-types-classes.html#converting-between-types-2",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwithout intention…\n\n\nc(2, \"Just this one!\")\n\n[1] \"2\"              \"Just this one!\"\n\n\n\nR will happily convert between various types without complaint when different types of data are concatenated in a vector, and that’s not always a great thing!"
  },
  {
    "objectID": "slides/08-data-types-classes.html#converting-between-types-3",
    "href": "slides/08-data-types-classes.html#converting-between-types-3",
    "title": "Data types and classes",
    "section": "Converting between types",
    "text": "Converting between types\n\nwithout intention…\n\n\nc(FALSE, 3L)\n\n[1] 0 3\n\n\n\n\nc(1.2, 3L)\n\n[1] 1.2 3.0\n\n\n\n\n\nc(2L, \"two\")\n\n[1] \"2\"   \"two\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#explicit-vs.-implicit-coercion",
    "href": "slides/08-data-types-classes.html#explicit-vs.-implicit-coercion",
    "title": "Data types and classes",
    "section": "Explicit vs. implicit coercion",
    "text": "Explicit vs. implicit coercion\n\n\nExplicit coercion:\nWhen you call a function like as.logical(), as.numeric(), as.integer(), as.double(), or as.character().\n\n\nImplicit coercion:\nHappens when you use a vector in a specific context that expects a certain type of vector."
  },
  {
    "objectID": "slides/08-data-types-classes.html#data-classes-1",
    "href": "slides/08-data-types-classes.html#data-classes-1",
    "title": "Data types and classes",
    "section": "Data classes",
    "text": "Data classes\n\n\nVectors are like Lego building blocks\nWe stick them together to build more complicated constructs, e.g. representations of data\n\nThe class attribute relates to the S3 class of an object which determines its behaviour\n\nYou don’t need to worry about what S3 classes really mean, but you can read more about it here if you’re curious\n\n\nExamples: factors, dates, and data frames"
  },
  {
    "objectID": "slides/08-data-types-classes.html#factors",
    "href": "slides/08-data-types-classes.html#factors",
    "title": "Data types and classes",
    "section": "Factors",
    "text": "Factors\nR uses factors to handle categorical variables, variables that have a fixed and known set of possible values\n\nclass_years &lt;- factor(\n  c(\n    \"First-year\", \"Sophomore\", \"Sophomore\", \"Senior\", \"Junior\"\n    )\n  )\nclass_years\n\n[1] First-year Sophomore  Sophomore  Senior     Junior    \nLevels: First-year Junior Senior Sophomore\n\n\n\n\n\ntypeof(class_years)\n\n[1] \"integer\"\n\n\n\n\n\nclass(class_years)\n\n[1] \"factor\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#more-on-factors",
    "href": "slides/08-data-types-classes.html#more-on-factors",
    "title": "Data types and classes",
    "section": "More on factors",
    "text": "More on factors\nWe can think of factors like character (level labels) and an integer (level numbers) glued together\n\nglimpse(class_years)\n\n Factor w/ 4 levels \"First-year\",\"Junior\",..: 1 4 4 3 2\n\n\n\nas.integer(class_years)\n\n[1] 1 4 4 3 2"
  },
  {
    "objectID": "slides/08-data-types-classes.html#dates",
    "href": "slides/08-data-types-classes.html#dates",
    "title": "Data types and classes",
    "section": "Dates",
    "text": "Dates\n\ntoday &lt;- as.Date(\"2024-09-24\")\ntoday\n\n[1] \"2024-09-24\"\n\n\n\ntypeof(today)\n\n[1] \"double\"\n\n\n\nclass(today)\n\n[1] \"Date\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#more-on-dates",
    "href": "slides/08-data-types-classes.html#more-on-dates",
    "title": "Data types and classes",
    "section": "More on dates",
    "text": "More on dates\nWe can think of dates like an integer (the number of days since the origin, 1 Jan 1970) and an integer (the origin) glued together\n\nas.integer(today)\n\n[1] 19990\n\n\n\nas.integer(today) / 365 # roughly 55 yrs\n\n[1] 54.76712"
  },
  {
    "objectID": "slides/08-data-types-classes.html#data-frames",
    "href": "slides/08-data-types-classes.html#data-frames",
    "title": "Data types and classes",
    "section": "Data frames",
    "text": "Data frames\nWe can think of data frames like like vectors of equal length glued together\n\ndf &lt;- data.frame(x = 1:2, y = 3:4)\ndf\n\n  x y\n1 1 3\n2 2 4\n\n\n\n\n\ntypeof(df)\n\n[1] \"list\"\n\n\n\n\nclass(df)\n\n[1] \"data.frame\""
  },
  {
    "objectID": "slides/08-data-types-classes.html#lists",
    "href": "slides/08-data-types-classes.html#lists",
    "title": "Data types and classes",
    "section": "Lists",
    "text": "Lists\nLists are a generic vector container; vectors of any type can go in them\n\nl &lt;- list(\n  x = 1:4,\n  y = c(\"hi\", \"hello\", \"jello\"),\n  z = c(TRUE, FALSE)\n)\nl\n\n$x\n[1] 1 2 3 4\n\n$y\n[1] \"hi\"    \"hello\" \"jello\"\n\n$z\n[1]  TRUE FALSE"
  },
  {
    "objectID": "slides/08-data-types-classes.html#lists-and-data-frames",
    "href": "slides/08-data-types-classes.html#lists-and-data-frames",
    "title": "Data types and classes",
    "section": "Lists and data frames",
    "text": "Lists and data frames\n\nA data frame is a special list containing vectors of equal length\n\n\ndf\n\n  x y\n1 1 3\n2 2 4\n\n\n\nWhen we use the pull() function, we extract a vector from the data frame\n\n\ndf |&gt;\n  pull(y)\n\n[1] 3 4"
  },
  {
    "objectID": "slides/08-data-types-classes.html#read-data-in-as-character-strings",
    "href": "slides/08-data-types-classes.html#read-data-in-as-character-strings",
    "title": "Data types and classes",
    "section": "Read data in as character strings",
    "text": "Read data in as character strings\n\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         tue_classes year      \n   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;     \n 1 2/6/2025 11:33:57           3 Sophomore \n 2 2/6/2025 11:37:39           3 First-year\n 3 2/6/2025 11:40:55           2 Senior    \n 4 2/6/2025 11:42:05           3 First-year\n 5 2/6/2025 11:42:46           3 Senior    \n 6 2/6/2025 11:43:28           3 Senior    \n 7 2/6/2025 11:44:41           3 First-year\n 8 2/6/2025 11:44:49           3 First-year\n 9 2/6/2025 11:44:51           2 Sophomore \n10 2/6/2025 11:44:51           3 Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/08-data-types-classes.html#but-coerce-when-plotting",
    "href": "slides/08-data-types-classes.html#but-coerce-when-plotting",
    "title": "Data types and classes",
    "section": "But coerce when plotting",
    "text": "But coerce when plotting\n\nggplot(survey, mapping = aes(x = year)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/08-data-types-classes.html#use-forcats-to-reorder-levels",
    "href": "slides/08-data-types-classes.html#use-forcats-to-reorder-levels",
    "title": "Data types and classes",
    "section": "Use forcats to reorder levels",
    "text": "Use forcats to reorder levels\n\nsurvey |&gt;\n  mutate(\n    year = fct_relevel(year, \"First-year\", \"Sophomore\", \"Junior\", \"Senior\")\n  ) |&gt;\n  ggplot(mapping = aes(x = year)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/08-data-types-classes.html#a-peek-into-forcats",
    "href": "slides/08-data-types-classes.html#a-peek-into-forcats",
    "title": "Data types and classes",
    "section": "A peek into forcats",
    "text": "A peek into forcats\nReordering levels by:\n\nfct_relevel(): hand\nfct_infreq(): frequency\nfct_reorder(): sorting along another variable\nfct_rev(): reversing\n\n…\n\nChanging level values by:\n\nfct_lump(): lumping uncommon levels together into “other”\nfct_other(): manually replacing some levels with “other”\n\n…"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 199 Introduction to Data Science and Statistical Thinking",
    "section": "",
    "text": "Below is a prospective outline for the course. Due dates are firm, but topics may change with advanced notice.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWEEK\nDATE\nPREPARE\nTOPIC\nMATERIALS\nDUE\n\n\n\n0\nWed, Jan 8\n\nLab 0: Hello, World!\nlab 0\nLab 0 @ End of Lab\n\n\n\nThu, Jan 9\n\nWelcome!\nslides 00\n\n\n\n1\nMon, Jan 13\n\nLab 1\nlab 1\n\n\n\n\nTue, Jan 14\n📗 r4ds - intro  📘 ims - chp 1  🎥 Meet the toolkit :: R and RStudio  🎥 Meet the toolkit :: Quarto  🎥 Code along :: First data viz with UN Votes\n\nMeet the Toolkit\nslides 01\n\n\n\n\nThu, Jan 16\n📗 r4ds - chp 1  📘 ims - chp 4  🎥 Visualizing data  🎥 Building a plot step-by-step with ggplot2  🎥 Grammar of graphics  🎥 Code along :: First look at Palmer Penguins\n\nData Vizualization\nslides 02\n\n\n\n2\nMon, Jan 20\n\nMLK Day - No Lab\n\n\n\n\n\nTue, Jan 21\n📗 r4ds - chp 2  📗 r4ds - chp 3.1-3.5  🎥 Grammar of data transformation  🎥 Code along :: Flights and pipes\n\nData Transformation\n\nslides 03 ae 02\n\n\n\n\n\nWed, Jan 22\n\n\n\nLab 1 @ 11:59 PM\n\n\n\nThu, Jan 23\n📗 r4ds - chp 3.6-3.7  🎥 Visualizing and summarizing categorical data  🎥 Visualizing and summarizing numerical data  🎥 Visualizing and summarizing relationships  🎥 Code along :: Star Wars characters\n\nData Exploration 1\n\nslides 04 ae 03\n\n\n\n\n3\nMon, Jan 27\n📗 r4ds - chp 4\n\nLab 2\nlab 2\n\n\n\n\nTue, Jan 28\n📘 ims - chp 5  📘 ims - chp 6  🎥 Code along :: Diving deeper with Palmer Penguins\n\nData Exploration 2\n\nslides 05 ae 04\n\n\n\n\n\nThu, Jan 30\n🎥 Tidy data  🎥 Tidying data  🎥 Code along :: Country populations over time  📗 r4ds - chp 5\n\nTidying data\n\nslides 06 ae 05\n\n\n\n\n4\nMon, Feb 3\n\nLab 3\nlab 3\nLab 2 @ 8:30AM\n\n\n\nTue, Feb 4\n🎥 Joining data  🎥 Code along :: Continent populations  📗 r4ds - chp 19.1-19.3\n\nJoining data\n\nslides 07 ae 06\n\n\n\n\n\nThu, Feb 6\n🎥 Data types  🎥 Data classes  🎥 Code along :: That’s my type  📗 r4ds - chp 16\n\nData types and classes\n\nslides 08 ae 07\n\n\n\n\n5\nMon, Feb 10\n\nLab 4\n\nlab 4 slides\n\nLab 3 @ 8:30AM\n\n\n\nTue, Feb 11\n🎥 Importing data  🎥 Code along :: Halving CO2 emissions  🎥 Code along :: Student survey  📗 r4ds - chp 7  📗 r4ds - chp 17.1 - 17.3\n\nImporting and recoding data\nslides 09\n\n\n\n\nThu, Feb 13\n\nMore practice\n\nslides 10 ae 08\n\n\n\n\n6\nMon, Feb 17\n\nExam Review\n\nLab 4 @ 8:30AM\n\n\n\nTue, Feb 18\n📕 mdsr - chp 8  📝 How to make a racist AI in R without really trying  🎥 Alberto Cairo - How charts lie  🎥 Joy Buolamwini - How I’m fighting bias in algorithms\n\nData science ethics\nslides 11\n\n\n\n\nThu, Feb 20\n\nSnow Day - No Class\n\n\n\n\n7\nMon, Feb 24\n\nMilestone 1\n\nslides project milestone 1\n\nTakehome 1 @ 8:30AM\n\n\n\nTue, Feb 25\n\nBatch A of practice problems Batch B of practice problems Kahoot\n\nMidterm 1\n\n\n\n\n\nThu, Feb 27\n🎥 The language of models  📘 ims - chp 7.1\n\nThe language of models\n\nslides 12 ae 9\n\n\n\n\nFri, Feb 28\n\n\n\nPeer evaluation 1 due by 5:00 pm\n\n\n8\nMon, Mar 3\n\nMilestone 2\nproject milestone 1\n\n\n\n\nTue, Mar 4\n🎥 Fitting and interpreting models  🎥 Modeling nonlinear relationships  📘 ims - chp 7.2\n\nSimple linear regression\n\nslides 13  ae 10\n\n\n\n\nThu, Mar 6\n🎥 Models with multiple predictors  🎥 More models with multiple predictors  📘 ims - chp 8.1-8.2\n\nMultiple linear regression 1\nslides 14  ae 11\n\n\n\n\nFri, Mar 7\n\n\n\nMilestone 2 @ 5PM\n\n\n9\nMon, Mar 10\n\nSpring Break - No Lab\n\n\n\n\n\nTue, Mar 11\n\nSpring Break - No Lecture\n\n\n\n\n\nThu, Mar 13\n\nSpring Break - No Lecture\n\n\n\n\n10\nMon, Mar 17\n\nLab 5\n\n\n\n\n\nTue, Mar 18\n\nMultiple linear regression 2\n\n\n\n\n\nThu, Mar 20\n\nModel selection\n\n\n\n\n\nFri, Mar 21\n\n\n\nPeer evaluation 2 due by 5:00 pm\n\n\n11\nMon, Mar 24\n\nLab 6\n\nLab 5 @ 8:30AM\n\n\n\nTue, Mar 25\n\nLogistic regression 1\n\n\n\n\n\nThu, Mar 27\n\nLogistic regression 2\n\n\n\n\n12\nMon, Mar 31\n\nLab 7\n\nLab 6 @ 8:30AM\n\n\n\nTue, Apr 1\n\nIntervals\n\n\n\n\n\nThu, Apr 3\n\nIntervals/Testing\n\n\n\n\n\nFri, Apr 4\n\n\n\nMilestone 3 @ 5PM\n\n\n13\nMon, Apr 7\n\nExam Review\n\nLab 7 @ 8:30AM\n\n\n\nTue, Apr 8\n\nTesting\n\n\n\n\n\nThu, Apr 10\n\nMidterm 2\n\n\n\n\n\nFri, Apr 11\n\n\n\nPeer evaluation 3 due by 5:00 pm\n\n\n14\nMon, Apr 14\n\nMilestone 4\n\nTakehome 2 @ 8:30AM  Milestone 4 @ End of Lab\n\n\n\nTue, Apr 15\n\nInference Overview\n\n\n\n\n\nThu, Apr 17\n\nCommunication, Quarto\n\n\n\n\n15\nMon, Apr 21\n\nMilestone 5\n\n\n\n\n\nTue, Apr 22\n\nFarewell!\n\n\n\n\n\nWed, Apr 23\n\n\n\nMilestone 5 @ 5PM\n\n\n16\nMon, Apr 28\n\nfinals week - no lab\n\nPeer evaluation 4 due by 5:00 pm\n\n\n\nTue, Apr 29\nsee…everything above\nFinal (9AM - 12PM)",
    "crumbs": [
      "Syllabus",
      "Schedule"
    ]
  },
  {
    "objectID": "lab/lab-0.html",
    "href": "lab/lab-0.html",
    "title": "Lab 0",
    "section": "",
    "text": "This lab will walk you through setting up the course technology, which consists of the following:\nVersion control software like Git and GitHub is indispensable in modern data science practice, and learning how to use it is one of the things that distinguishes STA 199 from a similar course like STA 101. At a minimum, version control helps prevent your files from looking like this:\nWe’ve all been there, but it’s time to kick the habit.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#access-r-and-rstudio",
    "href": "lab/lab-0.html#access-r-and-rstudio",
    "title": "Lab 0",
    "section": "1. Access R and RStudio",
    "text": "1. Access R and RStudio\nInstead of asking you to download any new programs onto your computer, we host everything pre-packaged for you in the cloud. You just have to login through your web browser, and you’re ready to go:\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 to log into the Docker container. You should now see the RStudio environment.\n\nGo to https://cmgr.oit.duke.edu/containers and under Reservations available click on reserve STA 198-199 to reserve a container for yourself.\n\n\n\n\n\n\nNote\n\n\n\nA container is a self-contained instance of RStudio for you, and you alone. You will do all of your computing in your container.\n\n\nOnce you’ve reserved the container you’ll see that it will show up under My reservations.\nTo launch your container click on it under My reservations, then click Login, and then Start.1\n\n\n\n\n\n\nWarning\n\n\n\nPlease double and triple check that you have reserved the STA 198-199 container and not some other. The various containers differ in the software they include, so if you reserve something else, you may be missing something we need.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#create-a-github-account",
    "href": "lab/lab-0.html#create-a-github-account",
    "title": "Lab 0",
    "section": "2. Create a GitHub account",
    "text": "2. Create a GitHub account\nGo to https://github.com/ and walk through the steps for creating an account. You do not have to use your Duke email address, but I recommend doing so.2\n\n\n\n\n\n\nNote\n\n\n\nYou’ll need to choose a user name. I recommend reviewing the user name advice at https://happygitwithr.com/github-acct#username-advice before choosing a username.\n\n\n\n\n\n\n\n\nWhat if I already have a GitHub account?\n\n\n\n\n\nIf you already have a GitHub account, you do not need to create a new one for this course. Just log in to that account to make sure you still remember your username and password. If you are unsure of your login credentials, carefully follow GitHub’s instructions for recovering this information. If you accumulate too many failed login attempts, you will be locked out of your account for the day, which will make it difficult for you to complete the rest of this lab.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#set-up-your-ssh-key",
    "href": "lab/lab-0.html#set-up-your-ssh-key",
    "title": "Lab 0",
    "section": "3. Set up your SSH key",
    "text": "3. Set up your SSH key\nYou will authenticate GitHub using SSH (Secure Shell Protocol – it doesn’t really matter what this means for the purpose of this course). Below is an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nGo back to your RStudio container and type credentials::ssh_setup_github() into your console.\nR will ask “No SSH key found. Generate one now?” You should click 1 for yes.\nYou will generate a key. R will then ask “Would you like to open a browser now?” You should click 1 for yes.\nYou may be asked to provide your GitHub username and password to log into GitHub. After entering this information, you should paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta199).\n\nYou can find more detailed instructions here if you’re interested.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#configure-git-to-introduce-yourself",
    "href": "lab/lab-0.html#configure-git-to-introduce-yourself",
    "title": "Lab 0",
    "section": "4. Configure Git to introduce yourself",
    "text": "4. Configure Git to introduce yourself\nNext, you need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\n\n\n\n\n\n\nNote\n\n\n\nYou’ll hear about 📦 packages a lot in the context of R – basically they’re how developers write functions and bundle them to distribute to the community (and more on this later too!).\n\n\nType the following lines of code in the console in RStudio filling in your name and the address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\"\n)\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"John Zito\", \n  user.email = \"johnczito@gmail.com\"\n)\n\nI used my gmail because that is the one I used to create my GitHub account. You should also be using the email address you used to create your GitHub account, it’s ok if it isn’t your Duke email.\n\n\n\n\n\n\nHow do I know if I did it right?\n\n\n\n\n\nWhen you input the usethis::use_git_config(...) command into the console and hit enter/return, it will appear as if nothing happened. To verify that everything worked, you can briefly switch over to the Terminal tab (should be to the right of Console) and type the commands git config user.name and git config user.email. If all is well, these will return whatever text you originally provided. If you notice a mistake or typo, you can just go back to the Console and rerun usethis::use_git_config(...) with modified inputs.\n\n\n\n\n\n\n\n\n\nNeed a recap? Watch this video!\n\n\n\n\n\nThe following video walks you through the steps outlined in the SSH key generation and Git configuration sections above.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#babys-first-repo",
    "href": "lab/lab-0.html#babys-first-repo",
    "title": "Lab 0",
    "section": "5. Baby’s first repo",
    "text": "5. Baby’s first repo\nA GitHub repository (repo) is a collection of files hosted on GitHub. Repos are the main way we will distribute files to you during the semester. When you copy the files in a repo to your local computing environment (your container, in this case), that’s called “cloning”. So, let’s clone our first repo:\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo hello-world.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\n\nYou will need to get used to these steps, because you’ll probably clone at least one new repo every week.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#hello-sta-199",
    "href": "lab/lab-0.html#hello-sta-199",
    "title": "Lab 0",
    "section": "6. Hello STA 199!",
    "text": "6. Hello STA 199!\nFill out the course “Getting to know you” survey on Canvas: https://canvas.duke.edu/courses/50057/quizzes/30406.\nWe will use the information collected in this survey for a variety of goals, from inviting you to the course GitHub organization (more on that later) to getting to know you as a person and your course goals and concerns.",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-0.html#footnotes",
    "href": "lab/lab-0.html#footnotes",
    "title": "Lab 0",
    "section": "Footnotes",
    "text": "Footnotes\n\nYes, it’s too many steps. I don’t know why! But it works, and you’ll get used to it. Trust me, it beats downloading and installing everything you need on your computers!↩︎\nGitHub has some perks for students you can take advantage of later in the course or in your future work, and it helps to have a .edu address to get verified as a student.↩︎",
    "crumbs": [
      "Labs",
      "Lab 0"
    ]
  },
  {
    "objectID": "lab/lab-3.html",
    "href": "lab/lab-3.html",
    "title": "Lab 3",
    "section": "",
    "text": "This lab gives you more practice with data wrangling and data pipelines, with an emphasis on mastering the subtleties of group_by, as well as introducing pivoting to the mix.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you have not yet done those, you should go back and review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nBe able to pivot/reshape data using tidyr\n\nContinue developing your data wrangling skills using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-3 repo from GitHub, open your lab-3.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#learning-objectives",
    "href": "lab/lab-3.html#learning-objectives",
    "title": "Lab 3",
    "section": "",
    "text": "By the end of the lab, you will…\n\nBe able to pivot/reshape data using tidyr\n\nContinue developing your data wrangling skills using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#getting-started",
    "href": "lab/lab-3.html#getting-started",
    "title": "Lab 3",
    "section": "",
    "text": "Log in to RStudio, clone your lab-3 repo from GitHub, open your lab-3.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-3. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-3.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-3.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#packages",
    "href": "lab/lab-3.html#packages",
    "title": "Lab 3",
    "section": "",
    "text": "In this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#guidelines",
    "href": "lab/lab-3.html#guidelines",
    "title": "Lab 3",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#part-1",
    "href": "lab/lab-3.html#part-1",
    "title": "Lab 3",
    "section": "Part 1",
    "text": "Part 1\nAll about group_by()!\nUse the following data frame for Question 1 and Question 2:\n\ndf &lt;- tibble(\n  var_1 = c(50, 20, 70, 10, 100, 30, 40, 80, 120, 60, 90, 110),\n  var_2 = c(\"Pizza\", \"Burger\", \"Pizza\", \"Pizza\", \"Burger\", \"Burger\",\n            \"Burger\", \"Pizza\", \"Burger\", \"Pizza\", \"Pizza\", \"Burger\"),\n  var_3 = c(\"Apple\", \"Apple\", \"Pear\", \"Banana\", \"Pear\", \"Banana\",\n            \"Apple\", \"Apple\", \"Pear\", \"Pear\", \"Banana\", \"Banana\")\n)\n\ndf\n\n# A tibble: 12 × 3\n   var_1 var_2  var_3 \n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; \n 1    50 Pizza  Apple \n 2    20 Burger Apple \n 3    70 Pizza  Pear  \n 4    10 Pizza  Banana\n 5   100 Burger Pear  \n 6    30 Burger Banana\n 7    40 Burger Apple \n 8    80 Pizza  Apple \n 9   120 Burger Pear  \n10    60 Pizza  Pear  \n11    90 Pizza  Banana\n12   110 Burger Banana\n\n\nQuestion 1\nGrouping by a single variable.\na. What does the following code chunk do? Run it, analyze the result, and articulate in words what arrange() does.\n\ndf |&gt;\n  arrange(var_2)\n\nb. What does the following code chunk do? Run it, analyze the result, and articulate in words what group_by() does. Also, comment on how it’s different from the arrange() in part (b).\n\ndf |&gt;\n  group_by(var_2)\n\nc. What does the following code chunk do? Run it, analyze the result, and articulate in words what the pipeline does.\n\ndf |&gt;\n  group_by(var_2) |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\nd. Compare this behavior to the following code chunk. Run it, analyze the result, and articulate in words what the pipeline does, and how it’s behavior is different from part (c).\n\ndf |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\nQuestion 2\nGrouping by two variables.\na. How many levels does var_2 have? How many levels does var_3 have? How many possible combinations are there of the levels of var_2 and var_3?\nb. Write some code that uses basic arithmetic operations to manually compute the average value of var_1 among all the rows that have Burger-Apple. Do the same thing for the rows that have Burger-Banana.\nc. You’re probably sick of that, right? What does the following code chunk do? Run it, analyze the result, and articulate in words what the pipeline does and how it compared to part (b). Then, comment on what the message says.\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1))\n\nd. What does the following code chunk do? Run it, analyze the result, and articulate in words what the pipeline does, especially mentioning what the .groups argument does. How is the output different from the one in part (c)?\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1), .groups = \"drop\")\n\ne. What do the following pipelines do? Run both, analyze their results, and articulate in words what each pipeline does. How are the outputs of the two pipelines different?\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  summarize(mean_var_1 = mean(var_1), .groups = \"drop\")\n\ndf |&gt;\n  group_by(var_2, var_3) |&gt;\n  mutate(mean_var_1 = mean(var_1))\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answers for Questions 1 and 2”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#part-2",
    "href": "lab/lab-3.html#part-2",
    "title": "Lab 3",
    "section": "Part 2",
    "text": "Part 2\nInflation across the world\nFor this part of the analysis you will work with inflation data from various countries in the world over the last 30 years.\n\ncountry_inflation &lt;- read_csv(\"data/country-inflation.csv\")\n\nQuestion 3\nGet to know the data.\n\nglimpse() at the country_inflation data frame and answer the following questions based on the output. How many rows does country_inflation have and what does each row represent? How many columns does country_inflation have and what does each column represent?\nDisplay a list of the unique countries included in the dataset. Hint: Another word for “unique” is distinct().\n\n\n\n\n\n\n\nTip\n\n\n\nA function that can be useful for part (b) is pull(). Check out its documentation for examples of usage.\n\n\nQuestion 4\nWhich countries had the top three highest inflation rates in 2023? Your output should be a data frame with two columns, country and 2023, with inflation rates in descending order, and three rows for the top three countries. Briefly comment on how the inflation rates for these countries compare to the inflation rate for United States in that year.\n\n\n\n\n\n\nTips\n\n\n\n\nYou might find the command slice_head helpful here.\nColumn names that are numbers are not considered “proper” in R, therefore to select them you’ll need to surround them with backticks, e.g. select( ` 1993 ` ).\n\n\n\nQuestion 5\nIn a single pipeline,\n\ncalculate the ratio of the inflation in 2023 and inflation in 1993 for each country and store this information in a new column called inf_ratio,\nselect the variables country and inf_ratio, and\nstore the result in a new data frame called country_inflation_ratios.\n\nThen, in two separate pipelines,\n\narrange country_inflation_ratios in increasing order of inf_ratio and\narrange country_inflation_ratios in decreasing order of inf_ratio.\n\nWhich country’s inflation increase is the largest over this time period and by how much? Which country’s inflation decrease is the largest over this time period and by how much?\n\n\n\n\n\n\nTip\n\n\n\nFor this question you’ll once again need to use variables whose names are numbers (years) in your pipeline. Make sure to surround the names of such variables with backticks (`).\n\n\nQuestion 6\nReshape (pivot) country_inflation such that each row represents a country/year combination, with columns country, year, and annual_inflation. Then, display the resulting data frame and state how many rows and columns it has.\nRequirements:\n\nYour code must use one of pivot_longer() or pivot_wider(). There are other ways you can do this reshaping move in R, but this question requires solving this problem by pivoting.\nIn your pivot_*() function, you must use names_transform = as.numeric as an argument to transform the variable type to numeric as you pivot the data so that in the resulting data frame the year variable is numeric.\nThe resulting data frame must be saved as something other than country_inflation so you (1) can refer to this data frame later in your analysis and (2) do not overwrite country_inflation. Use a short but informative name.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe remaining questions require the use of the pivoted data frame.\n\n\n\nIf you haven’t yet done so, now is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n\nQuestion 7\nUse a separate, single pipeline to answer each of the following questions.\nRequirement: Your code must use the filter() function for each part, not arrange().\n\nWhat is the highest inflation rate observed between 1993 and 2023? The output of the pipeline should be a data frame with one row and three columns. In addition to code and output, your response should include a single sentence stating the country and year.\nWhat is the lowest inflation rate observed between 1993 and 2023? The output of the pipeline should be a data frame with one row and three columns. In addition to code and output, your response should include a single sentence stating the country and year.\nPutting (a) and (b) together: What are the highest and the lowest inflation rates observed between 1993 and 2023? The output of the pipeline should be a data frame with two rows and three columns.\nQuestion 8\na. Create a vector called countries_of_interest which contains the names of up to five countries you want to visualize the inflation rates for over the years. For example, if these countries are Türkiye and United States, you can express this as follows:\n\ncountries_of_interest &lt;- c(\"Türkiye\", \"United States\")\n\nIf they are Türkiye, United States, and Chile, you can express this as follows:\n\ncountries_of_interest &lt;- c(\n  \"Türkiye\", \"United States\", \"Chile\"\n)\n\nSo on and so forth… Then, in 1-2 sentences, state why you chose these countries.\n\n\n\n\n\n\nNote\n\n\n\nYour countries_of_interest should consist of no more than five countries. Make sure that the spelling of your countries matches how they appear in the dataset.\n\n\nb. In a single pipeline, filter your reshaped dataset to include only the countries_of_interest from part (a), and save the resulting data frame with a new name so you (1) can refer to this data frame later in your analysis and (2) do not overwrite the data frame you’re starting with. Use a short but informative name. Then, in a new pipeline, find the distinct() countries in the data frame you created.\n\n\n\n\n\n\nTip\n\n\n\nThe number of distinct countries in the filtered data frame you created in part (b) should equal the number of countries you chose in part (a). If it doesn’t, you might have misspelled a country name or made a mistake in filtering for these countries. Go back and correct your work.\n\n\nQuestion 9\nUsing your data frame from the previous question, create a plot of annual inflation vs. year for these countries. Then, in a few sentences, describe the patterns you observe in the plot, particularly focusing on anything you find surprising or not surprising, based on your knowledge (or lack thereof) of these countries economies.\nRequirements for the plot:\n\nData should be represented with points as well as lines connecting the points for each country.\nEach country should be represented by a different color line and different color and shape points.\nAxes and legend should be properly labeled.\nThe plot should have an appropriate title (and optionally a subtitle).\nPlot should be customized in at least one way – you could use a different than default color scale, or different than default theme, or some other customization.\n\n\nNow is another good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#submission",
    "href": "lab/lab-3.html#submission",
    "title": "Lab 3",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered “on time”.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "lab/lab-3.html#grading-and-feedback",
    "href": "lab/lab-3.html#grading-and-feedback",
    "title": "Lab 3",
    "section": "Grading and feedback",
    "text": "Grading and feedback\n\nSome of the questions will be graded for accuracy.\nSome will be graded for completion.\n\nThere are also workflow points:\n\nfor coding style;\nfor committing at least three times as you work through your lab;\nfor pushing your final rendered PDF into your lab repo before the deadline (in addition to uploading it to Gradescope);\nfor overall organization.\n\n\nYou’ll receive feedback on your lab on Gradescope within a week.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html",
    "href": "ae/ae-07-durham-climate-factors.html",
    "title": "AE 07: Durham climate + factors",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html#getting-started",
    "href": "ae/ae-07-durham-climate-factors.html#getting-started",
    "title": "AE 07: Durham climate + factors",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe will use the tidyverse package in this application exercise.\n\nlibrary(tidyverse)\n\nData\nThe data come from https://www.usclimatedata.com/climate/durham/north-carolina/united-states/usnc0192 and are stored as durham-climate.csv in the data folder.\n\ndurham_climate &lt;- read_csv(\"data/durham-climate.csv\")\n\nAnd let’s take a look at the data.\n\ndurham_climate\n\n# A tibble: 12 × 4\n   month     avg_high_f avg_low_f precipitation_in\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n 1 January           49        28             4.45\n 2 February          53        29             3.7 \n 3 March             62        37             4.69\n 4 April             71        46             3.43\n 5 May               79        56             4.61\n 6 June              85        65             4.02\n 7 July              89        70             3.94\n 8 August            87        68             4.37\n 9 September         81        60             4.37\n10 October           71        47             3.7 \n11 November          62        37             3.39\n12 December          53        30             3.43"
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html#reorder",
    "href": "ae/ae-07-durham-climate-factors.html#reorder",
    "title": "AE 07: Durham climate + factors",
    "section": "Reorder",
    "text": "Reorder\nWhat’s wrong with the following plot?\nMonths are out of order.\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 2,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  )\n\n\n\n\n\n\n\nFix the plot.\n\ndurham_climate &lt;- durham_climate |&gt;\n  mutate(month = fct_relevel(month, month.name))\n\nggplot(\n  durham_climate,\n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 2,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  )"
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html#recode-and-reorder",
    "href": "ae/ae-07-durham-climate-factors.html#recode-and-reorder",
    "title": "AE 07: Durham climate + factors",
    "section": "Recode and reorder",
    "text": "Recode and reorder\nUpdate the plot above, coloring points based on season. Additionally:\n\nMake sure the legend is on top of the plot and the seasons appear in the legend in the order they appear in the plot (Winter, Spring, Summer, Fall).\n\nUse \"circle filled\" as the shape for points, set their size to 3 points, outline (stroke) to 1 point, and fill them in with the following colors:\n\nWinter: lightskyblue1\n\nSpring: chartreuse3\n\nSummer: gold2\n\nFall: lightsalmon4\n\n\n\n\n\ndurham_climate &lt;- durham_climate |&gt;\n  mutate(\n    season = case_when(\n      month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      month %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n      month %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n      month %in% c(\"September\", \"October\", \"November\") ~ \"Fall\",\n    ),\n    season = fct_relevel(season, \"Winter\", \"Spring\", \"Summer\", \"Fall\")\n  )\n\nggplot(\n  durham_climate,\n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 3, stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\",\n    fill = \"Season\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "ae/ae-07-durham-climate-factors.html#pivot",
    "href": "ae/ae-07-durham-climate-factors.html#pivot",
    "title": "AE 07: Durham climate + factors",
    "section": "Pivot",
    "text": "Pivot\nOverlay lines for both high and low temperatures on the same plot. Additionally, use different colors for the two lines – a darker color for high and a lighter color for low temperatures.\n\ndurham_climate |&gt;\n  pivot_longer(\n    cols = c(avg_high_f, avg_low_f),\n    names_to = \"temp_type\",\n    names_prefix = \"avg_\",\n    values_to = \"avg_temp_f\"\n  ) |&gt;\n  mutate(temp_type = str_remove(temp_type, \"_f\")) |&gt;\n  ggplot(aes(x = month, y = avg_temp_f, group = temp_type, color = temp_type)) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 3, stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) +\n  scale_color_manual(\n    values = c(\n      \"high\" = \"gray20\",\n      \"low\" = \"gray70\"\n    )\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average temperature (F)\",\n    title = \"Durham climate\",\n    fill = \"Season\",\n    color = \"Type\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html",
    "href": "ae/ae-05-majors-tidy.html",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html#getting-started",
    "href": "ae/ae-05-majors-tidy.html#getting-started",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are available in the data folder.\n\nstatsci &lt;- read_csv(\"data/statsci.csv\")\n\nRows: 4 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): degree\ndbl (14): 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAnd let’s take a look at the data.\n\nstatsci\n\n# A tibble: 4 × 15\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statist…     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist…      2      2      4      1      3      6      3      4      4      1\n3 Statist…      2      6      1     NA      5      6      6      8      8     17\n4 Statist…      5      9      4     13     10     17     24     21     26     27\n# ℹ 4 more variables: `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;, `2024` &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html#pivoting",
    "href": "ae/ae-05-majors-tidy.html#pivoting",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "Pivoting",
    "text": "Pivoting\nPivot the statsci data frame longer such that\n\neach row represents a degree type / year combination,\n\nyear and number of graduates for that year are columns,\n\nyear is numerical,\n\nNAs in counts are replaced with 0s,\n\ndegree_type has levels BS, BS2, AB, and AB2 (in this order), and\nthe resulting data frame is saved as statsci_longer.\n\nReview the code below with your neighbor and come up with at least one question about the code.\n\nstatsci_longer &lt;- statsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n  )\n\nstatsci_longer\n\n# A tibble: 56 × 4\n   major               degree_type  year     n\n   &lt;chr&gt;               &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science AB2          2011     0\n 2 Statistical Science AB2          2012     1\n 3 Statistical Science AB2          2013     0\n 4 Statistical Science AB2          2014     0\n 5 Statistical Science AB2          2015     4\n 6 Statistical Science AB2          2016     4\n 7 Statistical Science AB2          2017     1\n 8 Statistical Science AB2          2018     0\n 9 Statistical Science AB2          2019     0\n10 Statistical Science AB2          2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html#plotting",
    "href": "ae/ae-05-majors-tidy.html#plotting",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "Plotting",
    "text": "Plotting\nStep 1: Basics\nLet’s start with a basic plot, nothing too fancy! Create a line plot of number of majors vs. year, where lines are colored by degree type, and the data are also represented as points on the lines.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line()\n\n\n\n\n\n\n\nWhat aspects of the plot need to be updated to go from the draft you created above to the goal plot from the slides.\n\nx-axis scale: need to go from 2012 to 2024 in increments of 2 years\nline colors\naxis labels: title, subtitle, x, y, caption\ntheme\nlegend position and border\nStep 2: Scales\nUpdate x-axis scale such that the years displayed go from 2012 to 2024 in increments of 2 years. Do this by adding on to your ggplot call from earlier.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2))\n\n\n\n\n\n\n\nStep 3: Colors\nUpdate line colors using the following level / color assignments. Once again, do this by adding on to your ggplot call from earlier.\n\n“BS” = “cadetblue4”\n“BS2” = “cadetblue3”\n“AB” = “lightgoldenrod4”\n“AB2” = “lightgoldenrod3”\n\nNote: A handy reference for named colors in R is http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf, though you can use HEX color codes as well.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  )\n\n\n\n\n\n\n\nStep 4: Labels and themes\nUpdate the plot labels (title, subtitle, x, y, and caption) and use theme_minimal(). Once again, do this by adding on to your ggplot call from earlier. Note: The link in the caption is https://registrar.duke.edu/registration/enrollment-statistics.\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nStep 5: Legends and figure sizing via cell options\nFinally, adding to your pipeline you’ve developed so far, move the legend into the plot, make its background white, and its border gray. Additionally, in the cell options, set\n\n\nout-width: 100% – Output should span 100% of the width\n\nfig-width: 8 – Figure output should have a width of 8 inches\n\nfig-asp: 0.5 – Figure output should have an aspect ratio of 0.5, resulting in a height of 8 * 0.5 = 4 inches\n\n\nggplot(statsci_longer, aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2012, 2024, 2)) +\n  scale_color_manual(\n    values = c(\n      \"BS\" = \"cadetblue4\",\n      \"BS2\" = \"cadetblue3\",\n      \"AB\" = \"lightgoldenrod4\",\n      \"AB2\" = \"lightgoldenrod3\"\n    )\n  ) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2024\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(0.1, 0.7),\n    legend.background = element_rect(fill = \"white\", color = \"gray\")\n  )"
  },
  {
    "objectID": "ae/ae-05-majors-tidy.html#render-commit-and-push",
    "href": "ae/ae-05-majors-tidy.html#render-commit-and-push",
    "title": "AE 05: StatSci majors + data tidying",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-06-taxes-join.html",
    "href": "ae/ae-06-taxes-join.html",
    "title": "AE 06: Sales taxes + data joining",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#getting-started",
    "href": "ae/ae-06-taxes-join.html#getting-started",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are available in the data folder:\n\nsales-taxes.csv\nus-regions.csv\n\n\nsales_taxes &lt;- read_csv(\"data/sales-taxes.csv\")\nus_regions &lt;- read_csv(\"data/us-regions.csv\")\n\nAnd let’s take a look at the data.\n\nglimpse(sales_taxes)\n\nRows: 51\nColumns: 5\n$ state              &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"Califo…\n$ state_tax_rate     &lt;dbl&gt; 0.0400, 0.0000, 0.0560, 0.0650, 0.0725, 0.0290, 0.0…\n$ avg_local_tax_rate &lt;dbl&gt; 0.0529, 0.0182, 0.0278, 0.0295, 0.0160, 0.0491, 0.0…\n$ combined_rate      &lt;dbl&gt; 0.0929, 0.0182, 0.0838, 0.0945, 0.0885, 0.0781, 0.0…\n$ max_local_tax_rate &lt;dbl&gt; 0.0750, 0.0785, 0.0530, 0.0613, 0.0475, 0.0830, 0.0…\n\nglimpse(us_regions)\n\nRows: 50\nColumns: 2\n$ state_name &lt;chr&gt; \"Maine\", \"New Hampshire\", \"Vermont\", \"Massachusetts\", \"Rhod…\n$ region     &lt;chr&gt; \"Northeast\", \"Northeast\", \"Northeast\", \"Northeast\", \"Northe…"
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#sales-tax-in-swing-states-if_else",
    "href": "ae/ae-06-taxes-join.html#sales-tax-in-swing-states-if_else",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Sales tax in swing states: if_else\n",
    "text": "Sales tax in swing states: if_else\n\nCreate new swing_state variable using if_else:\n\nlist_of_swing_states &lt;- c(\"Arizona\", \"Georgia\", \"Michigan\", \"Nevada\", \n                          \"North Carolina\", \"Pennsylvania\", \"Wisconsin\")\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    swing_state = if_else(state %in% list_of_swing_states,\n                          \"Swing\",\n                          \"Non-swing\")) |&gt;\n  relocate(swing_state)\n\nsales_taxes\n\n# A tibble: 51 × 6\n   swing_state state       state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;       &lt;chr&gt;                &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Non-swing   Alabama             0.04               0.0529        0.0929\n 2 Non-swing   Alaska              0                  0.0182        0.0182\n 3 Swing       Arizona             0.056              0.0278        0.0838\n 4 Non-swing   Arkansas            0.065              0.0295        0.0945\n 5 Non-swing   California          0.0725             0.016         0.0885\n 6 Non-swing   Colorado            0.029              0.0491        0.0781\n 7 Non-swing   Connecticut         0.0635             0             0.0635\n 8 Non-swing   Delaware            0                  0             0     \n 9 Non-swing   Florida             0.06               0.01          0.07  \n10 Swing       Georgia             0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;\n\n\nSummarize to find the mean sales tax in each type of state:\n\nsales_taxes |&gt;\n  group_by(swing_state) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 2 × 2\n  swing_state mean_state_tax\n  &lt;chr&gt;                &lt;dbl&gt;\n1 Non-swing           0.0504\n2 Swing               0.0546"
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#sales-tax-in-coastal-states-case_when",
    "href": "ae/ae-06-taxes-join.html#sales-tax-in-coastal-states-case_when",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Sales tax in coastal states: case_when\n",
    "text": "Sales tax in coastal states: case_when\n\nCreate new coast variable using case_when:\n\npacific_coast &lt;- c(\"Alaska\", \"Washington\", \"Oregon\", \"California\", \"Hawaii\")\n\natlantic_coast &lt;- c(\n  \"Connecticut\", \"Delaware\", \"Georgia\", \"Florida\", \"Maine\", \"Maryland\", \n  \"Massachusetts\", \"New Hampshire\", \"New Jersey\", \"New York\", \n  \"North Carolina\", \"Rhode Island\", \"South Carolina\", \"Virginia\"\n)\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    coast = case_when(\n      state %in% pacific_coast ~ \"Pacific\",\n      state %in% atlantic_coast ~ \"Atlantic\",\n      .default = \"Neither\"\n    )\n  ) |&gt;\n  relocate(coast)\n\nsales_taxes\n\n# A tibble: 51 × 7\n   coast    swing_state state    state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Neither  Non-swing   Alabama          0.04               0.0529        0.0929\n 2 Pacific  Non-swing   Alaska           0                  0.0182        0.0182\n 3 Neither  Swing       Arizona          0.056              0.0278        0.0838\n 4 Neither  Non-swing   Arkansas         0.065              0.0295        0.0945\n 5 Pacific  Non-swing   Califor…         0.0725             0.016         0.0885\n 6 Neither  Non-swing   Colorado         0.029              0.0491        0.0781\n 7 Atlantic Non-swing   Connect…         0.0635             0             0.0635\n 8 Atlantic Non-swing   Delaware         0                  0             0     \n 9 Atlantic Non-swing   Florida          0.06               0.01          0.07  \n10 Atlantic Swing       Georgia          0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;\n\n\nSummarize to find the mean sales tax in each type of state:\n\nsales_taxes |&gt;\n  group_by(coast) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 3 × 2\n  coast    mean_state_tax\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Atlantic         0.0484\n2 Neither          0.0545\n3 Pacific          0.0355"
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#sales-tax-in-us-regions-joining",
    "href": "ae/ae-06-taxes-join.html#sales-tax-in-us-regions-joining",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Sales tax in US regions: joining",
    "text": "Sales tax in US regions: joining\nJoin the sales tax data with region data and save the joined data frame as a new data frame, not overwriting either data frame that goes into the join.\n\nsales_taxes_regions &lt;- sales_taxes |&gt;\n  full_join(us_regions, \n            by = join_by(state == state_name)) |&gt;\n  relocate(region)\n\nsales_taxes_regions\n\n# A tibble: 51 × 8\n   region    coast    swing_state state       state_tax_rate avg_local_tax_rate\n   &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;                &lt;dbl&gt;              &lt;dbl&gt;\n 1 South     Neither  Non-swing   Alabama             0.04               0.0529\n 2 West      Pacific  Non-swing   Alaska              0                  0.0182\n 3 West      Neither  Swing       Arizona             0.056              0.0278\n 4 South     Neither  Non-swing   Arkansas            0.065              0.0295\n 5 West      Pacific  Non-swing   California          0.0725             0.016 \n 6 West      Neither  Non-swing   Colorado            0.029              0.0491\n 7 Northeast Atlantic Non-swing   Connecticut         0.0635             0     \n 8 South     Atlantic Non-swing   Delaware            0                  0     \n 9 South     Atlantic Non-swing   Florida             0.06               0.01  \n10 South     Atlantic Swing       Georgia             0.04               0.0338\n# ℹ 41 more rows\n# ℹ 2 more variables: combined_rate &lt;dbl&gt;, max_local_tax_rate &lt;dbl&gt;\n\n\nCalculate the average sales tax of states in each region. What is surprising in the output?\n\nsales_taxes_regions |&gt;\n  group_by(region) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 5 × 2\n  region    mean_state_tax\n  &lt;chr&gt;              &lt;dbl&gt;\n1 Midwest           0.0569\n2 Northeast         0.0530\n3 South             0.0523\n4 West              0.0416\n5 &lt;NA&gt;              0.06  \n\n\nIdentify the state with NA for region.\n\nsales_taxes_regions |&gt;\n  filter(is.na(region)) |&gt;\n  select(state)\n\n# A tibble: 1 × 1\n  state               \n  &lt;chr&gt;               \n1 District of Columbia\n\n\nApply a fix for the NA in region, and calculate the mean sales taxes for regions again. Display the results in ascending order of mean sales tax.\n\nsales_taxes_regions |&gt;\n  mutate(\n    region = if_else(state == \"District of Columbia\", \"Northeast\", region)\n  ) |&gt;\n  group_by(region) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 4 × 2\n  region    mean_state_tax\n  &lt;chr&gt;              &lt;dbl&gt;\n1 Midwest           0.0569\n2 Northeast         0.0537\n3 South             0.0523\n4 West              0.0416"
  },
  {
    "objectID": "ae/ae-06-taxes-join.html#render-commit-and-push",
    "href": "ae/ae-06-taxes-join.html#render-commit-and-push",
    "title": "AE 06: Sales taxes + data joining",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html",
    "href": "ae/ae-03-gerrymander-explore-I.html",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html#getting-started",
    "href": "ae/ae-03-gerrymander-explore-I.html#getting-started",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\n\nData\nThe data are available in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…\n\n\nSince this dataset is shipped with a package, it has documentation that you can access via ?gerrymander. The flip18 variable is categorical with three levels:\n\n-1: control of the district flipped from Democrats to Republicans between 2016 and 2018;\n0: the district did not flip. If Democrats controlled it in 2016, they kept it in 2018. If Republicans controlled it in 2016, they kept it in 2018;\n1: control of the district flipped from Republicans to Democrats between 2016 and 2018."
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html#districts-at-the-tails",
    "href": "ae/ae-03-gerrymander-explore-I.html#districts-at-the-tails",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "Districts at the tails",
    "text": "Districts at the tails\nMake side-by-side box plots of percent of vote received by Trump in 2016 Presidential Election by prevalence of gerrymandering. Identify any Congressional Districts that are potential outliers. Are they different from the rest of the Congressional Districts due to high support or low support for Trump in the 2016 Presidential Election? Which state are they in? Which city are they in?\n\nggplot(gerrymander, aes(x = trump16, y = gerry)) +\n  geom_boxplot() + \n  labs(\n    x = \"% vote for Trump in 2016\",\n    y = \"Extent of gerrymandering in district\"\n  )\n\n\n\n\n\n\n\nThe outliers are:\n\ngerrymander |&gt;\n  filter(gerry == \"low\" & trump16 &lt; 10)\n\n# A tibble: 2 × 12\n  district last_name first_name party16 clinton16 trump16 dem16 state party18\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n1 NY-13    Espaillat Adriano    D            92.3     5.4     1 NY    D      \n2 NY-15    Serrano   Jose       D            93.8     4.9     1 NY    D      \n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html#flips",
    "href": "ae/ae-03-gerrymander-explore-I.html#flips",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "Flips",
    "text": "Flips\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\n\n\n\n\nHint\n\n\n\nCalculate the conditional distribution of prevalance of gerrymandering based on whether a Democrat was able to flip the seat in the 2018 election.\n\n\nThis code gives you a bar chart counting how many districts fall into each level of flip18, and then divides each bar according to the prevalence of gerrymandering in the districts:\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar()\n\n\n\n\n\n\n\nHowever, because the total number of counts is different in the three groups, it’s hard to directly compare the information about gerrmandering. So, this code normalizes each bar so that you can compare by eye:\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nThis code gives you the raw numbers that underpin the plot:\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132\n\n\nBased on this information, which party would you say benefited from gerrymandering more in the 2018 midterms?"
  },
  {
    "objectID": "ae/ae-03-gerrymander-explore-I.html#render-commit-and-push",
    "href": "ae/ae-03-gerrymander-explore-I.html#render-commit-and-push",
    "title": "AE 03: Gerrymandering + data exploration I",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html",
    "href": "ae/ae-04-gerrymander-explore-II.html",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#getting-started",
    "href": "ae/ae-04-gerrymander-explore-II.html#getting-started",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\nlibrary(usdata)\nlibrary(ggbeeswarm)\n\nData\nThe data are availale in the usdata package.\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#congressional-districts-per-state",
    "href": "ae/ae-04-gerrymander-explore-II.html#congressional-districts-per-state",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Congressional districts per state",
    "text": "Congressional districts per state\nWhich state has the most congressional districts? How many congressional districts are there in this state?\n\ngerrymander |&gt;\n  count(state, sort = TRUE)\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 CA       53\n 2 TX       36\n 3 FL       27\n 4 NY       27\n 5 IL       18\n 6 PA       18\n 7 OH       16\n 8 GA       14\n 9 MI       14\n10 NC       13\n# ℹ 40 more rows"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#gerrymandering-and-flipping",
    "href": "ae/ae-04-gerrymander-explore-II.html#gerrymandering-and-flipping",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Gerrymandering and flipping",
    "text": "Gerrymandering and flipping\nIs a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering? Support your answer with a visualization and summary statistics.\n\ngerrymander |&gt;\n  mutate(flip18 = as.factor(flip18)) |&gt;\n  ggplot(aes(x = gerry, fill = flip18)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\ngerrymander |&gt;\n  count(gerry, flip18) |&gt;\n  group_by(gerry) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   gerry [3]\n  gerry flip18     n      p\n  &lt;fct&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1 low       -1     2 0.0323\n2 low        0    52 0.839 \n3 low        1     8 0.129 \n4 mid       -1     3 0.0111\n5 mid        0   242 0.896 \n6 mid        1    25 0.0926\n7 high       0    98 0.951 \n8 high       1     5 0.0485"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#aesthetic-mappings",
    "href": "ae/ae-04-gerrymander-explore-II.html#aesthetic-mappings",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Aesthetic mappings",
    "text": "Aesthetic mappings\nRecreate the following visualization, and then improve it.\n\n\nggplot(gerrymander, aes(x = gerry, y = clinton16)) +\n  geom_beeswarm(color = \"gray50\", alpha = 0.5) +\n  geom_boxplot(aes(color = gerry), alpha = 0.5) +\n  theme_minimal()"
  },
  {
    "objectID": "ae/ae-04-gerrymander-explore-II.html#render-commit-and-push",
    "href": "ae/ae-04-gerrymander-explore-II.html#render-commit-and-push",
    "title": "AE 04: Gerrymandering + data exploration II",
    "section": "Render, commit, and push",
    "text": "Render, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html",
    "href": "ae/ae-02-bechdel-dataviz.html",
    "title": "AE 02: Bechdel + data visualization",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key.\nIn this mini-analysis, we use the data from the FiveThirtyEight story “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women.”\nThis analysis is about the Bechdel test, a measure of the representation of women in fiction."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#getting-started",
    "href": "ae/ae-02-bechdel-dataviz.html#getting-started",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe’ll use the tidyverse package for this analysis.\n\nlibrary(tidyverse)\n\nData\nThe data are stored as a CSV (comma-separated values) file in your repository’s data folder. Let’s read it from there and save it as an object called bechdel.\n\nbechdel &lt;- read_csv(\"data/bechdel.csv\")\n\nGet to know the data\nWe can use the glimpse() function to get an overview (or “glimpse”) of the data.\n\nglimpse(bechdel)\n\nRows: 1,615\nColumns: 7\n$ title       &lt;chr&gt; \"21 & Over\", \"Dredd 3D\", \"12 Years a Slave\", \"2 Guns\", \"42…\n$ year        &lt;dbl&gt; 2013, 2012, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n$ gross_2013  &lt;dbl&gt; 67878146, 55078343, 211714070, 208105475, 190040426, 18416…\n$ budget_2013 &lt;dbl&gt; 13000000, 45658735, 20000000, 61000000, 40000000, 22500000…\n$ roi         &lt;dbl&gt; 5.221396, 1.206305, 10.585703, 3.411565, 4.751011, 0.81851…\n$ binary      &lt;chr&gt; \"FAIL\", \"PASS\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"FAIL\", \"P…\n$ clean_test  &lt;chr&gt; \"notalk\", \"ok\", \"notalk\", \"notalk\", \"men\", \"men\", \"notalk\"…\n\n\n\nWhat does each observation (row) in the data set represent?\n\nEach observation represents a movie.\n\nHow many observations (rows) are in the data set?\n\nThere are 1615 movies in the dataset.\n\nHow many variables (columns) are in the data set?\n\nThere are 7 columns in the dataset.\nVariables of interest\nThe variables we’ll focus on are the following:\n\n\nroi: Return on investment, calculated as the ratio of the gross to budget.\n\nclean_test: Bechdel test result:\n\n\nok = passes test\ndubious\n\nmen = women only talk about men\n\nnotalk = women don’t talk to each other\n\nnowomen = fewer than two women\n\n\n\nbinary: Bechdel Test PASS vs FAIL binary\n\nWe will also use the year of release in data prep and title of movie to take a deeper look at some outliers.\nThere are a few other variables in the dataset, but we won’t be using them in this analysis."
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#film-finances",
    "href": "ae/ae-02-bechdel-dataviz.html#film-finances",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Film finances",
    "text": "Film finances\nThis code visualizes the distribution of film budgets in the dataset:\n\nggplot(bechdel, aes(x = budget_2013)) + \n  geom_histogram() + \n  labs(x = \"2013 USD\",\n       title = \"Film budgets (1990 - 2013)\")\n\n\n\n\n\n\n\nThis distribution is right-skewed, and unimodal. We can get a sense of the center and spread with the following summary statistics:\n\nbechdel |&gt;\n  summarise(\n    mean = mean(budget_2013),\n    median = median(budget_2013),\n    sd = sd(budget_2013),\n    iqr = IQR(budget_2013)\n  )\n\n# A tibble: 1 × 4\n       mean   median        sd      iqr\n      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 57035015. 37878971 55976978. 67848653\n\n\nA scatterplot visualizes the relationship between a film’s budget and its earnings:\n\nggplot(bechdel, aes(x = budget_2013, y = gross_2013)) + \n  geom_point() + \n  geom_smooth() + \n  labs(x = \"Budget (2013 USD)\",\n       y = \"Gross (2013 USD)\",\n       title = \"Film finances (1990 - 2013)\")\n\n\n\n\n\n\n\nThe relationship is positive, fairly linear (the curve in the trend seems due mostly to the effect of the two outliers), and moderately strong.\nThe two films with especially high grosses are:\n\nbechdel |&gt; \n  filter(gross_2013 &gt; 3e9)\n\n# A tibble: 2 × 7\n  title    year gross_2013 budget_2013   roi binary clean_test\n  &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 Avatar   2009 3848295959   461435929  8.34 FAIL   men       \n2 Titanic  1997 4127821329   290247625 14.2  PASS   ok"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#bechdel-test-results",
    "href": "ae/ae-02-bechdel-dataviz.html#bechdel-test-results",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Bechdel test results",
    "text": "Bechdel test results\nVisualizing data with ggplot2\n\nggplot2 is the package and ggplot() is the function in this package that is used to create a plot.\n\n\nggplot() creates the initial base coordinate system, and we will add layers to that base. We first specify the data set we will use with data = bechdel.\n\n\nggplot(data = bechdel)\n\n\n\n\n\n\n\n\nThe mapping argument is paired with an aesthetic (aes()), which tells us how the variables in our data set should be mapped to the visual properties of the graph.\n\n\nggplot(data = bechdel, mapping = aes(x = clean_test))\n\n\n\n\n\n\n\nAs we previously mentioned, we often omit the names of the first two arguments in R functions. So you’ll often see this written as:\n\nggplot(bechdel, aes(x = clean_test))\n\n\n\n\n\n\n\nNote that the result is exactly the same.\n\nThe geom_xx function specifies the type of plot we want to use to represent the data. In the code below, we use geom_point which creates a plot where each observation is represented by a point.\n\n\nggplot(bechdel, aes(x = clean_test)) +\n  geom_bar()\n\n\n\n\n\n\n\nWhat types of movies are more common, those that pass or do not pass the test?\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-02-bechdel-dataviz.html#return-on-investment",
    "href": "ae/ae-02-bechdel-dataviz.html#return-on-investment",
    "title": "AE 02: Bechdel + data visualization",
    "section": "Return-on-investment",
    "text": "Return-on-investment\nLet’s take a look at return-on-investment (ROI) for movies that do and do not pass the Bechdel test.\nStep 1 - Your turn\nCreate side-by-side box plots of roi by clean_test where the boxes are colored by binary.\n\nggplot(bechdel, aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n  )\n\nWarning: Removed 15 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nWhat are those movies with very high returns on investment?\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n# A tibble: 3 × 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen   \n\n\nStep 2 - Demo\nExpand on your plot from the previous step to zoom in on movies with roi &lt; ___ to get a better view of how the medians across the categories compare.\n\nggplot(bechdel, aes(x = clean_test, y = roi, color = binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Return on investment vs. Bechdel test result\",\n    x = \"Detailed Bechdel result\",\n    y = \"Return-on-investment (gross / budget)\",\n    color = \"Bechdel\\nresult\"\n  ) +\n  coord_cartesian(ylim = c(0, 16))\n\nWarning: Removed 15 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nWhat does this plot say about return-on-investment on movies that pass the Bechdel test?\nRender, commit, and push\n\nRender your Quarto document.\nGo to the Git pane and check the box next to each file listed, i.e., stage your changes. Commit your staged changes using a simple and informative message.\nClick on push (the green arrow) to push your changes to your application exercise repo on GitHub.\nGo to your repo on GitHub and confirm that you can see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-01-meet-the-penguins.html",
    "href": "ae/ae-01-meet-the-penguins.html",
    "title": "AE 01: Meet the penguins",
    "section": "",
    "text": "For this application exercise, we’ll use the tidyverse and palmerpenguins packages.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\n\nThe dataset we will visualize is called penguins. Let’s glimpse() at it.\n\n\nYour turn: Replace #add code here with the code for “glimpse”ing at the data penguins data frame – glimpse(penguins). Render the document and view the output.\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\n\n\nDemo: First, replace the blank below with the number of rows in the penguins data frame based on the output of the chunk below. Then, replace it with “inline code” and render again.\n\n\nnrow(penguins)\n\n[1] 344\n\n\nThere are 344 penguins in the penguins data frame."
  },
  {
    "objectID": "ae/ae-08-age-gaps-sales-import.html",
    "href": "ae/ae-08-age-gaps-sales-import.html",
    "title": "AE 08: Age gaps + sales + import",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers. This document should be used as a reference only; it’s not designed to be an exhaustive key."
  },
  {
    "objectID": "ae/ae-08-age-gaps-sales-import.html#getting-started",
    "href": "ae/ae-08-age-gaps-sales-import.html#getting-started",
    "title": "AE 08: Age gaps + sales + import",
    "section": "Getting started",
    "text": "Getting started\nPackages\nWe will use the following two packages in this application exercise.\n\n\ntidyverse: For data import, wrangling, and visualization.\n\nreadxl: For importing data from Excel.\n\n\nlibrary(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "ae/ae-08-age-gaps-sales-import.html#part-1-hollywood-relationships",
    "href": "ae/ae-08-age-gaps-sales-import.html#part-1-hollywood-relationships",
    "title": "AE 08: Age gaps + sales + import",
    "section": "Part 1: Hollywood relationships",
    "text": "Part 1: Hollywood relationships\nLoad the data from age-gaps.csv in your data and assign it to age_gaps. Confirm that this new object appears in your Environment tab. Click on the name of the object in your Environment tab to pop open the data in the data viewer.\n\nage_gaps &lt;- read_csv(\"data/age-gaps.csv\")\n\nRows: 1155 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): movie_name, director, actor_1_name, actor_2_name, character_1_gend...\ndbl  (5): release_year, age_difference, couple_number, actor_1_age, actor_2_age\ndate (2): actor_1_birthdate, actor_2_birthdate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCreate a subset of the data frame for heterosexual relationships on screen.\n\nage_gaps_heterosexual &lt;- age_gaps |&gt;\n  filter(character_1_gender != character_2_gender)\n\nSplit the data for heterosexual relationships into three – where woman is older, where man is older, where they are the same age. Save these subsets as two appropriately named data frames. Remember: Use concise and evocative names. Confirm that these new objects appear in your Environment tab and that the sum of the number of observations in the two new data frames add to the number of observations in the original data frame.\n\nage_gaps_heterosexual &lt;- age_gaps_heterosexual |&gt;\n  mutate(\n    older = case_when(\n      character_1_gender == \"woman\" & actor_1_age &gt; actor_2_age ~ \"woman older\",\n      character_2_gender == \"woman\" & actor_2_age &gt; actor_1_age ~ \"woman older\",\n      character_1_gender == \"man\"   & actor_1_age &gt; actor_2_age ~ \"man older\",\n      character_2_gender == \"man\"   & actor_2_age &gt; actor_1_age ~ \"man older\",\n      actor_1_age == actor_2_age ~ \"same age\"\n    )\n  )\n\nwoman_older &lt;- age_gaps_heterosexual |&gt; filter(older == \"woman older\")\nman_older   &lt;- age_gaps_heterosexual |&gt; filter(older == \"man older\")\nsame_age    &lt;- age_gaps_heterosexual |&gt; filter(older == \"same age\")\n\n(nrow(woman_older) + nrow(man_older) + nrow(same_age)) == nrow(age_gaps_heterosexual)\n\n[1] TRUE\n\n\nWrite out the three new datasets you created into the data folder:\n\nwrite_csv(woman_older, file = \"data/woman-older.csv\")\nwrite_csv(man_older, file = \"data/man-older.csv\")\nwrite_csv(same_age, file = \"data/same-age.csv\")"
  },
  {
    "objectID": "ae/ae-08-age-gaps-sales-import.html#part-2-sales",
    "href": "ae/ae-08-age-gaps-sales-import.html#part-2-sales",
    "title": "AE 08: Age gaps + sales + import",
    "section": "Part 2: Sales",
    "text": "Part 2: Sales\nSales data are stored in an Excel file that looks like the following:\n\nRead in the Excel file called sales.xlsx from the data-raw/ folder such that it looks like the following.\n\n\nsales_raw &lt;- read_excel(\n  \"data/sales.xlsx\", \n  skip = 3,\n  col_names = c(\"id\", \"n\")\n  )\n\nStretch goal: Manipulate the sales data such such that it looks like the following.\n\n\nsales &lt;- sales_raw |&gt;\n  mutate(\n    is_brand_name = str_detect(id, \"Brand\"),\n    brand = if_else(is_brand_name, id, NA)\n  ) |&gt;\n  fill(brand) |&gt;\n  filter(!is_brand_name) |&gt;\n  select(brand, id, n)\n\nsales\n\n# A tibble: 7 × 3\n  brand   id    n    \n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;\n1 Brand 1 1234  8    \n2 Brand 1 8721  2    \n3 Brand 1 1822  3    \n4 Brand 2 3333  1    \n5 Brand 2 2156  3    \n6 Brand 2 3987  6    \n7 Brand 2 3216  5    \n\n\nWhy should we bother with writing code for reading the data in by skipping columns and assigning variable names as well as cleaning it up in multiple steps instead of opening the Excel file and editing the data in there to prepare it for a clean import?\nBecause the code allows us to struggle once and re-use for future datasets and leaves a transparent trail of our modifications while manipulating the data in Excel directly is neither reproducible nor reusable."
  },
  {
    "objectID": "lab/lab-2.html",
    "href": "lab/lab-2.html",
    "title": "Lab 2",
    "section": "",
    "text": "In this lab, you’ll continue to hone your data science workflow and integrate what you learned so far in the course (data visualization) with what’s coming up (data wrangling).\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed Lab 0 and Lab 1 and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review them before starting with this one.\n\n\n\nBy the end of the lab, you will…\n\nBe able to create transform data using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH (this might already be selected by default; if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-2.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-2.qmd, update the author field to your name, render your document, and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository and, in your browser, confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\nImportant\n\n\n\nIf you encounter any issues with the above steps, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the tidyverse package, a collection of packages for performing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in the lecture, your plots should include an informative title, axes and legends should have human-readable labels and aesthetic choices should be carefully considered.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nAs you complete the lab and other assignments in this course, remember to develop a sound workflow for reproducible data analysis. This assignment will periodically remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#learning-objectives",
    "href": "lab/lab-2.html#learning-objectives",
    "title": "Lab 2",
    "section": "",
    "text": "By the end of the lab, you will…\n\nBe able to create transform data using dplyr\n\nBuild on your mastery of data visualizations using ggplot2\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#getting-started",
    "href": "lab/lab-2.html#getting-started",
    "title": "Lab 2",
    "section": "",
    "text": "Go to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-2. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH (this might already be selected by default; if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-2.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-2.qmd, update the author field to your name, render your document, and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository and, in your browser, confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\nImportant\n\n\n\nIf you encounter any issues with the above steps, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#packages",
    "href": "lab/lab-2.html#packages",
    "title": "Lab 2",
    "section": "",
    "text": "In this lab, we will work with the tidyverse package, a collection of packages for performing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#guidelines",
    "href": "lab/lab-2.html#guidelines",
    "title": "Lab 2",
    "section": "",
    "text": "As we’ve discussed in the lecture, your plots should include an informative title, axes and legends should have human-readable labels and aesthetic choices should be carefully considered.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nAs you complete the lab and other assignments in this course, remember to develop a sound workflow for reproducible data analysis. This assignment will periodically remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-1",
    "href": "lab/lab-2.html#question-1",
    "title": "Lab 2",
    "section": "Question 1",
    "text": "Question 1\nDo some states have counties that tend to be geographically larger than others?\nTo explore this question, create side-by-side boxplots of area (area) of a county based on state (state). How do typical county area sizes compare across states? How do variabilities of county sizes compare across states? Which state has the single largest county? Identify the name of this county. You can use the data viewer to identify it interactively, you do not have to write code.\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nOnce again, make sure to commit and push all changed files so that your Git pane is empty afterwards.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-2",
    "href": "lab/lab-2.html#question-2",
    "title": "Lab 2",
    "section": "Question 2",
    "text": "Question 2\nDo some states have a higher percentage of their counties located in a metropolitan area?\nCreate a segmented bar chart with one bar per state and the bar filled with colors according to the value of metro – one color indicating Yes and the other color indicating No for whether a county is considered to be a metro area. The y-axis of the segmented barplot should range from 0 to 1, indicating proportions. Compare the percentage of counties in metro areas across the states based on this plot. Make sure to supplement your narrative with rough estimates of these percentages.\n\n\n\n\n\n\nHint\n\n\n\nFor this question, you should begin with the data wrangling pipeline below. We will learn more about data wrangling in the coming weeks, so this is a mini-preview. This pipeline creates a new variable called metro based on the value of the existing variable called inmetro. If the value of inmetro is equal to 1 (inmetro == 1), it sets the value of metro to \"Yes\", and if not, it sets the value of metro to \"No\". The resulting data frame is assigned back to midwest, overwriting the existing midwest data frame with a version that includes the new metro variable.\n\nmidwest &lt;- midwest |&gt;\n  mutate(metro = if_else(inmetro == 1, \"Yes\", \"No\"))\n\n\n\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nAnd once again, make sure to commit and push all changed files so that your Git pane is empty afterward. We keep repeating this because it’s important and because we see students forget to do this. So take a moment to make sure you’re following along with the version control instructions.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-3",
    "href": "lab/lab-2.html#question-3",
    "title": "Lab 2",
    "section": "Question 3",
    "text": "Question 3\nCalculate the number of counties in each state and display your results in descending order of number of counties. Which state has the highest number of counties, and how many? Which state has the lowest number, and how many?\n\n\n\n\n\n\nNote\n\n\n\nThe number of counties in a state can change over time, so the values you see in this output may not be true today.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 3”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-4",
    "href": "lab/lab-2.html#question-4",
    "title": "Lab 2",
    "section": "Question 4",
    "text": "Question 4\nWhile two counties in a given state can’t have the same name, some county names might be shared across states. A classmate says “Look at that, there is a county called ___ in each state in this dataset!” In a single pipeline, discover all counties that could fill in the blanks. Your response should be a data frame with only the county names that could fill in the blank and the number of times they appear in the data.\n\n\n\n\n\n\nTip\n\n\n\nYou will want to use the filter() function in your answer, which requires a logical condition to describe what you want to filter for. For example, filter(x &gt; 2) means filter for values of x greater than 2, and filter(y &lt;= 3) means filter for values of y less than or equal to 3.\nThe table below is a summary of logical operators and how to articulate them in R.\n\n\noperator\ndefinition\n\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to\n\n\nx & y\n\nx AND y\n\n\n\n\nx | y\n\n\nx OR y\n\n\n\nis.na(x)\ntest if x is NA\n\n\n\n!is.na(x)\ntest if x is not NA\n\n\n\nx %in% y\ntest if x is in y\n\n\n\n!(x %in% y)\ntest if x is not in y\n\n\n\n!x\nnot x\n\n\n\n\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 4”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-5",
    "href": "lab/lab-2.html#question-5",
    "title": "Lab 2",
    "section": "Question 5",
    "text": "Question 5\nReturn to the following box plot of population densities where you were asked to identify at least one outlier.\n\n\n\n\n\n\n\n\nIn this question, we want you to revisit this box plot and identify the counties described in each section.\na. The counties with a population density higher than 25,000. Your code must use the filter() function.\nb. The county with the highest population density. Your code must use the max() function.\nAnswer using a single data wrangling pipeline for each part. Your response should be a data frame with five columns: county name, state name, population density, total population, and area, in this order. If your response has multiple rows, the data frame should be arranged in descending order of population density.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 5”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-6",
    "href": "lab/lab-2.html#question-6",
    "title": "Lab 2",
    "section": "Question 6",
    "text": "Question 6\nIn Lab 1 you were also asked to describe the distribution of population densities. The following is one acceptable description that touches on the shape, center, and spread of this distribution. Calculate the values that should go into the blanks.\n\nThe distribution of population density of counties is unimodal and extremely right-skewed. A typical Midwestern county has population density of ____ people per unit area. The middle 50% of the counties have population densities between ___ to ___ people per unit area.\n\n\n\n\n\n\n\nTip\n\n\n\nThink about which measures of center and spread are appropriate for skewed distributions.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 6”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-7",
    "href": "lab/lab-2.html#question-7",
    "title": "Lab 2",
    "section": "Question 7",
    "text": "Question 7\nThis is the plot we ask for in Question 2:\n\n\n\n\n\n\n\n\nUse a single data pipeline to calculate the proportions that underlie this plot.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 7”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-8",
    "href": "lab/lab-2.html#question-8",
    "title": "Lab 2",
    "section": "Question 8",
    "text": "Question 8\nReturn to the following scatter plot of percentage below poverty vs. percentage of people with a college degree, where the color and shape of points are determined by state where you were asked to identify at least one county that is a clear outlier by name.\n\n\n\n\n\n\n\n\na. In a single pipeline, identify the observations marked in the orange square in the upper left corner. Your answer should be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nb. In a single pipeline, identify the observations marked in the red square in the plot above. Your answer should again be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nc. Bring your answers from part (a) and part (b) together! In a single pipeline, and a single filter() statement, identify the observations marked in the red and orange square in the plot above. Your answer should again be a data frame with four variables: county, state, percentage below poverty, and percentage college educated.\nd. Create a new variable in midwest called potential_outlier. This variable should take on the value:\n\nYes if the point is one the ones you identified in part (c), i.e., one of the points marked in the squares in the plot above.\nNo otherwise.\n\nThen, display the updated midwest data frame, with county, state, percentage below poverty, percentage college educated, potential_outlier as the selected variables, arranged in descending order of potential_outlier.\ne. Recreate the visualization above, i.e., a scatterplot of the percentage below poverty vs. the percentage of people with a college degree. However, color the points by the newly created potential_outlier variable instead of the state.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 8”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-9",
    "href": "lab/lab-2.html#question-9",
    "title": "Lab 2",
    "section": "Question 9",
    "text": "Question 9\na. In a single pipeline, calculate the total population for each state and save the resulting data frame as state_population. Then, display the data frame, state_population, in descending order of total population.\nb. Then, in a separate pipeline, calculate the proportion of the total population in each state. Once again, display the results in descending order of proportion of population.\n\n\n\n\n\n\nTip\n\n\n\nIn answering parts (a) and (b), you’ll create two new variables, one for the total population and the other for the proportion of total proportion. Make sure to give them “reasonable” names – short but evocative.\n\n\nc. Which Midwestern state is most populous, and what percent of the Midwest population lives there? Which is the least populous and what percent lives there?\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 9”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#question-10",
    "href": "lab/lab-2.html#question-10",
    "title": "Lab 2",
    "section": "Question 10",
    "text": "Question 10\nCalculate the average percentage below poverty for each state and save the resulting data frame as state_poverty with the columns state and mean_percbelowpoverty.\nThen, in a new pipeline, display the state_poverty data frame in ascending order of mean_percbelowpoverty. Which state has the lowest average percentage below poverty across its counties? Which state has the highest average percentage below poverty across its counties?\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 10”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#submission",
    "href": "lab/lab-2.html#submission",
    "title": "Lab 2",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nTo be considered ” on time, ” you must turn in a PDF file to the Gradescope page by the submission deadline.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with each question. All the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#grading-and-feedback",
    "href": "lab/lab-2.html#grading-and-feedback",
    "title": "Lab 2",
    "section": "Grading and feedback",
    "text": "Grading and feedback\n\nSome of the questions will be graded for accuracy.\nSome will be graded for completion.\n\nThere are also workflow points:\n\nfor coding style;\nfor committing at least three times as you work through your lab;\nfor pushing your final rendered PDF into your lab repo before the deadline (in addition to uploading it to Gradescope);\nfor overall organization.\n\n\nYou’ll receive feedback on your lab on Gradescope within a week.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-2.html#footnotes",
    "href": "lab/lab-2.html#footnotes",
    "title": "Lab 2",
    "section": "Footnotes",
    "text": "Footnotes\n\nRemember, haikus, not novellas, when writing code!↩︎",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "lab/lab-1.html",
    "href": "lab/lab-1.html",
    "title": "Lab 1",
    "section": "",
    "text": "This lab will introduce you to the course computing workflow. The main goal is to reinforce our demo of R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\n\n\n\n\n\n\nNote\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface, commonly referred to as an integrated development environment or an IDE, for short.\n\n\nAn additional goal is to reinforce Git and GitHub, the version control, web hosting, and collaboration systems that we will be using throughout the course.\n\n\n\n\n\n\nNote\n\n\n\nGit is a version control system (like “Track Changes” features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\n\n\n\n\n\n\nWarning\n\n\n\nThis lab assumes that you have already completed Lab 0. If you have not, please\n\ngo back and do that first before proceeding and\nlet your TA know as they will need to set up a Lab 1 repository for you before you can complete this lab.\n\n\n\n\nBy the end of the lab, you will…\n\nBe familiar with the workflow using R, RStudio, Git, and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using Git and GitHub\nBe able to create data visualizations using ggplot2\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file.\n\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-1.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human-friendly data representation for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document.\nIf you get a popup window error, click “Try again”.\nExamine the rendered document and make sure your name is updated in the document.\n\n\n\nGo to the Git pane in RStudio. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. If you have rendered the document, you should also see its output, a PDF file, listed there.\n\n\nClick on it to select it in this list and then click on Diff.\nThis shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\n\n\nIf you’re happy with these changes, prepare the changes to be pushed to your remote repository.\n\nFirst, stage your changes by checking the appropriate box on the files you want to prepare.\nNext, write a meaningful commit message (for instance, “Updated author name”) in the Commit message box.\nFinally, click Commit. Note that every commit needs to have a commit message associated with it.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration (e.g., restoring a previous version of your document).\nIn the first few assignments, we will tell you exactly when to commit and, in some cases, what commit message to use. As the semester progresses, we will let you make these decisions.\n\n\n\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\n\nIn the Git pane, click on Push.\nThen, make sure all the changes went to GitHub. Go to your GitHub repo in your browser and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub, and you’re good to go!\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you don’t see your update, go back to Step 4. Remember that in order to push your changes to GitHub, you must have staged (checked boxes) your commit (with a commit message) to be pushed and then click on Push.\n\n\n\nIn this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.\n\n\nThe tidyverse is a meta-package. When you load it you get nine packages loaded for you:\n\n\ndplyr: for data wrangling\n\nforcats: for dealing with factors\n\nggplot2: for data visualization\n\nlubridate: for dealing with dates\n\npurrr: for iteration with functional programming\n\nreadr: for reading and writing data\n\nstringr: for string manipulation\n\ntibble: for modern, tidy data frames\n\ntidyr: for data tidying and rectangling\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#learning-objectives",
    "href": "lab/lab-1.html#learning-objectives",
    "title": "Lab 1",
    "section": "",
    "text": "By the end of the lab, you will…\n\nBe familiar with the workflow using R, RStudio, Git, and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using Git and GitHub\nBe able to create data visualizations using ggplot2",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#getting-started",
    "href": "lab/lab-1.html#getting-started",
    "title": "Lab 1",
    "section": "",
    "text": "Go to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file.\n\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-1. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-1.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human-friendly data representation for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document.\nIf you get a popup window error, click “Try again”.\nExamine the rendered document and make sure your name is updated in the document.\n\n\n\nGo to the Git pane in RStudio. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. If you have rendered the document, you should also see its output, a PDF file, listed there.\n\n\nClick on it to select it in this list and then click on Diff.\nThis shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\n\n\nIf you’re happy with these changes, prepare the changes to be pushed to your remote repository.\n\nFirst, stage your changes by checking the appropriate box on the files you want to prepare.\nNext, write a meaningful commit message (for instance, “Updated author name”) in the Commit message box.\nFinally, click Commit. Note that every commit needs to have a commit message associated with it.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration (e.g., restoring a previous version of your document).\nIn the first few assignments, we will tell you exactly when to commit and, in some cases, what commit message to use. As the semester progresses, we will let you make these decisions.\n\n\n\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\n\nIn the Git pane, click on Push.\nThen, make sure all the changes went to GitHub. Go to your GitHub repo in your browser and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub, and you’re good to go!\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you don’t see your update, go back to Step 4. Remember that in order to push your changes to GitHub, you must have staged (checked boxes) your commit (with a commit message) to be pushed and then click on Push.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#packages",
    "href": "lab/lab-1.html#packages",
    "title": "Lab 1",
    "section": "",
    "text": "In this lab we will work with the tidyverse package, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package to make its features (the functions and datasets in it) be accessible from your Console.\nThen, render the document which loads this package to make its features (the functions and datasets in it) be available for other code cells in your Quarto document.\n\n\nThe tidyverse is a meta-package. When you load it you get nine packages loaded for you:\n\n\ndplyr: for data wrangling\n\nforcats: for dealing with factors\n\nggplot2: for data visualization\n\nlubridate: for dealing with dates\n\npurrr: for iteration with functional programming\n\nreadr: for reading and writing data\n\nstringr: for string manipulation\n\ntibble: for modern, tidy data frames\n\ntidyr: for data tidying and rectangling",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#guidelines",
    "href": "lab/lab-1.html#guidelines",
    "title": "Lab 1",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.1\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub.\n\n\n\n\n\n\nImportant\n\n\n\nYou should have at least 3 commits with meaningful commit messages by the end of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#part-1---lets-take-a-trip-to-the-midwest",
    "href": "lab/lab-1.html#part-1---lets-take-a-trip-to-the-midwest",
    "title": "Lab 1",
    "section": "Part 1 - Let’s take a trip to the Midwest!",
    "text": "Part 1 - Let’s take a trip to the Midwest!\nWe will use the midwest data frame for this lab. It is part of the ggplot2 R package, so the midwest data set is automatically loaded when you load the tidyverse package.\nThe data contains demographic characteristics of counties in the Midwest region of the United States.\nBecause the data set is part of the ggplot2 package, you can read documentation for the data set, including variable definitions by typing ?midwest in the Console or searching for midwest in the Help pane.\nQuestion 1\nVisualize the distribution of population density of counties using a histogram with geom_histogram() with four separate binwidths: a binwidth of 100, a binwidth of 1,000, a binwidth of 10,000, and a binwidth of 100,000. For example, you can create the first plot with:\n\nggplot(midwest, aes(x = popdensity)) +\n  geom_histogram(binwidth = 100) +\n  labs(\n    x = \"Population density\",\n    y = \"Count\",\n    title = \"Population density of Midwestern counties\",\n    subtitle = \"Binwidth = 100\"\n  )\n\n\n\n\n\n\n\nYou will need to make four different histograms. Make sure to set informative titles and axis labels for each of your plots. Then, comment on which binwidth is most appropriate for these data and why.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 1”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 2\nVisualize the distribution of population density of counties again, this time using a boxplot with geom_boxplot(). Make sure to set informative titles and axis labels for your plot. Then, using information as needed from the box plot as well as the histogram from Question 1, describe the distribution of population density of counties and comment on any potential outliers, making sure to identify at least one county that is a clear outlier by name in your narrative and commenting on whether it makes sense to you that this county is an outlier. You can use the data viewer to identify the outliers interactively, you do not have to write code to identify them.\n\n\n\n\n\n\nImportant\n\n\n\nIn describing a distribution, make sure to mention shape, center, spread, and any unusual observations.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 2”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 3\nUse geom_point to create a scatterplot of the percentage below poverty (percbelowpoverty on the y-axis) versus percentage of people with a college degree (percollege on the x-axis), where the color and shape of points are determined by state. Make sure to set informative titles, axis, and legend labels for your plot. First, describe the overall relationship between percentage of people with a college degree and percentage below poverty in Midwestern states, making sure to identify at least one county that is a clear outlier by name in your narrative. You can use the data viewer to identify the outliers interactively, you do not have to write code to identify them. Then, comment on whether you can identify how this relationship varies across states.\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 3”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 4\nNow, let’s examine the relationship between the same two variables, once again using different colors and shapes to represent each state, and using a separate plot for each state, i.e., with faceting with facet_wrap(). In addition to points (geom_point()), represent the data with a smooth curve fit to the data with geom_smooth(), with the argument se = FALSE. Make sure to set informative titles, axis, and legend labels for your plot. Which plot do you prefer - this plot or the plot in Question 3? Briefly explain your choice.\n\n\n\n\n\n\nNote\n\n\n\nse = FALSE removes the confidence bands around the line. These bands show the uncertainty around the smooth curve. We’ll discuss uncertainty around estimates later in the course and bring these bands back then.\n\n\n\nRender, commit, and push your changes to GitHub with the commit message “Added answer for Question 4”.\nMake sure to commit and push all changed files so that your Git pane is empty afterward.\n\nQuestion 5\nRecreate the plot below, and then give it a title. Then, identify at least one county that is a clear outlier in Wisconsin (WI) by name. You can use the data viewer to identify them interactively, you do not have to write code. Comment on the population composition of this county by investigating the percentage of other races living there.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe ggplot2 reference for themes will be helpful in determining the theme.\nThe size of the points is 2.\nThe transparency (alpha) of the points is 0.5.\nYou can put line breaks in labels with \\n.\n\n\n\n\nNow is another good time to render, commit, and push your changes to GitHub with a meaningful commit message.\nAnd once again, make sure to commit and push all changed files so that your Git pane is empty afterward. We keep repeating this because it’s important and because we see students forget to do this. So take a moment to make sure you’re following along with the version control instructions.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#part-2---enough-about-the-midwest",
    "href": "lab/lab-1.html#part-2---enough-about-the-midwest",
    "title": "Lab 1",
    "section": "Part 2 - Enough about the Midwest!",
    "text": "Part 2 - Enough about the Midwest!\nIn this part we will use a new, more recent, and potentially more relevant dataset on counties in North Carolina.\nThis dataset is stored in a file called nc-county.csv in the data folder of your project/repository.\nYou can read this file into R with the following code:\n\nnc_county &lt;- read_csv(\"data/nc-county.csv\")\n\nThis will read the CSV (comma separated values) file from the data folder and store the dataset as a data frame called nc_county in R.\nThe variables in the dataset and their descriptions are as follows:\n\n\ncounty: Name of county.\n\nstate_abb: State abbreviation (NC).\n\nstate_name: State name (North Carolina).\n\nland_area_m2: Land area of county in meters-squared, based on the 2020 census.\n\nland_area_mi2: Land area of county in miles-squared, based on the 2020 census.\n\npopulation: Population of county, based on the 2020 census.\n\ndensity: Population density calculated as population divided by land area in miles-squared.\n\nIn addition to being more recent and more relevant, this dataset is also more complete in the sense that we know the units of population density: people per mile-squared!\nQuestion 6\nFirst, guess what the relationship between population density and land area might be – positive? negative? no relationship?\nThen, make a scatter plot of population density (density on the y-axis) vs. land area in miles-squared (land_area_mi2 on the x-axis). Make sure to set an informative title and axis labels for your plot. Describe the relationship. Was your guess correct?\nQuestion 7\nNow make a scatter plot of population density (density on the y-axis) vs. land area in meters-squared (land_area_m2 on the x-axis). Make sure to set an informative title and axis labels for your plot. Comment on how this scatterplot compares to the one in Exercise 6 — is the relationship displayed same or different. Explain why.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#part-3---potpourri-graded-for-a-good-faith-effort",
    "href": "lab/lab-1.html#part-3---potpourri-graded-for-a-good-faith-effort",
    "title": "Lab 1",
    "section": "Part 3 - Potpourri graded for a good faith effort",
    "text": "Part 3 - Potpourri graded for a good faith effort\nQuestion 8\nOne of the key reasons we care about data science and statistics in the first place is because they can help us make decisions under uncertainty. For example:\n\nWhen we save for retirement, we have to make a decision about what asset classes to invest in (stocks, bonds, real estate, etc) and in what proportions. We want to make the most stable and lucrative choice possible, accounting for the fact that we are uncertain about how the assets will ultimately perform. Data on past asset performance may help guide this decision;\nWhen insurance companies sell policies, they have to decide who to sell to and what sized premium to charge. They face uncertainty about how many policies will ultimately result in a claim (if it’s everyone, they’re ruined). In order to navigate this environment, they employ armies of actuaries to study historical data and help make decisions about profit, loss, and risk of ruin;\nGood barbecue cannot be made-to-order. A restaurant has to start preparing in the morning, before they know for certain how many folks will show up that day. If they prepare too little, they have to turn a lot of folks away and forfeit their money. If they prepare too much, it can go to waste. So a decision must be made under uncertainty, and it can be guided by historical data on demand, as it varies over the week and the year and during holidays and special events;\nThe manager of a presidential campaign must decide how to allocate the campaign’s resources to different states, counties, neighborhoods, types of media, etc. But these decisions are made before they know how the voters will ultimately behave, and so they try to resolve this uncertainty by analyzing all sorts of data: polling, prediction markets, social media sentiment, economic indicators, historical trends, etc.\nYou darn Duke students must decide what time you’re going to grab lunch at WU, subject to uncertainty about how long the lines will be. When you first matriculate, you might get burned a few times because you have no experience to base this decision on. By your senior year, you’ve accumulated a lot of data about the good and bad times at the different vendors, and how these vary across the days of the week and seasons of the year.\n\nYou get the idea. Now it’s your turn. Write a few paragraph describing an example from your everyday life where you have to make a decision under uncertainty (obviously, don’t recycle one of the examples above). What’s the decision? What are the sources of uncertainty? What is your decision-making process? What data, if it were available, could you consult to resolve some of this uncertainty and help you meet your objective?\n\n\n\n\n\n\nDon’t break my heart.\n\n\n\nThis is graded for completion, but JZ will read all of them. I am not interested in an example from ChatGPT’s everyday life where it has to make a decision under uncertainty. I want to know about you.\n\n\nQuestion 9\nData science is the process of turning messy, incomplete, imperfect data into knowledge, and statistics studies how we can quantify our uncertainty about that knowledge. To illustrate these ideas, we played a game on the first day of class; you were given data of various kinds about a celebrity (names vs pictures, clear pictures vs noisy ones), and you were asked to answer a simple question with a quantitative answer: how old is the person? The results of this exercise are memorialized in the lecture slides from that day, and I summarized some of the high-level lessons here.\nWrite a paragraph or two summarizing another lesson that we can learn from this game. It can be a generic, high-level lesson about the practice of data science and stats, like the ones I listed. It can be a lesson about the application itself that you took away from reviewing the substantive results. Or, you can cast your mind back to when you were guessing, and you can describe and evaluate your guessing process with the benefit of hindsight. What factors were you weighing and/or neglecting? Did you learn anything that could make you a better age-guesser in the future?\nAs you ponder this, note that you have access to the complete dataset of everyone’s guesses. Feel free to play around with it.\nQuestion 10\nDid you select your pages on Gradescope? You don’t need to write an answer for this question, if you select your pages when you upload your lab to Gradescope, you’ll get full points on this question. Otherwise, you’ll get a 0 on this question.2\nQuestion 11\nRecommend some music for us to listen to while we grade this.\n\n\n\n\n\n\nNote\n\n\n\nNot worth any points, but still important.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#submission",
    "href": "lab/lab-1.html#submission",
    "title": "Lab 1",
    "section": "Submission",
    "text": "Submission\nOnce you are finished with the lab, you will submit your final PDF document to Gradescope.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all of your documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered “on time”.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with question. All the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nChecklist\n\n\n\nMake sure you have:\n\nattempted all questions\nrendered your Quarto document\ncommitted and pushed everything to your GitHub repository such that the Git pane in RStudio is empty\nuploaded your PDF to Gradescope\nselected pages associated with each question on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#grading-and-feedback",
    "href": "lab/lab-1.html#grading-and-feedback",
    "title": "Lab 1",
    "section": "Grading and feedback",
    "text": "Grading and feedback\n\nSome of the questions will be graded for accuracy.\nSome will be graded for completion.\nQuestion 10 is just asking you to select your pages on Gradescope, and you get points for following the instructions!\nThere are also workflow points, for coding style, for committing at least three times as you work through your lab, and for overall organization.\nYou’ll receive feedback on your lab on Gradescope within a week.\n\nGood luck, and have fun with it!",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-1.html#footnotes",
    "href": "lab/lab-1.html#footnotes",
    "title": "Lab 1",
    "section": "Footnotes",
    "text": "Footnotes\n\nRemember, haikus not novellas when writing code!↩︎\nWe’re assigning points to this seemingly trivial task because not selecting your pages and questions will greatly slow down the grading. So we want to make sure you’re properly motivated to complete this task!↩︎",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "lab/lab-4.html",
    "href": "lab/lab-4.html",
    "title": "Lab 4",
    "section": "",
    "text": "In this lab, you’ll review topics you’ve worked with in previous labs, practice importing data, and dive into the concepts of data types and classes.\n\n\n\n\n\n\nNote\n\n\n\nThis lab assumes you’ve completed the labs so far and doesn’t repeat setup and overview content from those labs. If you haven’t done those yet, you should review the previous labs before starting on this one.\n\n\n\nBy the end of the lab, you will…\n\nLearn to read data in from Excel spreadsheets\nGain more experience with joining and pivoting data frames\nReview Quarto cell options\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub\n\nLog in to RStudio, clone your lab-4 repo from GitHub, open your lab-4.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-4. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-4.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-4.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.\n\n\n\nIn this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\nreadxl package for reading in Excel files,\n\njanitor package for cleaning up variable names, and\n\npalmerpenguins and datasauRus packages for some datasets\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(palmerpenguins)\nlibrary(datasauRus)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.\n\nAs we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nStarting with this lab, you are expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#learning-objectives",
    "href": "lab/lab-4.html#learning-objectives",
    "title": "Lab 4",
    "section": "",
    "text": "By the end of the lab, you will…\n\nLearn to read data in from Excel spreadsheets\nGain more experience with joining and pivoting data frames\nReview Quarto cell options\n\nAnd, as usual, you will also…\n\nGet more experience with data science workflow using R, RStudio, Git, and GitHub\nFurther your reproducible authoring skills with Quarto\nImprove your familiarity with version control using Git and GitHub",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#getting-started",
    "href": "lab/lab-4.html#getting-started",
    "title": "Lab 4",
    "section": "",
    "text": "Log in to RStudio, clone your lab-4 repo from GitHub, open your lab-4.qmd document, and get started!\n\n\n\n\n\n\nClick here if you prefer to see step-by-step instructions\n\n\n\n\n\n\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA198-199 under My reservations to log into your container. You should now see the RStudio environment.\n\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-4. It contains the starter documents you need to complete the lab.\nClick on the green CODE button and select Use SSH. This might already be selected by default; if it is, you’ll see the text Clone with SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-4.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.\n\nIn lab-4.qmd, update the author field to your name, render your document and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, push the changes to your GitHub repository, and in your browser confirm that these changes have indeed propagated to your repository.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you run into any issues with the first steps outlined above, flag a TA for help before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#packages",
    "href": "lab/lab-4.html#packages",
    "title": "Lab 4",
    "section": "",
    "text": "In this lab, we will work with the\n\n\ntidyverse package for doing data analysis in a “tidy” way,\n\nreadxl package for reading in Excel files,\n\njanitor package for cleaning up variable names, and\n\npalmerpenguins and datasauRus packages for some datasets\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(palmerpenguins)\nlibrary(datasauRus)\n\n\n\nRun the code cell by clicking on the green triangle (play) button for the code cell labeled load-packages. This loads the package so that its features (the functions and datasets in it) are accessible from your Console.\nThen, render the document that loads this package to make its features (the functions and datasets in it) available for other code cells in your Quarto document.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#guidelines",
    "href": "lab/lab-4.html#guidelines",
    "title": "Lab 4",
    "section": "",
    "text": "As we’ve discussed in lecture, your plots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\nAdditionally, code should follow the tidyverse style. Particularly,\n\nthere should be spaces before and line breaks after each + when building a ggplot,\nthere should also be spaces before and line breaks after each |&gt; in a data transformation pipeline,\ncode should be properly indented,\nthere should be spaces around = signs and spaces after commas.\n\nFurthermore, all code should be visible in the PDF output, i.e., should not run off the page on the PDF. Long lines that run off the page should be split across multiple lines with line breaks.\n\n\n\n\n\n\nImportant\n\n\n\nContinuing to develop a sound workflow for reproducible data analysis is important as you complete the lab and other assignments in this course. There will be periodic reminders in this assignment to remind you to render, commit, and push your changes to GitHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nStarting with this lab, you are expected to pay attention to code smell in addition to code style and readability. You should review and improve your code to avoid redundant steps (e.g., grouping, ungrouping, and grouping again by the same variable in a pipeline), using inconsistent syntax (e.g., ! to say “not” in one place and - in another place), etc.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-1---inflation-in-the-us",
    "href": "lab/lab-4.html#part-1---inflation-in-the-us",
    "title": "Lab 4",
    "section": "Part 1 - Inflation in the US",
    "text": "Part 1 - Inflation in the US\nThe OECD defines inflation as follows:\n\nInflation is a rise in the general level of prices of goods and services that households acquire for the purpose of consumption in an economy over a period of time.\nThe main measure of inflation is the annual inflation rate which is the movement of the Consumer Price Index (CPI) from one month/period to the same month/period of the previous year expressed as percentage over time.\nSource: OECD CPI FAQ\n\nCPI is broken down into 12 expenditures such as food, housing, health, etc. Your goal in this part is to create a time series plot of annual inflation for the US.\nThe data you will need to create this visualization is spread across two files:\n\n\nus-inflation.csv: Annual inflation rate for the US for 12 CPI expenditures. Each expenditure is identified by an ID number.\n\ncpi-expenditures.csv: A “lookup table” of CPI expenditure ID numbers and their descriptions.\n\nLet’s load both of these files.\n\nus_inflation &lt;- read_csv(\"data/us-inflation.csv\")\ncpi_expenditures &lt;- read_csv(\"data/cpi-expenditures.csv\")\n\nQuestion 1\na. How many columns and how many rows does the us_inflation dataset have? What are the variables in it? Which years do these data span? Write a brief (1-2 sentences) narrative summarizing this information.\nb. How many columns and how many rows does the cpi_expenditures dataset have? What are the variables in it? Write a brief (1-2 sentences) narrative summarizing this information.\nc. Create a new dataset by joining the us_inflation dataset with the cpi_expenditures dataset.\n\nDetermine which type of join is the most appropriate one and use that.\nNote that the two datasets don’t have a variable with a common name, though they do have variables that contain common information but are named differently. You will need to first figure out which variables those are, and then define the by argument and use the join_by() function to indicate these variables to join the datasets by.\nUse a short but informative name for the joined dataset, and do not overwrite either of the datasets that go into creating it.\n\nThen, find the number of rows and columns of the resulting dataset and report the names of its columns. Add a brief (1-2 sentences) narrative summarizing this information.\nQuestion 2\na. Create a vector called expenditures_of_interest which contains the descriptions or IDs of CPI expenditures you want to visualize. Your expenditures_of_interest should consist of no more than five expenditures. If you’re using descriptions, make sure that the spelling of your expenditures matches how they appear in the dataset. Then, in 1-2 sentences, state why you chose these expenditures.\nb. In a single pipeline, filter your joined dataset to include only the expenditures_of_interest from part (a), and save the resulting data frame with a new name so you (1) can refer to this data frame later in your analysis and (2) do not overwrite the data frame you’re starting with. Use a short but informative name. Then, in a new pipeline, find the distinct() expenditures in the data frame you created.\nQuestion 3\nUsing your data frame from the previous question, create a plot of annual inflation vs. year for these expenditures. Then, in a few sentences, describe the patterns you observe in the plot, particularly focusing on anything you find surprising or not surprising, based on your knowledge (or lack thereof) of inflation rates in the US over the last decade.\n\nData should be represented with points as well as lines connecting the points for each expenditure.\nEach expenditure should be represented by a different color line and different color and shape points.\nAxes and legend should be properly labeled.\nThe plot should have an appropriate title (and optionally a subtitle).\nPlot should be customized in at least one way – you could use a different than default color scale, or different than default theme, or some other customization.\nIf your legend has labels that are too long, you can try moving the legend to the bottom and stack the labels vertically. Hint: The legend.position and legend.direction arguments of the theme() functions will be useful.\n\n\nggplot(...) +\n  ... +\n  theme(\n    legend.position = \"bottom\", \n    legend.direction = \"vertical\"\n  )",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-2---mtcars",
    "href": "lab/lab-4.html#part-2---mtcars",
    "title": "Lab 4",
    "section": "Part 2 - mtcars\n",
    "text": "Part 2 - mtcars\n\nIn this part, you’ll work with one of the most basic and overused datasets in R: mtcars. The data in this dataset come from the 1974 Motor Trend US magazine (so, yes, they’re old!) and provide information on fuel efficiency and other car characteristics.\nQuestion 4\nSince the dataset is used in many code examples, it’s not unexpected that some analyses of the data are good and some not so much.\n\n\n\n\n\n\nTip\n\n\n\nFor both parts of this question, you should review the data dictionary that is in the documentation for the dataset which you can find at https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html or by typing ?mtcars in your Console.\n\n\na. You come across the following visualization of these data. First, determine what is wrong with this visualization and describe it in one sentence. Then, fix and improve the visualization. As part of your improvement, make sure your legend\n\nis on top of the plot,\nis informative, and\nlists levels in the order they appear in the plot.\n\n\nggplot(mtcars, aes(x = wt, y = mpg, color = am)) +\n  geom_point() +\n  labs(\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles / gallon\"\n  )\n\n\n\n\n\n\n\nb. Update your plot from part (a) further, this time using different shaped points for cars with V-shaped and straight engines. Once again, some requirements for your legend – it should be informative and on the right of the plot.\nQuestion 5\nYour task is to make your plot from Question 4b as ugly and as ineffective as possible. Like, seriously. I want something that is apocalyptically heinous, loathsome, and rotten. Change colors, axes, fonts, themes, or anything else you can think of. You can also search online for other themes, fonts, etc. that you want to tweak. The sky is truly the limit. I want Sauron, Voldemort, Cruella de Vil, Count Dracula, and Regina George all nodding in approval at how horrendous your plot is.\nYou must make at least 5 updates to the plot, and your answer must include:\n\na list of the at least 5 updates you’ve made to your plot from Question 4b, and\n1-2 sentence explanation of why the plot you created is ugly (to you, at least) and ineffective.\n\nDid I mention that the plot should be bad? A prize will be awarded for the worst submission, so get crackin’!\n\n\n\n\n\n\nTip\n\n\n\nThe tidyverse documentation on themes may give you ideas about how you can alter the various features of the plot. Furthermore, the solutions for AEs 5 and 7 demo some of the advanced layers you can add to tweak colors and positioning and so on.\n\n\n\nRender, commit, and push your work so far. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-3---medical-marijuana-in-nc",
    "href": "lab/lab-4.html#part-3---medical-marijuana-in-nc",
    "title": "Lab 4",
    "section": "Part 3 - Medical marijuana in NC",
    "text": "Part 3 - Medical marijuana in NC\nSurveyUSA polled 900 NC adults between September 4-7, 2024. Of the 900 NC adults, 771 were identified by SurveyUSA as being registered to vote.1 The following question was asked to these 771 adults:\n\nShould the use of marijuana for medical use remain against the law in North Carolina? Or be legalized?\n\nResponses were broken down into the following categories:\n\n\nVariable\nLevels\n\n\n\nAge\n18-49; 50+\n\n\nOpinion\nRemain Against The Law; Be Made Legal; Not Sure\n\n\n\nOf the 771 responses, 391 were between the ages of 18-49. Of the individuals that are between 18-49, 59 individuals responded that they think medical marijuana should remain against the law, 292 said it should be made legal, and the remainder were not sure. Of the individuals that are 50+, 67 individuals responded that they think medical marijuana should remain against the law, 245 said it should be made legal, and the remainder were not sure.\nQuestion 6\n\nFill in the code below to create a two-way table that summarizes these data.\n\n\nsurvey_counts &lt;- tibble( \n  age = c(),\n  opinion = c(),\n  n = c()\n  )\n\nsurvey_counts |&gt;\n  pivot_wider( \n    names_from = ___,\n    values_from = ___\n  )\n\nFor parts b-d below, use a single pipeline starting with survey_counts, calculate the desired proportions, and make sure the result is an ungrouped data frame with a column for relevant counts, a column for relevant proportions, and a column for the groups you’re interested in.\n\nCalculate the proportions of 18-49 year olds and 50+ year-olds in this sample.\nCalculate the proportions of those who think medical marijuana should remain against the law, should be made legal, and who are not sure.\n\nCalculate the proportions of individuals in this sample who think medical marijuana should remain against the law, should be made legal, and who are not sure\n\namong those who are 18-49 years old and\namong those who are 50+ years old.\n\n\nQuestion 7\n\n\nCreate a visualization that can be used to evaluate the relationship between age and opinion on legalizing medical marijuana in North Carolina based on this survey’s results.\n\n\n\n\n\n\nTip\n\n\n\nYour visualization should display the proportions you calculated in Question 6d.\n\n\n\nBased on your calculations so far, as well as your visualization, write 1-2 sentences that describe the relationship, in this sample, between age and opinion on legalizing medical marijuana in North Carolina.\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-4---team-usa-at-the-olympics",
    "href": "lab/lab-4.html#part-4---team-usa-at-the-olympics",
    "title": "Lab 4",
    "section": "Part 4 - Team USA at the Olympics",
    "text": "Part 4 - Team USA at the Olympics\nFor this part, you’ll work with data from the rosters of Team USA from the 2020 and 2024 Olympics. The data come from https://www.teamusa.com and the rosters for the two games are in a single Excel file (team-usa.xlsx in your data folder), accross two separate spreadsheets within that file. Figure 1 shows screenshots of these spreadsheets.\n\n\n\n\n\n\nTeam USA 2020\n\n\n\n\n\nTeam USA 2024\n\n\n\n\n\nFigure 1: Excel file with two sheets for rosters of Team USA 2020 and 2024.\n\n\nYour goal is to answer questions about athletes who competed in both games and only one of the games.\nQuestion 8\n\nRead data from the two sheets of team-usa.xlsx as two separate data frames called team_usa_2020 and team_usa_2024.\n\n\n\n\n\n\n\nTip\n\n\n\nThe names of the sheets are shown in the screenshots in Figure 1, or you can use the excel_sheets() function to discover them. Additionally, note that the first row of the sheets contain a logo and a title describing the contents of the data, and not the header row containing variable names.\n\n\n\nRead the documentation for the clean_names() function from the janitor package at https://sfirke.github.io/janitor/reference/clean_names.html. Use this function to “clean” the variable names of team_usa_2020 and team_usa_2024 and save the data frames with the new variable names.\n\nCreate a new variable in both of the datasets called name that:\n\n\npaste()s together the first_name and last_name variables with a space in between and\nis the first variable in the resulting data frame.\n\n\nUsing the appropriate *_join() function, determine how many athletes participated in both Olympic Games?\n\n\n\n\n\n\n\nImportant\n\n\n\nYour answer to this question, based on the data frames you created, should be 0, even if it doesn’t make sense in context of actual Olympic athletes.\n\n\nQuestion 9\nIf you have even a passing knowledge of the Olympic Games, you might know that there are some athletes that participated in both the 2020 and 2024 games, e.g., Simone Biles, Katie Ledecky, etc.\n\nThe reason why athlete names didn’t match across the two data frames is that in one data frame, names are in UPPER CASE, and in the other, they’re in Title Case. Update the 2020 data frame to make name all upper case. Display the first 10 rows of team_usa_2020 with upper case names.\n\n\n\n\n\n\n\nImportant\n\n\n\nYour answer must use the str_to_upper() function.\n\n\n\nLet’s try that question again: How many athletes participated in both Olympic Games?\nHow many athletes participated in the 2020 Olympic Games but not the 2024 Olympic Games? How many athletes participated in the 2024 Olympic Games but not the 2020 Olympic Games?",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-5---back-to-basics-with-datasaurus",
    "href": "lab/lab-4.html#part-5---back-to-basics-with-datasaurus",
    "title": "Lab 4",
    "section": "Part 5 - back to basics with datasauRus",
    "text": "Part 5 - back to basics with datasauRus\nThe data frame you will be working with in this part is called datasaurus_dozen and it’s in the datasauRus package. This single data frame contains 13 datasets, designed to show us why data visualization is important and how summary statistics alone can be misleading. The different datasets are marked by the dataset variable, as shown in Figure 2.\n\n\n\n\n\nFigure 2: The `datasaurus_dozen` data frame stacks 13 datasets on top of each other. This figure shows the first three datasets.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf it’s confusing that the data frame is called datasaurus_dozen when it contains 13 datasets, you’re not alone! Have you heard of a baker’s dozen?\n\n\nHere is a peek at the top 10 rows of the dataset:\n\ndatasaurus_dozen\n\n# A tibble: 1,846 × 3\n   dataset     x     y\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 dino     55.4  97.2\n 2 dino     51.5  96.0\n 3 dino     46.2  94.5\n 4 dino     42.8  91.4\n 5 dino     40.8  88.3\n 6 dino     38.7  84.9\n 7 dino     35.6  79.9\n 8 dino     33.1  77.6\n 9 dino     29.0  74.5\n10 dino     26.2  71.4\n# ℹ 1,836 more rows\n\n\nQuestion 10\n\nIn a single pipeline, calculate the mean of x, mean of y, standard deviation of x, standard deviation of y, and the correlation between x and y for each level of the dataset variable. Then, in 1-2 sentences, comment on how these summary statistics compare across groups (datasets).\n\n\n\n\n\n\n\nTip\n\n\n\nThere are 13 groups but tibbles only print out 10 rows by default. To display all rows, add print(n = 13) as the last step of your pipeline.\n\n\n\nCreate a scatterplot of y versus x and color and facet it by dataset. Then, in 1-2 sentences, how these plots compare across groups (datasets). How does your response in this question compare to your response to the previous question and what does this say about using visualizations and summary statistics when getting to know a dataset?\n\n\n\n\n\n\n\nTip\n\n\n\nWhen you both color and facet by the same variable, you’ll end up with a redundant legend. Turn off the legend by adding show.legend = FALSE to the geom creating the legend.\n\n\n\nRender, commit, and push your changes. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#part-6---all-about-quarto",
    "href": "lab/lab-4.html#part-6---all-about-quarto",
    "title": "Lab 4",
    "section": "Part 6 - All about Quarto",
    "text": "Part 6 - All about Quarto\nQuestion 11\nYou have the following code chunk:\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nAdd the following code cell options, one at a time, and set each to false and then to true. After each value, render your document and observe its effect. Ultimately, choose the values that are the most appropriate for this code cell. Based on the behaviors you observe, describe what each code cell option does.\n\necho\nwarning\neval\nQuestion 12\n\nYou have the following code cell again.\n\n\nggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nAdd fig-width and fig-asp as code chunk options. Try setting fig-width to values between 1 and 10. Try setting fig-asp to values between 0.1 and 1. Re-render the document after each value and observe its effect. Ultimately, choose values that make the plot look visually pleasing in the rendered document. Based on the behavior you observe, describe what each chunk option does.\n\n\n\n\n\n\nTip\n\n\n\nNow that you’ve had more practice with figure sizing in Quarto documents, review all of the plots you made in this lab and adjust their widths and aspect rations to improve how they look in your rendered document.\n\n\nb. You have the following code cell, but look carefully, it’s not exactly the same!\n\ngplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point()\n\nAdd error as a code chunk option and set it to false and then set it to true. After each value, render your document and observe its effect. Ultimately, choose the value that allows you to render your document without altering the code. Based on the behavior you observe, describe what this code chunk option does.\n\n\n\n\n\n\nTip\n\n\n\nReading the documentation might also be helpful.\n\n\n\nRender, commit, and push your work. Make sure that you commit and push all changed documents and that your Git pane is completely empty before proceeding.\n\n\n\n\nTeam USA 2020\nTeam USA 2024\nFigure 2: The `datasaurus_dozen` data frame stacks 13 datasets on top of each other. This figure shows the first three datasets.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "lab/lab-4.html#footnotes",
    "href": "lab/lab-4.html#footnotes",
    "title": "Lab 4",
    "section": "Footnotes",
    "text": "Footnotes\n\nFull survey results can be found at https://www.surveyusa.com/client/PollReport.aspx?g=c6995e17-3837-413e-ac98-3684e1c74dc1.↩︎",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "slides/05-exploring-data-2.html#while-you-wait",
    "href": "slides/05-exploring-data-2.html#while-you-wait",
    "title": "Exploring data II",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-04-gerrymander-explore-II\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-04-gerrymander-explore-II.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file.\n\n\n\n\n\n\n\n\nAEs are due by the end of class\n\n\nSuccessful completion means at least one commit + push by 2PM today"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#intro-to-coding-principles-with-dav-king",
    "href": "slides/05-exploring-data-2.html#intro-to-coding-principles-with-dav-king",
    "title": "Exploring data II",
    "section": "Intro to Coding Principles with Dav King",
    "text": "Intro to Coding Principles with Dav King\n\n\n\n8:30 PM Thursday January 30;\nSocial Sciences 139;\nSpace is limited, so please sign up;\nMaterials will be posted afterward;\nWe might do more if there is interest and Dav is available.\n\n\n\n\n:::"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#reminder-lab-guidelines",
    "href": "slides/05-exploring-data-2.html#reminder-lab-guidelines",
    "title": "Exploring data II",
    "section": "Reminder: Lab guidelines",
    "text": "Reminder: Lab guidelines\n\n\nPlots should include an informative title, axes and legends should have human-readable labels, and careful consideration should be given to aesthetic choices.\n\nCode should follow the tidyverse style (style.tidyverse.org) Particularly,\n\nspace before and line breaks after each + when building a ggplot\n\nspace before and line breaks after each |&gt; in a data transformation pipeline\ncode should be properly indented\nspaces around = signs and spaces after commas\n\n\nProofread your rendered PDF before submission! We cannot give you points for stuff we cannot see, so make sure your code and output is not running off the page. Use line breaks.\nAt least three commits with meaningful commit messages."
  },
  {
    "objectID": "slides/05-exploring-data-2.html#code-style-and-readability",
    "href": "slides/05-exploring-data-2.html#code-style-and-readability",
    "title": "Exploring data II",
    "section": "Code style and readability",
    "text": "Code style and readability\n\nWhydowecareaboutthestyleandreadabilityofyourcode? \\(\\rightarrow\\) Why do we care about the style and readability of your code?\n\n\n\n\nJe voudrais un cafe \\(\\rightarrow\\) Je voudrais un café"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#packages",
    "href": "slides/05-exploring-data-2.html#packages",
    "title": "Exploring data II",
    "section": "Packages",
    "text": "Packages\n\nFor the data: usdata\n\n\n\nlibrary(usdata)\n\n\nFor the analysis: tidyverse and ggthemes\n\n\n\nlibrary(tidyverse)\nlibrary(ggthemes)"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#from-last-time",
    "href": "slides/05-exploring-data-2.html#from-last-time",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar()"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#from-last-time-1",
    "href": "slides/05-exploring-data-2.html#from-last-time-1",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar(position = \"dodge\")"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#from-last-time-2",
    "href": "slides/05-exploring-data-2.html#from-last-time-2",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\nggplot(gerrymander, aes(x = flip18, fill = gerry)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#from-last-time-3",
    "href": "slides/05-exploring-data-2.html#from-last-time-3",
    "title": "Exploring data II",
    "section": "From last time",
    "text": "From last time\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election? Support your answer with a visualization as well as summary statistics.\n\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#step-1",
    "href": "slides/05-exploring-data-2.html#step-1",
    "title": "Exploring data II",
    "section": "Step 1",
    "text": "Step 1\n\ngerrymander\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#step-2",
    "href": "slides/05-exploring-data-2.html#step-2",
    "title": "Exploring data II",
    "section": "Step 2",
    "text": "Step 2\n\ngerrymander |&gt;\n  count(flip18, gerry)\n\n# A tibble: 8 × 3\n  flip18 gerry     n\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;\n1     -1 low       2\n2     -1 mid       3\n3      0 low      52\n4      0 mid     242\n5      0 high     98\n6      1 low       8\n7      1 mid      25\n8      1 high      5"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#step-3",
    "href": "slides/05-exploring-data-2.html#step-3",
    "title": "Exploring data II",
    "section": "Step 3",
    "text": "Step 3\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18)\n\n# A tibble: 8 × 3\n# Groups:   flip18 [3]\n  flip18 gerry     n\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;\n1     -1 low       2\n2     -1 mid       3\n3      0 low      52\n4      0 mid     242\n5      0 high     98\n6      1 low       8\n7      1 mid      25\n8      1 high      5"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#step-4",
    "href": "slides/05-exploring-data-2.html#step-4",
    "title": "Exploring data II",
    "section": "Step 4",
    "text": "Step 4\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#same-thing-without-the-pipe",
    "href": "slides/05-exploring-data-2.html#same-thing-without-the-pipe",
    "title": "Exploring data II",
    "section": "Same thing, without the pipe",
    "text": "Same thing, without the pipe\n\nmutate(group_by(count(gerrymander, flip18, gerry), flip18), prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#with-the-pipe",
    "href": "slides/05-exploring-data-2.html#with-the-pipe",
    "title": "Exploring data II",
    "section": "With the pipe",
    "text": "With the pipe"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#without-the-pipe",
    "href": "slides/05-exploring-data-2.html#without-the-pipe",
    "title": "Exploring data II",
    "section": "Without the pipe",
    "text": "Without the pipe"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#what-does-group_by-do",
    "href": "slides/05-exploring-data-2.html#what-does-group_by-do",
    "title": "Exploring data II",
    "section": "What does group_by() do?",
    "text": "What does group_by() do?\n\nWhat does group_by() do in the following pipeline?\n\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   flip18 [3]\n  flip18 gerry     n  prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1     -1 low       2 0.4  \n2     -1 mid       3 0.6  \n3      0 low      52 0.133\n4      0 mid     242 0.617\n5      0 high     98 0.25 \n6      1 low       8 0.211\n7      1 mid      25 0.658\n8      1 high      5 0.132"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#what-does-group_by-do-1",
    "href": "slides/05-exploring-data-2.html#what-does-group_by-do-1",
    "title": "Exploring data II",
    "section": "What does group_by() do?",
    "text": "What does group_by() do?\n\nWhat does group_by() do in the following pipeline?\n\n\ngerrymander |&gt;\n  count(flip18, gerry) |&gt;\n  #group_by(flip18) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n  flip18 gerry     n    prop\n   &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;   &lt;dbl&gt;\n1     -1 low       2 0.00460\n2     -1 mid       3 0.00690\n3      0 low      52 0.120  \n4      0 mid     242 0.556  \n5      0 high     98 0.225  \n6      1 low       8 0.0184 \n7      1 mid      25 0.0575 \n8      1 high      5 0.0115"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#lets-simplify",
    "href": "slides/05-exploring-data-2.html#lets-simplify",
    "title": "Exploring data II",
    "section": "Let’s simplify!",
    "text": "Let’s simplify!\n\nWhat does group_by() do in the following pipeline?\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(mean_trump16 = mean(trump16))\n\n# A tibble: 50 × 2\n   state mean_trump16\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 AK            52.8\n 2 AL            62.6\n 3 AR            60.9\n 4 AZ            46.9\n 5 CA            31.7\n 6 CO            43.6\n 7 CT            41.0\n 8 DE            41.9\n 9 FL            47.9\n10 GA            51.3\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#lets-simplify-1",
    "href": "slides/05-exploring-data-2.html#lets-simplify-1",
    "title": "Exploring data II",
    "section": "Let’s simplify!",
    "text": "Let’s simplify!\n\nWhat does group_by() do in the following pipeline?\n\n\ngerrymander |&gt;\n  #group_by(state) |&gt;\n  summarize(mean_trump16 = mean(trump16))\n\n# A tibble: 1 × 1\n  mean_trump16\n         &lt;dbl&gt;\n1         45.9"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#group_by",
    "href": "slides/05-exploring-data-2.html#group_by",
    "title": "Exploring data II",
    "section": "group_by()",
    "text": "group_by()\n\nit converts a data frame to a grouped data frame, where subsequent operations are performed once per group\nungroup() removes grouping\n\n\ngerrymander |&gt;\n  group_by(state)\n\n# A tibble: 435 × 12\n# Groups:   state [50]\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#group_by-1",
    "href": "slides/05-exploring-data-2.html#group_by-1",
    "title": "Exploring data II",
    "section": "group_by()",
    "text": "group_by()\n\nit converts a data frame to a grouped data frame, where subsequent operations are performed once per group\nungroup() removes grouping\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  ungroup()\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#group_by-summarize",
    "href": "slides/05-exploring-data-2.html#group_by-summarize",
    "title": "Exploring data II",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\nA common pipeline is group_by() and then summarize() to calculate summary statistics for each group:\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(\n    mean_trump16 = mean(trump16),\n    median_trump16 = median(trump16)\n  )\n\n# A tibble: 50 × 3\n   state mean_trump16 median_trump16\n   &lt;chr&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n 1 AK            52.8           52.8\n 2 AL            62.6           64.9\n 3 AR            60.9           63.0\n 4 AZ            46.9           47.7\n 5 CA            31.7           28.4\n 6 CO            43.6           41.3\n 7 CT            41.0           40.4\n 8 DE            41.9           41.9\n 9 FL            47.9           49.6\n10 GA            51.3           56.6\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#group_by-summarize-1",
    "href": "slides/05-exploring-data-2.html#group_by-summarize-1",
    "title": "Exploring data II",
    "section": "group_by() |> summarize()",
    "text": "group_by() |&gt; summarize()\nThis pipeline can also be used to count number of observations for each group:\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n())\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#summarize",
    "href": "slides/05-exploring-data-2.html#summarize",
    "title": "Exploring data II",
    "section": "summarize()",
    "text": "summarize()\n... |&gt;\n  summarize(\n    name_of_summary_statistic = summary_function(variable)\n  )\n\n\n\nname_of_summary_statistic: Anything you want to call it!\n\nRecommendation: Keep it short and evocative\n\n\n\nsummary_function():\n\n\nn(): number of observations\n\nmean(): mean\n\nmedian(): median\n…"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#spot-the-difference",
    "href": "slides/05-exploring-data-2.html#spot-the-difference",
    "title": "Exploring data II",
    "section": "Spot the difference",
    "text": "Spot the difference\n\nWhat’s the difference between the following two pipelines?\n\n\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n())\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows\n\n\n\n\ngerrymander |&gt;\n  count(state)\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK        1\n 2 AL        7\n 3 AR        4\n 4 AZ        9\n 5 CA       53\n 6 CO        7\n 7 CT        5\n 8 DE        1\n 9 FL       27\n10 GA       14\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#count",
    "href": "slides/05-exploring-data-2.html#count",
    "title": "Exploring data II",
    "section": "count()",
    "text": "count()\n\n\n... |&gt;\n  count(variable)\n\n... |&gt;\n  count(variable1, variable2)\n\n\n\nCount the number of observations in each level of variable(s)\nPlace the counts in a variable called n"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#count-and-sort",
    "href": "slides/05-exploring-data-2.html#count-and-sort",
    "title": "Exploring data II",
    "section": "\ncount() and sort\n",
    "text": "count() and sort\n\n\nWhat does the following pipeline do? Rewrite it with count() instead.\n\n\ngerrymander |&gt;\n  group_by(state) |&gt;\n  summarize(n = n()) |&gt;\n  arrange(desc(n))\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 CA       53\n 2 TX       36\n 3 FL       27\n 4 NY       27\n 5 IL       18\n 6 PA       18\n 7 OH       16\n 8 GA       14\n 9 MI       14\n10 NC       13\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#count-and-sort-1",
    "href": "slides/05-exploring-data-2.html#count-and-sort-1",
    "title": "Exploring data II",
    "section": "\ncount() and sort\n",
    "text": "count() and sort\n\n\nWhat does the following pipeline do? Rewrite it with count() instead.\n\n\ngerrymander |&gt;\n  count(state) |&gt;\n  arrange(desc(n))\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 CA       53\n 2 TX       36\n 3 FL       27\n 4 NY       27\n 5 IL       18\n 6 PA       18\n 7 OH       16\n 8 GA       14\n 9 MI       14\n10 NC       13\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#count-and-sort-2",
    "href": "slides/05-exploring-data-2.html#count-and-sort-2",
    "title": "Exploring data II",
    "section": "\ncount() and sort\n",
    "text": "count() and sort\n\n\nWhat does the following pipeline do? Rewrite it with count() instead.\n\n\ngerrymander |&gt;\n  count(state, sort = TRUE)\n\n# A tibble: 50 × 2\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 CA       53\n 2 TX       36\n 3 FL       27\n 4 NY       27\n 5 IL       18\n 6 PA       18\n 7 OH       16\n 8 GA       14\n 9 MI       14\n10 NC       13\n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#flip-the-question",
    "href": "slides/05-exploring-data-2.html#flip-the-question",
    "title": "Exploring data II",
    "section": "Flip the question",
    "text": "Flip the question\n\n\n\n\n\n\nNote\n\n\nIs a Congressional District more likely to have high prevalence of gerrymandering if a Democrat was able to flip the seat in the 2018 election?\n\n\n\nvs.\n\n\n\n\n\n\nNote\n\n\nIs a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#flipping-vs.-gerrymandering-prevalence",
    "href": "slides/05-exploring-data-2.html#flipping-vs.-gerrymandering-prevalence",
    "title": "Exploring data II",
    "section": "Flipping vs. gerrymandering prevalence",
    "text": "Flipping vs. gerrymandering prevalence\n\nThe following code should produce a visualization that answers the question “Is a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?” However, it produces a warning and an unexpected plot. What’s going on?\n\n\n\n\nggplot(\n  gerrymander, \n  aes(x = gerry, fill = flip18)\n  ) +\n  geom_bar(position = \"fill\")\n\nWarning: The following aesthetics were dropped during statistical transformation: fill.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#another-glimpse-at-gerrymander",
    "href": "slides/05-exploring-data-2.html#another-glimpse-at-gerrymander",
    "title": "Exploring data II",
    "section": "Another glimpse at gerrymander\n",
    "text": "Another glimpse at gerrymander\n\n\nglimpse(gerrymander)\n\nRows: 435\nColumns: 12\n$ district   &lt;chr&gt; \"AK-AL\", \"AL-01\", \"AL-02\", \"AL-03\", \"AL-04\", \"AL-05\", \"AL-0…\n$ last_name  &lt;chr&gt; \"Young\", \"Byrne\", \"Roby\", \"Rogers\", \"Aderholt\", \"Brooks\", \"…\n$ first_name &lt;chr&gt; \"Don\", \"Bradley\", \"Martha\", \"Mike D.\", \"Rob\", \"Mo\", \"Gary\",…\n$ party16    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ clinton16  &lt;dbl&gt; 37.6, 34.1, 33.0, 32.3, 17.4, 31.3, 26.1, 69.8, 30.2, 41.7,…\n$ trump16    &lt;dbl&gt; 52.8, 63.5, 64.9, 65.3, 80.4, 64.7, 70.8, 28.6, 65.0, 52.4,…\n$ dem16      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,…\n$ state      &lt;chr&gt; \"AK\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AR\", \"AR\",…\n$ party18    &lt;chr&gt; \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"D\", \"R\", \"R\", \"R\", \"R\",…\n$ dem18      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,…\n$ flip18     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,…\n$ gerry      &lt;fct&gt; mid, high, high, high, high, high, high, high, mid, mid, mi…"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#mutate-1",
    "href": "slides/05-exploring-data-2.html#mutate-1",
    "title": "Exploring data II",
    "section": "mutate()",
    "text": "mutate()\n\nWe want to use flip18 as a categorical variable\nBut it’s stored as a numeric\nSo we need to change its type first, before we can use it as a categorical variable\nThe mutate() function transforms (mutates) a data frame by creating a new column or updating an existing one"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#mutate-in-action",
    "href": "slides/05-exploring-data-2.html#mutate-in-action",
    "title": "Exploring data II",
    "section": "\nmutate() in action",
    "text": "mutate() in action\n\ngerrymander |&gt;\n  mutate(flip18 = as.factor(flip18))\n\n# A tibble: 435 × 12\n   district last_name first_name party16 clinton16 trump16 dem16 state party18\n   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  \n 1 AK-AL    Young     Don        R            37.6    52.8     0 AK    R      \n 2 AL-01    Byrne     Bradley    R            34.1    63.5     0 AL    R      \n 3 AL-02    Roby      Martha     R            33      64.9     0 AL    R      \n 4 AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL    R      \n 5 AL-04    Aderholt  Rob        R            17.4    80.4     0 AL    R      \n 6 AL-05    Brooks    Mo         R            31.3    64.7     0 AL    R      \n 7 AL-06    Palmer    Gary       R            26.1    70.8     0 AL    R      \n 8 AL-07    Sewell    Terri      D            69.8    28.6     1 AL    D      \n 9 AR-01    Crawford  Rick       R            30.2    65       0 AR    R      \n10 AR-02    Hill      French     R            41.7    52.4     0 AR    R      \n# ℹ 425 more rows\n# ℹ 3 more variables: dem18 &lt;dbl&gt;, flip18 &lt;fct&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#mutate-in-action-1",
    "href": "slides/05-exploring-data-2.html#mutate-in-action-1",
    "title": "Exploring data II",
    "section": "\nmutate() in action",
    "text": "mutate() in action\n\ngerrymander |&gt;\n  mutate(flip18 = as.factor(flip18)) |&gt;\n  relocate(flip18)\n\n# A tibble: 435 × 12\n   flip18 district last_name first_name party16 clinton16 trump16 dem16 state\n   &lt;fct&gt;  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1 0      AK-AL    Young     Don        R            37.6    52.8     0 AK   \n 2 0      AL-01    Byrne     Bradley    R            34.1    63.5     0 AL   \n 3 0      AL-02    Roby      Martha     R            33      64.9     0 AL   \n 4 0      AL-03    Rogers    Mike D.    R            32.3    65.3     0 AL   \n 5 0      AL-04    Aderholt  Rob        R            17.4    80.4     0 AL   \n 6 0      AL-05    Brooks    Mo         R            31.3    64.7     0 AL   \n 7 0      AL-06    Palmer    Gary       R            26.1    70.8     0 AL   \n 8 0      AL-07    Sewell    Terri      D            69.8    28.6     1 AL   \n 9 0      AR-01    Crawford  Rick       R            30.2    65       0 AR   \n10 0      AR-02    Hill      French     R            41.7    52.4     0 AR   \n# ℹ 425 more rows\n# ℹ 3 more variables: party18 &lt;chr&gt;, dem18 &lt;dbl&gt;, gerry &lt;fct&gt;"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#revisit-the-plot",
    "href": "slides/05-exploring-data-2.html#revisit-the-plot",
    "title": "Exploring data II",
    "section": "Revisit the plot",
    "text": "Revisit the plot\n\n“Is a Congressional District more likely to be flipped to a Democratic seat if it has high prevalence of gerrymandering or low prevalence of gerrymandering?”\n\n\ngerrymander |&gt;\n  mutate(flip18 = as.factor(flip18)) |&gt;\n  ggplot(aes(x = gerry, fill = flip18)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "slides/05-exploring-data-2.html#ae-04-gerrymander-explore-ii",
    "href": "slides/05-exploring-data-2.html#ae-04-gerrymander-explore-ii",
    "title": "Exploring data II",
    "section": "ae-04-gerrymander-explore-II",
    "text": "ae-04-gerrymander-explore-II\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-04-gerrymander-explore-II.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/05-exploring-data-2.html#recap-aesthetic-mappings",
    "href": "slides/05-exploring-data-2.html#recap-aesthetic-mappings",
    "title": "Exploring data II",
    "section": "Recap: aesthetic mappings",
    "text": "Recap: aesthetic mappings\n\nLocal aesthetic mappings for a given geom\nGlobal aesthetic mappings for all geoms"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#reminders",
    "href": "slides/01-meet-the-toolkit.html#reminders",
    "title": "Meet the toolkit",
    "section": "Reminders",
    "text": "Reminders\n\nIf you have not yet completed the Getting to Know You survey, please do so ASAP!\nIf you have not yet accepted the invite to join the course GitHub Organization, please do so pronto!\nMake your appointments in the Testing Center now!\nAny questions about the syllabus?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "href": "slides/01-meet-the-toolkit.html#course-toolkit-1",
    "title": "Meet the toolkit",
    "section": "Course toolkit",
    "text": "Course toolkit\n\n\nCourse operation\n\nMaterials: sta199-f24.github.io\n\nSubmission: Gradescope\nDiscussion: Ed Discussion\nGradebook: Canvas\n\n\nDoing data science\n\nComputing:\n\nR\nRStudio\ntidyverse\nQuarto\n\n\nVersion control and collaboration:\n\nGit\nGitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#learning-goals",
    "href": "slides/01-meet-the-toolkit.html#learning-goals",
    "title": "Meet the toolkit",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the course, you will be able to…\n\n\ngain insight from data\ngain insight from data, reproducibly\n\ngain insight from data, reproducibly, using modern programming tools and techniques\n\ngain insight from data, reproducibly and collaboratively, using modern programming tools and techniques\ngain insight from data, reproducibly (with literate programming and version control) and collaboratively, using modern programming tools and techniques"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "href": "slides/01-meet-the-toolkit.html#reproducibility-checklist",
    "title": "Meet the toolkit",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for a data analysis to be “reproducible”?\n\n\nShort-term goals:\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done?\n\n\n\nLong-term goals:\n\nCan the code be used for other data?\nCan you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "href": "slides/01-meet-the-toolkit.html#toolkit-for-reproducibility",
    "title": "Meet the toolkit",
    "section": "Toolkit for reproducibility",
    "text": "Toolkit for reproducibility\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-and-rstudio-1",
    "href": "slides/01-meet-the-toolkit.html#r-and-rstudio-1",
    "title": "Meet the toolkit",
    "section": "R and RStudio",
    "text": "R and RStudio\n\n\n\n\n\n\n\nR is an open-source statistical programming language\n\nR is also an environment for statistical computing and graphics\nIt’s easily extensible with packages\n\n\n\n\n\nRStudio is a convenient interface for R called an IDE (integrated development environment), e.g. “I write R code in the RStudio IDE”\n\nRStudio is not a requirement for programming with R, but it’s very commonly used by R programmers and data scientists"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-vs.-rstudio",
    "href": "slides/01-meet-the-toolkit.html#r-vs.-rstudio",
    "title": "Meet the toolkit",
    "section": "R vs. RStudio",
    "text": "R vs. RStudio\n\n\n\n\n\n\nSource: Modern Dive."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#r-packages",
    "href": "slides/01-meet-the-toolkit.html#r-packages",
    "title": "Meet the toolkit",
    "section": "R packages",
    "text": "R packages\n\n\nPackages: Fundamental units of reproducible R code, including reusable R functions, the documentation that describes how to use them, and sample data1\nAs of 27 August 2024, there are 21,168 R packages available on CRAN (the Comprehensive R Archive Network)2\nWe’re going to work with a small (but important) subset of these!\n\n\n\n\n1 Wickham and Bryan, R Packages.\n2CRAN contributed packages."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-r-rstudio",
    "href": "slides/01-meet-the-toolkit.html#tour-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour: R + RStudio",
    "text": "Tour: R + RStudio\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\nOption 2:\nGo to your container and launch RStudio."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-r-rstudio",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-r-rstudio",
    "title": "Meet the toolkit",
    "section": "Tour recap: R + RStudio",
    "text": "Tour recap: R + RStudio"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#packages",
    "href": "slides/01-meet-the-toolkit.html#packages",
    "title": "Meet the toolkit",
    "section": "Packages",
    "text": "Packages\n\nInstalled with install.packages(), once per system:\n\n\ninstall.packages(\"palmerpenguins\")\n\n\n\n\n\n\n\nNote\n\n\nWe already pre-installed many of the package you’ll need for this course, so you might go the whole semester without needing to run install.packages()!\n\n\n\n\n\nLoaded with library(), once per session:\n\n\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#packages-an-analogy",
    "href": "slides/01-meet-the-toolkit.html#packages-an-analogy",
    "title": "Meet the toolkit",
    "section": "Packages, an analogy",
    "text": "Packages, an analogy\nIf data analysis was cooking…\n\n\nRStudio is your kitchen. It comes with a fridge, a stove, a sink, etc pre-installed;\nInstalling a package would be like buying more appliances at the store: mixer, blender, toaster, instapot, air fryer;\nLoading a package would be like taking these things out of the cupboard;\nYour containers are like kitchens where we have already bought all of the extra appliances for you. In other words, “batteries included.”"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tidyverse",
    "href": "slides/01-meet-the-toolkit.html#tidyverse",
    "title": "Meet the toolkit",
    "section": "tidyverse",
    "text": "tidyverse\n\naka the package you’ll hear about the most…\n\n\n\n\n\ntidyverse.org\n\nThe tidyverse is an opinionated collection of R packages designed for data science\nAll packages share an underlying philosophy and a common grammar"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#data-frames-and-variables",
    "href": "slides/01-meet-the-toolkit.html#data-frames-and-variables",
    "title": "Meet the toolkit",
    "section": "Data frames and variables",
    "text": "Data frames and variables\n\nEach row of a data frame is an observation\n\n\n\n\nEach column of a data frame is a variable\n\n\n\n\n\nColumns (variables) in data frames can be accessed with $:\n\n\ndataframe$variable_name"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#help",
    "href": "slides/01-meet-the-toolkit.html#help",
    "title": "Meet the toolkit",
    "section": "Help",
    "text": "Help\nObject documentation can be accessed with ?\n\n\n\n?mean\n\n\nVideo"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#git-and-github",
    "href": "slides/01-meet-the-toolkit.html#git-and-github",
    "title": "Meet the toolkit",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\n\n\n\n\n\n\nGit is a version control system – like “Track Changes” features from Microsoft Word, on steroids\nIt’s not the only version control system, but it’s a very popular one\n\n\n\n\n\n\n\nGitHub is the home for your Git-based projects on the internet – like DropBox but much, much better\nWe will use GitHub as a platform for web hosting and collaboration (and as our course management system!)"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#versioning---done-badly",
    "href": "slides/01-meet-the-toolkit.html#versioning---done-badly",
    "title": "Meet the toolkit",
    "section": "Versioning - done badly",
    "text": "Versioning - done badly"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#versioning---done-better",
    "href": "slides/01-meet-the-toolkit.html#versioning---done-better",
    "title": "Meet the toolkit",
    "section": "Versioning - done better",
    "text": "Versioning - done better"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#versioning---done-even-better",
    "href": "slides/01-meet-the-toolkit.html#versioning---done-even-better",
    "title": "Meet the toolkit",
    "section": "Versioning - done even better",
    "text": "Versioning - done even better\n\nwith human readable messages"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-1",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-1",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-2",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-2",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-3",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-git-and-github-3",
    "title": "Meet the toolkit",
    "section": "How will we use Git and GitHub?",
    "text": "How will we use Git and GitHub?"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#git-and-github-tips",
    "href": "slides/01-meet-the-toolkit.html#git-and-github-tips",
    "title": "Meet the toolkit",
    "section": "Git and GitHub tips",
    "text": "Git and GitHub tips\n\n\nThere are millions of git commands – ok, that’s an exaggeration, but there are a lot of them – and very few people know them all. 99% of the time you will use git to add, commit, push, and pull.\nWe will be doing Git things and interfacing with GitHub through RStudio, but if you google for help you might come across methods for doing these things in the command line – skip that and move on to the next resource unless you feel comfortable trying it out.\nThere is a great resource for working with git and R: happygitwithr.com. Some of the content in there is beyond the scope of this course, but it’s a good place to look for help."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-git-github",
    "href": "slides/01-meet-the-toolkit.html#tour-git-github",
    "title": "Meet the toolkit",
    "section": "Tour: Git + GitHub",
    "text": "Tour: Git + GitHub\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\n\n\n\n\nNote\n\n\nYou’ll need to stick to this option if you haven’t yet accepted your GitHub invite and don’t have a repo created for you.\n\n\n\n\n\nOption 2:\nGo to the course GitHub organization and clone ae-your_github_name repo to your container."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-git-github",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-git-github",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\n\nFind your application repo, that will always be named using the naming convention assignment_title-your_github_name\nClick on the green “Code” button, make sure SSH is selected, copy the repo URL"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-git-github-1",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-git-github-1",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\n\nIn RStudio, File &gt; New Project &gt; From Version Control &gt; Git\nPaste repo URL copied in previous step, then click tab to auto-fill the project name, then click Create Project\n\nFor one time only, type yes in the pop-up dialogue\n\n\nVideo"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#what-could-have-gone-wrong",
    "href": "slides/01-meet-the-toolkit.html#what-could-have-gone-wrong",
    "title": "Meet the toolkit",
    "section": "What could have gone wrong?",
    "text": "What could have gone wrong?\n\nNever received GitHub invite \\(\\rightarrow\\) Fill out “Getting to know you survey\nNever accepted GitHub invite \\(\\rightarrow\\) Look for it in your email and accept it\nCloning repo fails \\(\\rightarrow\\) Review/redo Lab 0 steps for setting up SSH key\nStill no luck? Visit OH or post on Ed."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#quarto-1",
    "href": "slides/01-meet-the-toolkit.html#quarto-1",
    "title": "Meet the toolkit",
    "section": "Quarto",
    "text": "Quarto\n\n\nFully reproducible reports – each time you render the analysis is ran from the beginning\nCode goes in chunks narrative goes outside of chunks\nA visual editor for a familiar / Google docs-like editing experience"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-quarto",
    "href": "slides/01-meet-the-toolkit.html#tour-quarto",
    "title": "Meet the toolkit",
    "section": "Tour: Quarto",
    "text": "Tour: Quarto\n\n\n\nOption 1:\nSit back and enjoy the show!\n\n\n\n\n\n\n\nNote\n\n\nIf you chose (or had to choose) this option for the previous tour, or if you couldn’t clone your repo for any reason, you’ll need to stick to this option.\n\n\n\n\n\nOption 2:\nGo to RStudio and open the document ae-01-meet-the-penguins.qmd."
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-quarto",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-quarto",
    "title": "Meet the toolkit",
    "section": "Tour recap: Quarto",
    "text": "Tour recap: Quarto"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#tour-recap-git-github-2",
    "href": "slides/01-meet-the-toolkit.html#tour-recap-git-github-2",
    "title": "Meet the toolkit",
    "section": "Tour recap: Git + GitHub",
    "text": "Tour recap: Git + GitHub\nOnce we made changes to our Quarto document, we\n\nwent to the Git pane in RStudio\nstaged our changes by clicking the checkboxes next to the relevant files\ncommitted our changes with an informative commit message\npushed our changes to our application exercise repos\nconfirmed on GitHub that we could see our changes pushed from RStudio"
  },
  {
    "objectID": "slides/01-meet-the-toolkit.html#how-will-we-use-quarto",
    "href": "slides/01-meet-the-toolkit.html#how-will-we-use-quarto",
    "title": "Meet the toolkit",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise, lab, project, etc. is an Quarto document\nYou’ll always have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#alison-bechdel",
    "href": "slides/03-grammar-of-data-transformation.html#alison-bechdel",
    "title": "Grammar of data transformation",
    "section": "Alison Bechdel",
    "text": "Alison Bechdel"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-bechdel-test",
    "href": "slides/03-grammar-of-data-transformation.html#the-bechdel-test",
    "title": "Grammar of data transformation",
    "section": "The Bechdel Test",
    "text": "The Bechdel Test\n\n\n (Dykes to Watch Out For - 1985)\n\nFilm passes if…\n\ntwo female characters;\ntalk to each other;\nabout something besides a man."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#do-jzs-favorite-movies-pass",
    "href": "slides/03-grammar-of-data-transformation.html#do-jzs-favorite-movies-pass",
    "title": "Grammar of data transformation",
    "section": "Do JZ’s favorite movies pass?",
    "text": "Do JZ’s favorite movies pass?\n\n\n\nDouble Indemnity (1944)\n🥴\n\n\nSunset Boulevard (1950)\n🥴\n\n\nSweet Smell of Success (1957)\n❌\n\n\nOne Hundred and One Dalmatians (1961)\n✅\n\n\nChinatown (1974)\n❌\n\n\nAmadeus (1984)\n❌\n\n\nGoodfellas (1990)\n🥴\n\n\nBram Stoker’s Dracula (1992)\n❌\n\n\nThe Lord of the Rings (2001 - 2003)\n❌\n\n\nVera Drake (2004)\n✅"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#our-starting-point",
    "href": "slides/03-grammar-of-data-transformation.html#our-starting-point",
    "title": "Grammar of data transformation",
    "section": "Our starting point",
    "text": "Our starting point\n\n\n\n\n\n\nFrom FiveThirtyEight\n\n\n\n\n\n\n\n\n\n\n“We did a statistical analysis of films to test two claims: first, that films that pass the Bechdel test — featuring women in stronger roles — see a lower return on investment, and second, that they see lower gross profits. We found no evidence to support either claim.”"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#ae-02-bechdel-dataviz",
    "href": "slides/03-grammar-of-data-transformation.html#ae-02-bechdel-dataviz",
    "title": "Grammar of data transformation",
    "section": "ae-02-bechdel-dataviz",
    "text": "ae-02-bechdel-dataviz\n\nGo to RStudio, confirm that you’re in the ae project, and open the document ae-02-bechdel-dataviz.qmd."
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#recap-code-cells-aka-code-chunks",
    "href": "slides/03-grammar-of-data-transformation.html#recap-code-cells-aka-code-chunks",
    "title": "Grammar of data transformation",
    "section": "Recap: Code cells (aka code chunks)",
    "text": "Recap: Code cells (aka code chunks)\n . . .\n\nCell labels are helpful for describing what the code is doing, for jumping between code cells in the editor, and for troubleshooting\nmessage: false hides any messages emitted by the code in your rendered document"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#talking-about-one-numerical-variable",
    "href": "slides/03-grammar-of-data-transformation.html#talking-about-one-numerical-variable",
    "title": "Grammar of data transformation",
    "section": "Talking about one numerical variable",
    "text": "Talking about one numerical variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncenter: what is the “typical” value (mean, median, mode) the data are concentrating around?\nspread: how concentrated are the data around a typical value?\nshape: does the distribution have one peak, or many? is it symmetric or skewed?"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#interaction-between-shape-and-center",
    "href": "slides/03-grammar-of-data-transformation.html#interaction-between-shape-and-center",
    "title": "Grammar of data transformation",
    "section": "Interaction between shape and center",
    "text": "Interaction between shape and center"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#histograms-provide-more-detail",
    "href": "slides/03-grammar-of-data-transformation.html#histograms-provide-more-detail",
    "title": "Grammar of data transformation",
    "section": "Histograms provide more detail…",
    "text": "Histograms provide more detail…"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#but-boxplots-are-nice-for-side-by-side-comparisons",
    "href": "slides/03-grammar-of-data-transformation.html#but-boxplots-are-nice-for-side-by-side-comparisons",
    "title": "Grammar of data transformation",
    "section": "…but boxplots are nice for side-by-side comparisons",
    "text": "…but boxplots are nice for side-by-side comparisons"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#talking-about-two-numerical-variables",
    "href": "slides/03-grammar-of-data-transformation.html#talking-about-two-numerical-variables",
    "title": "Grammar of data transformation",
    "section": "Talking about two numerical variables",
    "text": "Talking about two numerical variables\n\n\n\n\n\n\n\n\n\n\ndirection: positive or negative\nshape: linear or nonlinear\nstrength: how close are points to the “trend”"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#strength-and-direction-of-linear-relationships",
    "href": "slides/03-grammar-of-data-transformation.html#strength-and-direction-of-linear-relationships",
    "title": "Grammar of data transformation",
    "section": "Strength and direction of linear relationships",
    "text": "Strength and direction of linear relationships"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#nonlinear-relationships",
    "href": "slides/03-grammar-of-data-transformation.html#nonlinear-relationships",
    "title": "Grammar of data transformation",
    "section": "Nonlinear relationships",
    "text": "Nonlinear relationships"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#a-quick-reminder",
    "href": "slides/03-grammar-of-data-transformation.html#a-quick-reminder",
    "title": "Grammar of data transformation",
    "section": "A quick reminder",
    "text": "A quick reminder\n\n1bechdel |&gt;\n2  filter(roi &gt; 400) |&gt;\n3  select(title, roi, budget_2013, gross_2013, year, clean_test)\n\n\n1\n\nStart with the bechdel data frame\n\n2\n\nFilter for movies with roi greater than 400 (gross is more than 400 times budget)\n\n3\n\nSelect the columns title, roi, budget_2013, gross_2013, year, and clean_test\n\n\n\n\n# A tibble: 3 × 6\n  title                     roi budget_2013 gross_2013  year clean_test\n  &lt;chr&gt;                   &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Paranormal Activity      671.      505595  339424558  2007 dubious   \n2 The Blair Witch Project  648.      839077  543776715  1999 ok        \n3 El Mariachi              583.       11622    6778946  1992 nowomen"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe",
    "title": "Grammar of data transformation",
    "section": "The pipe |>",
    "text": "The pipe |&gt;\nThe pipe operator passes what comes before it into the function that comes after it as the first argument in that function.\n\n\n\nsum(1, 2)\n\n[1] 3\n\n\n\n\n1 |&gt; \n  sum(2)\n\n[1] 3\n\n\n\n\n\n\n\n\nselect(filter(bechdel, roi &gt; 400), title)\n\n# A tibble: 3 × 1\n  title                  \n  &lt;chr&gt;                  \n1 Paranormal Activity    \n2 The Blair Witch Project\n3 El Mariachi            \n\n\n\n\nbechdel |&gt;\n  filter(roi &gt; 400) |&gt;\n  select(title)\n\n# A tibble: 3 × 1\n  title                  \n  &lt;chr&gt;                  \n1 Paranormal Activity    \n2 The Blair Witch Project\n3 El Mariachi"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#code-style-tip",
    "href": "slides/03-grammar-of-data-transformation.html#code-style-tip",
    "title": "Grammar of data transformation",
    "section": "Code style tip ",
    "text": "Code style tip \n\nIn data transformation pipelines, always use a\n\nspace before |&gt;\nline break after |&gt;\nindent the next line of code\n\n\n\n\nIn data visualization layers, always use a\n\nspace before +\nline break after +\nindent the next line of code"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\n\nStart with the bechdel data frame:\n\nbechdel\n\n# A tibble: 1,615 × 7\n   title                   year gross_2013 budget_2013    roi binary clean_test\n   &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n 1 21 & Over               2013   67878146    13000000  5.22  FAIL   notalk    \n 2 Dredd 3D                2012   55078343    45658735  1.21  PASS   ok        \n 3 12 Years a Slave        2013  211714070    20000000 10.6   FAIL   notalk    \n 4 2 Guns                  2013  208105475    61000000  3.41  FAIL   notalk    \n 5 42                      2013  190040426    40000000  4.75  FAIL   men       \n 6 47 Ronin                2013  184166317   225000000  0.819 FAIL   men       \n 7 A Good Day to Die Hard  2013  371598396    92000000  4.04  FAIL   notalk    \n 8 About Time              2013  102648667    12000000  8.55  PASS   ok        \n 9 Admission               2013   36014634    13000000  2.77  PASS   ok        \n10 After Earth             2013  304895295   130000000  2.35  FAIL   notalk    \n# ℹ 1,605 more rows"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-1",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-1",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nFilter for rows where binary is equal to \"PASS\":\n\nbechdel |&gt;\n  filter(binary == \"PASS\")\n\n# A tibble: 753 × 7\n   title                 year gross_2013 budget_2013   roi binary clean_test\n   &lt;chr&gt;                &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n 1 Dredd 3D              2012   55078343    45658735  1.21 PASS   ok        \n 2 About Time            2013  102648667    12000000  8.55 PASS   ok        \n 3 Admission             2013   36014634    13000000  2.77 PASS   ok        \n 4 American Hustle       2013  397915817    40000000  9.95 PASS   ok        \n 5 August: Osage County  2013   87609748    25000000  3.50 PASS   ok        \n 6 Beautiful Creatures   2013   75392809    50000000  1.51 PASS   ok        \n 7 Blue Jasmine          2013  101793664    18000000  5.66 PASS   ok        \n 8 Carrie                2013  120268278    30000000  4.01 PASS   ok        \n 9 Despicable Me 2       2013 1338831390    76000000 17.6  PASS   ok        \n10 Elysium               2013  379242208   120000000  3.16 PASS   ok        \n# ℹ 743 more rows"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-2",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-2",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nArrange the rows in descending order of roi:\n\nbechdel |&gt;\n  filter(binary == \"PASS\") |&gt;\n  arrange(desc(roi))\n\n# A tibble: 753 × 7\n   title                     year gross_2013 budget_2013   roi binary clean_test\n   &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n 1 The Blair Witch Project   1999  543776715      839077 648.  PASS   ok        \n 2 The Devil Inside          2012  157289709     1014639 155.  PASS   ok        \n 3 My Big Fat Greek Wedding  2002  768922942     6475896 119.  PASS   ok        \n 4 Chasing Amy               1997   39417963      362810 109.  PASS   ok        \n 5 Slacker                   1991    4200140       39349 107.  PASS   ok        \n 6 Insidious                 2010  164379554     1602348 103.  PASS   ok        \n 7 Paranormal Activity 2     2010  280159759     3204696  87.4 PASS   ok        \n 8 Paranormal Activity 3     2011  322170936     5178454  62.2 PASS   ok        \n 9 The Last Exorcism         2010  118787648     1922817  61.8 PASS   ok        \n10 Cinderella                1997  246710482     4208591  58.6 PASS   ok        \n# ℹ 743 more rows"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-3",
    "href": "slides/03-grammar-of-data-transformation.html#the-pipe-in-action-3",
    "title": "Grammar of data transformation",
    "section": "The pipe, in action",
    "text": "The pipe, in action\n\nFind movies that pass the Bechdel test and display their titles and ROIs in descending order of ROI.\n\nSelect columns title and roi:\n\nbechdel |&gt;\n  filter(binary == \"PASS\") |&gt;\n  arrange(desc(roi)) |&gt;\n  select(title, roi)\n\n# A tibble: 753 × 2\n   title                      roi\n   &lt;chr&gt;                    &lt;dbl&gt;\n 1 The Blair Witch Project  648. \n 2 The Devil Inside         155. \n 3 My Big Fat Greek Wedding 119. \n 4 Chasing Amy              109. \n 5 Slacker                  107. \n 6 Insidious                103. \n 7 Paranormal Activity 2     87.4\n 8 Paranormal Activity 3     62.2\n 9 The Last Exorcism         61.8\n10 Cinderella                58.6\n# ℹ 743 more rows"
  },
  {
    "objectID": "slides/03-grammar-of-data-transformation.html#in-this-class-you-will",
    "href": "slides/03-grammar-of-data-transformation.html#in-this-class-you-will",
    "title": "Grammar of data transformation",
    "section": "In this class, you will…",
    "text": "In this class, you will…\n\n\nBuild cakes (ggplot) \n\nStack dolls (pipe |&gt;) \n\n\nMaster these constructs, and everything will be coming up roses!"
  },
  {
    "objectID": "slides/06-tidying-data.html#while-you-wait",
    "href": "slides/06-tidying-data.html#while-you-wait",
    "title": "Tidying data",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-05-majors-tidy\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-05-majors-tidy.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file.\n\n\n\n\n\n\n\n\nAEs are due by the end of class\n\n\nSuccessful completion means at least one commit + push by 2PM today"
  },
  {
    "objectID": "slides/06-tidying-data.html#intro-to-coding-principles-with-dav-king",
    "href": "slides/06-tidying-data.html#intro-to-coding-principles-with-dav-king",
    "title": "Tidying data",
    "section": "Intro to Coding Principles with Dav King",
    "text": "Intro to Coding Principles with Dav King\n\n\n\n8:30 PM Tonight!;\nSocial Sciences 139;\nSpace is limited, so please sign up;\nMaterials will be posted afterward;\nWe might do more if there is interest and Dav is available.\n\n\n\n\n:::"
  },
  {
    "objectID": "slides/06-tidying-data.html#syllabus-clarifications",
    "href": "slides/06-tidying-data.html#syllabus-clarifications",
    "title": "Tidying data",
    "section": "Syllabus clarifications",
    "text": "Syllabus clarifications\n\n\nYou can miss 30% of AEs before it starts affecting your final grade. This policy is meant to smooth over technical mishaps, absences due to illness, athletics, etc. So we’re generally not granting extensions or exemptions. Just let the 30% policy do its thing;\nChatGPT: Thank (most of) you for citing! But please do not just dump the question verbatim into the chat. It irritates my valve;\n\nLab grade includes workflow points:\n\nGit was configured successfully such that a GitHub name is associated with the commit on GitHub (i.e., did Lab 0 successfully).\nPDF exists in GitHub repo for lab.\nAt least 3 commits were made and pushed to the GitHub repo for lab."
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-logical-operators",
    "href": "slides/06-tidying-data.html#miscellany-logical-operators",
    "title": "Tidying data",
    "section": "Miscellany: logical operators",
    "text": "Miscellany: logical operators\nGenerally useful in a filter() but will come up in various other places as well…\n\n\n\n\n\n\noperator\ndefinition\n\n\n\n&lt;\nis less than?\n\n\n&lt;=\nis less than or equal to?\n\n\n&gt;\nis greater than?\n\n\n&gt;=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-logical-operators-cont.",
    "href": "slides/06-tidying-data.html#miscellany-logical-operators-cont.",
    "title": "Tidying data",
    "section": "Miscellany: logical operators (cont.)",
    "text": "Miscellany: logical operators (cont.)\nGenerally useful in a filter() but will come up in various other places as well…\n\n\n\n\n\n\noperator\ndefinition\n\n\n\nx & y\nis x AND y?\n\n\nx | y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x? (only makes sense if x is TRUE or FALSE)"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment",
    "href": "slides/06-tidying-data.html#miscellany-assignment",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\nLet’s make a tiny data frame to use as an example:\n\ndf &lt;- tibble(x = c(1, 2, 3, 4, 5), y = c(\"a\", \"a\", \"b\", \"c\", \"c\"))\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 a    \n2     2 a    \n3     3 b    \n4     4 c    \n5     5 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-1",
    "href": "slides/06-tidying-data.html#miscellany-assignment-1",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\nSuppose you run the following and then you inspect df, will the x variable have values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\ndf |&gt;\n  mutate(x = x * 2)\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\ndf"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-2",
    "href": "slides/06-tidying-data.html#miscellany-assignment-2",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\nSuppose you run the following and then you inspect df, will the x variable have values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\ndf |&gt;\n  mutate(x = x * 2)\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 a    \n2     2 a    \n3     3 b    \n4     4 c    \n5     5 c    \n\n\n\n\n\n\nDo something and show me"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-3",
    "href": "slides/06-tidying-data.html#miscellany-assignment-3",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\nSuppose you run the following and then you inspect df, will the x variable has values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\n\n\n\ndf"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-4",
    "href": "slides/06-tidying-data.html#miscellany-assignment-4",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\nSuppose you run the following and then you inspect df, will the x variable has values 1, 2, 3, 4, 5 or 2, 4, 6, 8, 10?\n\n\n\n\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\n\n\n\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\n\n\nDo something and save result"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-5",
    "href": "slides/06-tidying-data.html#miscellany-assignment-5",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\n\n\nDo something, save result, overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x * 2)\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c    \n\n\n\n\n\nDo something, save result, not overwriting original\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_new &lt;- df |&gt;\n  mutate(x = x * 2)\ndf_new\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     2 a    \n2     4 a    \n3     6 b    \n4     8 c    \n5    10 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-6",
    "href": "slides/06-tidying-data.html#miscellany-assignment-6",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\n\n\nDo something, save result, overwriting original when you shouldn’t\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf\n\n# A tibble: 3 × 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5\n\n\n\n\n\nDo something, save result, not overwriting original when you shouldn’t\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf_summary &lt;- df |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\ndf_summary\n\n# A tibble: 3 × 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a        1.5\n2 b        3  \n3 c        4.5"
  },
  {
    "objectID": "slides/06-tidying-data.html#miscellany-assignment-7",
    "href": "slides/06-tidying-data.html#miscellany-assignment-7",
    "title": "Tidying data",
    "section": "Miscellany: assignment",
    "text": "Miscellany: assignment\n\n\n\nDo something, save result, overwriting originaldata frame\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(z = x + 2)\ndf\n\n# A tibble: 5 × 3\n      x y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a         3\n2     2 a         4\n3     3 b         5\n4     4 c         6\n5     5 c         7\n\n\n\n\n\nDo something, save result, overwriting originalcolumn\n\n\ndf &lt;- tibble(\n  x = c(1, 2, 3, 4, 5), \n  y = c(\"a\", \"a\", \"b\", \"c\", \"c\")\n)\ndf &lt;- df |&gt;\n  mutate(x = x + 2)\ndf\n\n# A tibble: 5 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     3 a    \n2     4 a    \n3     5 b    \n4     6 c    \n5     7 c"
  },
  {
    "objectID": "slides/06-tidying-data.html#tidy-data",
    "href": "slides/06-tidying-data.html#tidy-data",
    "title": "Tidying data",
    "section": "Tidy data",
    "text": "Tidy data\n\n“Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.”\nTidy Data, https://vita.had.co.nz/papers/tidy-data.pdf\n\n\nNote: “easy to manipulate” = “straightforward to manipulate”"
  },
  {
    "objectID": "slides/06-tidying-data.html#goal",
    "href": "slides/06-tidying-data.html#goal",
    "title": "Tidying data",
    "section": "Goal",
    "text": "Goal\nVisualize StatSci majors over the years!"
  },
  {
    "objectID": "slides/06-tidying-data.html#data",
    "href": "slides/06-tidying-data.html#data",
    "title": "Tidying data",
    "section": "Data",
    "text": "Data\n\nstatsci &lt;- read_csv(\"data/statsci.csv\")\nstatsci\n\n# A tibble: 4 × 15\n  degree   `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019` `2020`\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Statist…     NA      1     NA     NA      4      4      1     NA     NA      1\n2 Statist…      2      2      4      1      3      6      3      4      4      1\n3 Statist…      2      6      1     NA      5      6      6      8      8     17\n4 Statist…      5      9      4     13     10     17     24     21     26     27\n# ℹ 4 more variables: `2021` &lt;dbl&gt;, `2022` &lt;dbl&gt;, `2023` &lt;dbl&gt;, `2024` &lt;dbl&gt;\n\n\n\nThe first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major).\nThe remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2024."
  },
  {
    "objectID": "slides/06-tidying-data.html#lets-plan",
    "href": "slides/06-tidying-data.html#lets-plan",
    "title": "Tidying data",
    "section": "Let’s plan!",
    "text": "Let’s plan!\nIn a perfect world, how would our data be formatted to create this plot? What do the columns need to be? What would go inside aes when we call ggplot?"
  },
  {
    "objectID": "slides/06-tidying-data.html#the-goal",
    "href": "slides/06-tidying-data.html#the-goal",
    "title": "Tidying data",
    "section": "The goal",
    "text": "The goal\nWe want to be able to write code that starts something like this:\n\nggplot(statsci, aes(x = year, y = n, color = degree_type)) + \n  ...\n\nBut the data are not in a format that will allow us to do that."
  },
  {
    "objectID": "slides/06-tidying-data.html#the-challenge",
    "href": "slides/06-tidying-data.html#the-challenge",
    "title": "Tidying data",
    "section": "The challenge",
    "text": "The challenge\n\n\n\nHow do we go from this…\n\n\n\n# A tibble: 4 × 8\n  degree `2011` `2012` `2013` `2014` `2015` `2016` `2017`\n  &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 AB2        NA      1     NA     NA      4      4      1\n2 AB          2      2      4      1      3      6      3\n3 BS2         2      6      1     NA      5      6      6\n4 BS          5      9      4     13     10     17     24\n\n\n\n\n\n…to this?\n\n\n\n# A tibble: 56 × 3\n   degree_type  year     n\n   &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 AB2          2011     0\n 2 AB2          2012     1\n 3 AB2          2013     0\n 4 AB2          2014     0\n 5 AB2          2015     4\n 6 AB2          2016     4\n 7 AB2          2017     1\n 8 AB2          2018     0\n 9 AB2          2019     0\n10 AB2          2020     1\n11 AB2          2021     2\n12 AB2          2022     0\n13 AB2          2023     3\n14 AB2          2024     1\n15 AB           2011     2\n16 AB           2012     2\n# ℹ 40 more rows\n\n\n\n\n\nWith the command pivot_longer()!"
  },
  {
    "objectID": "slides/06-tidying-data.html#pivot_longer",
    "href": "slides/06-tidying-data.html#pivot_longer",
    "title": "Tidying data",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\nPivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    values_to = \"n\"\n  )\n\n# A tibble: 56 × 3\n   degree                    year      n\n   &lt;chr&gt;                     &lt;chr&gt; &lt;dbl&gt;\n 1 Statistical Science (AB2) 2011     NA\n 2 Statistical Science (AB2) 2012      1\n 3 Statistical Science (AB2) 2013     NA\n 4 Statistical Science (AB2) 2014     NA\n 5 Statistical Science (AB2) 2015      4\n 6 Statistical Science (AB2) 2016      4\n 7 Statistical Science (AB2) 2017      1\n 8 Statistical Science (AB2) 2018     NA\n 9 Statistical Science (AB2) 2019     NA\n10 Statistical Science (AB2) 2020      1\n# ℹ 46 more rows"
  },
  {
    "objectID": "slides/06-tidying-data.html#year",
    "href": "slides/06-tidying-data.html#year",
    "title": "Tidying data",
    "section": "year",
    "text": "year\n\nWhat is the type of the year variable? Why? What should it be?\n\n\nIt’s a character (chr) variable since the information came from the columns of the original data frame and R cannot know that these character strings represent years. The variable type should be numeric."
  },
  {
    "objectID": "slides/06-tidying-data.html#pivot_longer-again",
    "href": "slides/06-tidying-data.html#pivot_longer-again",
    "title": "Tidying data",
    "section": "\npivot_longer() again",
    "text": "pivot_longer() again\n\nStart over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    values_to = \"n\",\n    names_transform = as.numeric,\n  )\n\n# A tibble: 56 × 3\n   degree                     year     n\n   &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science (AB2)  2011    NA\n 2 Statistical Science (AB2)  2012     1\n 3 Statistical Science (AB2)  2013    NA\n 4 Statistical Science (AB2)  2014    NA\n 5 Statistical Science (AB2)  2015     4\n 6 Statistical Science (AB2)  2016     4\n 7 Statistical Science (AB2)  2017     1\n 8 Statistical Science (AB2)  2018    NA\n 9 Statistical Science (AB2)  2019    NA\n10 Statistical Science (AB2)  2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "slides/06-tidying-data.html#na-counts",
    "href": "slides/06-tidying-data.html#na-counts",
    "title": "Tidying data",
    "section": "\nNA counts",
    "text": "NA counts\n\nWhat does an NA mean in this context? Hint: The data come from the university registrar, and they have records on every single graduates, there shouldn’t be anything “unknown” to them about who graduated when.\n\n\nNAs should actually be 0s."
  },
  {
    "objectID": "slides/06-tidying-data.html#clean-up",
    "href": "slides/06-tidying-data.html#clean-up",
    "title": "Tidying data",
    "section": "Clean-up",
    "text": "Clean-up\n\nAdd on to your pipeline that you started with pivoting and convert NAs in n to 0s.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n))\n\n# A tibble: 56 × 3\n   degree                     year     n\n   &lt;chr&gt;                     &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science (AB2)  2011     0\n 2 Statistical Science (AB2)  2012     1\n 3 Statistical Science (AB2)  2013     0\n 4 Statistical Science (AB2)  2014     0\n 5 Statistical Science (AB2)  2015     4\n 6 Statistical Science (AB2)  2016     4\n 7 Statistical Science (AB2)  2017     1\n 8 Statistical Science (AB2)  2018     0\n 9 Statistical Science (AB2)  2019     0\n10 Statistical Science (AB2)  2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "slides/06-tidying-data.html#more-clean-up",
    "href": "slides/06-tidying-data.html#more-clean-up",
    "title": "Tidying data",
    "section": "More clean-up",
    "text": "More clean-up\n\nIn our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don’t need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree. Do this by adding on to your pipeline from earlier.\n\n\nstatsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n  )\n\n# A tibble: 56 × 4\n   major               degree_type  year     n\n   &lt;chr&gt;               &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 Statistical Science AB2          2011     0\n 2 Statistical Science AB2          2012     1\n 3 Statistical Science AB2          2013     0\n 4 Statistical Science AB2          2014     0\n 5 Statistical Science AB2          2015     4\n 6 Statistical Science AB2          2016     4\n 7 Statistical Science AB2          2017     1\n 8 Statistical Science AB2          2018     0\n 9 Statistical Science AB2          2019     0\n10 Statistical Science AB2          2020     1\n# ℹ 46 more rows"
  },
  {
    "objectID": "slides/06-tidying-data.html#finish",
    "href": "slides/06-tidying-data.html#finish",
    "title": "Tidying data",
    "section": "Finish",
    "text": "Finish\n\nNow that you have your data pivoting and cleaning pipeline figured out, save the resulting data frame as statsci_longer.\n\n\nstatsci_longer &lt;- statsci |&gt;\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |&gt;\n  mutate(n = if_else(is.na(n), 0, n)) |&gt;\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |&gt;\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n  )"
  },
  {
    "objectID": "slides/06-tidying-data.html#ae-05-majors-tidy",
    "href": "slides/06-tidying-data.html#ae-05-majors-tidy",
    "title": "Tidying data",
    "section": "ae-05-majors-tidy",
    "text": "ae-05-majors-tidy\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-05-majors-tidy.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/06-tidying-data.html#recap-pivoting",
    "href": "slides/06-tidying-data.html#recap-pivoting",
    "title": "Tidying data",
    "section": "Recap: pivoting",
    "text": "Recap: pivoting\n\n\nData sets can’t be labeled as wide or long but they can be made wider or longer for a certain analysis that requires a certain format\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate."
  },
  {
    "objectID": "slides/00-welcome.html#teaching-team-a-glamorous-assemblage",
    "href": "slides/00-welcome.html#teaching-team-a-glamorous-assemblage",
    "title": "Welcome to STA 199!",
    "section": "Teaching team: a glamorous assemblage",
    "text": "Teaching team: a glamorous assemblage\n\n\nCaitrin Murphy\nHan Chen\nKatie Solarz\nHyunjin Lee\nJasmine Wang\nLiane Ma\nAvery Hodges\nAlexa Fahrer\nDomenic Fenoglio\nJulia Healey-Parera\nDavid King\nLisa Zhang\n\nEduardo Vasquez\nArijit Dey\nFederico Arboleda\nSarah Wu\nLi Fan\nDevarpita Bag\nNetra Mittal\nNatasha Harris\nSonya Eason\nNoah Obuya\nMary Knox\nJohn Zito"
  },
  {
    "objectID": "slides/00-welcome.html#what-are-we-studying",
    "href": "slides/00-welcome.html#what-are-we-studying",
    "title": "Welcome to STA 199!",
    "section": "What are we studying?",
    "text": "What are we studying?\n\n\n\n\n\n\nData science\n\n\nTransforming messy, incomplete, imperfect data into knowledge.\n\n\n\n\n\n\n\n\n\nStatistical thinking\n\n\nQuantifying our uncertainty about that knowledge."
  },
  {
    "objectID": "slides/00-welcome.html#the-data-science-life-cycle",
    "href": "slides/00-welcome.html#the-data-science-life-cycle",
    "title": "Welcome to STA 199!",
    "section": "The data science life cycle",
    "text": "The data science life cycle"
  },
  {
    "objectID": "slides/00-welcome.html#homepage",
    "href": "slides/00-welcome.html#homepage",
    "title": "Welcome to STA 199!",
    "section": "Homepage",
    "text": "Homepage\nhttps://sta199-s25.github.io\n\nAll course materials\nLinks to Canvas, GitHub, RStudio containers, etc."
  },
  {
    "objectID": "slides/00-welcome.html#course-toolkit",
    "href": "slides/00-welcome.html#course-toolkit",
    "title": "Welcome to STA 199!",
    "section": "Course toolkit",
    "text": "Course toolkit\nAll linked from the course website:\n\nGitHub organization: github.com/sta199-s25\n\nRStudio containers: cmgr.oit.duke.edu/containers\n\nCommunication: Ed Discussion\nAssignment submission and feedback: Gradescope"
  },
  {
    "objectID": "slides/00-welcome.html#activities",
    "href": "slides/00-welcome.html#activities",
    "title": "Welcome to STA 199!",
    "section": "Activities",
    "text": "Activities\n\nIntroduce new content and prepare for lectures by watching the videos and completing the readings\nAttend and actively participate in lectures and labs, office hours, team meetings\nPractice applying statistical concepts and computing with application exercises during lecture, graded for attempting\nPut together what you’ve learned to analyze real-world data\n\nLab assignments (7 or 8 throughout semester)\nExams (midterm x 2 + final)\nTerm project completed in teams"
  },
  {
    "objectID": "slides/00-welcome.html#application-exercises",
    "href": "slides/00-welcome.html#application-exercises",
    "title": "Welcome to STA 199!",
    "section": "Application exercises",
    "text": "Application exercises\n\nDaily-ish in lecture\n“Graded” for attempt, not accuracy\nPractice Weeks 1 + 2, graded thereafter\nAt least one commit by 2 pm of the day of lecture\nTurn in at least 70% for full credit"
  },
  {
    "objectID": "slides/00-welcome.html#labs",
    "href": "slides/00-welcome.html#labs",
    "title": "Welcome to STA 199!",
    "section": "Labs",
    "text": "Labs\n\nStart in lab session\nComplete at home\nDue within a week\nDiscussion with classmates ok, copying not ok!\nLowest score dropped"
  },
  {
    "objectID": "slides/00-welcome.html#exams",
    "href": "slides/00-welcome.html#exams",
    "title": "Welcome to STA 199!",
    "section": "Exams",
    "text": "Exams\n\nThree exams, each 20%\n\nMidterm comprised of two parts:\n\nIn-class: 75 minute in-class exam. Closed book, one sheet of notes (“cheat sheet”) – 70% of the grade.\nTake-home: Follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam – 30% of the grade.\n\n\nFinal in-class only (Apr 29, 9am - 12pm): Closed book, one sheet of notes (“cheat sheet”).\n“Cheat sheet”: No larger than 8.5” x 11”, both sides, must be prepared by you.\n\n\n\n\n\n\n\nCaution\n\n\nExam dates cannot be changed and no make-up exams will be given. If you can’t take the exams on these dates, you should drop this class."
  },
  {
    "objectID": "slides/00-welcome.html#project",
    "href": "slides/00-welcome.html#project",
    "title": "Welcome to STA 199!",
    "section": "Project",
    "text": "Project\n\nDataset of your choice, method of your choice\nTeamwork\nFive milestones, interim deadline throughout semester\nFinal milestone: Presentation (video) and write-up\nPresentations submitted as videos\nPeer review between teams for content, peer evaluation within teams for contribution\nSome lab sessions allocated to project progress\n\n\n\n\n\n\n\nCaution\n\n\nProject due date cannot be changed. You must complete the project to pass this class."
  },
  {
    "objectID": "slides/00-welcome.html#teams-of-4---5",
    "href": "slides/00-welcome.html#teams-of-4---5",
    "title": "Welcome to STA 199!",
    "section": "Teams of 4 - 5",
    "text": "Teams of 4 - 5\n\nAssigned by us within your lab section\n\nProject\nPeer evaluation during teamwork and after completion\nExpectations and roles\n\nEveryone is expected to contribute equal effort\n\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "slides/00-welcome.html#grading",
    "href": "slides/00-welcome.html#grading",
    "title": "Welcome to STA 199!",
    "section": "Grading",
    "text": "Grading\n\n\nCategory\nPercentage\n\n\n\nApplication Exercises\n5%\n\n\nLabs\n15%\n\n\nMidterm 1\n20%\n\n\nMidterm 2\n20%\n\n\nFinal\n20%\n\n\nProject\n20%\n\n\n\nNo specific points allocated to attendance, but the application exercise score is implicitly tied to attendance.\nSee course syllabus for how the final letter grade will be determined."
  },
  {
    "objectID": "slides/00-welcome.html#wiggle-room",
    "href": "slides/00-welcome.html#wiggle-room",
    "title": "Welcome to STA 199!",
    "section": "Wiggle room",
    "text": "Wiggle room\n\nYou only have to complete 70% of the AEs to receive full credit;\nWe drop the lowest lab score;\nWe replace the lowest in-class midterm score with your final exam score (if it’s better)."
  },
  {
    "objectID": "slides/00-welcome.html#support",
    "href": "slides/00-welcome.html#support",
    "title": "Welcome to STA 199!",
    "section": "Support",
    "text": "Support\n\nHelp from humans:\n\nAttend office hours\nAsk and answer questions on the discussion forum\n\n\nReserve email for questions on personal matters and/or grades\nRead the course support page"
  },
  {
    "objectID": "slides/00-welcome.html#announcements",
    "href": "slides/00-welcome.html#announcements",
    "title": "Welcome to STA 199!",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Canvas (Announcements tool) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day\nI’ll (try my best to) send a weekly update announcement each Friday, outlining the plan for the following week and reminding you what you need to do to prepare, practice, and perform"
  },
  {
    "objectID": "slides/00-welcome.html#accessibility",
    "href": "slides/00-welcome.html#accessibility",
    "title": "Welcome to STA 199!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know.\n\n\n\n\n\n\n\nIf you need testing accommodations\n\n\nMake sure I get a letter, and make your appointments in the Testing Center now."
  },
  {
    "objectID": "slides/00-welcome.html#late-work-waivers-lecture-recordings-regrades",
    "href": "slides/00-welcome.html#late-work-waivers-lecture-recordings-regrades",
    "title": "Welcome to STA 199!",
    "section": "Late work, waivers, lecture recordings, regrades…",
    "text": "Late work, waivers, lecture recordings, regrades…\n\nWe have policies!\nRead about them on the course syllabus and refer back to them when you need it"
  },
  {
    "objectID": "slides/00-welcome.html#collaboration",
    "href": "slides/00-welcome.html#collaboration",
    "title": "Welcome to STA 199!",
    "section": "Collaboration",
    "text": "Collaboration\n\nLabs: discussing and helping is fine. Sharing your solutions and copying others is not;\nExams: collaboration of any kind is completely forbidden on any part of any exam;\nProjects: collaboration of any kind is enthusiastically encouraged within your team. Between teams, it’s the same as labs; do not directly share your stuff or copy off of others."
  },
  {
    "objectID": "slides/00-welcome.html#use-of-ai-tools",
    "href": "slides/00-welcome.html#use-of-ai-tools",
    "title": "Welcome to STA 199!",
    "section": "Use of AI tools",
    "text": "Use of AI tools\n\n\n AI tools for code:\n\nSure, but be careful/critical! Working code != correct/good code.\nMust explicitly cite with a direct url linking to the conversation you had.\n\n\n AI tools for narrative: Absolutely not!\n AI tools for learning: Sure, but be careful/critical!"
  },
  {
    "objectID": "slides/00-welcome.html#academic-integrity",
    "href": "slides/00-welcome.html#academic-integrity",
    "title": "Welcome to STA 199!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\nZeros from conduct violations will not be dropped or replaced;\nIf people are copying, sharer and recipients penalized equally. It does not matter how well-intentioned everyone was;\nIf we discover violations, they go straight to the conduct office."
  },
  {
    "objectID": "slides/00-welcome.html#how-old-is-this-person",
    "href": "slides/00-welcome.html#how-old-is-this-person",
    "title": "Welcome to STA 199!",
    "section": "How old is this person?",
    "text": "How old is this person?\n\n\n\n \n\n\n\n\nEthel Merman"
  },
  {
    "objectID": "slides/00-welcome.html#ethel-merman",
    "href": "slides/00-welcome.html#ethel-merman",
    "title": "Welcome to STA 199!",
    "section": "Ethel Merman",
    "text": "Ethel Merman\n\n\n\n\n\n\nBorn\nJanuary 16, 1908\n\n\nDied\nFebruary 15, 1984\n\n\nAge\n76\n\n\nClaim to fame\nJZ’s favorite singer"
  },
  {
    "objectID": "slides/00-welcome.html#how-old-is-this-person-1",
    "href": "slides/00-welcome.html#how-old-is-this-person-1",
    "title": "Welcome to STA 199!",
    "section": "How old is this person?",
    "text": "How old is this person?\n\n\n\n \n\n\n\n\nMegan Pete"
  },
  {
    "objectID": "slides/00-welcome.html#megan-thee-stallion",
    "href": "slides/00-welcome.html#megan-thee-stallion",
    "title": "Welcome to STA 199!",
    "section": "Megan Thee Stallion",
    "text": "Megan Thee Stallion\n\n\n\n\n\n\nBorn\nFebruary 15, 1995\n\n\nAge\n29\n\n\nClaim to fame\nRapper"
  },
  {
    "objectID": "slides/00-welcome.html#how-old-is-this-person-2",
    "href": "slides/00-welcome.html#how-old-is-this-person-2",
    "title": "Welcome to STA 199!",
    "section": "How old is this person?",
    "text": "How old is this person?\n\n\n\n \n\n\n\n\n봉준호"
  },
  {
    "objectID": "slides/00-welcome.html#bong-joon-ho",
    "href": "slides/00-welcome.html#bong-joon-ho",
    "title": "Welcome to STA 199!",
    "section": "Bong Joon-ho",
    "text": "Bong Joon-ho\n\n\n\n\n\n\nBorn\nSeptember 14, 1969\n\n\nAge\n55\n\n\nClaim to fame\nDirected Parasite, Snowpiercer, etc"
  },
  {
    "objectID": "slides/00-welcome.html#now-do-it-with-pictures",
    "href": "slides/00-welcome.html#now-do-it-with-pictures",
    "title": "Welcome to STA 199!",
    "section": "Now do it with pictures…",
    "text": "Now do it with pictures…\n\n\nWhen the picture was taken, how old was the person?"
  },
  {
    "objectID": "slides/00-welcome.html#managing-expectations",
    "href": "slides/00-welcome.html#managing-expectations",
    "title": "Welcome to STA 199!",
    "section": "Managing expectations",
    "text": "Managing expectations\nThe stakes are low today. We’re just getting our feet wet and working out the kinks:\n\n\nIt’s the first time all 300+ of us are attempting to access our containers simultaneously. It may choke;\nIf you get stuck on a loading screen of some kind, be patient and let it do its thing. Refreshing, reloading, etc will just amplify our collective problem;\nIf yours never loads, no big deal. Just sit back and watch me, or follow along on a neighbor’s screen;\nEven if yours does load, you’re welcome to just watch."
  },
  {
    "objectID": "slides/00-welcome.html#yuja-wang",
    "href": "slides/00-welcome.html#yuja-wang",
    "title": "Welcome to STA 199!",
    "section": "Yuja Wang",
    "text": "Yuja Wang\n\n\n\n\n\n\n\n\n\nBorn\n2/10/1987\n\n\nAge in pic\n36\n\n\nClaim to fame\nClassical pianist"
  },
  {
    "objectID": "slides/00-welcome.html#im-sure-shed-be-pleased",
    "href": "slides/00-welcome.html#im-sure-shed-be-pleased",
    "title": "Welcome to STA 199!",
    "section": "I’m sure she’d be pleased",
    "text": "I’m sure she’d be pleased"
  },
  {
    "objectID": "slides/00-welcome.html#joan-crawford",
    "href": "slides/00-welcome.html#joan-crawford",
    "title": "Welcome to STA 199!",
    "section": "Joan Crawford",
    "text": "Joan Crawford\nA secret she took to her grave:\n\n\n\n\n\n\n\n\n\nBorn\n3/23/(1904 - 1908)\n\n\nDied\n5/10/1977\n\n\nAge in pic\n38 - 42\n\n\nClaim to fame\nOscar-winning actor"
  },
  {
    "objectID": "slides/00-welcome.html#well-never-know",
    "href": "slides/00-welcome.html#well-never-know",
    "title": "Welcome to STA 199!",
    "section": "We’ll never know…",
    "text": "We’ll never know…"
  },
  {
    "objectID": "slides/00-welcome.html#eubie-blake",
    "href": "slides/00-welcome.html#eubie-blake",
    "title": "Welcome to STA 199!",
    "section": "Eubie Blake",
    "text": "Eubie Blake\nHis actual birthday was not known at the time:\n\n\n\n\n\n\n\n\n\nBorn\n2/7/1887\n\n\nDied\n2/12/1983\n\n\nAge in pic\n82\n\n\nClaim to fame\nComposer"
  },
  {
    "objectID": "slides/00-welcome.html#lol-that-bar-at-86",
    "href": "slides/00-welcome.html#lol-that-bar-at-86",
    "title": "Welcome to STA 199!",
    "section": "lol that bar at 86",
    "text": "lol that bar at 86"
  },
  {
    "objectID": "slides/00-welcome.html#watch-out-for-data-quality",
    "href": "slides/00-welcome.html#watch-out-for-data-quality",
    "title": "Welcome to STA 199!",
    "section": "Watch out for data quality!",
    "text": "Watch out for data quality!"
  },
  {
    "objectID": "slides/00-welcome.html#raghuram-rajan",
    "href": "slides/00-welcome.html#raghuram-rajan",
    "title": "Welcome to STA 199!",
    "section": "Raghuram Rajan",
    "text": "Raghuram Rajan\n\n\n\n\n\n\nBorn\n2/3/1963\n\n\nAge in pic\n48\n\n\nClaim to fame\nUChicago economist\n\n\n\nRBI governor"
  },
  {
    "objectID": "slides/00-welcome.html#youre-natural-denoisers",
    "href": "slides/00-welcome.html#youre-natural-denoisers",
    "title": "Welcome to STA 199!",
    "section": "You’re natural denoisers!",
    "text": "You’re natural denoisers!"
  },
  {
    "objectID": "slides/00-welcome.html#james-gandolfini",
    "href": "slides/00-welcome.html#james-gandolfini",
    "title": "Welcome to STA 199!",
    "section": "James Gandolfini",
    "text": "James Gandolfini\n\n\n\n\n\n\n\n\n\nBorn\n9/18/1961\n\n\nDied\n6/19/2013\n\n\nAge in pic\n51\n\n\nClaim to fame\nplayed Tony Soprano"
  },
  {
    "objectID": "slides/00-welcome.html#the-wisdom-of-crowds",
    "href": "slides/00-welcome.html#the-wisdom-of-crowds",
    "title": "Welcome to STA 199!",
    "section": "The wisdom of crowds",
    "text": "The wisdom of crowds"
  },
  {
    "objectID": "slides/00-welcome.html#celia-cruz",
    "href": "slides/00-welcome.html#celia-cruz",
    "title": "Welcome to STA 199!",
    "section": "Celia Cruz",
    "text": "Celia Cruz\n\n\n\n\n\n\n\n\n\nBorn\n10/21/1925\n\n\nDied\n7/16/2003\n\n\nAge in pic\n76\n\n\nClaim to fame\nQueen of Salsa"
  },
  {
    "objectID": "slides/00-welcome.html#azúcar",
    "href": "slides/00-welcome.html#azúcar",
    "title": "Welcome to STA 199!",
    "section": "¡Azúcar!",
    "text": "¡Azúcar!"
  },
  {
    "objectID": "slides/00-welcome.html#our-best-guessers",
    "href": "slides/00-welcome.html#our-best-guessers",
    "title": "Welcome to STA 199!",
    "section": "Our best guessers",
    "text": "Our best guessers\n\n\n\nTruth\nNo. 1\nNo. 2\nNo. 4\nNo. 4\n\n\n\nWang\n36\n34\n36\n27\n34\n\n\nCrawford\n40?\n38\n42\n33\n40\n\n\nBlake\n82\n77\n74\n80\n72\n\n\nRajan\n48\n50\n50\n45\n53\n\n\nGandolfini\n51\n58\n48\n50\n46\n\n\nCruz\n76\n72\n68\n73\n73\n\n\n\n\n3.66\n3.83\n4.16\n4.16"
  },
  {
    "objectID": "slides/00-welcome.html#whence-ggplot",
    "href": "slides/00-welcome.html#whence-ggplot",
    "title": "Welcome to STA 199!",
    "section": "Whence ggplot?",
    "text": "Whence ggplot?"
  },
  {
    "objectID": "slides/00-welcome.html#statistical-lessons",
    "href": "slides/00-welcome.html#statistical-lessons",
    "title": "Welcome to STA 199!",
    "section": "Statistical lessons",
    "text": "Statistical lessons\n\n\nDomain knowledge and modeling assumptions: data do not speak for themselves. You need some subject-matter expertise about what you’re studying, as well as an interpretive lens;\nAre you asking questions the data can actually answer?\nUncertainty has many sources, and in some cases, it may be simply irreducible, no matter how hard you try;\n\nData quality and data cleaning: Data are not gospel. There could be noise and mistakes. Then what?\n\nWisdom of crowds: aggregating many imperfect guesses can do better than any one individual guess."
  },
  {
    "objectID": "slides/00-welcome.html#hard-skills",
    "href": "slides/00-welcome.html#hard-skills",
    "title": "Welcome to STA 199!",
    "section": "Hard skills",
    "text": "Hard skills\n\nGitHub repositories: cloning and pulling;\nWorking with data in CSV format;\nRendering a Quarto document to get PDFs that seamlessly integrate written text, code, and output;\nUsing ggplot to build up visualizations in layers, like a cake.\n\n\n\n\n\n\n\nGet ready\n\n\nYou will do all of these things on a weekly basis in this course."
  },
  {
    "objectID": "slides/00-welcome.html#this-weeks-tasks",
    "href": "slides/00-welcome.html#this-weeks-tasks",
    "title": "Welcome to STA 199!",
    "section": "This week’s tasks",
    "text": "This week’s tasks\n\nComplete Lab 0\n\nComputational setup\nGetting to know you survey\n\n\nRead the syllabus and ask questions on Ed\nComplete readings and videos for next class\nAccept your invitation to the GitHub organization pronto!"
  },
  {
    "objectID": "slides/10-more-practice.html#midterm-exam-1",
    "href": "slides/10-more-practice.html#midterm-exam-1",
    "title": "More practice",
    "section": "Midterm Exam 1",
    "text": "Midterm Exam 1\n\n\nIn-class (70%)\n\nThursday February 20 11:45 AM - 1:00 PM;\nAll multiple choice;\nYou should have gotten an email about room assignment;\n8.5” x 11” cheat sheet.\n\n\n\nTake-home (30%)\n\nReleased Thursday February 20 at 1:00 PM;\nDue Monday February 24 at 8:30 AM.\nBasically a mini lab;\nOpen resource (citation policies apply);\nNo collaboration.\n\n\n\nSee slides from 2/11 for more details."
  },
  {
    "objectID": "slides/10-more-practice.html#code-smell",
    "href": "slides/10-more-practice.html#code-smell",
    "title": "More practice",
    "section": "Code smell",
    "text": "Code smell\n\nOne way to look at smells is with respect to principles and quality: “Smells are certain structures in the code that indicate violation of fundamental design principles and negatively impact design quality”. Code smells are usually not bugs; they are not technically incorrect and do not prevent the program from functioning. Instead, they indicate weaknesses in design that may slow down development or increase the risk of bugs or failures in the future.\n\n\n\n\nSource: Code smell on Wikipedia"
  },
  {
    "objectID": "slides/10-more-practice.html#code-style",
    "href": "slides/10-more-practice.html#code-style",
    "title": "More practice",
    "section": "Code style",
    "text": "Code style\nFollow the Tidyverse style guide:\n\nSpaces before and line breaks after each + when building a ggplot\nSpaces before and line breaks after each |&gt; in a data transformation pipeline,\nProper indentation\nSpaces around = signs and spaces after commas\nLines should not span more than 80 characters, long lines should be broken up with each argument on its own line"
  },
  {
    "objectID": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks",
    "href": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks",
    "title": "More practice",
    "section": "Quotes VS no quotes VS backticks",
    "text": "Quotes VS no quotes VS backticks\n\n\ndf &lt;- tibble(\n  x = c(-2, -0.5, 0.5, 1, 2),\n  `2011` = c(-2, -0.5, 0.5, 1, 2)\n)\ndf\n\n# A tibble: 5 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  -2     -2  \n2  -0.5   -0.5\n3   0.5    0.5\n4   1      1  \n5   2      2"
  },
  {
    "objectID": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks-1",
    "href": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks-1",
    "title": "More practice",
    "section": "Quotes VS no quotes VS backticks",
    "text": "Quotes VS no quotes VS backticks\n\ndf &lt;- tibble(\n  x = c(-2, -0.5, 0.5, 1, 2),\n  `2011` = c(-2, -0.5, 0.5, 1, 2)\n)\n\nReferencing a column in a pipeline:\n\n\n\ndf |&gt;\n  filter(\"x\" &gt; 0)\n\n# A tibble: 5 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  -2     -2  \n2  -0.5   -0.5\n3   0.5    0.5\n4   1      1  \n5   2      2  \n\n\n\"x\" means the literal character string.\n\n\n\ndf |&gt;\n  filter(x &gt; 0)\n\n# A tibble: 3 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1   0.5    0.5\n2   1      1  \n3   2      2  \n\n\nx means the column name in df.\n\n\n\ndf |&gt;\n  filter(`x` &gt; 0)\n\n# A tibble: 3 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1   0.5    0.5\n2   1      1  \n3   2      2  \n\n\n`x` also means the column name in df."
  },
  {
    "objectID": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks-2",
    "href": "slides/10-more-practice.html#quotes-vs-no-quotes-vs-backticks-2",
    "title": "More practice",
    "section": "Quotes VS no quotes VS backticks",
    "text": "Quotes VS no quotes VS backticks\n\ndf &lt;- tibble(\n  x = c(-2, -0.5, 0.5, 1, 2),\n  `2011` = c(-2, -0.5, 0.5, 1, 2)\n)\n\nReferencing a column in a pipeline:\n\n\n\ndf |&gt;\n  filter(\"2011\" &gt; 0)\n\n# A tibble: 5 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  -2     -2  \n2  -0.5   -0.5\n3   0.5    0.5\n4   1      1  \n5   2      2  \n\n\n\"2011\" means the literal character string.\n\n\n\ndf |&gt;\n  filter(2011 &gt; 0)\n\n# A tibble: 5 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  -2     -2  \n2  -0.5   -0.5\n3   0.5    0.5\n4   1      1  \n5   2      2  \n\n\n2011 means the literal number.\n\n\n\ndf |&gt;\n  filter(`2011` &gt; 0)\n\n# A tibble: 3 × 2\n      x `2011`\n  &lt;dbl&gt;  &lt;dbl&gt;\n1   0.5    0.5\n2   1      1  \n3   2      2  \n\n\n`2011` means the column name in df."
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of",
    "href": "slides/10-more-practice.html#why-in-instead-of",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\n\nConsider adding a season column:\n\ndurham_climate\n\n# A tibble: 12 × 4\n   month     avg_high_f avg_low_f precipitation_in\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n 1 January           49        28             4.45\n 2 February          53        29             3.7 \n 3 March             62        37             4.69\n 4 April             71        46             3.43\n 5 May               79        56             4.61\n 6 June              85        65             4.02\n 7 July              89        70             3.94\n 8 August            87        68             4.37\n 9 September         81        60             4.37\n10 October           71        47             3.7 \n11 November          62        37             3.39\n12 December          53        30             3.43"
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of-1",
    "href": "slides/10-more-practice.html#why-in-instead-of-1",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\nConsider adding a season column:\n\ndurham_climate |&gt;\n  mutate(\n    season = if_else(\n      month ????? c(\"December\", \"January\", \"February\"),\n      \"Winter\",\n      \"Not Winter\"\n    )\n  )"
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of-2",
    "href": "slides/10-more-practice.html#why-in-instead-of-2",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\nConsider adding a season column:\n\ndurham_climate |&gt;\n  mutate(\n    season = if_else(\n      month %in% c(\"December\", \"January\", \"February\"),\n      \"Winter\",\n      \"Not Winter\"\n    )\n  )\n\n# A tibble: 12 × 5\n   month     avg_high_f avg_low_f precipitation_in season    \n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;     \n 1 January           49        28             4.45 Winter    \n 2 February          53        29             3.7  Winter    \n 3 March             62        37             4.69 Not Winter\n 4 April             71        46             3.43 Not Winter\n 5 May               79        56             4.61 Not Winter\n 6 June              85        65             4.02 Not Winter\n 7 July              89        70             3.94 Not Winter\n 8 August            87        68             4.37 Not Winter\n 9 September         81        60             4.37 Not Winter\n10 October           71        47             3.7  Not Winter\n11 November          62        37             3.39 Not Winter\n12 December          53        30             3.43 Winter"
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of-3",
    "href": "slides/10-more-practice.html#why-in-instead-of-3",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\nConsider adding a season column:\n\ndurham_climate |&gt;\n  mutate(\n    season = if_else(\n      month == c(\"December\", \"January\", \"February\"),\n      \"Winter\",\n      \"Not Winter\"\n    )\n  )\n\n# A tibble: 12 × 5\n   month     avg_high_f avg_low_f precipitation_in season    \n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;     \n 1 January           49        28             4.45 Not Winter\n 2 February          53        29             3.7  Not Winter\n 3 March             62        37             4.69 Not Winter\n 4 April             71        46             3.43 Not Winter\n 5 May               79        56             4.61 Not Winter\n 6 June              85        65             4.02 Not Winter\n 7 July              89        70             3.94 Not Winter\n 8 August            87        68             4.37 Not Winter\n 9 September         81        60             4.37 Not Winter\n10 October           71        47             3.7  Not Winter\n11 November          62        37             3.39 Not Winter\n12 December          53        30             3.43 Not Winter"
  },
  {
    "objectID": "slides/10-more-practice.html#why-in-instead-of-4",
    "href": "slides/10-more-practice.html#why-in-instead-of-4",
    "title": "More practice",
    "section": "Why %in% instead of ==?",
    "text": "Why %in% instead of ==?\n\n\"January\" == c(\"December\", \"January\", \"February\")\n\n[1] FALSE  TRUE FALSE\n\n\"January\" %in% c(\"December\", \"January\", \"February\")\n\n[1] TRUE\n\n\n\n\n\n\n\n\nPunchline\n\n\nInside if_else or case_when your condition needs to result in a single value of TRUE or FALSE for each row. If it results in multiple values of TRUE/FALSE (a vector of TRUE/FALSE), you will not necessarily get an error or even a warning, but unexpected things could happen."
  },
  {
    "objectID": "slides/10-more-practice.html#task-1-prettifying-the-plot-from-ae-07",
    "href": "slides/10-more-practice.html#task-1-prettifying-the-plot-from-ae-07",
    "title": "More practice",
    "section": "Task 1: Prettifying the plot from ae-07",
    "text": "Task 1: Prettifying the plot from ae-07\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) + \n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#things-to-change",
    "href": "slides/10-more-practice.html#things-to-change",
    "title": "More practice",
    "section": "Things to change",
    "text": "Things to change\n\n\nReorder the months chronologically;\nFill the circles with season-specific colors;\nAdd a legend for these colors to the top of the plot;\nMake sure the legend is ordered chronologically by season."
  },
  {
    "objectID": "slides/10-more-practice.html#why-group-1",
    "href": "slides/10-more-practice.html#why-group-1",
    "title": "More practice",
    "section": "0. Why group = 1?",
    "text": "0. Why group = 1?\nWith it:\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#why-group-1-1",
    "href": "slides/10-more-practice.html#why-group-1-1",
    "title": "More practice",
    "section": "0. Why group = 1?",
    "text": "0. Why group = 1?\nWithout it (even though I have geom_line!):\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#why-group-1-2",
    "href": "slides/10-more-practice.html#why-group-1-2",
    "title": "More practice",
    "section": "0. Why group = 1?",
    "text": "0. Why group = 1?\nDon’t need group for numerical vs numerical:\n\nggplot(\n  durham_climate, \n  aes(x = avg_low_f, y = avg_high_f)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Average low temperature (F)\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#why-group-1-3",
    "href": "slides/10-more-practice.html#why-group-1-3",
    "title": "More practice",
    "section": "0. Why group = 1?",
    "text": "0. Why group = 1?\nDo need group for categorical vs numerical:\n\nggplot(\n  durham_climate, \n  aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#reorder-the-months-chronologically",
    "href": "slides/10-more-practice.html#reorder-the-months-chronologically",
    "title": "More practice",
    "section": "1. Reorder the months chronologically",
    "text": "1. Reorder the months chronologically\n\ndurham_climate |&gt;\n  mutate(\n    month = fct_relevel(month, month.name)\n  ) |&gt;\n  ggplot(\n    aes(x = month, y = avg_high_f, group = 1)\n  ) +\n  geom_line() +\n  geom_point(\n    shape = \"circle filled\", size = 4,\n    color = \"black\", fill = \"white\", stroke = 1\n  ) +\n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#fill-the-circles-with-season-specific-colors",
    "href": "slides/10-more-practice.html#fill-the-circles-with-season-specific-colors",
    "title": "More practice",
    "section": "2. Fill the circles with season-specific colors",
    "text": "2. Fill the circles with season-specific colors\n\ndurham_climate |&gt;\n  mutate(\n    month = fct_relevel(month, month.name),\n    season = case_when(\n      month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      month %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n      month %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n      month %in% c(\"September\", \"October\", \"November\") ~ \"Fall\",\n    )\n  ) |&gt;\n  ggplot(\n    aes(x = month, y = avg_high_f, group = 1)\n    ) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 4,\n    color = \"black\", stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) + \n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/10-more-practice.html#add-legend-for-season-to-top-of-plot",
    "href": "slides/10-more-practice.html#add-legend-for-season-to-top-of-plot",
    "title": "More practice",
    "section": "3. Add legend for season to top of plot",
    "text": "3. Add legend for season to top of plot\n\ndurham_climate |&gt;\n  mutate(\n    month = fct_relevel(month, month.name),\n    season = case_when(\n      month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      month %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n      month %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n      month %in% c(\"September\", \"October\", \"November\") ~ \"Fall\",\n    )\n  ) |&gt;\n  ggplot(\n    aes(x = month, y = avg_high_f, group = 1)\n    ) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 4,\n    color = \"black\", stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) + \n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal() + \n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "slides/10-more-practice.html#order-legend-chronologically",
    "href": "slides/10-more-practice.html#order-legend-chronologically",
    "title": "More practice",
    "section": "4. Order legend chronologically",
    "text": "4. Order legend chronologically\n\ndurham_climate |&gt;\n  mutate(\n    month = fct_relevel(month, month.name),\n    season = case_when(\n      month %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n      month %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n      month %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n      month %in% c(\"September\", \"October\", \"November\") ~ \"Fall\",\n    ),\n    season = fct_relevel(season, \"Winter\", \"Spring\", \"Summer\", \"Fall\")\n  ) |&gt;\n  ggplot(\n    aes(x = month, y = avg_high_f, group = 1)\n    ) +\n  geom_line() +\n  geom_point(\n    aes(fill = season),\n    shape = \"circle filled\", size = 4,\n    color = \"black\", stroke = 1\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"Winter\" = \"lightskyblue1\",\n      \"Spring\" = \"chartreuse3\",\n      \"Summer\" = \"gold2\",\n      \"Fall\" = \"lightsalmon4\"\n    )\n  ) + \n  labs(\n    x = \"Month\",\n    y = \"Average high temperature (F)\",\n    title = \"Durham climate\"\n  ) +\n  theme_minimal() + \n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "slides/10-more-practice.html#task-2-pivot-to-replicate-this",
    "href": "slides/10-more-practice.html#task-2-pivot-to-replicate-this",
    "title": "More practice",
    "section": "Task 2: pivot to replicate this…",
    "text": "Task 2: pivot to replicate this…\n\n\n\n\n\n\n\n\nGive it a shot in your ae-07-durham-climate-factors file. And don’t worry about prettification. Just get the two lines correct."
  },
  {
    "objectID": "slides/10-more-practice.html#task-3-recoding-and-writing-to-file",
    "href": "slides/10-more-practice.html#task-3-recoding-and-writing-to-file",
    "title": "More practice",
    "section": "Task 3: recoding and writing to file",
    "text": "Task 3: recoding and writing to file\n\nRead a CSV file\nSplit it into subsets based on features of the data\nWrite out subsets as CSV files\n\nWork on the first part in ae-08-age-gaps-sales-import.qmd."
  },
  {
    "objectID": "slides/10-more-practice.html#age-gap-in-hollywood-relationships",
    "href": "slides/10-more-practice.html#age-gap-in-hollywood-relationships",
    "title": "More practice",
    "section": "Age gap in Hollywood relationships",
    "text": "Age gap in Hollywood relationships\n\n\n\nWhat is the story in this visualization?"
  },
  {
    "objectID": "slides/10-more-practice.html#task-4-reading-in-from-excel-yuck",
    "href": "slides/10-more-practice.html#task-4-reading-in-from-excel-yuck",
    "title": "More practice",
    "section": "Task 4: reading in from excel (yuck!)",
    "text": "Task 4: reading in from excel (yuck!)\n\nUsing readr:\n\nMost commonly: read_csv()\n\nMaybe also: read_tsv(), read_delim(), etc.\n\n\n\n\n\nUsing readxl: read_excel()\n\n\n\n\n\nUsing googlesheets4: read_sheet() – We haven’t covered this in the videos, but might be useful for your projects"
  },
  {
    "objectID": "slides/10-more-practice.html#reading-excel-files",
    "href": "slides/10-more-practice.html#reading-excel-files",
    "title": "More practice",
    "section": "Reading Excel files",
    "text": "Reading Excel files\n\nRead an Excel file with non-tidy data\nTidy it up!\n\nWork on the second part in ae-08-age-gaps-sales-import.qmd."
  },
  {
    "objectID": "slides/10-more-practice.html#sales-data",
    "href": "slides/10-more-practice.html#sales-data",
    "title": "More practice",
    "section": "Sales data",
    "text": "Sales data\n\n\n\nAre these data tidy? Why or why not?"
  },
  {
    "objectID": "slides/10-more-practice.html#sales-data-1",
    "href": "slides/10-more-practice.html#sales-data-1",
    "title": "More practice",
    "section": "Sales data",
    "text": "Sales data\n\nWhat “data moves” do we need to go from the original, non-tidy data to this, tidy one?"
  },
  {
    "objectID": "slides/lab-4.html#while-you-wait-get-your-repo-ready",
    "href": "slides/lab-4.html#while-you-wait-get-your-repo-ready",
    "title": "Lab 4",
    "section": "While you wait… get your repo ready",
    "text": "While you wait… get your repo ready\n\n\n\nLog in to RStudio (via your container)\n\nGo to https://cmgr.oit.duke.edu/containers and click STA198-199\n\n\n\n\nClone the repo & start a new RStudio project\n\nGo to the course organization at github.com/sta199-s25 organization on GitHub. Click on the repo with the prefix lab-4.\nClick on the green CODE button and select Use SSH. Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git to clone your Lab 4 repo.\n\n\n\nUpdate the YAML\n\nIn lab-4.qmd, update the author field to your name, Render your document, and examine the changes. Then, in the Git pane, click on Diff to view your changes, add a commit message (e.g., “Added author name”), and click Commit. Then, Push the changes to your GitHub repository and, in your browser, confirm that these changes have indeed propagated to your repository.\n\n\n\n\nShould look at Marie’s notes again (from email on 1/22/25). There are more notes there to incorporate, especially in earlier labs with the motivation."
  },
  {
    "objectID": "slides/lab-4.html#a-review",
    "href": "slides/lab-4.html#a-review",
    "title": "Lab 4",
    "section": "A review",
    "text": "A review\nYou have learned a lot thus far\n\nGit/GitHub\n\nR\n\n\nPlot related functions\nggplot(), aes(), geom_boxplot(), geom_point(), geom_histogram(), geom_smooth(), geom_line(), geom_beeswarm(), labs(), theme_minimal(), theme() scale_x_continuous(), scale_color_manual()\n\n\nMore functions\nglimpse(), nrow(), ncol(), dim(), slice_head(), filter(), arrange(), relocate(), if_else(), case_when(), count(), group_by(), ungroup(), read_csv(), separate(), mutate(), summarize(), pivot_*(), *_join()\n\n\n\n\nGit/Github: had lots of practice pulling, committing and pushing changes to update your repos on GitHub.\nR: These functions were taken from ae-02 to ae-06 and the prepare videos (a good places to practice and refresh what you’ve learned).\n(optional, may not be enough time – can transition by stating let’s talk about a few of these in more detail) Have students raise hands to ask state these functions do (with an emphasis on those under more functions) – just for 5 or so functions. Hopefully, multiple students raise their hands. Otherwise you can simply move on.\nTransition: now let’s do a more thorough review of some of these functions"
  },
  {
    "objectID": "slides/lab-4.html#mutate-and-summarize",
    "href": "slides/lab-4.html#mutate-and-summarize",
    "title": "Lab 4",
    "section": "\nmutate() and summarize()\n",
    "text": "mutate() and summarize()\n\n \n \n\n\nmutate(): modifies existing data frame – creates new columns (i.e., variables) or modifies existing columns. Note that the number of rows does not change.\n\n \n\n\nsummarize(): creates a new data frame – returns one for for each combination of grouping variables. If there is no grouping it will have a single row summarizing all observations"
  },
  {
    "objectID": "slides/lab-4.html#example-set-up",
    "href": "slides/lab-4.html#example-set-up",
    "title": "Lab 4",
    "section": "Example: Set up",
    "text": "Example: Set up\n\nlibrary(tidyverse)\nlibrary(knitr)\n\ndf &lt;- tibble(\n  col_1 = c(\"A\", \"A\", \"A\", \"B\", \"B\"),\n  col_2 = c(\"X\", \"Y\", \"X\", \"X\", \"Y\"),\n  col_3 = c(1, 2, 3, 4, 5)\n)\n\ndf #this is used to display the data frame\n\n# A tibble: 5 × 3\n  col_1 col_2 col_3\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     X         1\n2 A     Y         2\n3 A     X         3\n4 B     X         4\n5 B     Y         5\n\n\n\nWhat would be the result of the following code? # rows? # cols? column/variable names?\n\ndf |&gt;\n  mutate(med_col_3 = median(col_3))\n\n\ndf |&gt;\n  summarize(med_col_3 = median(col_3))\n\nHAVE THE STUDENTS GUESS how many rows, columns, what the variable names will be?\nmutate: number of rows does not change, number of columns increases by 1 (med_col_3). Could have also introduced more new variables within the mutate function using commas,\n\ndf |&gt;\n  mutate(\n    med_col_3 = median(col_3),\n    mean_col_3 = mean(col_3)\n    )\n\nsummarize: there is only 1 row and 1 col! (this is a much different data frame than df!). Could have had more columns/variables if added more variables within summarize function using commas. [same as above, just replace mutate with summarize]\nassignment: have the students guess"
  },
  {
    "objectID": "slides/lab-4.html#example-no-groups",
    "href": "slides/lab-4.html#example-no-groups",
    "title": "Lab 4",
    "section": "Example: no groups",
    "text": "Example: no groups\nmutate()\n\ndf |&gt;\n  mutate(med_col_3 = median(col_3))\n\n# A tibble: 5 × 4\n  col_1 col_2 col_3 med_col_3\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 A     X         1         3\n2 A     Y         2         3\n3 A     X         3         3\n4 B     X         4         3\n5 B     Y         5         3\n\n\n\nsummarize()\n\ndf |&gt;\n  summarize(med_col_3 = median(col_3))\n\n# A tibble: 1 × 1\n  med_col_3\n      &lt;dbl&gt;\n1         3\n\n\n\n\nWe did not assign any new or existing data frames (e.g., no ??? &lt;-). In particular, we did not write over df (i.e., no df &lt;-), so what will be the result of the following code?\n\ndf\n\nmutate: there was no column named med_col_3, so a new column was created\nsummarize: there is no grouping, so there is one output summarizing so the median is computed over all of the original rows of the data (five rows in this example)\nassignment: have the students guess"
  },
  {
    "objectID": "slides/lab-4.html#example-assignment",
    "href": "slides/lab-4.html#example-assignment",
    "title": "Lab 4",
    "section": "Example: assignment",
    "text": "Example: assignment\n\nIt’s the same as when it was originally assigned. It has not been overwritten!\n\n\ndf \n\n# A tibble: 5 × 3\n  col_1 col_2 col_3\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 A     X         1\n2 A     Y         2\n3 A     X         3\n4 B     X         4\n5 B     Y         5\n\n\n\n\nWe will often write a single pipeline and show the result, i.e., no assignment.\n\nIf you will need to refer to the data frame later, it might be a good idea to assign a name to the data frame. Otherwise, see the result and continue on.\nNote: if you assign the new/updated data frame, the result does not appear in the Console or the rendered document! (Type the name of the variable, e.g., df as shown above, to display the data frame.)"
  },
  {
    "objectID": "slides/lab-4.html#example-with-groups",
    "href": "slides/lab-4.html#example-with-groups",
    "title": "Lab 4",
    "section": "Example: with groups",
    "text": "Example: with groups\nWhat if there is grouping?\n\n# group by 1 variable\ndf |&gt;\n  group_by(col_1) |&gt;\n  mutate(med_col_3 = median(col_3))\n\n\ndf |&gt;\n  group_by(col_1) |&gt;\n  summarize(med_col_3 = median(col_3))\n\n# group by 2 variables\ndf |&gt;\n  group_by(col_1, col_2) |&gt;\n  mutate(med_col_3 = median(col_3))\n\n\ndf |&gt;\n  group_by(col_1, col_2) |&gt;\n  summarize(med_col_3 = median(col_3))\n\n\nIf you aren’t sure, try it out and see what happens (e.g., use data frame from Lab 3, Part 1).\nI would have written this out in Lab 3 prep. But there is other stuff to get to for Lab 4 prep that I didn’t want this to take up too much of the time. Plus, by now they saw what happened already in Lab 3.\nAlso, make a comment about the grouping when expanding upon this next semester."
  },
  {
    "objectID": "slides/lab-4.html#pivot_",
    "href": "slides/lab-4.html#pivot_",
    "title": "Lab 4",
    "section": "pivot_*()",
    "text": "pivot_*()\n\nPivoting reshapes the data frame.\npivot_longer makes the updated data frame longer (i.e., fewer columns)\npivot_wider makes the updated data frame wider (i.e., more columns)"
  },
  {
    "objectID": "slides/lab-4.html#example-pivot_",
    "href": "slides/lab-4.html#example-pivot_",
    "title": "Lab 4",
    "section": "Example: pivot_*()\n",
    "text": "Example: pivot_*()\n\nLet’s examine the number of hours people slept during the week.\n\n\n\n\nHow do we go from this…\n\n\n\n\n\nppl\nMon\nTues\nWeds\nThurs\nFri\n\n\n\nperson1\n8\n7\n6\n10\n8\n\n\nperson2\n7\n5\n4\n6\n7\n\n\n\n\n\n\n\n…to this?\n\n\n\n\n\nppl\nday\nhours\n\n\n\nperson1\nMon\n8\n\n\nperson1\nTues\n7\n\n\nperson1\nWeds\n6\n\n\nperson1\nThurs\n10\n\n\nperson1\nFri\n8\n\n\nperson2\nMon\n7\n\n\nperson2\nTues\n5\n\n\nperson2\nWeds\n4\n\n\nperson2\nThurs\n6\n\n\nperson2\nFri\n7\n\n\n\n\n\n\n\n\n\n\ndf_longer &lt;- df |&gt;\n  pivot_longer(\n    cols = -ppl,\n    names_to = \"day\",\n    values_to = \"hours\"\n  )\n\npivot_longer() or pivot_wider()? Have the students vote. pivot_longer()!\nWhat should the arguments be? (Go through the argument discussion first, then reveal the result toward the end – giving them enough time to look at it for visual learners)\ncols = -ppl: cols – the columns to be pivoted (i.e., stacked into rows). in this case all of the columns except ppl (ppl column/variable remains)\nnames_to = \"day\": names_to – the new column/variable name for the original column/variable names [point to the Mon, Tues, Weds, … in the original table]\nvalues_to = \"hours\": names_to – the new column/variable name for the values from the original data [point to the hours of sleep in the original table]\nNote that the column/variable names “day” and “hours” did not exist until using pivot_longer()\nQuestion: What if I hadn’t assigned the result to df_longer? What would the display look like and what would the df data frame be if I had deleted the df_longer &lt;- portion of the code?\nAnswer: The console would show the data frame df_longer (though it wouldn’t be named – it would just read # A tibble: 10 x 3 and so on), and df remains unchanged. It’s the same wide (2 x 6) tibble it originally was defined as."
  },
  {
    "objectID": "slides/lab-4.html#join",
    "href": "slides/lab-4.html#join",
    "title": "Lab 4",
    "section": "*_join()",
    "text": "*_join()\n\n\nTypically we use *_join() to merge data from two data frames (e.g., left_join(), right_join(), full_join(), inner_join()), i.e., create a new data frames with more columns/variables.\nFor example, there is useful info in two data frames: x and y. We want to create a new data frame which includes variables from both (e.g., data frame x has student ID numbers and student names and data frame y has student ID numbers and email addresses).\n\n\n\n\nSometimes we use *_join() to filter rows/observations, e.g., find the rows from one data frame that do (or do not) exist in another data frame (e.g., semi_join(), anti_join())\n\n\n\n\nLet’s focus on the joins that merge data…"
  },
  {
    "objectID": "slides/lab-4.html#example-_join-setup",
    "href": "slides/lab-4.html#example-_join-setup",
    "title": "Lab 4",
    "section": "Example: *_join() setup",
    "text": "Example: *_join() setup\nFor the next few slides…\n\n\n\nx &lt;- tibble(\n  id = c(1, 2, 3),\n  value_x = c(\"x1\", \"x2\", \"x3\")\n  )\n\nx\n\n# A tibble: 3 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny &lt;- tibble(\n  id = c(1, 2, 4),\n  value_y = c(\"y1\", \"y2\", \"y4\")\n  )\n\ny\n\n# A tibble: 3 × 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/lab-4.html#left_join",
    "href": "slides/lab-4.html#left_join",
    "title": "Lab 4",
    "section": "left_join()",
    "text": "left_join()\n\n\n\n\n\nleft_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n\n\n\n\nKeep all rows from left data frame."
  },
  {
    "objectID": "slides/lab-4.html#right_join",
    "href": "slides/lab-4.html#right_join",
    "title": "Lab 4",
    "section": "right_join()",
    "text": "right_join()\n\n\n\n\n\nright_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     4 &lt;NA&gt;    y4     \n\n\n\n\n  Keep all rows from right data frame."
  },
  {
    "objectID": "slides/lab-4.html#full_join",
    "href": "slides/lab-4.html#full_join",
    "title": "Lab 4",
    "section": "full_join()",
    "text": "full_join()\n\n\n\n\n\nfull_join(x, y)\n\n# A tibble: 4 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4     \n\n\n\n\n \nKeep all rows from both data frames."
  },
  {
    "objectID": "slides/lab-4.html#inner_join",
    "href": "slides/lab-4.html#inner_join",
    "title": "Lab 4",
    "section": "inner_join()",
    "text": "inner_join()\n\n\n\n\n\ninner_join(x, y)\n\n# A tibble: 2 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n\n\n\n\n \nKeep all rows that exist in both data frames."
  },
  {
    "objectID": "slides/lab-4.html#example-_join-more-info",
    "href": "slides/lab-4.html#example-_join-more-info",
    "title": "Lab 4",
    "section": "Example: *_join() more info",
    "text": "Example: *_join() more info\n\nWe could also use *_join() within a pipeline.\n\n\nx |&gt;\n  left_join(y)\n\n\nWhich data frame is on the left and which is on the right? x or y?\n\n\n\nThe above code is equivalent to left_join(x, y) since the result before the pipe |&gt; is passed as the first argument to the function after the pipe.\n\n\n\n\nIn this example x has 2 variables: id and value_x and y has 2 variables: id and value_x, so there was only one common variable between x and y – id. We could have been more explicit and used the following code\n\n\nleft_join(x, y, by = join_by(id))\n\n# or alternatively\n\nleft_join(x, y, by = join_by(id == id))\n\nThe first option is useful when there are multiple matching columns [and by default *_join() will use all variables in common across x and y] but perhaps only one of interest (e.g., student_ids and email_address – the same student could have multiple email addresses but you want each student to be one row/observation, so you would use by = join_by(student_ids)).\nThe second option is used when the variables do not share the same variable name but are referring to the same information, e.g., id == student_id.\nBackup info: why piping? piping is much easier to read (can see all data frame manipulation at once – and it isn’t an extreme run-on sentence, e.g., summarize(mutatate(), arg, arg, arg….); also, potentially less having to save and remember intermediate variables) – both for you and others."
  },
  {
    "objectID": "slides/lab-4.html#factors",
    "href": "slides/lab-4.html#factors",
    "title": "Lab 4",
    "section": "Factors",
    "text": "Factors\n\nFactors are used for categorical variables, e.g., days of the week; religion; low, mid, high\nVery helpful for ordering (i.e., when numerical and alphabetical ordering don’t cut it!)\n\n\n\n\nExamples\n\nFriday, Monday, Saturday, Sunday, Tuesday, Thursday, Wednesday\nApr, Feb, Jan, July, Jun, Mar, May\nAgree, Disagree, Neither agree nor disagree, Strongly agree, Strongly disagree\nExample below (from prepare [r4ds] chp 16.4)"
  },
  {
    "objectID": "slides/lab-4.html#factor-example",
    "href": "slides/lab-4.html#factor-example",
    "title": "Lab 4",
    "section": "Factor example",
    "text": "Factor example\nRecall from Thursday’s lecture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsurvey |&gt;\n  mutate(\n    year = fct_relevel(year, \"First-year\", \"Sophomore\", \"Junior\", \"Senior\")\n    ) |&gt;\n  ggplot(aes(x = year)) +\n  geom_bar() + \n  labs(\n    title = \"Number of students by year\",\n    x = \"Year\",\n    y = \"Count\"\n  )\n\n\n\nHow is the x-axis ordered in the left and right plots?\n\nRecall from Thursday’s lecture, using context we know about the data it’s more appropriate for the year to have the order: first-year, sophomore, junior, senior and we used fct_revel to manually (we explicityly wrote out the order) change the ordering of the year variable.\nThe data is ordered alphabetically on the left (default for ggplot to order numerically or alphabetically).\nOrdered according to fct_relevel ordering on the right\nAlso that fct_revel did two things: it made the year variable a factor AND it set the order. (aside if asked) Note that ggplot will by default coerce the character variable to be a factor. Regardless if you assigned the data frame after running fct_revel it will be a factor (and you don’t need to separately use the factor() function)."
  },
  {
    "objectID": "slides/lab-4.html#this-weeks-lab",
    "href": "slides/lab-4.html#this-weeks-lab",
    "title": "Lab 4",
    "section": "This week’s lab",
    "text": "This week’s lab\n\nGain more experience with joining and pivoting data frames; and modifying the order of factors.\nReview Quarto cell options\nLearn to read data in from Excel spreadsheets (will learn more on Tuesday about this)\n\nDatasets\n\nMore inflation!\n2020 and 2024 US Olympic Team rosters\nSurvey regarding medical marijuana in NC\nmtcars from 1974 Motor Trend US magazine"
  },
  {
    "objectID": "slides/07-joining-data.html#while-you-wait",
    "href": "slides/07-joining-data.html#while-you-wait",
    "title": "Joining data",
    "section": "While you wait…",
    "text": "While you wait…\nPrepare for today’s application exercise: ae-06-taxes-join\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-06-taxes-join.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file."
  },
  {
    "objectID": "slides/07-joining-data.html#whats-going-on-in-this-plot",
    "href": "slides/07-joining-data.html#whats-going-on-in-this-plot",
    "title": "Joining data",
    "section": "What’s going on in this plot?",
    "text": "What’s going on in this plot?\n\nCan you guess the variable plotted here?"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-taxes-in-us-states",
    "href": "slides/07-joining-data.html#sales-taxes-in-us-states",
    "title": "Joining data",
    "section": "Sales taxes in US states",
    "text": "Sales taxes in US states\n\nsales_taxes\n\n# A tibble: 51 × 5\n   state      state_tax_rate avg_local_tax_rate combined_rate max_local_tax_rate\n   &lt;chr&gt;               &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;              &lt;dbl&gt;\n 1 Alabama            0.04               0.0529        0.0929             0.075 \n 2 Alaska             0                  0.0182        0.0182             0.0785\n 3 Arizona            0.056              0.0278        0.0838             0.053 \n 4 Arkansas           0.065              0.0295        0.0945             0.0613\n 5 California         0.0725             0.016         0.0885             0.0475\n 6 Colorado           0.029              0.0491        0.0781             0.083 \n 7 Connectic…         0.0635             0             0.0635             0     \n 8 Delaware           0                  0             0                  0     \n 9 Florida            0.06               0.01          0.07               0.02  \n10 Georgia            0.04               0.0338        0.0738             0.05  \n# ℹ 41 more rows"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-swing-states",
    "href": "slides/07-joining-data.html#sales-tax-in-swing-states",
    "title": "Joining data",
    "section": "Sales tax in swing states",
    "text": "Sales tax in swing states\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of swing states (Arizona, Georgia, Michigan, Nevada, North Carolina, Pennsylvania, and Wisconsin) vs. non-swing states.\n\nHow would you approach this task?\n\n\n\nCreate a new variable called swing_state with levels \"Swing\" and \"Non-swing\"\n\nGroup by swing_state\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data.html#ae-06-taxes-join",
    "href": "slides/07-joining-data.html#ae-06-taxes-join",
    "title": "Joining data",
    "section": "ae-06-taxes-join",
    "text": "ae-06-taxes-join\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-06-taxes-join.qmd.\nWork through the application exercise in class, and render, commit, and push your edits by the end of class."
  },
  {
    "objectID": "slides/07-joining-data.html#mutate-with-if_else",
    "href": "slides/07-joining-data.html#mutate-with-if_else",
    "title": "Joining data",
    "section": "\nmutate() with if_else()\n",
    "text": "mutate() with if_else()\n\n\nCreate a new variable called swing_state with levels \"Swing\" and \"Non-swing\".\n\n\nlist_of_swing_states &lt;- c(\"Arizona\", \"Georgia\", \"Michigan\", \"Nevada\", \n                          \"North Carolina\", \"Pennsylvania\", \"Wisconsin\")\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    swing_state = if_else(state %in% list_of_swing_states,\n                          \"Swing\",\n                          \"Non-swing\")) |&gt;\n  relocate(swing_state)\n\nsales_taxes\n\n# A tibble: 51 × 6\n   swing_state state       state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;       &lt;chr&gt;                &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Non-swing   Alabama             0.04               0.0529        0.0929\n 2 Non-swing   Alaska              0                  0.0182        0.0182\n 3 Swing       Arizona             0.056              0.0278        0.0838\n 4 Non-swing   Arkansas            0.065              0.0295        0.0945\n 5 Non-swing   California          0.0725             0.016         0.0885\n 6 Non-swing   Colorado            0.029              0.0491        0.0781\n 7 Non-swing   Connecticut         0.0635             0             0.0635\n 8 Non-swing   Delaware            0                  0             0     \n 9 Non-swing   Florida             0.06               0.01          0.07  \n10 Swing       Georgia             0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-if_else",
    "href": "slides/07-joining-data.html#recap-if_else",
    "title": "Joining data",
    "section": "Recap: if_else()\n",
    "text": "Recap: if_else()\n\nif_else(\n1  x == y,\n2  \"x is equal to y\",\n3  \"x is not equal to y\"\n)\n\n1\n\nCondition\n\n2\n\nValue if condition is TRUE\n\n3\n\nValue if condition is FALSE"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-swing-states-1",
    "href": "slides/07-joining-data.html#sales-tax-in-swing-states-1",
    "title": "Joining data",
    "section": "Sales tax in swing states",
    "text": "Sales tax in swing states\n\nCompare the average state sales tax rates of swing states vs. non-swing states.\n\n\nsales_taxes |&gt;\n  group_by(swing_state) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 2 × 2\n  swing_state mean_state_tax\n  &lt;chr&gt;                &lt;dbl&gt;\n1 Non-swing           0.0504\n2 Swing               0.0546"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-coastal-states",
    "href": "slides/07-joining-data.html#sales-tax-in-coastal-states",
    "title": "Joining data",
    "section": "Sales tax in coastal states",
    "text": "Sales tax in coastal states\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of states on the Pacific Coast, states on the Atlantic Coast, and the rest of the states.\n\nHow would you approach this task?\n\n\n\nCreate a new variable called coast with levels \"Pacific\", \"Atlantic\", and \"Neither\"\n\nGroup by coast\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data.html#mutate-with-case_when",
    "href": "slides/07-joining-data.html#mutate-with-case_when",
    "title": "Joining data",
    "section": "\nmutate() with case_when()\n",
    "text": "mutate() with case_when()\n\n\nCreate a new variable called coast with levels \"Pacific\", \"Atlantic\", and \"Neither\".\n\n\npacific_coast &lt;- c(\"Alaska\", \"Washington\", \"Oregon\", \"California\", \"Hawaii\")\n\natlantic_coast &lt;- c(\n  \"Connecticut\", \"Delaware\", \"Georgia\", \"Florida\", \"Maine\", \"Maryland\", \n  \"Massachusetts\", \"New Hampshire\", \"New Jersey\", \"New York\", \n  \"North Carolina\", \"Rhode Island\", \"South Carolina\", \"Virginia\"\n)\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    coast = case_when(\n      state %in% pacific_coast ~ \"Pacific\",\n      state %in% atlantic_coast ~ \"Atlantic\",\n      .default = \"Neither\"\n    )\n  ) |&gt;\n  relocate(coast)\n\nsales_taxes\n\n# A tibble: 51 × 7\n   coast    swing_state state    state_tax_rate avg_local_tax_rate combined_rate\n   &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Neither  Non-swing   Alabama          0.04               0.0529        0.0929\n 2 Pacific  Non-swing   Alaska           0                  0.0182        0.0182\n 3 Neither  Swing       Arizona          0.056              0.0278        0.0838\n 4 Neither  Non-swing   Arkansas         0.065              0.0295        0.0945\n 5 Pacific  Non-swing   Califor…         0.0725             0.016         0.0885\n 6 Neither  Non-swing   Colorado         0.029              0.0491        0.0781\n 7 Atlantic Non-swing   Connect…         0.0635             0             0.0635\n 8 Atlantic Non-swing   Delaware         0                  0             0     \n 9 Atlantic Non-swing   Florida          0.06               0.01          0.07  \n10 Atlantic Swing       Georgia          0.04               0.0338        0.0738\n# ℹ 41 more rows\n# ℹ 1 more variable: max_local_tax_rate &lt;dbl&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#recap-case_when",
    "href": "slides/07-joining-data.html#recap-case_when",
    "title": "Joining data",
    "section": "Recap: case_when()\n",
    "text": "Recap: case_when()\n\ncase_when(\n1  x &gt; y  ~ \"x is greater than y\",\n2  x &lt; y  ~ \"x is less than y\",\n3  .default = \"x is equal to y\"\n)\n\n1\n\nValue if first condition is TRUE\n\n2\n\nValue if second condition is TRUE\n\n3\n\nValue if neither condition is TRUE, i.e., default value"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-coastal-states-1",
    "href": "slides/07-joining-data.html#sales-tax-in-coastal-states-1",
    "title": "Joining data",
    "section": "Sales tax in coastal states",
    "text": "Sales tax in coastal states\n\nCompare the average state sales tax rates of states on the Pacific Coast, states on the Atlantic Coast, and the rest of the states.\n\n\nsales_taxes |&gt;\n  group_by(coast) |&gt;\n  summarize(mean_state_tax = mean(state_tax_rate))\n\n# A tibble: 3 × 2\n  coast    mean_state_tax\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Atlantic         0.0484\n2 Neither          0.0545\n3 Pacific          0.0355"
  },
  {
    "objectID": "slides/07-joining-data.html#sales-tax-in-us-regions",
    "href": "slides/07-joining-data.html#sales-tax-in-us-regions",
    "title": "Joining data",
    "section": "Sales tax in US regions",
    "text": "Sales tax in US regions\n\nSuppose you’re tasked with the following:\n\nCompare the average state sales tax rates of states in various regions (Midwest - 12 states, Northeast - 9 states, South - 16 states, West - 13 states).\n\nHow would you approach this task?\n\n\n\nCreate a new variable called region with levels \"Midwest\", \"Northeast\", \"South\", and \"West\".\nGroup by region\n\nSummarize to find the mean sales tax in each type of state"
  },
  {
    "objectID": "slides/07-joining-data.html#mutate-with-case_when-1",
    "href": "slides/07-joining-data.html#mutate-with-case_when-1",
    "title": "Joining data",
    "section": "\nmutate() with case_when()\n",
    "text": "mutate() with case_when()\n\n\nWho feels like filling in the blanks lists of states in each region? Who feels like it’s simply too tedious to write out names of all states?\n\n\nlist_of_midwest_states &lt;- c(___)\nlist_of_northeast_states &lt;- c(___)\nlist_of_south_states &lt;- c(___)\nlist_of_west_states &lt;- c(___)\n\nsales_taxes &lt;- sales_taxes |&gt;\n  mutate(\n    coast = case_when(\n      state %in% list_of_west_states ~ \"Midwest\",\n      state %in% list_of_northeast_states ~ \"Northeast\",\n      state %in% list_of_south_states ~ \"South\",\n      state %in% list_of_west_states ~ \"West\"\n    )\n  )"
  },
  {
    "objectID": "slides/07-joining-data.html#why-join",
    "href": "slides/07-joining-data.html#why-join",
    "title": "Joining data",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nIs there a relationship between\n- number of QS courses taken\n- having scored a 4 or 5 on the AP stats exam\n- motivation for taking course\n- …\nand performance in this course?”\n\n\nEach of these would require joining class performance data with an outside data source so we can have all relevant information (columns) in a single data frame."
  },
  {
    "objectID": "slides/07-joining-data.html#why-join-1",
    "href": "slides/07-joining-data.html#why-join-1",
    "title": "Joining data",
    "section": "Why join?",
    "text": "Why join?\nSuppose we want to answer questions like:\n\nCompare the average state sales tax rates of states in various regions (Midwest - 12 states, Northeast - 9 states, South - 16 states, West - 13 states).\n\n\nThis can also be solved with joining region information with the state-level sales tax data."
  },
  {
    "objectID": "slides/07-joining-data.html#setup",
    "href": "slides/07-joining-data.html#setup",
    "title": "Joining data",
    "section": "Setup",
    "text": "Setup\nFor the next few slides…\n\n\n\nx &lt;- tibble(\n  id = c(1, 2, 3),\n  value_x = c(\"x1\", \"x2\", \"x3\")\n  )\n\nx\n\n# A tibble: 3 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2     \n3     3 x3     \n\n\n\n\ny &lt;- tibble(\n  id = c(1, 2, 4),\n  value_y = c(\"y1\", \"y2\", \"y4\")\n  )\n\ny\n\n# A tibble: 3 × 2\n     id value_y\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 y1     \n2     2 y2     \n3     4 y4"
  },
  {
    "objectID": "slides/07-joining-data.html#left_join",
    "href": "slides/07-joining-data.html#left_join",
    "title": "Joining data",
    "section": "left_join()",
    "text": "left_join()\n\n\n\n\n\nleft_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;"
  },
  {
    "objectID": "slides/07-joining-data.html#right_join",
    "href": "slides/07-joining-data.html#right_join",
    "title": "Joining data",
    "section": "right_join()",
    "text": "right_join()\n\n\n\n\n\nright_join(x, y)\n\n# A tibble: 3 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data.html#full_join",
    "href": "slides/07-joining-data.html#full_join",
    "title": "Joining data",
    "section": "full_join()",
    "text": "full_join()\n\n\n\n\n\nfull_join(x, y)\n\n# A tibble: 4 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2     \n3     3 x3      &lt;NA&gt;   \n4     4 &lt;NA&gt;    y4"
  },
  {
    "objectID": "slides/07-joining-data.html#inner_join",
    "href": "slides/07-joining-data.html#inner_join",
    "title": "Joining data",
    "section": "inner_join()",
    "text": "inner_join()\n\n\n\n\n\ninner_join(x, y)\n\n# A tibble: 2 × 3\n     id value_x value_y\n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  \n1     1 x1      y1     \n2     2 x2      y2"
  },
  {
    "objectID": "slides/07-joining-data.html#semi_join",
    "href": "slides/07-joining-data.html#semi_join",
    "title": "Joining data",
    "section": "semi_join()",
    "text": "semi_join()\n\n\n\n\n\nsemi_join(x, y)\n\n# A tibble: 2 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 x1     \n2     2 x2"
  },
  {
    "objectID": "slides/07-joining-data.html#anti_join",
    "href": "slides/07-joining-data.html#anti_join",
    "title": "Joining data",
    "section": "anti_join()",
    "text": "anti_join()\n\n\n\n\n\nanti_join(x, y)\n\n# A tibble: 1 × 2\n     id value_x\n  &lt;dbl&gt; &lt;chr&gt;  \n1     3 x3"
  },
  {
    "objectID": "slides/07-joining-data.html#summary",
    "href": "slides/07-joining-data.html#summary",
    "title": "Joining data",
    "section": "Summary",
    "text": "Summary"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#while-you-wait",
    "href": "slides/09-importing-recoding-data.html#while-you-wait",
    "title": "Importing and recoding data",
    "section": "While you wait…",
    "text": "While you wait…\n\n\nGo to your ae project in RStudio.\nMake sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nClick Pull to get today’s application exercise file: ae-08-age-gaps-sales-import.qmd.\nWait till the you’re prompted to work on the application exercise during class before editing the file.\n\n\n\n\n\n\n\n\nAEs are due by the end of class\n\n\nSuccessful completion means at least one commit + push by 2PM today."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#midterm-exam-1",
    "href": "slides/09-importing-recoding-data.html#midterm-exam-1",
    "title": "Importing and recoding data",
    "section": "Midterm Exam 1",
    "text": "Midterm Exam 1\nWorth 20% of your final grade; consists of two parts:\n\n\nIn-class: worth 70% of the Midterm 1 grade;\n\nThursday February 20 11:45 AM - 1:00 PM\n\n\n\nTake-home: worth 30% of the Midterm 1 grade.\n\nReleased Thursday February 20 at 1:00 PM;\nDue Monday February 24 at 8:30 AM."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#in-class",
    "href": "slides/09-importing-recoding-data.html#in-class",
    "title": "Importing and recoding data",
    "section": "In-class",
    "text": "In-class\n\n\nAll multiple choice;\nYou will take it in Bio Sciences 111 (this room) or Physics 128;\nYou get both sides of one 8.5” x 11” note sheet that you and only you created (written, typed, iPad, etc);\nIf you do better on the final than you do on this, the final exam score will replace this.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nIf you have testing accommodations, make sure I get proper documentation from SDAO and make appointments in the Testing Center by Friday. The appointment should overlap substantially with our class time if possible."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#example-in-class-question",
    "href": "slides/09-importing-recoding-data.html#example-in-class-question",
    "title": "Importing and recoding data",
    "section": "Example in-class question",
    "text": "Example in-class question\nWhich command will replace a pre-existing column in a data frame with a new and improved version of itself?\n\ngroup_by\nsummarize\npivot_wider\ngeom_replace\nmutate"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#example-in-class-question-1",
    "href": "slides/09-importing-recoding-data.html#example-in-class-question-1",
    "title": "Importing and recoding data",
    "section": "Example in-class question",
    "text": "Example in-class question\n\n\n\ndf\n\n# A tibble: 6 × 2\n      x y      \n  &lt;dbl&gt; &lt;chr&gt;  \n1     1 John   \n2     2 John   \n3     3 Cameron\n4     4 Zito   \n5     5 Zito   \n6     6 Zito   \n\n\n\n\ndf |&gt;\n  group_by(y) |&gt;\n  summarize(xbar = mean(x))\n\nHow many rows will this output have?\n\n1\n2\n3\n6\n11"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#example-in-class-question-2",
    "href": "slides/09-importing-recoding-data.html#example-in-class-question-2",
    "title": "Importing and recoding data",
    "section": "Example in-class question",
    "text": "Example in-class question\n\n\nWhich box plot is visualizing the same data as the histogram?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#what-should-i-put-on-my-cheat-sheet",
    "href": "slides/09-importing-recoding-data.html#what-should-i-put-on-my-cheat-sheet",
    "title": "Importing and recoding data",
    "section": "What should I put on my cheat sheet?",
    "text": "What should I put on my cheat sheet?\n\nAsk one of our undergrad TAs! They took the class. I didn’t.\n\n\ndescription of common functions;\ndescription of different visualizations: how to interpret, and what to use when;\ndoodles;\ncute words of affirmation.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nDon’t waste space on the details of any specific applications or datasets we’ve seen (penguins, Bechdel, gerrymandering, midwest, etc). Anything we want you to know about a particular application will be introduced from scratch within the exam."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#take-home",
    "href": "slides/09-importing-recoding-data.html#take-home",
    "title": "Importing and recoding data",
    "section": "Take-home",
    "text": "Take-home\n\n\nIt will be just like a lab, only shorter;\nCompletely open-resource, but citation policies apply;\nAbsolutely no collaboration of any kind;\nSeek help by posting privately on Ed;\nSubmit your final PDF to Gradescope in the usual way."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#reminder-conduct-policies",
    "href": "slides/09-importing-recoding-data.html#reminder-conduct-policies",
    "title": "Importing and recoding data",
    "section": "Reminder: conduct policies",
    "text": "Reminder: conduct policies\n\n\nUncited use of outside resources or inappropriate collaboration will result in a zero and be referred to the conduct office;\nIf a conduct violation of any kind is discovered, your final letter grade in the course will be permanently reduced (A- down to B+, B+ down to B, etc);\nIf folks share solutions, all students involved will be penalized equally, the sharer the same as the recipient.\n\n\n\n\n\n\n\n\n\nIt’s not personal.\n\n\nThese policies apply to everyone. I don’t care who your parents are, or what medical schools you are applying to in the fall. Grow up and act right."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#things-you-can-do-to-study",
    "href": "slides/09-importing-recoding-data.html#things-you-can-do-to-study",
    "title": "Importing and recoding data",
    "section": "Things you can do to study",
    "text": "Things you can do to study\n\n\n\nPractice problems: released Thursday February 13;\n\nAttend lab: review game on Monday February 17;\n\nOld labs: correct parts where you lost points;\n\nOld AEs: complete tasks we didn’t get to and compare with key;\n\nCode along: watch these videos specifically;\n\nTextbook: odd-numbered exercises in the back of Chs. 1, 4, 5, 6."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-and-statistical-thinking",
    "href": "slides/09-importing-recoding-data.html#data-science-and-statistical-thinking",
    "title": "Importing and recoding data",
    "section": "Data science and statistical thinking",
    "text": "Data science and statistical thinking\nBefore Midterm 1…\n\n\nData science: the real-world art of transforming messy, imperfect, incomplete data into knowledge;\n\nAfter Midterm 1…\n\n\nStatistics: the mathematical discipline of quantifying our uncertainty about that knowledge."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science",
    "href": "slides/09-importing-recoding-data.html#data-science",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-1",
    "href": "slides/09-importing-recoding-data.html#data-science-1",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science\n\n\n\nCollection: we won’t seriously study this!\n\n\nfor us: data importing (read_csv), and webscraping (next time);\n\nbut really: domain-specific issues of measurement, survey design, experimental design, etc;"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-collection",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-collection",
    "title": "Importing and recoding data",
    "section": "From last time: data collection",
    "text": "From last time: data collection\nI sent out my lil’ survey with Google Forms, downloaded the responses in a CSV, and read that sucker in:\n\n\n\n&lt;p&gt;Loading…&lt;/p&gt;\n\n\n\nsurvey &lt;- read_csv(\"data/survey-2025-02-06.csv\")\nsurvey\n\n# A tibble: 209 × 3\n   Timestamp         How many classes do you have on Tues…¹ `What year are you?`\n   &lt;chr&gt;             &lt;chr&gt;                                  &lt;chr&gt;               \n 1 2/6/2025 11:33:57 3                                      Sophomore           \n 2 2/6/2025 11:37:39 3                                      First-year          \n 3 2/6/2025 11:40:55 2                                      Senior              \n 4 2/6/2025 11:42:05 3                                      First-year          \n 5 2/6/2025 11:42:46 3                                      Senior              \n 6 2/6/2025 11:43:28 3                                      Senior              \n 7 2/6/2025 11:44:41 3                                      First-year          \n 8 2/6/2025 11:44:49 3                                      First-year          \n 9 2/6/2025 11:44:51 2                                      Sophomore           \n10 2/6/2025 11:44:51 3                                      Sophomore           \n# ℹ 199 more rows\n# ℹ abbreviated name: ¹​`How many classes do you have on Tuesdays?`"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-2",
    "href": "slides/09-importing-recoding-data.html#data-science-2",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science\n\n\nCollection: we won’t seriously study this!\n\n\nfor us: data importing (read_csv), and webscraping (next time);\n\nbut really: domain-specific issues of measurement, survey design, experimental design, etc;\n\n\n\n\n\n\nPreparation: cleaning, wrangling, and otherwise tidying the data so we can actually work with it.\n\n\nkeywords: mutate, fct_relevel, pivot_*, *_join"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-preparation",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-preparation",
    "title": "Importing and recoding data",
    "section": "From last time: data preparation",
    "text": "From last time: data preparation\n\nsurvey &lt;- survey |&gt;\n  rename(\n    tue_classes = `How many classes do you have on Tuesdays?`,\n    year = `What year are you?`\n  ) |&gt;\n  mutate(\n    tue_classes = case_when(\n      tue_classes == \"2 -3\" ~ \"3\",\n      tue_classes == \"3 classes\" ~ \"3\",\n      tue_classes == \"Four\" ~ \"4\",\n      tue_classes == \"TWO MANY\" ~ \"2\",\n      tue_classes == \"Three\" ~ \"3\",\n      tue_classes == \"Two\" ~ \"2\",\n      tue_classes == \"Two plus a chemistry lab\" ~ \"3\",\n      tue_classes == \"three\" ~ \"3\",\n      .default = tue_classes\n    ),\n    tue_classes = as.numeric(tue_classes),\n    year = fct_relevel(year, \"First-year\", \"Sophomore\", \"Junior\", \"Senior\")\n  ) |&gt;\n  select(tue_classes, year)\nsurvey\n\n# A tibble: 209 × 2\n   tue_classes year      \n         &lt;dbl&gt; &lt;fct&gt;     \n 1           3 Sophomore \n 2           3 First-year\n 3           2 Senior    \n 4           3 First-year\n 5           3 Senior    \n 6           3 Senior    \n 7           3 First-year\n 8           3 First-year\n 9           2 Sophomore \n10           3 Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-3",
    "href": "slides/09-importing-recoding-data.html#data-science-3",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science\n\n\nCollection: we won’t seriously study this!\n\n\nfor us: data importing (read_csv), and webscraping (next time);\n\nbut really: domain-specific issues of measurement, survey design, experimental design, etc;\n\n\n\nPreparation: cleaning, wrangling, and otherwise tidying the data so we can actually work with it.\n\n\nkeywords: mutate, fct_relevel, pivot_*, *_join\n\n\n\n\n\n\n\nAnalysis: finally transform the data into knowledge…\n\n\npictures: ggplot, geom_*, etc\n\nnumerical summaries: summarize, group_by, count, mean, median, sd, quantile, IQR, cor, etc"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-analysis",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-analysis",
    "title": "Importing and recoding data",
    "section": "From last time: data analysis",
    "text": "From last time: data analysis\nA human being can learn nothing from staring at this box:\n\nsurvey\n\n# A tibble: 209 × 2\n   tue_classes year      \n         &lt;dbl&gt; &lt;fct&gt;     \n 1           3 Sophomore \n 2           3 First-year\n 3           2 Senior    \n 4           3 First-year\n 5           3 Senior    \n 6           3 Senior    \n 7           3 First-year\n 8           3 First-year\n 9           2 Sophomore \n10           3 Sophomore \n# ℹ 199 more rows"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-1",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-1",
    "title": "Importing and recoding data",
    "section": "From last time: data analysis",
    "text": "From last time: data analysis\nPicture!\n\nggplot(survey, aes(x = tue_classes, fill = year)) + \n  geom_bar(position = \"dodge\")"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-2",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-2",
    "title": "Importing and recoding data",
    "section": "From last time: data analysis",
    "text": "From last time: data analysis\nBetter picture?\n\nggplot(survey, aes(x = tue_classes, fill = year)) + \n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-3",
    "href": "slides/09-importing-recoding-data.html#from-last-time-data-analysis-3",
    "title": "Importing and recoding data",
    "section": "From last time: data analysis",
    "text": "From last time: data analysis\nNumbers!\n\nsurvey |&gt;\n  count(tue_classes, year) |&gt;\n  group_by(tue_classes) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 17 × 4\n# Groups:   tue_classes [5]\n   tue_classes year           n   prop\n         &lt;dbl&gt; &lt;fct&gt;      &lt;int&gt;  &lt;dbl&gt;\n 1           1 Sophomore      4 0.4   \n 2           1 Junior         4 0.4   \n 3           1 Senior         2 0.2   \n 4           2 First-year    25 0.439 \n 5           2 Sophomore     19 0.333 \n 6           2 Junior         9 0.158 \n 7           2 Senior         4 0.0702\n 8           3 First-year    47 0.427 \n 9           3 Sophomore     46 0.418 \n10           3 Junior         9 0.0818\n11           3 Senior         8 0.0727\n12           4 First-year    18 0.621 \n13           4 Sophomore      9 0.310 \n14           4 Junior         1 0.0345\n15           4 Senior         1 0.0345\n16           5 First-year     2 0.667 \n17           5 Sophomore      1 0.333"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#data-science-4",
    "href": "slides/09-importing-recoding-data.html#data-science-4",
    "title": "Importing and recoding data",
    "section": "Data science",
    "text": "Data science\n\n\nCollection: we won’t seriously study this!\n\n\nfor us: data importing (read_csv), and webscraping (next time);\n\nbut really: domain-specific issues of measurement, survey design, experimental design, etc;\n\n\n\nPreparation: cleaning, wrangling, and otherwise tidying the data so we can actually work with it.\n\n\nkeywords: mutate, fct_relevel, pivot_*, *_join\n\n\n\n\nAnalysis: finally transform the data into knowledge…\n\n\npictures: ggplot, geom_*, etc\n\nnumerical summaries: summarize, group_by, count, mean, median, sd, quantile, iqr, cor, etc\n\n\n\n\nThe pictures and the summaries need to work together!"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet",
    "href": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet",
    "title": "Importing and recoding data",
    "section": "A cautionary tale: Anscombe’s quartet",
    "text": "A cautionary tale: Anscombe’s quartet\n\n\nDataset I\n\n\n    x     y\n1  10  8.04\n2   8  6.95\n3  13  7.58\n4   9  8.81\n5  11  8.33\n6  14  9.96\n7   6  7.24\n8   4  4.26\n9  12 10.84\n10  7  4.82\n11  5  5.68\n\n\n\nDataset II\n\n\n    x    y\n1  10 9.14\n2   8 8.14\n3  13 8.74\n4   9 8.77\n5  11 9.26\n6  14 8.10\n7   6 6.13\n8   4 3.10\n9  12 9.13\n10  7 7.26\n11  5 4.74\n\n\n\nDataset III\n\n\n    x     y\n1  10  7.46\n2   8  6.77\n3  13 12.74\n4   9  7.11\n5  11  7.81\n6  14  8.84\n7   6  6.08\n8   4  5.39\n9  12  8.15\n10  7  6.42\n11  5  5.73\n\n\n\nDataset IV\n\n\n    x     y\n1   8  6.58\n2   8  5.76\n3   8  7.71\n4   8  8.84\n5   8  8.47\n6   8  7.04\n7   8  5.25\n8  19 12.50\n9   8  5.56\n10  8  7.91\n11  8  6.89"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet-1",
    "href": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet-1",
    "title": "Importing and recoding data",
    "section": "A cautionary tale: Anscombe’s quartet",
    "text": "A cautionary tale: Anscombe’s quartet\n\nggplot(anscombe_tidy, aes(x, y)) +\n  geom_point() +\n  facet_wrap(~ set)"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet-2",
    "href": "slides/09-importing-recoding-data.html#a-cautionary-tale-anscombes-quartet-2",
    "title": "Importing and recoding data",
    "section": "A cautionary tale: Anscombe’s quartet",
    "text": "A cautionary tale: Anscombe’s quartet\n\nggplot(anscombe_tidy, aes(x, y)) +\n  geom_point() +\n  facet_wrap(~ set) +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#if-you-only-looked-at-summary-statistics",
    "href": "slides/09-importing-recoding-data.html#if-you-only-looked-at-summary-statistics",
    "title": "Importing and recoding data",
    "section": "If you only looked at summary statistics…",
    "text": "If you only looked at summary statistics…\n\nanscombe_tidy |&gt;\n  group_by(set) |&gt;\n  summarize(\n    xbar = mean(x),\n    ybar = mean(y),\n    sx = sd(x),\n    sy = sd(y),\n    r = cor(x, y)\n  )\n\n# A tibble: 4 × 6\n  set    xbar  ybar    sx    sy     r\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 I         9  7.50  3.32  2.03 0.816\n2 II        9  7.50  3.32  2.03 0.816\n3 III       9  7.5   3.32  2.03 0.816\n4 IV        9  7.50  3.32  2.03 0.817"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#our-motto-abv",
    "href": "slides/09-importing-recoding-data.html#our-motto-abv",
    "title": "Importing and recoding data",
    "section": "Our motto: ABV!",
    "text": "Our motto: ABV!\n\nNo, not alcohol by volume…\n\n\n\n\n\nAlways!\n\nBe!\n\nVisualizing!"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#finish-up-ae-08-durham-climate-factors",
    "href": "slides/09-importing-recoding-data.html#finish-up-ae-08-durham-climate-factors",
    "title": "Importing and recoding data",
    "section": "Finish up: ae-08-durham-climate-factors\n",
    "text": "Finish up: ae-08-durham-climate-factors\n\n\n\nGo to your ae project in RStudio.\nOpen ae-08-durham-climate-factors.qmd and pick up at “Recode and reorder”."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#reading-rectangular-data",
    "href": "slides/09-importing-recoding-data.html#reading-rectangular-data",
    "title": "Importing and recoding data",
    "section": "Reading rectangular data",
    "text": "Reading rectangular data\n\nUsing readr:\n\nMost commonly: read_csv()\n\nMaybe also: read_tsv(), read_delim(), etc.\n\n\n\n\n\nUsing readxl: read_excel()\n\n\n\n\n\nUsing googlesheets4: read_sheet() – We haven’t covered this in the videos, but might be useful for your projects"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#goal-1-reading-and-writing-csv-files",
    "href": "slides/09-importing-recoding-data.html#goal-1-reading-and-writing-csv-files",
    "title": "Importing and recoding data",
    "section": "Goal 1: Reading and writing CSV files",
    "text": "Goal 1: Reading and writing CSV files\n\nRead a CSV file\nSplit it into subsets based on features of the data\nWrite out subsets as CSV files"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#age-gap-in-hollywood-relationships",
    "href": "slides/09-importing-recoding-data.html#age-gap-in-hollywood-relationships",
    "title": "Importing and recoding data",
    "section": "Age gap in Hollywood relationships",
    "text": "Age gap in Hollywood relationships\n\n\n\nWhat is the story in this visualization?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#ae-08-age-gaps-sales-import---part-1",
    "href": "slides/09-importing-recoding-data.html#ae-08-age-gaps-sales-import---part-1",
    "title": "Importing and recoding data",
    "section": "ae-08-age-gaps-sales-import - Part 1",
    "text": "ae-08-age-gaps-sales-import - Part 1\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-08-age-gaps-sales-import.qmd.\nWork through Part 1 of the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#goal-2-reading-excel-files",
    "href": "slides/09-importing-recoding-data.html#goal-2-reading-excel-files",
    "title": "Importing and recoding data",
    "section": "Goal 2: Reading Excel files",
    "text": "Goal 2: Reading Excel files\n\nRead an Excel file with non-tidy data\nTidy it up!"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#sales-data",
    "href": "slides/09-importing-recoding-data.html#sales-data",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\n\n\nAre these data tidy? Why or why not?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#sales-data-1",
    "href": "slides/09-importing-recoding-data.html#sales-data-1",
    "title": "Importing and recoding data",
    "section": "Sales data",
    "text": "Sales data\n\nWhat “data moves” do we need to go from the original, non-tidy data to this, tidy one?"
  },
  {
    "objectID": "slides/09-importing-recoding-data.html#ae-08-age-gaps-sales-import---part-2",
    "href": "slides/09-importing-recoding-data.html#ae-08-age-gaps-sales-import---part-2",
    "title": "Importing and recoding data",
    "section": "ae-08-age-gaps-sales-import - Part 2",
    "text": "ae-08-age-gaps-sales-import - Part 2\n\n\nGo to your ae project in RStudio.\nIf you haven’t yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there’s nothing left in your Git pane.\nIf you haven’t yet done so, click Pull to get today’s application exercise file: ae-08-age-gaps-sales-import.qmd.\nWork through Part 2 of the application exercise in class, and render, commit, and push your edits."
  },
  {
    "objectID": "syllabus/syllabus_materials.html",
    "href": "syllabus/syllabus_materials.html",
    "title": "Course materials",
    "section": "",
    "text": "All books are freely available online:\n\n[ims]: Mine Çetinkaya-Rundel and Jo Hardin. Introduction to Modern Statistics. 2nd edition. OpenIntro, 2024.\n[r4ds]: Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science. 2nd edition. O’Reilly, 2022.",
    "crumbs": [
      "Syllabus",
      "Materials"
    ]
  },
  {
    "objectID": "syllabus/syllabus_materials.html#textbooks",
    "href": "syllabus/syllabus_materials.html#textbooks",
    "title": "Course materials",
    "section": "",
    "text": "All books are freely available online:\n\n[ims]: Mine Çetinkaya-Rundel and Jo Hardin. Introduction to Modern Statistics. 2nd edition. OpenIntro, 2024.\n[r4ds]: Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science. 2nd edition. O’Reilly, 2022.",
    "crumbs": [
      "Syllabus",
      "Materials"
    ]
  },
  {
    "objectID": "syllabus/syllabus_materials.html#technology",
    "href": "syllabus/syllabus_materials.html#technology",
    "title": "Course materials",
    "section": "Technology",
    "text": "Technology\nYou will need to bring a laptop to all lectures and labs. Options for obtaining a laptop through the university are described here. Armed with your trusty laptop, you must be able to access the following:\n\nThis course page that you are on right now;\nR/RStudio as provided by the Duke Container Manager;\nCanvas, through which you can access…\n\nGradescope;\nEd Discussion;\n\nPanopto (for the lecture recordings);\nZoom (e.g. for remote office hours).\n\nIf access to technology becomes a concern for you during the semester, contact the instructor immediately to discuss options.",
    "crumbs": [
      "Syllabus",
      "Materials"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html",
    "href": "syllabus/syllabus_resources.html",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#course-costs",
    "href": "syllabus/syllabus_resources.html#course-costs",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#tech-support",
    "href": "syllabus/syllabus_resources.html#tech-support",
    "title": "University resources",
    "section": "Tech support",
    "text": "Tech support\nContact the Duke OIT Service Desk at oit.duke.edu/help.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#academic-support",
    "href": "syllabus/syllabus_resources.html#academic-support",
    "title": "University resources",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#accessibility",
    "href": "syllabus/syllabus_resources.html#accessibility",
    "title": "University resources",
    "section": "Accessibility",
    "text": "Accessibility\nIf any portion of the course is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students can engage with their courses and related assignments. Students should contact the SDAO to request or update accommodations under these circumstances.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#mental-health-and-well-being",
    "href": "syllabus/syllabus_resources.html#mental-health-and-well-being",
    "title": "University resources",
    "section": "Mental health and well-being",
    "text": "Mental health and well-being\nDuke is committed to holistic student well-being, including mental, emotional, and physical health. The university offers resources to help students manage daily stress, encourage intentional self-care, and access just-in-time support. If you find you need support, your mental and/or emotional health concerns are impacting your day-to-day activities and your academic performance, or you need someone to talk to, the resources below are available to you:\n\nDukeReach: DukeReach provides comprehensive outreach services to support students in managing all aspects of well-being, including referrals and follow-up services for students who are experiencing significant challenges related to mental health, physical health, social adjustment, and/or a variety of other stressors. You can reach the DukeReach team at dukereach@duke.edu.\nCounseling and Psychological Services (CAPS): CAPS services include individual and group counseling services, psychiatric services, and workshops. CAPS also provides referrals to off-campus resources for specialized care. You can reach CAPS at (919) 660-1000.\nTimelyCare: TimelyCare is an online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling.\nBC Fellows for Healthy Relationship: The BC Fellows meet with students individually and in groups, supporting the development of healthy relationships and building meaningful community in all areas of a student’s life.\nDukeLine: Students who want to connect anonymously with a Peer Coach can text 984-230-4888 from 5 to 11 p.m. daily. DukeLine offers in-the-moment anonymous, non-emergency text support from a peer.\nDuWell: DuWell provides Moments of Mindfulness (stress management and resilience building) and meditation programming (Koru workshop) to assist students in developing a daily emotional well-being practice. All are welcome, and no experience is necessary. You can reach DuWell at (919) 681-8421.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html",
    "href": "syllabus/syllabus_assignments.html",
    "title": "Assignments and grading",
    "section": "",
    "text": "Your final course grade will be calculated as follows:\nYour final letter grade will be determined based on these thresholds:",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#application-exercises-5",
    "href": "syllabus/syllabus_assignments.html#application-exercises-5",
    "title": "Assignments and grading",
    "section": "Application exercises (5%)",
    "text": "Application exercises (5%)\nDuring most lectures, we will work through an application exercise (AE) together. This is essentially a guided mini-lab that shows you how to implement the concepts introduced that day. On-time completion of at least 70% of AEs will result in full credit for the AE component of the final course grade. Here is what that means:\n\nAEs are due at 2PM ET on the day they are introduced;\nSubmit an AE by pushing your work to your GitHub repo;\nAEs are graded for completion; if you make a good faith attempt at all parts of the exercisem you get the credit.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can miss 30% of AEs before it starts affecting your final grade. This policy is meant to smooth over technical mishaps, absences due to illness, athletics, etc. So we generally will not grant extensions or exemptions for AEs. We just let the 30% policy do its thing;",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#labs-15",
    "href": "syllabus/syllabus_assignments.html#labs-15",
    "title": "Assignments and grading",
    "section": "Labs (15%)",
    "text": "Labs (15%)\nIn labs, you will apply what you have learned in the videos and during lectures to complete data analysis tasks. You may discuss lab assignments with other students; however, the lab should be completed and submitted individually. Lab assignments must be typed up using Quarto, all work must be pushed to your GitHub repository for the lab, and the lab’s PDF output must be submitted on Gradescope by the deadline. Labs are due at 8:30 am ET on the indicated due date (generally the Monday after the lab is first introduced).\n\n\n\n\n\n\nNote\n\n\n\nYour lowest lab score will be dropped. This policy will be applied to the gradebook at the end of the semester, after all labs have been graded/regraded, and before the final exam.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#midterm-exams-20-each",
    "href": "syllabus/syllabus_assignments.html#midterm-exams-20-each",
    "title": "Assignments and grading",
    "section": "Midterm Exams (20% each)",
    "text": "Midterm Exams (20% each)\nThere will be two midterm exams, each with two components:\n\nIn-class (70% of the grade): sit-down, in-person, “pencil-and-paper,” with no technology, and with no outside resources apart from a note sheet that you and only you have prepared (both sides of an 8.5” x 11” piece of paper);\nTake-home (30% of the grade): each in-class exam will end at 1:00 PM ET on a Thursday. You will then have until 8:00 AM ET the following Monday to work independently on the take-home. This will consist of a data analysis in R, and submission will be identical to our usual labs (Quarto &gt; PDF &gt; Gradescope). The take-home portion of the midterms is completely open resource, but the citation policies of the course still apply, and you are forbidden from discussing the exam with your peers in any way.\n\nUnless we indicate otherwise, you should assume that all course content and materials (videos, readings, lectures, labs, AEs, etc) are testable.\n\n\n\n\n\n\nWarning\n\n\n\nSee the course schedule for dates and times of the exams. Exam dates cannot be changed and no make-up exams will be given. If you cannot take the exams on these dates, you should drop this class.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#final-exam-20",
    "href": "syllabus/syllabus_assignments.html#final-exam-20",
    "title": "Assignments and grading",
    "section": "Final Exam (20%)",
    "text": "Final Exam (20%)\nOn Tuesday April 29 we have our final exam from 9AM ET to 12PM ET. This exam will be cumulative, and it will have the same format as the in-class components of the midterm exams. The final exam does not have a take-home portion.\n\n\n\n\n\n\nNote\n\n\n\nIf you do better on the final exam than you did on the in-class component of a midterm, we will replace your lowest in-class midterm exam score with your final exam score.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#final-project-20",
    "href": "syllabus/syllabus_assignments.html#final-project-20",
    "title": "Assignments and grading",
    "section": "Final project (20%)",
    "text": "Final project (20%)\nAfter the first midterm exam, we will assign you to teams of four or five within your lab section. Teams will select a dataset and conduct an original data analysis using the tools from the course. The project has various intermediate deadlines (“Milestones”) that contribute to the project grade, and on the last day of the semester (Wednesday April 23) teams will submit a final written report and a five minute video presentation summarizing the results of the analysis.\n\n\n\n\n\n\nWarning\n\n\n\nIf you do not complete the project, you will not receive a passing grade in this course.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "project/2-proposal.html",
    "href": "project/2-proposal.html",
    "title": "Proposal",
    "section": "",
    "text": "The goals of this milestone are as follows:\n\nDiscuss topics you’re interested in investigating and find data sets on those topics.\nIdentify 2 data sets you’re interested in potentially using for the project.\nGet these datasets into R.\nWrite up reasons and justifications for why you want to work with these datasets.\nReview your team contract.\n\n\n\n\n\n\n\nImportant\n\n\n\nYou must use one of the data sets in the proposal for the final project, unless instructed otherwise when given feedback.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#criteria-for-datasets",
    "href": "project/2-proposal.html#criteria-for-datasets",
    "title": "Proposal",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 500 observations.\nAt least 8 columns.\nAt least 6 of the columns must be useful and unique explanatory variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\nYou can curate one of your datasets via web scraping.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#resources-for-datasets",
    "href": "project/2-proposal.html#resources-for-datasets",
    "title": "Proposal",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nUNICEF Data\nGoogle Dataset Search\nData is Plural\nElection Studies\nUS Census Data\nWorld Bank Data\nCDC\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nHarvard Dataverse\nInternational Monetary Fund [See “Popular Datasets”]\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nResponsible Datasets in Context\nStatistics Canada\nTidyTuesday\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Government Data\nFRED Economic Data\nData.gov\nAwesome public datasets\nDurham Open Data Portal\nFiveThirtyEight",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#introduction-and-data",
    "href": "project/2-proposal.html#introduction-and-data",
    "title": "Proposal",
    "section": "Introduction and data",
    "text": "Introduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#research-question",
    "href": "project/2-proposal.html#research-question",
    "title": "Proposal",
    "section": "Research question",
    "text": "Research question\nYour research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#glimpse-of-data",
    "href": "project/2-proposal.html#glimpse-of-data",
    "title": "Proposal",
    "section": "Glimpse of data",
    "text": "Glimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the glimpse() function to provide a glimpse of the data set.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/2-proposal.html#data-dictionary",
    "href": "project/2-proposal.html#data-dictionary",
    "title": "Proposal",
    "section": "Data dictionary",
    "text": "Data dictionary\nFor each data set, add a data dictionary to the README.md file in the data folder describing each variable.",
    "crumbs": [
      "Project",
      "Milestone 2"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html",
    "href": "project/1-working-collaboratively.html",
    "title": "Working collaboratively",
    "section": "",
    "text": "Important\n\n\n\nYou must attend this lab in person and participate in the merge conflict activity to be eligible for the points for this milestone. Team members who are not in lab in person for this activity will not be eligible for these points, regardless of their contribution throughout the rest of the project.\nData science is a collaborative discipline. Pretty much no data scientist works alone, so neither should you! In this course you’ll collaborate with teammates on the project.\nThe first milestone of the project, today’s activity, will introduce you to the technical aspects of collaborating on a reproducible data science project that is version controlled by Git and hosted on GitHub in a repository shared by all teammates.\nYes, this means you and all of your teammates will be pushing to the same repository! Sometimes things will go swimmingly, and sometimes you’ll run into merge conflicts.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html#activity",
    "href": "project/1-working-collaboratively.html#activity",
    "title": "Working collaboratively",
    "section": "Activity",
    "text": "Activity\nSetup\n\nClone the project repo and open the about.qmd file.\nAssign the numbers 1, 2, 3, 4, and 5 to each of the team members. If your team has fewer than 5 people, some people will need to have multiple numbers.\nLet’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\nBefore starting\nEveryone should have the repo cloned and know which role number(s) they are.\nRole 1\n\nGo to about.qmd in your project repo. Change the [team name] to your actual team name.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\nRole 2\n\nChange the team name to some other word.\nRender the project by clicking on Render in the Build tab, commit (all changed files), and push. You should get an error.\nPull. Take a look at the document (about.qmd) with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nRender the project by clicking on Render in the Build tab.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\nCommit and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\nRole 3\n\nChange the name of the first team member.\nRender the project by clicking on Render in the Build tab, commit, and push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\nRole 4\n\nChange the name of the first team member to something other than what the previous team member did.\nRender the project by clicking on Render in the Build tab, commit, and push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. Render the project by clicking on Render in the Build tab, commit, and push.\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure the previous role has finished before moving on to the next step.\n\n\nRole 5\n\nChange the name of the rest of the team members and add descriptions for each person with the help of your team members. Role 5 should be the only one typing; the others should help verbally.\nRender the project by clicking on Render in the Build tab and commit. Discuss as a team what you expect to happen when you hit push. Should there be a merge conflict error or not?\nIf there is a merge conflict, fix it. If not, push your changes.\nEveryone\nPull, and observe the changes in your project.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "href": "project/1-working-collaboratively.html#tips-for-collaborating-via-github",
    "title": "Working collaboratively",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (render and push) before continuing your work. Never do new work while resolving a merge conflict.\nRender, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger.",
    "crumbs": [
      "Project",
      "Milestone 1"
    ]
  },
  {
    "objectID": "project/tips-resources.html",
    "href": "project/tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "The project is very open ended. For instance, in creating a compelling visualization(s) of your data in R, there is no limit on what tools or packages you may use. You do not need to visualize all of the data at once. A single high quality visualization will receive a much higher grade than a large number of poor quality visualizations.\nBefore you finalize your write up, make sure the printing of code chunks is turned off with the option echo: false. In addition to code chunks, ensure all messages are turned off with the options warning: false and message: false.\nFinally, pay attention to details in your write-up and presentation. Neatness, coherency, and clarity will count."
  },
  {
    "objectID": "project/tips-resources.html#suppress-code-and-warnings",
    "href": "project/tips-resources.html#suppress-code-and-warnings",
    "title": "Project tips + resources",
    "section": "Suppress code and warnings",
    "text": "Suppress code and warnings\n\nInclude the following in the YAML of your report.qmd to suppress all code, warnings, and other messages.\n\nexecute:\n  echo: false\n  warning: false"
  },
  {
    "objectID": "project/tips-resources.html#headers",
    "href": "project/tips-resources.html#headers",
    "title": "Project tips + resources",
    "section": "Headers",
    "text": "Headers\nUse headers to clearly label each section. Make sure there is a space between the previous line and the header. Use appropriate header levels."
  },
  {
    "objectID": "project/tips-resources.html#references",
    "href": "project/tips-resources.html#references",
    "title": "Project tips + resources",
    "section": "References",
    "text": "References\nInclude all references in a section called “References” at the end of the report. This course does not have specific requirements for formatting citations and references. Optional: Use Quarto’s citation support for generating your reference. See Citations & Footnotes on the Quarto documentation for more on that."
  },
  {
    "objectID": "project/tips-resources.html#appendix",
    "href": "project/tips-resources.html#appendix",
    "title": "Project tips + resources",
    "section": "Appendix",
    "text": "Appendix\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”. The items in the appendix should be properly labeled. The appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix. We will not grade your appendix."
  },
  {
    "objectID": "project/tips-resources.html#resize-figures",
    "href": "project/tips-resources.html#resize-figures",
    "title": "Project tips + resources",
    "section": "Resize figures",
    "text": "Resize figures\nResize plots and figures, so you have more space for the narrative. Resize individual figures: Set fig-width and fig-height in chunk options, e.g.,\n#| echo: fenced\n#| label: code-cell-label\n#| fig-width: 5\n#| fig-asp: 0.628\nreplacing code-cell-label with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig-width and fig-asp options in the YAML header as shown below:\nexecute:\n  fig-width: 5\n  fig-asp: 0.628\nReplace the height and width values with values appropriate for your write up."
  },
  {
    "objectID": "project/tips-resources.html#arranging-plots",
    "href": "project/tips-resources.html#arranging-plots",
    "title": "Project tips + resources",
    "section": "Arranging plots",
    "text": "Arranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\nThe patchwork package makes it easy to arrange plots in a grid."
  },
  {
    "objectID": "project/4-peer-review.html",
    "href": "project/4-peer-review.html",
    "title": "Peer review",
    "section": "",
    "text": "During the peer feedback process, you will be provided read-only access to your partner team’s GitHub repo. You will provide your feedback in the form of GitHub issues to your partner team’s GitHub repo.\nGoals\nThe goals of this milestone are as follows:\n\nReview others’ project drafts as a team and provide feedback\nPost issues on GitHub using an issue template\nLearn from others’ projects and improve your own project based on their strengths and weaknesses\nInstructions\nReview two other teams’ projects. As a team you should spend ~30 minutes on each team’s project.\n\nFind the names of the teams whose projects you’re reviewing below. You should already have access to this team’s repo.\nEach team member should go to the repo of the team you’re reviewing.\n\nThen,\n\n1-2 team members clone the team’s project and renders it to check for reproducibility.\n1-2 team members open the team’s project in their browser and starts reading through the project draft.\n1 team member opens an issue on the team’s repo using the peer review template.\nAll team members discuss the project based on the prompts on the issue template and one team member records the feedback and submits the issue.\n\n\n\nTo open an issue in the repo you’re reviewing, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical reasoning aspect of the project, but do feel free to comment on aspects beyond the reasoning as well.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation?\nWere you able to reproduce the project by clicking on Render Website once you cloned it? Were there any issues with reproducibility?\nProvide constructive feedback on any issues with file and/or code organization.\nWhat have you learned from this team’s project that you are considering implementing in your own project?\n(Optional) Any further comments or feedback?\n\n\nReview pairings\n\n\nL1 - 8:30 am\nL2 - 10:05 am\nL3 - 10:05 am\nL4 - 11:45 am\nL5 - 11:45 am\nL6 - 1:25 pm\nL7 - 1:25 pm\nL8 - 3:05 pm\nL9 - 3:05 pm\nL10 - 4:40 pm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrading\nPeer reviews will be graded on the extent to which it comprehensively and constructively addresses the components of the reviewee’s team’s report.\nOnly the team members participating in the review during the lab session are eligible for points for the peer review. If you’re unable to make it to lab in person, you should arrange to virtually connect with your team during your lab session.\n\n0 points: No peer review\n1 point: Feedback provided is not constructive or actionable\n2-4 points: Feedback provided is not sufficiently thorough\n5 points: Peer review is constructive, actionable, and sufficiently thorough\n\n\n\n\n\n\n\nNote\n\n\n\nThe feedback issue will come from one team member on GitHub since you can’t collectively edit an issue. However it must represent the opinions of the entire team. It is not a single team member’s responsibility to provide feedback, they’re just the record keeper for the team.",
    "crumbs": [
      "Project",
      "Milestone 4"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html",
    "href": "exam/midterm-1-batch-B.html",
    "title": "Midterm 1 Practice Questions",
    "section": "",
    "text": "Solutions\n\n\n\n\n\nSee here.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#penguins",
    "href": "exam/midterm-1-batch-B.html#penguins",
    "title": "Midterm 1 Practice Questions",
    "section": "Penguins",
    "text": "Penguins\nThe penguins data set includes measurements for penguin species, including: flipper length, body mass, bill dimensions, and sex. The following table summarizes information on which species of penguins (Adelie, Gentoo, and Chinstrap) live on which islands (Biscoe, Dream, or Torgersen).\n\n\n\n\n\n\nIsland\nAdelie\nGentoo\nChinstrap\nTotal\n\n\n\nBiscoe\n44\n124\n0\n168\n\n\nDream\n56\n0\n68\n124\n\n\nTorgersen\n52\n0\n0\n52\n\n\nTotal\n152\n124\n68\n344\n\n\n\n\n\n\nQuestion 1\nWhich of the following plots is the result of the following code?\n\nggplot(penguins, aes(x = island, fill = species)) + \n  geom_bar()",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#nyc-flights",
    "href": "exam/midterm-1-batch-B.html#nyc-flights",
    "title": "Midterm 1 Practice Questions",
    "section": "NYC Flights",
    "text": "NYC Flights\nThe flights dataset includes characteristics of all flights departing from New York City airports (JFK, LGA, EWR) in 2013. Below is a peek at the first ten rows of the flights data.\n\nflights |&gt;\n  relocate(year, month, day, arr_delay, carrier)\n\n# A tibble: 336,776 × 19\n    year month   day arr_delay carrier dep_time sched_dep_time dep_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n 1  2013     1     1        11 UA           517            515         2\n 2  2013     1     1        20 UA           533            529         4\n 3  2013     1     1        33 AA           542            540         2\n 4  2013     1     1       -18 B6           544            545        -1\n 5  2013     1     1       -25 DL           554            600        -6\n 6  2013     1     1        12 UA           554            558        -4\n 7  2013     1     1        19 B6           555            600        -5\n 8  2013     1     1       -14 EV           557            600        -3\n 9  2013     1     1        -8 B6           557            600        -3\n10  2013     1     1         8 AA           558            600        -2\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_time &lt;int&gt;, sched_arr_time &lt;int&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nQuestion 2\nBased on this output, which of the following must be true about the flights data frame? Select all that are true.\n\nThe flights data frame is a tibble.\nThe flights data frame has 10 rows.\nThe flights data frame has 8 columns.\nThe carrier variable in the flights data frame is a character variable.\nThere are no missing data in the flights data frame.\nQuestion 3\nWhich of the following pipelines produce(s) the output shown below? Select all that apply.\n\n\n# A tibble: 336,776 × 5\n   arr_delay carrier  year month   day\n       &lt;dbl&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1      1272 HA       2013     1     9\n 2      1127 MQ       2013     6    15\n 3      1109 MQ       2013     1    10\n 4      1007 AA       2013     9    20\n 5       989 MQ       2013     7    22\n 6       931 DL       2013     4    10\n 7       915 DL       2013     3    17\n 8       895 DL       2013     7    22\n 9       878 AA       2013    12     5\n10       875 MQ       2013     5     3\n# ℹ 336,766 more rows\n\n\na.\n\nflights |&gt;\n  select(arr_delay, carrier, year, month, day) |&gt;\n  arrange(desc(arr_delay))\n\nb.\n\nflights |&gt;\n  select(arr_delay, carrier, year, month, day) |&gt;\n  arrange(arr_delay)\n\nc.\n\nflights |&gt;\n  select(arr_delay, carrier, year, month, day) |&gt;\n  arrange(year)\n\nd.\n\nflights |&gt;\n  arrange(desc(arr_delay)) |&gt;\n  select(arr_delay, carrier, year, month, day)\n\ne.\n\nflights |&gt;\n  arrange(desc(arr_delay)) |&gt;\n  select(day, month, year, arr_delay, carrier)",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#countries-and-populations",
    "href": "exam/midterm-1-batch-B.html#countries-and-populations",
    "title": "Midterm 1 Practice Questions",
    "section": "Countries and populations",
    "text": "Countries and populations\nWe have a small dataset of six countries and their populations:\n\npopulation\n\n# A tibble: 6 × 2\n  country       population\n  &lt;chr&gt;              &lt;dbl&gt;\n1 Curacao            150  \n2 Ecuador          18001  \n3 Iraq             44496. \n4 New Zealand       5124. \n5 Palau               18.0\n6 United States   333288. \n\n\nAnd another small dataset of five countries and the continent they’re in:\n\ncontinents\n\n# A tibble: 5 × 3\n  entity      code  continent    \n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        \n1 Angola      AGO   Africa       \n2 Curacao     CUW   North America\n3 Ecuador     ECU   South America\n4 Iraq        IRQ   Asia         \n5 New Zealand NZL   Oceania      \n\n\nYou join the two datasets with the following:\n\npopulation |&gt;\n  left_join(continents, by = join_by(country == entity))\n\nQuestion 4\nHow many rows will the resulting data frame have?\n\n4\n5\n6\n7\n8\nQuestion 5\nWhat will be the columns of the resulting data frame?\n\ncountry, population\ncountry, population, code, continent\nentity, code, continent\nentity, population, code, continent\ncountry, entity, population, code, continent",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#duke-forest-houses",
    "href": "exam/midterm-1-batch-B.html#duke-forest-houses",
    "title": "Midterm 1 Practice Questions",
    "section": "Duke Forest houses",
    "text": "Duke Forest houses\nThe duke_forest dataset includes information on prices and various other features (number of bedrooms, bathrooms, area, year built, type of cooling, type of heating, etc.) of houses in the Duke Forest neighborhood of Durham, NC.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…\n\n\nThe following summary table gives us some information about whether homes in this data set have garages and when they were built.\n\n\n\n\n\n\n\nBuilt earlier than 1950\nBuilt in 1950 or later\n\n\n\nGarage\n5\n33\n\n\nNo garage\n3\n57\n\n\n\n\n\n\nThe pipeline below produces a data frame with a fewer number of rows than duke_forest.\n\nduke_forest |&gt;\n  filter(parking == \"Garage\" _(1)_ year_built _(2)_ 1950) |&gt;\n  select(parking, year_built, price, area) |&gt;\n  _(3)_(price_per_sqfeet = price / area)\n\n\n\n# A tibble: 5 × 5\n  parking year_built  price  area price_per_sqfeet\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;\n1 Garage        1945 900000  2933            307. \n2 Garage        1938 265000  1300            204. \n3 Garage        1934 600000  2514            239. \n4 Garage        1941 412500  1661            248. \n5 Garage        1940 105000  1094             96.0\n\n\nQuestion 6\nWhich of the following goes in blanks (1) and (2)?\n\n\n\n(1)\n(2)\n\n\n\na.\n&\n&lt;\n\n\nb.\n|\n&lt;\n\n\nc.\n&\n&gt;=\n\n\nd.\n|\n&gt;=\n\n\ne.\n&\n!=\n\n\nQuestion 7\nWhich function or functions go into blank (3)? Select all that apply.\n\narrange()\nmutate()\nfilter()\nsummarize()\nslice()",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#law-order",
    "href": "exam/midterm-1-batch-B.html#law-order",
    "title": "Midterm 1 Practice Questions",
    "section": "Law & Order",
    "text": "Law & Order\nYou’ve heard of the tidyverse, now let’s visit the Law & Order-verse. Doink doink!1\nLaw & Order is a police procedural and legal drama television series that has been running since the 1990s. The Law & Order franchise includes a number of series such as Law & Order, Law & Order: SVU, Law & Order: Criminal Intent, etc.\nYou will work with data on average ratings for each season of three series from the Law & Order-verse – a subset of the data from the previous questions. Below is a peek at the first ten rows of the Law & Order data.\nThe plot below shows the distributions of average ratings of various Law & Order series across seasons.\n\n\n\n\n\n\n\n\nQuestion 8\nBased on the information from the side-by-side box plots, fill in the legend of the plot below with Law & Order series titles.\n\n\n\n\n\n\n\n\nQuestion 9\nThe following code calculates the standard deviations of average season ratings of the five Law & Order series. Unfortunately, the output is partially erased and replaced with blanks.\n\nlo_titles &lt;- c(\"Law & Order\", \"Law & Order: Criminal Intent\", \"Law & Order: SVU\")\n\nlaw_and_order |&gt;\n  filter(title %in% lo_titles) |&gt;\n  group_by(title) |&gt;\n  summarize(mean_av_rating = mean(av_rating), sd_av_rating = sd(av_rating))\n\n# A tibble: 5 × 3\n  title                         mean_av_rating sd_av_rating\n  &lt;chr&gt;                                  &lt;dbl&gt;        &lt;dbl&gt;\n1 Law & Order                            _(1)_        0.106\n2 Law & Order: Criminal Intent            8.20        0.129\n4 Law & Order: SVU                        8.67        _(2)_\nBased on the visualizations you’ve seen of these data so far, which of the following is true about the blanks in the output? Select all that are true.\n\nThe mean of average ratings (Blank 1) of Law & Order seasons is lower than the other two means.\nThe mean of average ratings (Blank 1) of Law & Order seasons is higher than the other two means.\nThe standard deviation of average ratings of Law & Order: SVU seasons (Blank 2) is lower than the other two standard deviations.\nThe standard deviation of average ratings of Law & Order: SVU seasons (Blank 2) is higher than the other two standard deviations.\nThe standard deviation of average ratings of Law & Order: SVU seasons (Blank 2) is between the other two standard deviations.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#romance-and-comedy",
    "href": "exam/midterm-1-batch-B.html#romance-and-comedy",
    "title": "Midterm 1 Practice Questions",
    "section": "Romance and comedy",
    "text": "Romance and comedy\nFinally, we focus on romance and comedy shows. We first filter the dataset for any shows that have romance or comedy as their genre (genre_1, genre_2, or genre_3) and then remove shows that have both of these genre labels. For the next two questions, we focus on these shows that we identify as either romance or comedy. We then calculate the mean of the average season ratings for each show, to obtain a single “mean average rating” value per show.\nThe plot below shows the distributions of mean average ratings of seasons of comedy and romance shows.\n\n\n\n\n\n\n\n\nQuestion 10\nWhich of the following statements is true about these distributions? Select all that are true.\n\nMean average ratings of romance shows are bimodal.\nMean average ratings of comedy are unimodal.\nMean average ratings of romance shows is left skewed.\nMean average ratings of comedy shows is right skewed.\nThere are more romance shows than comedy shows.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#imdb",
    "href": "exam/midterm-1-batch-B.html#imdb",
    "title": "Midterm 1 Practice Questions",
    "section": "IMDB",
    "text": "IMDB\nThe data for the next few questions come from the Internet Movie Database (IMDB). Specifically, the data are a random sample of movies released between 1980 and 2020.\n\nmovies &lt;- read_csv(\"data/movies.csv\")\n\nThe name of the data frame used for this analysis is movies, and it contains the variables shown in Table 1.\n\n\nTable 1: Data dictionary for movies\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\nname\nname of the movie\n\n\nrating\nrating of the movie (R, PG, etc.)\n\n\ngenre\nmain genre of the movie.\n\n\nruntime\nduration of the movie\n\n\nyear\nyear of release\n\n\nrelease_date\nrelease date (YYYY-MM-DD)\n\n\nrelease_country\nrelease country\n\n\nscore\nIMDB user rating\n\n\nvotes\nnumber of user votes\n\n\ndirector\nthe director\n\n\nwriter\nwriter of the movie\n\n\nstar\nmain actor/actress\n\n\ncountry\ncountry of origin\n\n\nbudget\nthe budget of a movie (some movies don’t have this, so it appears as 0)\n\n\ngross\nrevenue of the movie\n\n\ncompany\nthe production company\n\n\n\n\n\n\nThe first thirty rows of the movies data frame are shown in Table 2, with variable types suppressed (since we’ll ask about them later).\n\n\nTable 2\n\nFirst 30 rows of movies, with variable types suppressed.\n\n\n# A tibble: 500 × 16\n   name           score runtime genre     rating    release_country release_date\n 1 Blue City        4.4 83 mins Action    R         United States   1986-05-02  \n 2 Winter Sleep     8.1 196     Drama     Not Rated Turkey          2014-06-12  \n 3 Rang De Basan…   8.1 167     Comedy    Not Rated United States   2006-01-26  \n 4 Pokémon Detec…   6.6 104     Action    PG        United States   2019-05-10  \n 5 A Bad Moms Ch…   5.6 104     Comedy    R         United States   2017-11-01  \n 6 Replicas         5.5 107     Drama     PG-13     United States   2019-01-11  \n 7 Windy City       5.8 103     Drama     R         Uruguay         1986-01-01  \n 8 War for the P…   7.4 140     Action    PG-13     United States   2017-07-14  \n 9 Tales from th…   6.4 98      Crime     R         United States   1995-05-24  \n10 Fire with Fire   6.5 103     Drama     PG-13     United States   1986-05-09  \n11 Raising Helen    6   119     Comedy    PG-13     United States   2004-05-28  \n12 Feeling Minne…   5.4 99      Comedy    R         United States   1996-09-13  \n13 The Babe         5.9 115     Biography PG        United States   1992-04-17  \n14 The Real Blon…   6   105     Comedy    R         United States   1998-02-27  \n15 To vlemma tou…   7.6 176     Drama     Not Rated United States   1997-11-01  \n16 Going the Dis…   6.3 102     Comedy    R         United States   2010-09-03  \n17 Jung on zo       6.8 103     Action    R         Hong Kong       1993-06-24  \n18 Rita, Sue and…   6.5 93      Comedy    R         United Kingdom  1987-05-29  \n19 Phone Booth      7   81      Crime     R         United States   2003-04-04  \n20 Happy Death D…   6.6 96      Comedy    PG-13     United States   2017-10-13  \n21 Barely Legal     4.7 90      Comedy    R         Thailand        2006-05-25  \n22 Three Kings      7.1 114     Action    R         United States   1999-10-01  \n23 Menace II Soc…   7.5 97      Crime     R         United States   1993-05-26  \n24 Four Rooms       6.8 98      Comedy    R         United States   1995-12-25  \n25 Quartet          6.8 98      Comedy    PG-13     United States   2013-03-01  \n26 Tape             7.2 86      Drama     R         Denmark         2002-07-12  \n27 Marked for De…   6   93      Action    R         United States   1990-10-05  \n28 Congo            5.2 109     Action    PG-13     United States   1995-06-09  \n29 Stop-Loss        6.4 112     Drama     R         United States   2008-03-28  \n30 Con Air          6.9 115     Action    R         United States   1997-06-06  \n      budget     gross  votes  year director         writer        star         \n                                      \n 1  10000000   6947787   1100  1986 Michelle Manning Ross Macdona… Judd Nelson  \n 2        NA   4018705  48000  2014 Nuri Bilge Ceyl… Ebru Ceylan   Haluk Bilgin…\n 3        NA  10800778 115000  2006 Rakeysh Ompraka… Renzil D'Sil… Aamir Khan   \n 4 150000000 433921300 146000  2019 Rob Letterman    Dan Hernandez Ryan Reynolds\n 5  28000000 130560428  46000  2017 Jon Lucas        Jon Lucas     Mila Kunis   \n 6  30000000   9330075  34000  2018 Jeffrey Nachman… Chad St. John Keanu Reeves \n 7        NA    343890    262  1984 Armyan Bernstein Armyan Berns… John Shea    \n 8 150000000 490719763 235000  2017 Matt Reeves      Mark Bomback  Andy Serkis  \n 9   6000000  11837928   7400  1995 Rusty Cundieff   Rusty Cundie… Clarence Wil…\n10        NA   4636169   1500  1986 Duncan Gibbins   Bill Phillips Craig Sheffer\n11  50000000  49718611  36000  2004 Garry Marshall   Patrick J. C… Kate Hudson  \n12        NA   3124440  11000  1996 Steven Baigelman Steven Baige… Keanu Reeves \n13        NA  19930973   9300  1992 Arthur Hiller    John Fusco    John Goodman \n14        NA     83488   3900  1997 Tom DiCillo      Tom DiCillo   Matthew Modi…\n15        NA        NA   6400  1995 Theodoros Angel… Theodoros An… Harvey Keitel\n16  32000000  42059111  57000  2010 Nanette Burstein Geoff LaTuli… Drew Barrymo…\n17        NA   3741869   6100  1993 Kirk Wong        Tin Nam Chun  Jackie Chan  \n18        NA    124167   3600  1987 Alan Clarke      Andrea Dunbar Siobhan Finn…\n19  13000000  97837138 255000  2002 Joel Schumacher  Larry Cohen   Colin Farrell\n20   4800000 125479266 124000  2017 Christopher Lan… Scott Lobdell Jessica Rothe\n21        NA     83439   5900  2003 David Mickey Ev… David H. Ste… Erik von Det…\n22  75000000 107752036 163000  1999 David O. Russell John Ridley   George Cloon…\n23   3500000  27912072  54000  1993 Albert Hughes    Allen Hughes  Tyrin Turner \n24   4000000   4257354 100000  1995 Directors        Allison Ande… Tim Roth     \n25  11000000  59520298  19000  2012 Dustin Hoffman   Ronald Harwo… Maggie Smith \n26    100000    515900  19000  2001 Richard Linklat… Stephen Belb… Ethan Hawke  \n27  12000000  57968936  21000  1990 Dwight H. Little Michael Grais Steven Seagal\n28  50000000 152022101  43000  1995 Frank Marshall   Michael Cric… Laura Linney \n29  25000000  11212953  20000  2008 Kimberly Peirce  Mark Richard  Ryan Phillip…\n30  75000000 224012234 282000  1997 Simon West       Scott Rosenb… Nicolas Cage \n# ℹ 470 more rows\n# ℹ 2 more variables: company, country\n\n\n\n\n\nQuestion 11\nThe name and runtime variables are shown below, with the variable types suppressed.\nmovies |&gt;\n  select(name, runtime)\n\n\n\n\n\n# A tibble: 500 × 2\n  name                      runtime\n1 Blue City                 83 mins\n2 Winter Sleep              196    \n3 Rang De Basanti           167    \n4 Pokémon Detective Pikachu 104    \n5 A Bad Moms Christmas      104    \n6 Replicas                  107    \n# ℹ 494 more rows\n\n\n\n\nWhat is the type of the runtime variable?\n\nCharacter\nDouble\nFactor\nInteger\nLogical\n\n\n\n\nQuestion 12\nThe code below summarizes the data in a certain way.\n\nmovies |&gt;\n  summarize(sum(release_country == \"United States\"))\n\n# A tibble: 1 × 1\n  `sum(release_country == \"United States\")`\n                                      &lt;int&gt;\n1                                       435\n\n\nWhich of the following is TRUE about the code and its result? Select all that are true.\n\nEvaluates whether each release_country is equal to \"United States\" or not, which results in a logical variable.\nFilters out rows where release_country is not equal to \"United States\" and counts the remaining rows.\nSums the logical values, where each TRUE is considered a 1 and each FALSE is considered a 0.\nResults in a character vector.\nThe result shows there are 435 movies released in the United States.\nQuestion 13\nSuppose you want a visualization that shows the number of movies in the sample in each genre. Your first attempt is as follows.\n\nggplot(movies, aes(x = genre)) +\n  geom_bar()\n\n\n\n\n\n\n\nA friend of yours says that the visualization is difficult to read and they suggest using the following visualization instead.\n\n\n\n\n\n\n\n\nWhich of the following modifications would your friend have made to your code to create their version? Select all that apply.\n\nCombine movies in genres other than Comedy, Drama, Action, and Horror into a new level called \"Other\".\nReorder the levels in descending order of numbers of observations, except for the \"Other\" level.\nMap genre to the y aesthetic.\nAdd a title, x and y-axis labels, and a caption.\nFilter out all moves in genres other than Comedy, Drama, Action, and Horror before plotting.\nQuestion 14\nWhich of the following is TRUE about the code and its result? Select all that are true.\n\nmovies |&gt;\n  count(rating, genre) |&gt;\n  pivot_wider(names_from = genre, values_from = n, values_fill = 0)\n\n# A tibble: 6 × 6\n  rating    Other Drama Action Comedy Horror\n  &lt;fct&gt;     &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n1 G             5     1      1      1      0\n2 PG           38    13     10     18      0\n3 PG-13        19    25     35     35      0\n4 R            45    50     57     96     21\n5 NC-17         1     2      0      1      0\n6 Not Rated     4    11      4      6      1\n\n\n\nThe code counts how many movies are in each rating and genre combination.\nThe code sorts the results in descending order.\nEach row of the output is a movie.\nThe output shows that there are six distinct ratings in the dataset.\nThe code reduces the number of variables and observations in the movies data frame to six.",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1-batch-B.html#footnotes",
    "href": "exam/midterm-1-batch-B.html#footnotes",
    "title": "Midterm 1 Practice Questions",
    "section": "Footnotes",
    "text": "Footnotes\n\n“Doink doink” is the scene and episode introductory sound on the Law & Order series. If you’ve never heard it, you’re not at any disadvantage for the exam. If you’ve ever heard it, good luck getting it out of your head!↩︎",
    "crumbs": [
      "Exam practice",
      "Midterm 1 Batch B"
    ]
  },
  {
    "objectID": "exam/midterm-1.html",
    "href": "exam/midterm-1.html",
    "title": "Extra Practice for Midterm 1",
    "section": "",
    "text": "Midterm 1 begins Thursday February 20. During our usual class meeting that day, you will sit for the in-class portion of the exam. Then you have from 1:00 PM Thursday Feb 20 to 8:30 AM Monday Feb 24 to complete the take-home portion of the exam. If you seek extra practice to prepare for Midterm 1, here are four things you can do:\n\nCorrect old labs: look back at old labs and fix anything you lost points on;\nFinish old AEs: revisit old AEs and complete the tasks we didn’t get to in lecture (solutions are posted);\nWatch “Code along” videos: search the course schedule for the videos with “Code along” in the title and…code along! This repo has the files;\nWork textbook problems: we have invoked IMS Chs. 1, 4, 5, 6. There are exercises at the end of each chapter, and the back of the book includes solutions for the odd-numbered exercises.\n\nBeyond that, we have compiled below a set of practice problems that you can work. Solutions will be released on Tuesday February 18 at 1:00 PM."
  },
  {
    "objectID": "exam/kahoot-howto.html",
    "href": "exam/kahoot-howto.html",
    "title": "Kahoot How-to",
    "section": "",
    "text": "You should not need to make a Kahoot account to complete any of this, but if you do, I posted my login credentials on slack.\n\nMidterm 1: https://create.kahoot.it/share/sta-199-midterm-1-review/57954244-aef7-48b7-bc98-2f44202340fd\n\n\n1. Click the link and select “Host live”\nClick the link and you’ll see something like this, where you can quickly skim through the questions and answers:\n\nWhen you’re ready to go, click “Host live” and you will arrive at this screen:\n\n\n\n2. Randomizing questions/answers\nGo to the settings:\n\nYou must please randomize both the question and answer order.\n\n\n\n3. Team Mode\nThis is an option that you can choose to use or not depending on attendance and the personality of your section:\n\n\nIf you go this route, it would be good to have the lab helper write down the teams, because it may contain useful information for assigning the project groups. But this is not super important.\n\n\n4. Launch the game and play\nThe music is apparently part of the charm here, so make sure you’ve got that cranked to 11. Otherwise, you’re an MC and the game basically takes care of itself. You can either play it straight and discuss at the end, or you can stop in between questions and discuss the ones that folks found challenging."
  },
  {
    "objectID": "exam/final-review.html",
    "href": "exam/final-review.html",
    "title": "Final review",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "computing/coding-principles-oh.html",
    "href": "computing/coding-principles-oh.html",
    "title": "Intro to Coding Principles",
    "section": "",
    "text": "library(tidyverse)",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#definition",
    "href": "computing/coding-principles-oh.html#definition",
    "title": "Intro to Coding Principles",
    "section": "Definition",
    "text": "Definition\nSo what even is a variable, in the first place? There are many possible definitions:\n\nAnything you assign!\nPractically speaking, variables are a way for you to store data without having to type it out every time.\nThey allow you to manipulate data with the help of pre-built functions (more on that later).\nThey can also be changed - hence the name “variable”.\n\nWhat are some examples of variables?\n\nThe simplest is a single value - like in math. I could say “x = 10”.\nIt might also be a vector - essentially a list of values. For example, I might just store every name in this class in a vector.\nMost frequently, your variables will be your entire data frames.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#assignment-saving",
    "href": "computing/coding-principles-oh.html#assignment-saving",
    "title": "Intro to Coding Principles",
    "section": "Assignment & Saving",
    "text": "Assignment & Saving\nOk, these seem pretty useful - so how do we use them? In math and most programming languages, you use the “=” operator. This is also possible to do in R:\n\nx = 10\nx\n\n[1] 10\n\n\nHowever, in R, we prefer to use the “&lt;-” operator, to avoid confusion between variable assignment and function arguments. Here’s how that looks:\n\ny &lt;- 15\ny\n\n[1] 15\n\n\nSaving Changes\nSuppose you run a function on a variable. By default, R will show you the output of this function, but it will not actually modify your variable. For example, let’s look at the midwest data set:\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow, let’s run a function that “changes” the data frame. We can use select() to look only at the county column:\n\nmidwest |&gt;\n  select(county)\n\n# A tibble: 437 × 1\n   county   \n   &lt;chr&gt;    \n 1 ADAMS    \n 2 ALEXANDER\n 3 BOND     \n 4 BOONE    \n 5 BROWN    \n 6 BUREAU   \n 7 CALHOUN  \n 8 CARROLL  \n 9 CASS     \n10 CHAMPAIGN\n# ℹ 427 more rows\n\n\nCool change! So, just to make sure, let’s look at the midwest data frame one more time.\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow wait a minute - what happened here? I clearly told it to select the county column, and it did! So why is it that, when I went to look at the midwest data frame again, it had all of the columns, not just the one that I selected?\nThe answer is that we never saved midwest back to a variable! By default, R will show the output, but not modify the data frame unless I want it to. Let’s look at a couple ways we can do that:\n\nmidwest &lt;- midwest |&gt;\n  select(county)\n\nmidwest\n\n# A tibble: 437 × 1\n   county   \n   &lt;chr&gt;    \n 1 ADAMS    \n 2 ALEXANDER\n 3 BOND     \n 4 BOONE    \n 5 BROWN    \n 6 BUREAU   \n 7 CALHOUN  \n 8 CARROLL  \n 9 CASS     \n10 CHAMPAIGN\n# ℹ 427 more rows\n\n\nThe first option is to simply overwrite the variable. This is useful if you’re never going to need those data in their original form - it saves you some confusion in that case.\nHowever, what if later on I decide I did need those data after all? Perhaps I wanted population density data. I go to try and find this variable in the midwest data set, because that’s where I know it’s stored…\n\nmidwest |&gt;\n  select(popdensity)\n\nError in `select()`:\n! Can't select columns that don't exist.\n✖ Column `popdensity` doesn't exist.\n\n\n…but the variable is gone! This is a common point of confusion for students in STA 199, so it’s important to understand what you’re doing whenever you modify your data in-place like this - you’re overwriting the existing data.\nWe have a couple of options here. If we were loading these data from a .csv file, we could go back to the top of the document. Or, we could do something more effective: Go to Environment, click the little broom icon, and select “yes”.\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow the second option: let’s try making the modification a little more carefully: saving the data to a new variable.\n\nmidwest_counties &lt;- midwest |&gt;\n  select(county)\n\nmidwest_counties\n\n# A tibble: 437 × 1\n   county   \n   &lt;chr&gt;    \n 1 ADAMS    \n 2 ALEXANDER\n 3 BOND     \n 4 BOONE    \n 5 BROWN    \n 6 BUREAU   \n 7 CALHOUN  \n 8 CARROLL  \n 9 CASS     \n10 CHAMPAIGN\n# ℹ 427 more rows\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow we have two data frames: the new data frame midwest_counties, which contains our modifications from the data pipeline above, and the original data frame midwest, which has not been changed. Both of these are useful operations, and you will undoubtedly use both this semester! However, keep this distinction in mind when you’re mutating your data - don’t remove anything you think you’ll need later.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#displaying-variables",
    "href": "computing/coding-principles-oh.html#displaying-variables",
    "title": "Intro to Coding Principles",
    "section": "Displaying Variables",
    "text": "Displaying Variables\nThe first several weeks of this course are dedicated to data cleaning, manipulation, and transformation. As a result, you will often be asked to display the resulting output of your code (and even if we don’t ask you to do this, it’s often a good idea to do so anyway).\nIn the previous section, I mentioned that by default, R will show the output of code but not modify your variables. The opposite is true if you save your changes: R will not display the output of your code.\n\nx &lt;- 10\n\nThere are many ways to display the output of your code in a quarto document. The first, and most common, is simply to write the name of the variable at the bottom of a code chunk:\n\ny &lt;- 30\ny\n\n[1] 30\n\n\nNote: Unlike many languages, R does not require the use of the print() function: While you can still use it, this is a very common artifact of AI-generated code, so if you use it we’re going to look a lot closer at the rest of your responses.\nThis first approach works well for small examples, but may not work as well for data frames:\n\nmidwest\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nThere are a couple of good workarounds for this! My personal favorite is to use the glimpse() function, which gives you important information on the data frame:\n\nglimpse(midwest)\n\nRows: 437\nColumns: 28\n$ PID                  &lt;int&gt; 561, 562, 563, 564, 565, 566, 567, 568, 569, 570,…\n$ county               &lt;chr&gt; \"ADAMS\", \"ALEXANDER\", \"BOND\", \"BOONE\", \"BROWN\", \"…\n$ state                &lt;chr&gt; \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"…\n$ area                 &lt;dbl&gt; 0.052, 0.014, 0.022, 0.017, 0.018, 0.050, 0.017, …\n$ poptotal             &lt;int&gt; 66090, 10626, 14991, 30806, 5836, 35688, 5322, 16…\n$ popdensity           &lt;dbl&gt; 1270.9615, 759.0000, 681.4091, 1812.1176, 324.222…\n$ popwhite             &lt;int&gt; 63917, 7054, 14477, 29344, 5264, 35157, 5298, 165…\n$ popblack             &lt;int&gt; 1702, 3496, 429, 127, 547, 50, 1, 111, 16, 16559,…\n$ popamerindian        &lt;int&gt; 98, 19, 35, 46, 14, 65, 8, 30, 8, 331, 51, 26, 17…\n$ popasian             &lt;int&gt; 249, 48, 16, 150, 5, 195, 15, 61, 23, 8033, 89, 3…\n$ popother             &lt;int&gt; 124, 9, 34, 1139, 6, 221, 0, 84, 6, 1596, 20, 7, …\n$ percwhite            &lt;dbl&gt; 96.71206, 66.38434, 96.57128, 95.25417, 90.19877,…\n$ percblack            &lt;dbl&gt; 2.57527614, 32.90043290, 2.86171703, 0.41225735, …\n$ percamerindan        &lt;dbl&gt; 0.14828264, 0.17880670, 0.23347342, 0.14932156, 0…\n$ percasian            &lt;dbl&gt; 0.37675897, 0.45172219, 0.10673071, 0.48691813, 0…\n$ percother            &lt;dbl&gt; 0.18762294, 0.08469791, 0.22680275, 3.69733169, 0…\n$ popadults            &lt;int&gt; 43298, 6724, 9669, 19272, 3979, 23444, 3583, 1132…\n$ perchsd              &lt;dbl&gt; 75.10740, 59.72635, 69.33499, 75.47219, 68.86152,…\n$ percollege           &lt;dbl&gt; 19.63139, 11.24331, 17.03382, 17.27895, 14.47600,…\n$ percprof             &lt;dbl&gt; 4.355859, 2.870315, 4.488572, 4.197800, 3.367680,…\n$ poppovertyknown      &lt;int&gt; 63628, 10529, 14235, 30337, 4815, 35107, 5241, 16…\n$ percpovertyknown     &lt;dbl&gt; 96.27478, 99.08714, 94.95697, 98.47757, 82.50514,…\n$ percbelowpoverty     &lt;dbl&gt; 13.151443, 32.244278, 12.068844, 7.209019, 13.520…\n$ percchildbelowpovert &lt;dbl&gt; 18.011717, 45.826514, 14.036061, 11.179536, 13.02…\n$ percadultpoverty     &lt;dbl&gt; 11.009776, 27.385647, 10.852090, 5.536013, 11.143…\n$ percelderlypoverty   &lt;dbl&gt; 12.443812, 25.228976, 12.697410, 6.217047, 19.200…\n$ inmetro              &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0…\n$ category             &lt;chr&gt; \"AAR\", \"LHR\", \"AAR\", \"ALU\", \"AAR\", \"AAR\", \"LAR\", …\n\n\nIn this output, we can see the total number of rows (437 observations) and columns (28 variables), the names of every variable, the variable types, and the first few entries in each column. Note: each column in your data frame is displayed as a row in the glimpse() output. Pay attention to the numbers at the top, and don’t get confused!\nIf you don’t need to display output in your pdf, running view() in the console can actually be very effective! This has the same effect as clicking on the name of a variable in the “Environment” pane in the top-right corner of your R studio. This will open up your data in a new tab, known as the “data viewer”, where you can look through columns, sort by clicking, and even apply filters. Running this in the console means you will be able to view it on your own computer as you work through the problem, but it will not be printed in your final pdf - the best of both worlds.\nIn Lab 1, we used the data viewer to identify outliers in the midwest population density. In the future, you will not be allowed to do this: We expect reproducible code, so you will need to use an assortment of dplyr commands to sort, filter, and select data for display. However, the data viewer can still be useful in a number of situations, so long as you’re careful about it!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#variable-examples",
    "href": "computing/coding-principles-oh.html#variable-examples",
    "title": "Intro to Coding Principles",
    "section": "Variable Examples",
    "text": "Variable Examples\n\nx &lt;- 10\nx\n\n[1] 10\n\ny &lt;- c(3, 5)\ny\n\n[1] 3 5\n\nz &lt;- midwest\nz\n\n# A tibble: 437 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 427 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#examples",
    "href": "computing/coding-principles-oh.html#examples",
    "title": "Intro to Coding Principles",
    "section": "Examples",
    "text": "Examples\nEvery column in a data frame will have a particular data type - sort of a way that R recognizes, classifies, and interacts with the data. Let’s look at an example, using the convenient glimpse function:\n\nglimpse(midwest)\n\nRows: 437\nColumns: 28\n$ PID                  &lt;int&gt; 561, 562, 563, 564, 565, 566, 567, 568, 569, 570,…\n$ county               &lt;chr&gt; \"ADAMS\", \"ALEXANDER\", \"BOND\", \"BOONE\", \"BROWN\", \"…\n$ state                &lt;chr&gt; \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"…\n$ area                 &lt;dbl&gt; 0.052, 0.014, 0.022, 0.017, 0.018, 0.050, 0.017, …\n$ poptotal             &lt;int&gt; 66090, 10626, 14991, 30806, 5836, 35688, 5322, 16…\n$ popdensity           &lt;dbl&gt; 1270.9615, 759.0000, 681.4091, 1812.1176, 324.222…\n$ popwhite             &lt;int&gt; 63917, 7054, 14477, 29344, 5264, 35157, 5298, 165…\n$ popblack             &lt;int&gt; 1702, 3496, 429, 127, 547, 50, 1, 111, 16, 16559,…\n$ popamerindian        &lt;int&gt; 98, 19, 35, 46, 14, 65, 8, 30, 8, 331, 51, 26, 17…\n$ popasian             &lt;int&gt; 249, 48, 16, 150, 5, 195, 15, 61, 23, 8033, 89, 3…\n$ popother             &lt;int&gt; 124, 9, 34, 1139, 6, 221, 0, 84, 6, 1596, 20, 7, …\n$ percwhite            &lt;dbl&gt; 96.71206, 66.38434, 96.57128, 95.25417, 90.19877,…\n$ percblack            &lt;dbl&gt; 2.57527614, 32.90043290, 2.86171703, 0.41225735, …\n$ percamerindan        &lt;dbl&gt; 0.14828264, 0.17880670, 0.23347342, 0.14932156, 0…\n$ percasian            &lt;dbl&gt; 0.37675897, 0.45172219, 0.10673071, 0.48691813, 0…\n$ percother            &lt;dbl&gt; 0.18762294, 0.08469791, 0.22680275, 3.69733169, 0…\n$ popadults            &lt;int&gt; 43298, 6724, 9669, 19272, 3979, 23444, 3583, 1132…\n$ perchsd              &lt;dbl&gt; 75.10740, 59.72635, 69.33499, 75.47219, 68.86152,…\n$ percollege           &lt;dbl&gt; 19.63139, 11.24331, 17.03382, 17.27895, 14.47600,…\n$ percprof             &lt;dbl&gt; 4.355859, 2.870315, 4.488572, 4.197800, 3.367680,…\n$ poppovertyknown      &lt;int&gt; 63628, 10529, 14235, 30337, 4815, 35107, 5241, 16…\n$ percpovertyknown     &lt;dbl&gt; 96.27478, 99.08714, 94.95697, 98.47757, 82.50514,…\n$ percbelowpoverty     &lt;dbl&gt; 13.151443, 32.244278, 12.068844, 7.209019, 13.520…\n$ percchildbelowpovert &lt;dbl&gt; 18.011717, 45.826514, 14.036061, 11.179536, 13.02…\n$ percadultpoverty     &lt;dbl&gt; 11.009776, 27.385647, 10.852090, 5.536013, 11.143…\n$ percelderlypoverty   &lt;dbl&gt; 12.443812, 25.228976, 12.697410, 6.217047, 19.200…\n$ inmetro              &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0…\n$ category             &lt;chr&gt; \"AAR\", \"LHR\", \"AAR\", \"ALU\", \"AAR\", \"AAR\", \"LAR\", …\n\n\nNext to the data, we can see various designations - &lt;int&gt;, &lt;dbl&gt;, &lt;chr&gt;, etc. These are data types. But what exactly is the difference?\nDouble/Numeric\nThe dbl data type, which is the default implementation of the numeric class, stands for double - meaning “double-precision floating-point format”. It’s pretty clear that double is an easier word to remember! This allows you to store numbers with a lot of decimal points (but not infinite!). For example, let’s look at \\(\\pi\\), which is built in as pi in R:\n\npi\n\n[1] 3.141593\n\ntypeof(pi)\n\n[1] \"double\"\n\n\nHere, we use the typeof() function to determine what data type R is using to store our variables. In this case, we can see that R stores pi as a double variable, which is the default for all numeric variables. In general, whenever you work with numbers, they will be doubles, and for purposes of STA 199 there is no issue with this.\nInteger\nThe int data type means integer - as in, the mathematical concept of an integer. All data represented as integers will be whole numbers. This data type is not capable of storing decimal places, so if you try to do decimal operations with it, R will implicitly cast it to another data type. Implicitly means that it does this without us telling it to. Let’s take a look at a couple of examples:\n\na &lt;- 3\ntypeof(a)\n\n[1] \"double\"\n\n\nBy default, R will treat all numbers as the numeric class. If you want to explicitly tell R that your number is an integer, follow the number with “L”:\n\na &lt;- 3L\ntypeof(a)\n\n[1] \"integer\"\n\n\nNow, let’s say we want to divide this number by 2:\n\nb &lt;- a / 2\ntypeof(b)\n\n[1] \"double\"\n\n\nSince 3 is not divisible by 2, the output is a decimal. However, since we have performed a decimal operation, rather than trying to guess whether to round up or down, R simply implicitly casts it back to numeric.\nLogical/Boolean\nWhile there isn’t an example in this data frame, there is a data type called logical - which represents true/false.\n\nc &lt;- TRUE\ntypeof(c)\n\n[1] \"logical\"\n\n\nIn R, you need to type out TRUE/FALSE in all caps for it to be recognized. Under the hood, R stores these values as “FALSE = 0” and “TRUE = 1”, which means that if you want to find the percentage of TRUE in your data, you can just take the average:\n\nd &lt;- c(TRUE, FALSE, TRUE)\nmean(d)\n\n[1] 0.6666667\n\n\nCharacter/String\nThe character data type represents all characters and strings in R. Unlike some languages, R does not differentiate between these. In general, strings are used to represent words and categorical data, for example:\n\nplace &lt;- \"Durham, NC\"\ntypeof(place)\n\n[1] \"character\"\n\n\nIn order for R to recognize a variable as a string, it needs to be wrapped in quotation marks. Single or double quotation marks are acceptable:\n\nnew_place &lt;- 'Cincinnati'\ntypeof(new_place)\n\n[1] \"character\"\n\n\nHowever, missing quotation marks will generate an error:\n\nanother_place &lt;- Timbuktu\n\nError in eval(expr, envir, enclos): object 'Timbuktu' not found\n\n\nIn this case, since Timbuktu is not wrapped in quotation marks, R is looking for a pre-existing object - a variable or a function - called Timbuktu. Since no such object exists, R throws an error, and will refuse to compile your document (unless you force it to).\nThere is another important point of caution here. Sometimes, when you load in a data frame, there will be columns that should be represented as numbers, but are accidentally represented as strings. If you’re not careful, this can have consequences. For example, consider the following:\n\n0 == 00\n\n[1] TRUE\n\n\"0\" == \"00\"\n\n[1] FALSE\n\n\nIn R, the numbers 0 and 00 represent the same thing! However, when they are strings, they do not. R treats numbers differently than it does strings, so it’s important to pay attention to which one you are actually implementing. You might also run into issues with some of your operations - for example, if you try to take the average of a column of strings, R has no idea what to do and will throw an error.\nNote: pay attention to the usage of two equal signs here, rather than just one. Why did we do this? (More on this shortly.)",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#casting",
    "href": "computing/coding-principles-oh.html#casting",
    "title": "Intro to Coding Principles",
    "section": "Casting",
    "text": "Casting\nSo what is the solution to this problem? The answer is called casting, which means changing the data type. You do this using the as.character(), as.numeric(), and as.logical() commands. Let’s look at an example:\n\ne &lt;- \"00\"\ntypeof(e)\n\n[1] \"character\"\n\ne\n\n[1] \"00\"\n\ne &lt;- as.numeric(e)\ntypeof(e)\n\n[1] \"double\"\n\ne\n\n[1] 0\n\ne &lt;- as.logical(e)\ntypeof(e)\n\n[1] \"logical\"\n\ne\n\n[1] FALSE\n\ne &lt;- as.character(e)\ntypeof(e)\n\n[1] \"character\"\n\ne\n\n[1] \"FALSE\"\n\ne &lt;- as.numeric(e) # What happened?\n\nWarning: NAs introduced by coercion\n\ne\n\n[1] NA\n\n\nBe mindful with your casting - you can lose information along the way!\nNote: NA is a specific type in R. It essentially means “nothing” or “there was an error”. You cannot use == to check whether a value is NA. Instead, you must use is.na(). Similarly, you may come across NULL, which essentially means “this memory has not been declared”. To check for NULL, you must use is.null().",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#equals",
    "href": "computing/coding-principles-oh.html#equals",
    "title": "Intro to Coding Principles",
    "section": "Equals",
    "text": "Equals\nThe first Boolean operator is “equals”. This is a place where it is easy to get confused. We use the single equals sign, =, to denote assignment - essentially, telling R “this thing takes this value.” We use the double equals sign, ==, to denote comparison - essentially, asking R “are these two values equal?” It is important to keep these two things distinct - if you want to check equality, or filter for a specific value, you always need to use the double equals sign!\n\nmidwest |&gt;\n  filter(county = \"Cook\")\n\nError in `filter()`:\n! We detected a named input.\nℹ This usually means that you've used `=` instead of `==`.\nℹ Did you mean `county == \"Cook\"`?\n\n\nHere’s an example of where a single equals sign is incorrect, and R returns an error. Fortunately, it has a very helpful suggestion in the error message! Let’s replace that with the double equals:\n\nmidwest |&gt;\n  filter(county == \"Cook\")\n\n# A tibble: 0 × 28\n# ℹ 28 variables: PID &lt;int&gt;, county &lt;chr&gt;, state &lt;chr&gt;, area &lt;dbl&gt;,\n#   poptotal &lt;int&gt;, popdensity &lt;dbl&gt;, popwhite &lt;int&gt;, popblack &lt;int&gt;,\n#   popamerindian &lt;int&gt;, popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;, …\n\n\nNow there’s no error message, but we also didn’t return any values. Why did this happen? When I use ==, I am checking whether these two strings are exactly equivalent, and that includes being case sensitive. If I view the data in the data frame, I see that all of the county names are actually in all caps. I can fix the string in my example…\n\nmidwest |&gt;\n  filter(county == \"COOK\")\n\n# A tibble: 1 × 28\n    PID county state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   576 COOK   IL    0.058  5105067     88018.  3204947  1317147         10289\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\n…and finally find Chicago!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#and",
    "href": "computing/coding-principles-oh.html#and",
    "title": "Intro to Coding Principles",
    "section": "And",
    "text": "And\nThe second Boolean operator is “and”. We use this when we want multiple conditions to be true. In R, to denote and, we use the single ampersand & (in some other languages, you use a double ampersand). When R sees this, it checks both statements, and only returns TRUE if both statements are true. Let’s look at an example, again using filter():\n\nmidwest |&gt;\n  filter(state == \"IL\")\n\n# A tibble: 102 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   561 ADAMS   IL    0.052    66090      1271.    63917     1702            98\n 2   562 ALEXAN… IL    0.014    10626       759      7054     3496            19\n 3   563 BOND    IL    0.022    14991       681.    14477      429            35\n 4   564 BOONE   IL    0.017    30806      1812.    29344      127            46\n 5   565 BROWN   IL    0.018     5836       324.     5264      547            14\n 6   566 BUREAU  IL    0.05     35688       714.    35157       50            65\n 7   567 CALHOUN IL    0.017     5322       313.     5298        1             8\n 8   568 CARROLL IL    0.027    16805       622.    16519      111            30\n 9   569 CASS    IL    0.024    13437       560.    13384       16             8\n10   570 CHAMPA… IL    0.058   173025      2983.   146506    16559           331\n# ℹ 92 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nUsing our == operator, we can find all of the counties in Illinois. Now, let’s find only the ones with a population density over 30,000:\n\nmidwest |&gt;\n  filter(state == \"IL\" & popdensity &gt;= 30000)\n\n# A tibble: 2 × 28\n    PID county  state  area poptotal popdensity popwhite popblack popamerindian\n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n1   576 COOK    IL    0.058  5105067     88018.  3204947  1317147         10289\n2   582 DU PAGE IL    0.02    781666     39083.   714905    15462           962\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow, the filter() statement is returning all of the rows from this data frame where BOTH the state is “IL” AND the population density is \\(\\geq\\) 30,000.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#or",
    "href": "computing/coding-principles-oh.html#or",
    "title": "Intro to Coding Principles",
    "section": "Or",
    "text": "Or\nThe third Boolean operator is “or”. We use this when we want at least one condition to be true. In R, to denote or, we use the vertical line | (again, in some other languages, you use a double line). When R sees this, it checks both statements, and returns TRUE if either (or both) of the statements are true. Let’s go back to our example:\n\nmidwest |&gt;\n  filter(state == \"IL\" | popdensity &gt;= 30000) |&gt;\n  arrange(desc(popdensity))\n\n# A tibble: 107 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1   576 COOK    IL    0.058  5105067     88018.  3204947  1317147         10289\n 2  3021 MILWAU… WI    0.015   959275     63952.   718918   195470          6994\n 3  1278 WAYNE   MI    0.035  2111687     60334.  1212007   849109          8048\n 4  2026 CUYAHO… OH    0.026  1412140     54313.  1025756   350185          2533\n 5   582 DU PAGE IL    0.02    781666     39083.   714905    15462           962\n 6   711 MARION  IN    0.023   797159     34659.   615039   169654          1698\n 7  2039 HAMILT… OH    0.025   866228     34649.   672972   181145          1204\n 8   609 LAKE    IL    0.028   516418     18444.   450666    34771          1198\n 9   605 KANE    IL    0.029   317471     10947.   269675    19006           620\n10   661 Winneb… IL    0.03    252913      8430.   222439    23256           651\n# ℹ 97 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nNow, R returns all of the rows that are in Illinois, as well as all of the rows that are not in Illinois, but have a population density of at least 30,000.\nNote: Keep in mind that | is not exclusive. That means that | will return true if only one condition is true, but it will also return true if both conditions are true. If you want exactly one condition to be true, look up the operator XOR.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#not",
    "href": "computing/coding-principles-oh.html#not",
    "title": "Intro to Coding Principles",
    "section": "Not",
    "text": "Not\nThe fourth Boolean operator is “not”. We use this when we want to exclude certain values from the data or prevent something from happening. In R, to denote not, we use the exclamation mark !. Specifically, you place the !, also known as a bang sign, in front of the statement that you want to be false. The most frequent use of this is to say “not equals”, which is denoted != (note that it is only one equals sign now, not two!) Let’s look at an example:\n\nmidwest |&gt;\n  filter(state != \"IL\") |&gt;\n  arrange(desc(popdensity))\n\n# A tibble: 335 × 28\n     PID county  state  area poptotal popdensity popwhite popblack popamerindian\n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;         &lt;int&gt;\n 1  3021 MILWAU… WI    0.015   959275     63952.   718918   195470          6994\n 2  1278 WAYNE   MI    0.035  2111687     60334.  1212007   849109          8048\n 3  2026 CUYAHO… OH    0.026  1412140     54313.  1025756   350185          2533\n 4   711 MARION  IN    0.023   797159     34659.   615039   169654          1698\n 5  2039 HAMILT… OH    0.025   866228     34649.   672972   181145          1204\n 6  2033 FRANKL… OH    0.034   961437     28278.   783714   152840          2056\n 7  1246 MACOMB  MI    0.028   717400     25621.   693686    10400          2639\n 8  2056 LUCAS   OH    0.021   462361     22017.   380155    68456          1164\n 9  2085 SUMMIT  OH    0.024   514990     21458.   446902    61185          1065\n10  2065 MONTGO… OH    0.027   573809     21252.   463551   101817          1065\n# ℹ 325 more rows\n# ℹ 19 more variables: popasian &lt;int&gt;, popother &lt;int&gt;, percwhite &lt;dbl&gt;,\n#   percblack &lt;dbl&gt;, percamerindan &lt;dbl&gt;, percasian &lt;dbl&gt;, percother &lt;dbl&gt;,\n#   popadults &lt;int&gt;, perchsd &lt;dbl&gt;, percollege &lt;dbl&gt;, percprof &lt;dbl&gt;,\n#   poppovertyknown &lt;int&gt;, percpovertyknown &lt;dbl&gt;, percbelowpoverty &lt;dbl&gt;,\n#   percchildbelowpovert &lt;dbl&gt;, percadultpoverty &lt;dbl&gt;,\n#   percelderlypoverty &lt;dbl&gt;, inmetro &lt;int&gt;, category &lt;chr&gt;\n\n\nIn these data, all rows from Illinois have been removed. You can check this by commenting out the filter line, and observing the difference, or just noting that Cook County, IL (home of Chicago, the densest city in the midwest) is absent!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#combining-boolean-operators",
    "href": "computing/coding-principles-oh.html#combining-boolean-operators",
    "title": "Intro to Coding Principles",
    "section": "Combining Boolean Operators",
    "text": "Combining Boolean Operators\nYou can also combine multiple Boolean operators in more complex logical statements. We will not look at any examples here, because they can get very confusing, very quickly (and are generally unnecessary for this course). However, if you do want to combine Boolean operators, here are some things to keep in mind:\n\nParentheses: Just like in math, any statements that you put in parentheses will execute first. If I say “A and B or C”, it’s unclear exactly what I mean. If I would accept either (A and B) or (A and C), I would write A & (B | C), meaning I need at least one of B or C to be true. If I would accept either (A and B) or C, I would write (A & B) | C, meaning I need either (A and B) or C to be true.\nOrder of operations: Pay attention to the order in which your statements evaluate! If I write !(A & B), that means I need at least one of A or B to be false. If I write !A & !B, that means I need both A and B to be false. This can get confusing, so it’s best to write out your logic fully and work through a few examples by hand (or avoid layering these operators entirely).",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#definition-1",
    "href": "computing/coding-principles-oh.html#definition-1",
    "title": "Intro to Coding Principles",
    "section": "Definition",
    "text": "Definition\nWhat is a function? A function is, essentially, a block of code that does something (so that you don’t have to implement it!). A function will always have a name, followed by open and closed parentheses (). Some functions do not take arguments. However, if they do, these arguments will go within the parentheses. Once R sees an opening parenthesis, it will not execute the code until it sees a closing parenthesis. Beware - when you start layering functions, such as using aes() inside of ggplot(), you need to pay attention to what your parentheses are around and make sure that they all close!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#arguments",
    "href": "computing/coding-principles-oh.html#arguments",
    "title": "Intro to Coding Principles",
    "section": "Arguments",
    "text": "Arguments\nArguments are the commands that you give to a function that tell it what to do. Most functions take at least one argument, and some can take arbitrarily many. Functions have a default order for (some of) their arguments. If you know this order, you do not have to explicitly name the arguments. If not, you must list them explicitly. Here are two examples:\n\n# Named Arguments\nggplot(\n  data = midwest, \n  mapping = aes(x = poptotal, y = popdensity, color = percwhite)\n  ) +\n  geom_point()\n\n\n\n\n\n\n# Unnamed Arguments\nggplot(\n  midwest, \n  aes(poptotal, popdensity, percwhite)\n  ) +\n  geom_point()\n\n\n\n\n\n\n\nIn ggplot, the first two arguments are always data and mapping, so it is common to drop these. However, in the second plot here, we lost our fill aesthetic. Why?\nWhen we look at the aes() documentation, we see that x is the first named argument and y is the second, but after that there are no named arguments. That means, while you can add more aesthetics, you must name them explicitly, since they do not appear by default.\nArguments Requiring Quotes\nIn R, you will sometimes need to pass a function an argument that is from a list of options. In this case, you need to wrap it in quotation marks (can anyone tell me why?) Let’s take a look at the following function, and try to identify arguments with and without quotes:\n\nggplot(midwest, aes(\n                    x = state,\n                    y = poptotal,\n                    fill = county\n                  )) +\n  geom_col(position = \"stack\") +\n  theme(legend.position = \"none\") # STA 199 students are not allowed to do this\n\n\n\n\n\n\n\nIn this case, we can pass in x = state, y = poptotal, and fill = county without quotation marks, because R knows we are referencing columns in a data frame, which are actual objects in our environment. However, we pass in position = \"stack\" with quotation marks. To see why, let’s look at what happens when we drop our quotes:\n\nggplot(midwest, aes(\n                    x = state,\n                    y = poptotal,\n                    fill = county\n                  )) +\n  geom_col(position = stack) +\n  theme(legend.position = \"none\") # STA 199 students are not allowed to do this\n\nError in `check_subclass()`:\n! `x` must be either a string or a &lt;Position&gt; object, not a function.\n\n\nThe argument for position is looking for either a string or a &lt;Position&gt; object. Since we don’t know what &lt;Position&gt; objects are, it’s clear that we should be giving it a string. R needs to find this argument in a list: we could say position = \"dodge\" or position = \"fill\", so long as we include quotation marks, since those are on the list of accepted arguments.\n\nggplot(midwest, aes(\n                    x = state,\n                    y = poptotal,\n                    fill = county\n                  )) +\n  geom_col(position = \"fill\") +\n  theme(legend.position = \"none\") # STA 199 students are not allowed to do this\n\n\n\n\n\n\n\nPipe Operator\nMany times in this class, you will see the symbol |&gt; used. This is known as the pipe operator, and it allows us to have a so-called “data pipeline”. This helps make code a lot more readable! Let’s take a look at why:\n\nhead(arrange(mutate(select(filter(midwest, state == \"IL\"), county, state, area, poptotal, inmetro), inmetro = as.logical(inmetro)), desc(poptotal)), 10)\n\n# A tibble: 10 × 5\n   county    state  area poptotal inmetro\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt; &lt;lgl&gt;  \n 1 COOK      IL    0.058  5105067 TRUE   \n 2 DU PAGE   IL    0.02    781666 TRUE   \n 3 LAKE      IL    0.028   516418 TRUE   \n 4 WILL      IL    0.05    357313 TRUE   \n 5 KANE      IL    0.029   317471 TRUE   \n 6 ST CLAIR  IL    0.04    262852 TRUE   \n 7 Winnebago IL    0.03    252913 TRUE   \n 8 MADISON   IL    0.045   249238 TRUE   \n 9 MCHENRY   IL    0.036   183241 TRUE   \n10 PEORIA    IL    0.038   182827 TRUE   \n\n\nTechnically, we can write our code in this manner! Strictly speaking, under the hood, the pipe operator is reconstructing your code into this format. However, this is nearly impossible to read (I’ve been coding in R for years, and I still ran into multiple errors trying to write this).\nWith the pipe operator, we can skip this and execute each function on its own line. Every pipeline starts with a data frame or equivalent object, so that R knows what we are operating on. By default, the pipe operator “pipes” your data into the first argument of a function - which, in the tidyverse, is almost always the “data” argument. This lets us write our data in a much neater pipeline, where you can see step-by-step what is happening to the data:\n\nmidwest |&gt;   # Operate on the midwest data frame\n  filter(state == \"IL\") |&gt;   # Filter for only the counties in Illinois\n  select(county, state, area, poptotal, inmetro) |&gt;   # Select only these five columns, and drop all others\n  mutate(inmetro = as.logical(inmetro)) |&gt;   # Cast inmetro to a logical type\n  arrange(desc(poptotal)) |&gt;   # Arrange the data frame by poptotal in descending order\n  head(10)   # Select the top 10 rows\n\n# A tibble: 10 × 5\n   county    state  area poptotal inmetro\n   &lt;chr&gt;     &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt; &lt;lgl&gt;  \n 1 COOK      IL    0.058  5105067 TRUE   \n 2 DU PAGE   IL    0.02    781666 TRUE   \n 3 LAKE      IL    0.028   516418 TRUE   \n 4 WILL      IL    0.05    357313 TRUE   \n 5 KANE      IL    0.029   317471 TRUE   \n 6 ST CLAIR  IL    0.04    262852 TRUE   \n 7 Winnebago IL    0.03    252913 TRUE   \n 8 MADISON   IL    0.045   249238 TRUE   \n 9 MCHENRY   IL    0.036   183241 TRUE   \n10 PEORIA    IL    0.038   182827 TRUE   \n\n\nMuch better, right? Remember, whenever you’re using the pipe operator (or the +, in ggplot, which is different!), you should start a new line of code. As long as you have a pipe operator, R is expecting another function, so it won’t execute only part of your code.\nNote: In this class, we focus on the base R pipe, which is denoted by |&gt;. However, when you’re debugging on the internet, you may come across the symbol %&gt;%, which is the magrittr pipe. There are some technical differences in these that generally go beyond the scope of this class, but they essentially serve the same purpose. Don’t be scared by the magrittr pipe when you’re doing your debugging!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#definition-2",
    "href": "computing/coding-principles-oh.html#definition-2",
    "title": "Intro to Coding Principles",
    "section": "Definition",
    "text": "Definition\nEvery time we start programming in this class, we run library(tidyverse). Why do we do this?\nLibraries are collections of functions, and running them means that we are loading those functions into our current R session. If you try to open up a fresh R session and run ggplot() immediately, you will get an error, because that function is not found. However, with the library, you can load in everything that you need, all at once. The tidyverse is especially cool, because it is actually a collection of libraries - libraryception!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#environment",
    "href": "computing/coding-principles-oh.html#environment",
    "title": "Intro to Coding Principles",
    "section": "Environment",
    "text": "Environment\nYour environment in R is basically the current instance of your program. When you run a library, it is part of your environment until you restart R, meaning you can call any of its functions at any time. When you create a variable, it is part of your environment until you restart R, meaning you can reference those variables at any time.\nWhen you use the containers, they do not regularly restart R. This can be a problem sometimes, when old code gets tangled up with new code! It is my personal recommendation that you (at a minimum) restart R and clear your environment every time you start a new project (AE, lab, etc). You can restart R by going to Session -&gt; Restart R, and clear your environment by going to the environment pane and clicking the broom icon.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#rendering-quarto",
    "href": "computing/coding-principles-oh.html#rendering-quarto",
    "title": "Intro to Coding Principles",
    "section": "Rendering Quarto",
    "text": "Rendering Quarto\nWhen you click the “Render” button for your .qmd file, what happens? R executes a program, called a “compiler”, that runs your entire .qmd file in a new environment. In other words, if you have loaded a library, or edited a variable, or done any number of things in the console (or even later in the .qmd file) without saving them in the .qmd file, and then you try to render, you will get an error because that function/variable/etc has not been defined in the rendering environment. This forces you to write reproducible code, and it’s the first thing to think about when you run into errors while rendering!\nAside: LaTeX\nWhen you click “Render”, if you are rendering to a .pdf file, R uses a tool called LaTeX to pull all of your code together. LaTeX is a very cool program, which allows you to input all sorts of things: Greek letters, formatted exponents, etc. If you want to insert such things, place code between dollar signs: For example, to write the Greek letter \\(\\gamma\\), you would input $\\gamma$ in your quarto document. You can google LaTeX for more information!",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#documentation",
    "href": "computing/coding-principles-oh.html#documentation",
    "title": "Intro to Coding Principles",
    "section": "Documentation",
    "text": "Documentation\nUnless you have a function and its usage entirely memorized, you are going to be reading documentation. Documentation is useful, but it is dense, and can be hard to parse. Let’s look at an example of how we can look through documentation.\n\n?if_else\n\n?geom_point",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#errors",
    "href": "computing/coding-principles-oh.html#errors",
    "title": "Intro to Coding Principles",
    "section": "Errors",
    "text": "Errors\nUnless you are the Roman God of Programming (and even then, I’m not too sure), you are going to encounter errors in your programming. These are completely natural, and nothing to be ashamed of - sometimes I write partial code, just to see where it will catch errors. However, some error messages are easier to understand than others. Let’s look through a couple of examples of common errors, and what I would do to interpret and fix them.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#example-1",
    "href": "computing/coding-principles-oh.html#example-1",
    "title": "Intro to Coding Principles",
    "section": "Example 1",
    "text": "Example 1\n\nmidwest |&gt;\n  sumarize(avg_pop_dens = mean(popdensity))\n\nError in sumarize(midwest, avg_pop_dens = mean(popdensity)): could not find function \"sumarize\"\n\n\n\n\n\n\n\n\nWhat’s wrong with this code?\n\n\n\n\n\nIn this case, we just have a simple spelling error! It may seem trivial, but this will constitute at least half of the errors that you have. Make this the first thing you check - you will never meet a programmer who doesn’t have a story of the time they spent at least 30 minutes debugging a function, just to realize it was a typo all along.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#example-2",
    "href": "computing/coding-principles-oh.html#example-2",
    "title": "Intro to Coding Principles",
    "section": "Example 2",
    "text": "Example 2\n\nggplot(midwest, aes(x = poptotal, y = popdensity,)) |&gt;\n  geom_point() |&gt;\n  labs(x = \"Total Population\", y = \"Population Density\")\n\nError in `geom_point()`:\n! `mapping` must be created by `aes()`.\nℹ Did you use `%&gt;%` or `|&gt;` instead of `+`?\n\n\n\n\n\n\n\n\nWhat’s wrong with this code?\n\n\n\n\n\nThis one should be pretty obvious, since it’s a common enough error that R gives an extremely helpful error message. When you’re building a ggplot object, you use + rather than |&gt; to add additional lines!\nThere’s a second error here, that R knew well enough to handle here, but which could become an issue in more complicated code chunks. Did anyone spot it?",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  },
  {
    "objectID": "computing/coding-principles-oh.html#example-3",
    "href": "computing/coding-principles-oh.html#example-3",
    "title": "Intro to Coding Principles",
    "section": "Example 3",
    "text": "Example 3\n\nggplot(midwest, aes(x = state, y = poptotal, fill = state)) +\n  geom_bar() +\n  theme_bw() +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\", scale = 1e-6)) +\n  labs(\n    x = \"State\",\n    y = \"Total Population\\n(Millions)\",\n    title = \"Total Population by State\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    panel.grid.major.x = element_blank(),\n    legend.position = \"none\"\n  ) +\n  scale_fill_viridis_d()\n\nError in `geom_bar()`:\n! Problem while computing stat.\nℹ Error occurred in the 1st layer.\nCaused by error in `setup_params()`:\n! `stat_count()` must only have an x or y aesthetic.\n\n\nThere’s a lot going on here, so it might not be obvious at first where the issue is! The error has something to do with the function stat_count(), but that’s not a function we used (explicitly) anywhere in this code. This is why you should iterate on your code, running it intermittently, so that you can catch errors when they pop up.\nMy first thought would be to run rlang::last_trace(), as suggested by the error message. This is sometimes helpful - it can reference certain functions and even lines of code, especially when you’re executing something more complex. Frequently, though, it’s too complicated to understand. In this case, I would certainly say I can’t make any sense of that.\nMy next thought is to google the error message. It can be a little tricky to know what to google from the error message. You want to look for anything that seems general enough that other people might have asked, but specific enough that it will apply to your situation. Let’s go line by line:\n\n“Error in geom_bar()”: Probably too general to bother googling. There are a lot of possible errors with geom_bar(), and it would take too long to look through them all to get to your specific problem!\n“Problem while computing stat.”: This is more helpful, because it gives a little more direction as to the source of the error, but it is still too general - what stat are we computing? What problem?\n“Error occured in the 1st layer”: This can be helpful for you, if you know the order of ggplot layers. However, it is probably not helpful to google, since people could have built their layers in a different order before encountering this error.\n“Caused by error in setup_params()”: Closer! This is getting more and more specific, and this might be good enough to google. However, it still doesn’t say what the error is, it just says that there was one.\n“stat_count() must only have an x or y aesthetic”: Bingo! This is the one we’re looking for, which tells us exactly what the issue is. Now, it may be possible to interpret manually, but let’s say you can’t. Here’s where we go now:\n\nI would copy-paste the entire final line into google. You don’t want to copy-paste the full error message, since that’s probably too specific, and you might not find any results. At the same time, you don’t want to copy-paste only a couple of words, since that might not be specific enough, and you could be stuck looking through a lot of links. If you google just that line, you are likely to find someone on stack exchange who has posted a question with this exact (or almost this exact) error message. You can also help your google out by throwing in some relevant key words:\n\nggplot\nR\nerror\n\nTake a couple minutes to google this, and see if you can figure out what’s wrong with the code! Then, remember to cite the source where you found this answer! In general, it’s okay to google your error messages for help, but not to use someone else’s solution without credit.\n\n\n\n\n\n\nWhat’s wrong with this code?\n\n\n\n\n\nI looked at https://stackoverflow.com/questions/61068031/error-stat-count-can-only-have-an-x-or-y-aesthetic for my answer. There’s a few different suggestions on this page, all of which could be useful! This page definitely suggests to me that the issue with my plot is in the geom_bar() line - which makes sense, since this is layer 1 of the plot. While they have a couple simple fixes, here’s the actual error I wrote: geom_bar() is expecting only one variable. If you want two variables, like this, you should use geom_col() instead.",
    "crumbs": [
      "Computing",
      "Dav's coding review"
    ]
  }
]